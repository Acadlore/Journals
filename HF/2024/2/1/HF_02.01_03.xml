<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">HF</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Healthcraft Frontiers</journal-title>
        <abbrev-journal-title abbrev-type="issn">Healthcraft. Front.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">HF</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">3005-799X</issn>
      <issn publication-format="print">3005-7981</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-uBxDOdz7GrO3cFEPOd6A9EDbFxuyFpJB</article-id>
      <article-id pub-id-type="doi">10.56578/hf020103</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Pneumonia Detection Technique Empowered with Transfer Learning Approach</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-3860-1345</contrib-id>
          <name>
            <surname>Baig</surname>
            <given-names>Muhammad Daniyal</given-names>
          </name>
          <email>s4326957@glos.ac.uk</email>
          <xref ref-type="aff" rid="aff_1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3026-3728</contrib-id>
          <name>
            <surname>Haq</surname>
            <given-names>Hafiz Burhan Ul</given-names>
          </name>
          <email>burhanhashmi64@lgu.edu.pk</email>
          <xref ref-type="aff" rid="aff_2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1782-4658</contrib-id>
          <name>
            <surname>Irshad</surname>
            <given-names>Muhammad Nauman</given-names>
          </name>
          <email>nauman@csu.edu.cn</email>
          <xref ref-type="aff" rid="aff_3">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2734-1844</contrib-id>
          <name>
            <surname>Akram</surname>
            <given-names>Waseem</given-names>
          </name>
          <email>D11210217@yuntech.edu.tw</email>
          <xref ref-type="aff" rid="aff_4">4</xref>
        </contrib>
        <aff id="aff_1">Department of Cyber and Applied Computing, University of Gloucestershire, GL50 2RH Gloucestershire, United Kingdom</aff>
        <aff id="aff_2">Department of Computer Sciences, Faculty of Information Technology, Lahore Garrison University, 54000 Lahore, Pakistan</aff>
        <aff id="aff_3">School of Computer Science and Engineering Central South University, 410000 Changsha, China</aff>
        <aff id="aff_4">Graduate School of Engineering Science and Technology, National Yunlin University of Science and Technology, 640 Douliu, Taiwan</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>14</day>
        <month>03</month>
        <year>2024</year>
      </pub-date>
      <volume>2</volume>
      <issue>1</issue>
      <fpage>20</fpage>
      <lpage>33</lpage>
      <page-range>20-33</page-range>
      <history>
        <date date-type="received">
          <day>15</day>
          <month>12</month>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <day>05</day>
          <month>03</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Â©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract>Detection of normal findings or pneumonia using modern technology has a lot of significance in medical analysis and artificial intelligence. Still, more specifically, its importance increases in deep learning. Deep learning is extensively applied in the realm of medicine and disease classification. Early diagnosis of pneumonia is essential so it can be efficiently treated with the type of antibiotics. Bacterium and viruses are the population's first cause of pneumonia and death. Bacteria and viruses are part of mammalian pathogens and the most invasive type of bacteria or virus causing many diseases. Bacterial infection is among the most common types of disease in all age groups, but most bacterial infectious diseases are not the same. Our research will propose a transfer learning-based approach for pneumonia prediction utilizing a dataset comprising chest X-ray images. The dataset-based images will be grouped into two groups based on the parameters. Our proposed model displayed an average accuracy of 94.54% on the dataset. The proposed model (PDTLA) performed well compared with previous quantitative and qualitative research studies. Pneumonia detection transfer learning algorithm (PDTLA) is the name of the modified model.</abstract>
      <kwd-group>
        <kwd>Convolutional neural network (CNN)</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Pneumonia</kwd>
        <kwd>Medical imagining</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="4"/>
        <fig-count count="9"/>
        <table-count count="7"/>
        <ref-count count="43"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Our bodies and surrounding environments host a multitude of bacteria and virus species. Among these, certain bacteria species play a positive role in human health, aiding in processes such as food digestion, fermentation of dairy products, and even drug synthesis. Conversely, there are bacteria and viruses that can pose threats to human health. This diversity underscores the complex relationship between microorganisms and human biology, encompassing both beneficial and harmful interactions. The toxic species of bacteria are the leading cause of various diseases. Pneumonia is a dangerous illness of the lungs that causes severe respiratory problems. The patient's lung gets inflamed with fluid, leading to breathing difficulty with severe symptoms, which can lead to a high mortality rate. Bacterial pneumonia causes severe symptoms of the disease as compared with viral pneumonia. The most affected population includes people with a weakened immune system, the elderly, and infants. Early pneumonia detection and timely treatment provision can save lives (<xref ref-type="bibr" rid="ref_28">Patel et al., 2021</xref>). Chest X-ray is mainly used for detecting pneumonia. Chest X-ray images are often not so clear and are misclassified. A bacterial and viral pneumonia chest X-ray is similar in many aspects and can lead to inaccurate diagnosis by the medical professional (<xref ref-type="bibr" rid="ref_30">Rahman et al., 2020</xref>).</p><p>Traditional machine learning methods are often employed for feature extraction, where the acquired representations are subsequently fed into classifiers like SVMs or random forests for tasks like classification. However, in recent times, deep learning models, notably convolutional neural networks (CNNs), have gained widespread adoption in diverse fields such as image processing and computer vision. CNN architectures have demonstrated remarkable success in areas including healthcare, security, language translation, pathology, and microbiology. Typically, these networks are trained on sizable, labeled datasets, employing supervised learning techniques and leveraging pre-trained weights (<xref ref-type="bibr" rid="ref_35">Sarwar et al., 2019</xref>). The highest reported level of accuracy in the research analysis phase was 92.5%, with significant areas to improve upon by changing the algorithm and modifying the CNN layers. Our problem is a binary classification problem commonly dealt with in Convolution neural networks (<xref ref-type="bibr" rid="ref_16">Hameed et al., 2021</xref>). The proposed study provides a transfer learning-based model to classify pneumonia more accurately than other models. In the proposed research, the model will classify the chest X-ray as either standard or pneumonia. <xref ref-type="fig" rid="fig_1">Figure 1</xref> Shows the typical and pneumonia images.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Chest X-ray samples representing normal and pneumonia images</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_52DA-7rMkEr5DETd.jpeg"/>
        </fig>
      
      <p>Image detection and machine learning refer to the algorithms employed for the artificial intelligence diagnosis system developed. We utilize a mixed supervised deep detection method when using many different types of images to conclude. In the supervised approach, we map a function F with two inputs, a, and b. x=f (a, b) from the convolutional neural network extracts information from input images using a set of pre-defined weights denoted by W. This procedure entails scrutinizing pixels within designated areas of interest to acquire pertinent characteristics. The subsequent segments of the document adhere to this format: Segment 2 delves into correlated studies regarding bacterial identification via machine learning and deep learning techniques. In Segment 3, we delve into the constituents and blueprint of the framework. The fifth segment addresses the research dataset and effectiveness assessment.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related works</title>
      <p>The identification of normal chest X-ray or pneumonia X-ray images is a challenge in medical imaging and deep learning. With vast amounts of data, it won't be easy to classify the data efficiently and accurately manually. Deep understanding will provide us with a mechanism that will detect the virus and bacteria pneumonia using an automated approach. The presence of pneumonia is detected using X-ray-based images, which contain both cases of the bacterial and virus-related disease. The detection of pneumonia has been extensively researched using traditional machine-learning methods. The data on bacterial and virus-related pneumonia is not in abundance. Therefore, researching this problem takes a lot of effort. When performing analysis using machine learning algorithms, features need to be extracted manually, while when we use Deep learning models, components get autonomously selected by the input layer. Compared to traditional machine learning approaches, deep learning is preferred when using the image dataset. <xref ref-type="bibr" rid="ref_31">Rajpurkar et al. (2017)</xref> developed an application base system exceeding the results the radiologist gathered. The researchers used ChexNet to detect almost 14 diseases of the lungs, including pneumonia. Data scarcity is an issue in lung diseases that negatively affects the research study. The researchers (<xref ref-type="bibr" rid="ref_25">Liang &amp;amp; Zheng, 2020</xref>) used the imageNet dataset to gather a considerable amount of data and fine-tuned it by processing many Image-based datasets. <xref ref-type="bibr" rid="ref_9">Chouhan et al. (2020)</xref> proposed a novel deep-learning approach that extracted features from the dataset, and the dataset used was ImageNet.</p><p>The scientists introduced a collaborative framework that amalgamated all pre-existing trained models to achieve elevated accuracy. Pneumonia stands as a prominent contributor to mortality among juveniles globally (<xref ref-type="bibr" rid="ref_14">Gabruseva et al., 2020</xref>). The researchers devised a computational strategy for identifying pneumonia within thoracic X-ray regions squeeze and extinction-based convolutional neural networks. <xref ref-type="bibr" rid="ref_18">Hashmi et al. (2020)</xref> worked on a novel approach using a weight classifier that used Denset as the base model. The predictions were made on the bases of the quality a dataset contains. <xref ref-type="bibr" rid="ref_24">Li et al. (2018)</xref> improved upon the model by developing a fewer layerâs deep learning model to reduce the significant computational complexity and time complexity of model training and testing. The covid-19 virus has hit the world and caused a lot of harm to the global medical health community coronavirus affects the lung tissue and causes inflammation in the air sacs of the lungs (<xref ref-type="bibr" rid="ref_29">Phankokkruad, 2020</xref>). The researcher used three pre-trained models to achieve the best accuracy and develop a deep comparative analysis for the best detection technique. The researchers (<xref ref-type="bibr" rid="ref_26">Narayanan et al., 2020</xref>) have worked on a two-stage deep learning model to detect the presence of viral pneumonia by using chest radiography and incorporated it with image segmentation techniques to achieve better results. Early diagnosis is necessary to detect the presence of viral or bacterial infection in the lungs <xref ref-type="bibr" rid="ref_2">Al Mamlook et al. (2020)</xref> conducted a comparative analysis with the previous studies to signify the use of deep learning compared with machine learning approaches. Over the deep learning, models performed better on performance evaluation metrics. <xref ref-type="bibr" rid="ref_41">Zebin &amp;amp; Rezvy (2020)</xref> applied a combination of CNN layers and depth-wise separable convolutional layers to decrease the time required for training. <xref ref-type="bibr" rid="ref_42">Zhang et al. (2020)</xref> worked on a deep-learning neural network by conducting a multinational study on the matter and used DenseNet as a base model to drive the analysis. Researchers, specialists, and medical professionals are working towards an artificial solution for diagnosing pneumonia. In this research study, a comparison is conducted between binary classification models VVG 16 and denseNet (<xref ref-type="bibr" rid="ref_13">Fu et al., 2021</xref>). A different approach using GAN adversarial network technique was implemented in <xref ref-type="bibr" rid="ref_42">Zhang et al. (2020)</xref>âs study, in which the researchers used the DCCN network to classify MRI images. The researchers (<xref ref-type="bibr" rid="ref_20">Iparraguirre-Villanueva et al., 2022</xref>) conducted a comparative analysis among CT scan images and chest X-rays to devise a more robust technique for detection (<xref ref-type="bibr" rid="ref_13">Fu et al., 2021</xref>). In <xref ref-type="bibr" rid="ref_7">Berrimi et al. (2021)</xref>âs study, researchers used 14 databases and mobile net V2 to conduct a comparative analysis among different types of diseases in the lungs. In the previous studies, most of the research was specific to one classification. Most of the research was related to machine learning algorithms that only utilized qualitative-type data with less accuracy. Transfer learning is a deep and machine learning-based technique (<xref ref-type="bibr" rid="ref_15">Haghanifar et al., 2022</xref>) that adopts a trained model and implements knowledge from previously learned data sequences. The model is already familiarized with the concept of an object by using transfer. With the help of transfer learning, we can implement our trained model on the different virus and bacteria-based X-ray images with an automated classification of the type of pneumonia detected (<xref ref-type="bibr" rid="ref_32">Ramzan et al., 2019</xref>). In recent research, using both quantitative and qualitative methods, <xref ref-type="bibr" rid="ref_10">Chow et al. (2023)</xref> carried out a thorough examination of 18 deep Convolutional Neural Network (CNN) models for COVID-19 diagnosis from chest X-ray (CXR) pictures. Their research clarifies the effectiveness of transfer learning in this field. Similar to this, <xref ref-type="bibr" rid="ref_3">Ali et al. (2023)</xref> presented a CNN-based model designed especially for the diagnosis of chest infections, making use of an isolated, multistage, multiclass transfer learning architecture. This method shows how versatile CNNs are for problems involving medical imaging. Furthermore, <xref ref-type="bibr" rid="ref_39">Vardhan et al. (2023)</xref> demonstrated the possibility of utilizing current knowledge in radiographic analysis by presenting a deep transfer learning framework modified for estimating lung opacities from chest X-rays. Together, these results highlight how important CNNs and transfer learning strategies are to improving diagnostic capacities. The main contributions towards solving this detection problem include:</p><p><p>The primary aim of this research investigation is to enhance precision and correctness.</p><p>Maintaining stringent threshold criteria.</p><p>Developing a comparative examination with existing research to refine the forecasting system.</p></p><p>The use of convolutional neural networks (CNNs) and transfer learning for pneumonia detection has been studied recently. For example, <xref ref-type="bibr" rid="ref_40">Wang et al. (2020)</xref> achieved an accuracy of 94.9% in pneumonia identification on chest X-rays by fine-tuning the ResNet-50 model that had been pre-trained on the ImageNet dataset using a transfer learning strategy. Similar to this, <xref ref-type="bibr" rid="ref_10">Chow et al. (2023)</xref> achieved 96.7% accuracy by fine-tuning the DenseNet-121 model, which had been pre-trained on the Chest X-ray Images (CXR) dataset, using transfer learning. The effectiveness of transfer learning in enhancing the efficiency of pneumonia detection methods based on chest X-rays is demonstrated by this research. To evaluate its application in various modalities and in actual clinical settings, more research is necessary. The cited studies underscore the effectiveness of this approach in refining pre-trained CNN models and enhancing pneumonia detection performance. However, additional research is required to investigate transfer learning's applicability to diverse modalities and its implementation in real clinical environments.</p>
      
        <sec>
          
            <title>2.1. Limitations</title>
          
          <p>Pneumonia identification through thoracic X-ray imaging has been thoroughly examined. Prior methodologies exhibit the subsequent limitations:</p><p><p>The majority of studies concerning pneumonia rely on traditional convolutional neural networks (<xref ref-type="bibr" rid="ref_9">Chouhan et al., 2020</xref>).</p><p>The dataset presented a restricted range of classes and insufficient images for thorough analysis.</p><p>Our model outperforms previous ones (<xref ref-type="bibr" rid="ref_7">Berrimi et al., 2021</xref>; <xref ref-type="bibr" rid="ref_20">Iparraguirre-Villanueva et al., 2022</xref>) in terms of accuracy, despite encountering a higher loss rate.</p></p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Materials and methods</title>
      <p>The fields of medicine and medical diagnosis have seen a transformation thanks to deep learning and machine learning. These days' high-capacity graphics cards can train and evaluate a significant quantity of data instantly. Artificial intelligence is being implemented in many fields related to fraud detection, image prediction, and object classification. A considerable amount of data can be analyzed and classified based on features (<xref ref-type="bibr" rid="ref_37">Sattar et al., 2019</xref>). Early detection of pneumonia will help medical practitioners solve the late diagnosis of the disease and will fasten the treatment plan for individual patients. Different algorithms have been implemented on quantitative data, but much research is related to machine learning. Deep learning has not been implemented in many diseases because of the high requirements of the resources related to Graphical processing units (<xref ref-type="bibr" rid="ref_36">Sarwar et al., 2022</xref>). The primary source of feature extraction is the images of the dataset, which are chest X-ray-based images. We are using a modified version of AlexNet, and AlexNet is a CNN that can extract features from an image. AlexNet is already a trained model, so the previous weights are used while training for the new dataset images.</p><p>The main reason for working on this research is to create an efficient system that will proceed toward an application-level system with actual implementation in the real world. The model system architecture is represented in <xref ref-type="fig" rid="fig_2">Figure 2</xref>. The enhanced system model (PDTLA) will contain two layers the pre-processing layer and the second one is the application layer. The pre-trained model for the use of the classification is AlexNet. For bacterial and virus pneumonia-based detection systems, our dataset was sourced from the Kaggle database (<xref ref-type="bibr" rid="ref_19">Hurtik et al., 2022</xref>). The employed dataset was in raw format. In pre-processing layer, the dataset images were converted to 227* 227*1 image size. All the images were of the same size and dimension. AlexNet pre-trained model was imported in the second layer and adapted according to our binary classification problem. The detailed diagram of the proposed (PDTLA) model is shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref> and <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Enhanced system application level model diagram</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_4q3vpSg9ghI3PaKt.png"/>
        </fig>
      
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Enhanced PDTLA model diagram</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_WEmUuTxSSa3Nb_Hh.png"/>
        </fig>
      
      <p>The proposed model undergoes validation. Inputting the chest radiograph images once it has completed training and testing on the dataset. The provided imagesâ height, width, and dimensions are modified to 227*227*3 by the initial pre-processing layer. Subsequently, the information is transmitted to the utility layer, the second stratum, after the images have been altered (<xref ref-type="bibr" rid="ref_33">Saleem et al., 2020</xref>). Utility strata then segregate the images into two categories: class 2, identified as pneumonia, and class 1, identified as typical. If pneumonia is detected in a chest radiograph, the individual will be directed to a healthcare practitioner for further evaluation. Machine learning and artificial intelligence utilize diverse sorts of algorithms (<xref ref-type="bibr" rid="ref_43">Zhuang et al., 2021</xref>) to derive valid deductions from the data and formulate future projections utilizing quantitative data. Projections utilizing images and videos necessitate more advanced approaches of feature map extraction, central loss, and intersection over union (IOU) loss. A plethora of techniques are accessible to conduct video and image detections. In the contemporary era, prognostications based on images and videos are imperative. This is the time when deep learning performs its usefulness in fields of biomedicine disease-based classification. Yolo v4 AlexebAB (<xref ref-type="bibr" rid="ref_34">Salem et al., 2022</xref>), res net, and AlexNet are advanced pre-trained models for transfer learning on new problems. When a model has a strong grasp of the fundamental principles underlying object classification, such as in the case of YOLO v4, its performance becomes notably swift and effective. With this proficiency, detections can be executed within milliseconds. The PDTLA architecture, consisting of both a pre-processing layer and an application layer, employs a customized version of the AlexNet convolutional neural network to streamline the process of diagnosing pneumonia from chest X-ray images. Pre-processing steps like grayscale conversion, resizing, and data augmentation ensure standardized inputs. The adapted AlexNet, featuring an eight-layer architecture with convolutional and fully connected layers, utilizes ReLU activation functions for effective training. Transfer learning expedites feature extraction by capitalizing on AlexNetâs familiarity with image patterns. The modelâs sequential flow, depicted in <xref ref-type="fig" rid="fig_2">Figure 2</xref> and <xref ref-type="fig" rid="fig_3">Figure 3</xref>, emphasizes its methodical approach to pneumonia detection, offering the potential for rapid diagnosis and treatment planning.</p>
      
        <sec>
          
            <title>3.1. Preprocessing</title>
          
          <p>The pre-detection system in our detection model is based on AlexNet, a convolutional neural network. AlexNet is an Object detection model it is trained on 1000 classes related to objects. During training, AlexNet utilizes the Imagenet dataset as its foundation, comprising millions of images to establish weights w for subsequent predictions. Throughout the training process, the image dimensions are standardized to 227*227*3, as depicted in <xref ref-type="fig" rid="fig_4">Figure 4</xref>.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Preprocessed images form the dataset</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_N-75zf4abW95UcQb.jpeg"/>
            </fig>
          
          <p>In the PDTLA model, the initial step involved cropping and resizing images to meet the requirements of the base model. The entire image in the binary classes underwent conversion to a height and width of 227*227. AlexNet is capable of detecting images in Red green blue color format.</p>
          
            <sec>
              
                <title>3.1.1 Procedure for preprocessing the dataset:</title>
              
              <p><p>Conversion to grayscale: Chest X-rays are typically in color, but grayscale is sufficient for analysis and reduces computational complexity.</p><p>Resizing: Images may have varying dimensions and need to be resized to a standard size for analysis.</p><p>Intensity normalization: The pixel intensities of the image may need to be adjusted to improve the contrast and make it easier for algorithms to detect patterns.</p><p>Denoising: X-rays often contain noise that can obscure important details, so denoising techniques can be applied to remove this noise.</p><p>Segmentation: The lungs in chest X-rays are the main focus of pneumonia detection, so a segmentation step is typically used to isolate the lungs from the rest of the image.</p><p>Augmenting Data: Expanding the dataset's size and accommodating disparities in chest X-ray position, orientation, and scale can be achieved through data augmentation methods. This involves techniques such as varying angles, mirror imaging, resizing, and shifting.</p></p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>3.2. Adapted deep learning alexnet</title>
          
          <p>In 2012, the earlier iteration of AlexNet boasted a larger number of layers compared to its current version (<xref ref-type="bibr" rid="ref_19">Hurtik et al., 2022</xref>). It has been widely adopted for transfer learning applications to address novel challenges. While the complete AlexNet model comprises eight layers, The complexity of the YOLO network surpasses that of AlexNet, which features a distinct structure consisting of a head, backbone, and tail, Consisting of more than 126 strata for instruction. In contrast to YOLO, AlexNet incorporates five Convolutional strata, in addition to a blend of maximum pooling and three Wholly Connected Strata. Each stratum of AlexNet encompasses multiple kernels (filters) (<xref ref-type="bibr" rid="ref_38">Sethy, 2022</xref>), which are activated by the Rectified Linear Unit (ReLU) function. ReLU, a function utilized in deep neural networks, accelerates training speed in comparison to the sigmoid function. Following the ReLU function's implementation, images undergo normalization, involving processes like cropping and resizing. Training a new model demands extensive data and preprocessing, hence the adoption of transfer learning to mitigate training time. Leveraging previously trained models expedites feature extraction compared to untrained models, as these models have already learned patterns, squares, and edges (<xref ref-type="bibr" rid="ref_27">Nasir et al., 2020</xref>). Gathering vast amounts of data from scratch consumes both time and computational resources.</p><p>The first five layers of the neural network are already pre-trained on a huge dataset ImageNet collected over the years and contains millions of pre-trained images using GPUs. The softmax functions convert the output into 0 and 1 and are implemented using softmax layers in the AlexNet model. Only the last three layers of the network are changed according to our requirements, as we do not require 1000 classes for classification purposes. Our problem is a binary solution based, so we only used two classes, bacterial or virus-based pneumonia. The model output will be equal to two as the problem contains only two classes. Using a pre-trained model already trained on a multi-class dataset, fasten the training time to detect multiple classes. The fully connected layers present at the last of the network model classify the images into particular binary classes. At the same time, the convolutional layers present in the second stage of the model are used for feature extraction and image filtering. In the proposed model of AlexNet, the last three layers of the system model are customized for custom image detection and are changed according to our specific problem. The network architecture comprises fully connected, softmax, and output classification layers, each requiring distinct properties to enhance accuracy. During the training phase, we experimented with varying learning rates between epochs 0 and 1, adjusting the number of iterations based on the problem's complexity. Initially, we set the total epochs to 60, but observed overfitting and failure to detect classes across different dataset images. Consequently, we settled on 40 epochs, with a learning rate of 1e-4, ensuring convergence with optimal weights. The proposed PDTLA system leverages transfer learning to adapt a pre-trained model to a new problem. By utilizing convolutional neural network layers, sourced domain knowledge, and specific learning parameters, the model effectively tackles pneumonia disease detection in children as well (<xref ref-type="bibr" rid="ref_6">Barakat et al., 2023</xref>; <xref ref-type="bibr" rid="ref_23">Key et al., 2022</xref>).</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Dataset</title>
          
          <p>The data has a group of X-ray images with different types of structures. One has normal class, and the other contains pneumonia and a total of 4883. The model uses a public dataset available on Kaggle (<xref ref-type="bibr" rid="ref_5">Bal Naypyane, 2021</xref>). The dataset is divided into binary classes. The total amount of images was 1499 for normal lungs and 3600 pneumonia-based images of a chest X-ray. After the images were classified as normal, pneumonia images were transferred to their particular class folder in Matlab 2019. The dimensions of the images were changed to a single dimension in all dataset images for both classes. After preprocessing, the number of images is shown in <xref ref-type="table" rid="table_1">Table 1</xref>. Quantity of visuals in the dataset for regular thorax radiographs was less than for pneumonia chest X-rays. <xref ref-type="table" rid="table_2">Table 2</xref> represents the validation dataset after preprocessing. </p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Class representation for training</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Total Classes</p></td><td colspan="1" rowspan="1"><p>Total Numbers</p></td></tr><tr><td colspan="1" rowspan="1"><p>Normal</p></td><td colspan="1" rowspan="1"><p>1199</p></td></tr><tr><td colspan="1" rowspan="1"><p>Pneumonia</p></td><td colspan="1" rowspan="1"><p>2880</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Class representation for validation</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Total Classes</p></td><td colspan="1" rowspan="1"><p>Total Numbers</p></td></tr><tr><td colspan="1" rowspan="1"><p>Normal</p></td><td colspan="1" rowspan="1"><p>300</p></td></tr><tr><td colspan="1" rowspan="1"><p>Pneumonia</p></td><td colspan="1" rowspan="1"><p>720</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Experimental analysis</title>
      <p>The appraisal segment, we will scrutinize the outcomes derived from both the coaching phase and the proposed model's effectiveness using knowledge transfer, concentrating on precise performance measures. The primary goal of this investigation was to devise a streamlined and swift mechanism for recognizing bacteria and healthy erythrocytes. MATLAB 2018 was employed to produce binary classification outcomes for the experimentation. Coaching was carried out on a sole rx 580 GPU with 8 GB of detected RAM for processing. The dataset was partitioned into coaching and authentication sets, with 80% designated for coaching and 20% for authentication. To assess the model's effectiveness, a variety of measures were employed, encompassing sensitivity, selectivity, exactitude, correctness, False negative rate (FNR), False positive rate (FPR), failure rate, F1 score, Likelihood ratio positive (LRP), and Likelihood ratio negative (LRN). Additionally, the Matthews Correlation coefficient (MCC) was utilized to gauge the overall discrepancy between anticipated and observed values.</p>
      
        <disp-formula>
          <label>(1)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>s</mi>
            <mi>e</mi>
            <mi>n</mi>
            <mi>s</mi>
            <mi>i</mi>
            <mi>t</mi>
            <mi>i</mi>
            <mi>v</mi>
            <mi>i</mi>
            <mi>t</mi>
            <mi>y</mi>
            <mo>=</mo>
            <mo>â</mo>
            <mfrac>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">(</mo>
                <mo data-mjx-texclass="CLOSE">)</mo>
                <mfrac>
                  <msub>
                    <mi>B</mi>
                    <mi>p</mi>
                  </msub>
                  <msub>
                    <mi>E</mi>
                    <mi>p</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>p</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>p</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>m</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>m</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>+</mo>
              </mrow>
            </mfrac>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(2)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>s</mi>
            <mi>p</mi>
            <mi>e</mi>
            <mi>c</mi>
            <mi>i</mi>
            <mi>f</mi>
            <mi>i</mi>
            <mi>c</mi>
            <mi>i</mi>
            <mi>t</mi>
            <mi>y</mi>
            <mo>=</mo>
            <mo>â</mo>
            <mfrac>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">(</mo>
                <mo data-mjx-texclass="CLOSE">)</mo>
                <mfrac>
                  <msub>
                    <mi>B</mi>
                    <mi>m</mi>
                  </msub>
                  <msub>
                    <mi>E</mi>
                    <mi>m</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>m</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>m</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <mi>B</mi>
                    <msub>
                      <mi>E</mi>
                      <mi>e</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>+</mo>
              </mrow>
            </mfrac>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(3)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>p</mi>
            <mi>r</mi>
            <mi>e</mi>
            <mi>c</mi>
            <mi>i</mi>
            <mi>s</mi>
            <mi>i</mi>
            <mi>o</mi>
            <mi>n</mi>
            <mo>=</mo>
            <mo>â</mo>
            <mfrac>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">(</mo>
                <mo data-mjx-texclass="CLOSE">)</mo>
                <mfrac>
                  <msub>
                    <mi>B</mi>
                    <mi>p</mi>
                  </msub>
                  <msub>
                    <mi>E</mi>
                    <mi>p</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>p</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>p</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>e</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>e</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>+</mo>
              </mrow>
            </mfrac>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(4)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>a</mi>
            <mi>c</mi>
            <mi>c</mi>
            <mi>u</mi>
            <mi>r</mi>
            <mi>a</mi>
            <mi>c</mi>
            <mi>y</mi>
            <mo>=</mo>
            <mo>â</mo>
            <mfrac>
              <mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>p</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>p</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>m</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>m</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>+</mo>
              </mrow>
              <mrow>
                <mi>p</mi>
                <mi>m</mi>
                <mo>+</mo>
              </mrow>
            </mfrac>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(5)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>m</mi>
            <mi>i</mi>
            <mi>s</mi>
            <mi>s</mi>
            <mi>r</mi>
            <mi>a</mi>
            <mi>t</mi>
            <mi>e</mi>
            <mstyle scriptlevel="0">
              <mspace width="0.167em"/>
            </mstyle>
            <mo>=</mo>
            <mo>â</mo>
            <mrow data-mjx-texclass="INNER">
              <mo data-mjx-texclass="OPEN">[</mo>
              <mo>â</mo>
              <mo data-mjx-texclass="CLOSE">]</mo>
              <mn>1</mn>
              <mfrac>
                <mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>p</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>p</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>m</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>m</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mo>+</mo>
                </mrow>
                <mrow>
                  <mi>p</mi>
                  <mi>m</mi>
                  <mo>+</mo>
                </mrow>
              </mfrac>
            </mrow>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(6)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>f</mi>
            <mi>a</mi>
            <mi>l</mi>
            <mi>s</mi>
            <mi>e</mi>
            <mi>p</mi>
            <mi>o</mi>
            <mi>s</mi>
            <mi>i</mi>
            <mi>t</mi>
            <mi>i</mi>
            <mi>v</mi>
            <mi>e</mi>
            <mi>r</mi>
            <mi>a</mi>
            <mi>t</mi>
            <mi>e</mi>
            <mstyle scriptlevel="0">
              <mspace width="0.167em"/>
            </mstyle>
            <mstyle scriptlevel="0">
              <mspace width="0.167em"/>
            </mstyle>
            <mo>=</mo>
            <mo>â</mo>
            <mrow data-mjx-texclass="INNER">
              <mo data-mjx-texclass="OPEN">[</mo>
              <mo>â</mo>
              <mo data-mjx-texclass="CLOSE">]</mo>
              <mn>1</mn>
              <mfrac>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>m</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>m</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>m</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>m</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>e</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>e</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mo>+</mo>
                </mrow>
              </mfrac>
            </mrow>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(7)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext>Â </mtext>
            <mi>f</mi>
            <mi>a</mi>
            <mi>l</mi>
            <mi>s</mi>
            <mi>e</mi>
            <mi>n</mi>
            <mi>a</mi>
            <mi>g</mi>
            <mi>e</mi>
            <mi>t</mi>
            <mi>i</mi>
            <mi>v</mi>
            <mi>e</mi>
            <mi>r</mi>
            <mi>a</mi>
            <mi>t</mi>
            <mi>e</mi>
            <mstyle scriptlevel="0">
              <mspace width="0.167em"/>
            </mstyle>
            <mstyle scriptlevel="0">
              <mspace width="0.167em"/>
            </mstyle>
            <mo>=</mo>
            <mo>â</mo>
            <mrow data-mjx-texclass="INNER">
              <mo data-mjx-texclass="OPEN">[</mo>
              <mo>â</mo>
              <mo data-mjx-texclass="CLOSE">]</mo>
              <mn>1</mn>
              <mfrac>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <msub>
                      <mi>B</mi>
                      <mi>p</mi>
                    </msub>
                    <msub>
                      <mi>E</mi>
                      <mi>p</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>p</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>p</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mrow data-mjx-texclass="INNER">
                    <mo data-mjx-texclass="OPEN">(</mo>
                    <mo data-mjx-texclass="CLOSE">)</mo>
                    <mfrac>
                      <msub>
                        <mi>B</mi>
                        <mi>m</mi>
                      </msub>
                      <msub>
                        <mi>E</mi>
                        <mi>m</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mo>+</mo>
                </mrow>
              </mfrac>
            </mrow>
            <mn>100</mn>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(8)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtable displaystyle="true" columnspacing="1em" rowspacing="3pt">
              <mtr>
                <mtd>
                  <mi>F</mi>
                  <mi>S</mi>
                  <mi>c</mi>
                  <mi>o</mi>
                  <mi>r</mi>
                  <mi>e</mi>
                  <mn>1</mn>
                  <mtext>Â </mtext>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mn>2</mn>
                      <mo>â</mo>
                      <mo stretchy="false">(</mo>
                      <mo>â</mo>
                      <mo stretchy="false">)</mo>
                      <mi>p</mi>
                      <mi>r</mi>
                      <mi>e</mi>
                      <mi>c</mi>
                      <mi>i</mi>
                      <mi>s</mi>
                      <mi>i</mi>
                      <mi>o</mi>
                      <mi>n</mi>
                      <mi>s</mi>
                      <mi>e</mi>
                      <mi>n</mi>
                      <mi>s</mi>
                      <mi>i</mi>
                      <mi>t</mi>
                      <mi>i</mi>
                      <mi>v</mi>
                      <mi>i</mi>
                      <mi>t</mi>
                      <mi>y</mi>
                    </mrow>
                    <mrow>
                      <mi>p</mi>
                      <mi>r</mi>
                      <mi>e</mi>
                      <mi>c</mi>
                      <mi>i</mi>
                      <mi>s</mi>
                      <mi>i</mi>
                      <mi>o</mi>
                      <mi>n</mi>
                      <mi>s</mi>
                      <mi>e</mi>
                      <mi>n</mi>
                      <mi>s</mi>
                      <mi>i</mi>
                      <mi>t</mi>
                      <mi>i</mi>
                      <mi>v</mi>
                      <mi>i</mi>
                      <mi>t</mi>
                      <mi>y</mi>
                      <mo>+</mo>
                    </mrow>
                  </mfrac>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>N</mi>
                  <mi>D</mi>
                  <mi>R</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>E</mi>
                      <mi>p</mi>
                    </mrow>
                    <mrow>
                      <mi>B</mi>
                      <mi>p</mi>
                      <mi>B</mi>
                      <mi>p</mi>
                      <mo>+</mo>
                    </mrow>
                  </mfrac>
                </mtd>
              </mtr>
            </mtable>
          </math>
        </disp-formula>
      
      
        <disp-formula>
          <label>(9)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mi>M</mi>
            <mi>C</mi>
            <mi>C</mi>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>B</mi>
                <mi>E</mi>
                <mi>N</mi>
                <msup>
                  <mi>P</mi>
                  <mo>â</mo>
                </msup>
                <mo>â</mo>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">[</mo>
                  <mo data-mjx-texclass="CLOSE">]</mo>
                  <mfrac>
                    <mrow>
                      <mi>B</mi>
                      <mi>E</mi>
                      <mi>N</mi>
                      <msup>
                        <mi>P</mi>
                        <mo>â</mo>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>sqrt</mi>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo stretchy="false">(</mo>
                        <mo>+</mo>
                        <mo stretchy="false">(</mo>
                        <mo>+</mo>
                        <mo stretchy="false">(</mo>
                        <mo>+</mo>
                        <mo stretchy="false">)</mo>
                        <mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"/>
                        <mi>B</mi>
                        <mi>P</mi>
                        <mi>E</mi>
                        <mi>P</mi>
                        <mi>B</mi>
                        <mi>P</mi>
                        <mi>E</mi>
                        <mi>N</mi>
                        <mi>B</mi>
                        <mi>N</mi>
                        <mi>E</mi>
                        <mi>P</mi>
                        <msup>
                          <mo stretchy="false">)</mo>
                          <mo>â</mo>
                        </msup>
                        <msup>
                          <mo stretchy="false">)</mo>
                          <mo>â</mo>
                        </msup>
                      </mrow>
                    </mrow>
                  </mfrac>
                </mrow>
              </mrow>
              <mrow>
                <mo stretchy="false">(</mo>
                <mo>+</mo>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">)</mo>
                <mi>B</mi>
                <mi>N</mi>
                <mi>E</mi>
                <mi>N</mi>
              </mrow>
            </mfrac>
          </math>
        </disp-formula>
      
      <p>The equations are self-created. Equations represent the results in the experimental method phase. All the equations represent the values of the confusion matrix and the results.</p><p>Pneumonia signifies the condition in which Systematic Nominalization of the lungs air sacs was detected in the particular chest X-ray image provided into the system and if the image not detected the proposed model will not classify as minimum threshold criteria will not be met. The proposed system model (PDTLA) pneumonia detection classifies the images into 2 different classes. Normal will represent the class in which the chest X-ray was not abnormal, and no disease of the lungs was detected.</p><p><xref ref-type="table" rid="table_3">Table 3</xref> illustrates the simulation parameters we used to train our PDTLA system model. The dataset was trained on multiple iterations, for example, 10, 20, 30, and 40. The number of epochs was selected after multiple training runs as more epochs will cause overfitting in the enhanced model. The proposed model rendered the maximum accuracy with a least loss per class at 40 epochs. The model generated 98.43 percent accuracy and a loss rate of 0.043. PDTLA model performed better in comparison with other models using different algorithms shown in the table. Seven exhibited less accuracy and more loss rate. Multiple parameters and layers were set according to problem and image dimensions.</p>
      
        <table-wrap id="table_3">
          <label>Table 3</label>
          <caption>
            <title>Simulation parameters</title>
          </caption>
          <table><tbody><tr><td><p>Iterations</p></td><td><p>Blocks</p></td><td><p>Image Dimensions</p></td><td><p>Gathering Method</p></td><td><p>Learning Curve</p></td></tr><tr><td><p>10</p></td><td><p>25</p></td><td><p>227*227*3</p></td><td><p>Maximum</p></td><td><p>1e-4</p></td></tr><tr><td><p>20</p></td><td><p>25</p></td><td><p>227*227*3</p></td><td><p>Maximum</p></td><td><p>1e-4</p></td></tr><tr><td><p>30</p></td><td><p>25</p></td><td><p>227*227*3</p></td><td><p>Maximum</p></td><td><p>1e-4</p></td></tr><tr><td><p>40</p></td><td><p>25</p></td><td><p>227*227*3</p></td><td><p>Maximum</p></td><td><p>1e-4</p></td></tr></tbody></table>
        </table-wrap>
      
      <p><xref ref-type="table" rid="table_4">Table 4</xref> displays the accuracy and miss classification rate at different epochs 10, 20, 30, and 40 on the proposed pneumonia detection system (PDTLA). At the ten epochs mark, the model accuracy was 70% with a high miss enhanced rate of 8.71%, 88% on 20 epochs. The model accuracy reached 98.23% with a miss classification rate of 0.0.520%. In the training's final phase, the model achieved maximum accuracy of 98.73% and a miss rate of 0.04179%. <xref ref-type="fig" rid="fig_5">Figure 5</xref> shows the results of labeled images of the validation dataset, with 18 as normal and two as pneumonia. The validated dataset results use mix classification for two of the classes.</p>
      
        <table-wrap id="table_4">
          <label>Table 4</label>
          <caption>
            <title>Enhanced model (PDTLA)</title>
          </caption>
          <table><tbody><tr><td><p>No. of Iterations</p></td><td><p>Max Accuracy %</p></td><td><p>Miss Classification Rate %</p></td></tr><tr><td><p>10</p></td><td><p>97.531</p></td><td><p>0.0671</p></td></tr><tr><td><p>15</p></td><td><p>97.989</p></td><td><p>0.0572</p></td></tr><tr><td><p>25</p></td><td><p>98.01</p></td><td><p>0.0473</p></td></tr><tr><td><p>45</p></td><td><p>98.432</p></td><td><p>0.0495</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Classification results by (PDTLA) proposed model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_aByhKEMTw17dmrig.png"/>
        </fig>
      
      <p><xref ref-type="fig" rid="fig_6">Figure 6</xref> displays the confusion matrix generated after training the proposed model (PDTLA). The dataset contains 5099 images of both class normal and pneumonia. 4079 images were utilized for training the proposed model. 1191 images were classified as normal 1191, and 1 image was classified as false positive. 2879 images in the training phase were classified as pneumonia, with 8 images classified as a false negative.</p>
      
        <fig id="fig_6">
          <label>Figure 6</label>
          <caption>
            <title>Proposed model (PDTLA) validation 20 % of dataset</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_F7bws1_7YlUOxxfX.png"/>
        </fig>
      
      <p><xref ref-type="fig" rid="fig_7">Figure 7</xref> displays the enhanced (PDTLA) confusion matrix diagram in the validation phase. The total number of epochs is 40. A total of 1020 images were used for validation purposes. 289 images were classified as true positive for a normal chest X-ray. Five images were classified as false positive. 715 images were classified as True for pneumonia, and 11 were identified as false negative findings in the proposed (PDTLA) model. Over, all models achieved an accuracy of 98.43%.</p>
      
        <fig id="fig_7">
          <label>Figure 7</label>
          <caption>
            <title>Proposed model (PDTLA) training 80% of dataset</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_zTTO7BpBvfZiybOo.png"/>
        </fig>
      
      <p>Confusion matrix is explicitly used in our paper to visualize the predictive analytical results and compare it with other studies to create a comparative analysis with different studies for more significance.</p><p>The proposed (PDTLA) system is tested on a single CPU maximum time taken of dataset trained method 140 minutes total iterations were 1240. <xref ref-type="fig" rid="fig_8">Figure 8</xref> display the minimization per class for the proposed model (PDTLA) on 40 iterations. <xref ref-type="fig" rid="fig_9">Figure 9</xref> shows the training progress throughout the 40 epochs. The total number of iterations per epochs was 30. Training results is displayed after 40 epochs. Initially the learning rate was low. Capable enhancing rate was set to 1e-4 to gain optimal results but the model converged slowly. </p>
      
        <fig id="fig_8">
          <label>Figure 8</label>
          <caption>
            <title>Training progress</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_qVH-vzDMPxsjmc-Q.jpeg"/>
        </fig>
      
      
        <fig id="fig_9">
          <label>Figure 9</label>
          <caption>
            <title>Proposed model (PDTLA) accuracy chart</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/3/img_eWNi0CJmQTPrAHCt.png"/>
        </fig>
      
      <p>The statistical results shown in <xref ref-type="table" rid="table_5">Table 5</xref> like accuracy, precision, sensitivity, specificity, FPR, FNR, F1 score, FDR, NPR, and MCC are discussed in <xref ref-type="table" rid="table_6">Table 6</xref>. <xref ref-type="table" rid="table_3">Table 3</xref> shows the results of specificity, sensitivity, precision, and accuracy, F1 score, NPR, FPR, FNR, FDR, and MCC are 99.9%, 99.2%, 99.7%, 99%, 0.9972%, 0.0003%, 0.0067%, 0.021%, 99.47%. The training provided an accuracy of 99.8%, and during the validation phase, it provided an accuracy of 98.43%. During the validation phase, the results of specificity, sensitivity, precision, and accuracy, F1 score, NPR, FPR, FNR, FDR, and MCC are 99.3%, 96.3%, 98.3%, 97.21%, 0.9848, 0.0069%, 0.0367%, 0.017%, and 96.21%.</p>
      
        <table-wrap id="table_5">
          <label>Table 5</label>
          <caption>
            <title>Performance evaluation metrics training and validation</title>
          </caption>
          <table><tbody><tr><td></td><td><p>Specificity</p></td><td><p>Sensitivity</p></td><td><p>Precision</p></td><td><p>Accuracy</p></td><td><p>F1 Score</p></td></tr><tr><td><p>Training </p></td><td><p>99.9 %</p></td><td><p>99.33%</p></td><td><p>99.2%</p></td><td><p>99.7 %</p></td><td><p>99.78</p></td></tr><tr><td><p>Validation </p></td><td><p>99.3%</p></td><td><p>96.3%</p></td><td><p>98.3%</p></td><td><p>98.43%</p></td><td><p>97.31</p></td></tr><tr><td></td><td><p>NPR</p></td><td><p>FPR</p></td><td><p>FNR</p></td><td><p>FDR</p></td><td><p>MCC</p></td></tr><tr><td><p>Training </p></td><td><p>0.9772%</p></td><td><p>0.0103 %</p></td><td><p>0.0057%</p></td><td><p>0.031%</p></td><td><p>95.47%</p></td></tr><tr><td><p>Validation </p></td><td><p>0.9481% </p></td><td><p>0.0066%</p></td><td><p>0.03467%</p></td><td><p>0.012%</p></td><td><p>92.21%</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>Different methodologies have already been applied to the problem of chest X-ray pneumonia. Researchers have utilized various algorithms and CNN models to classify chest X-rays (<xref ref-type="bibr" rid="ref_22">Islam et al., 2022</xref>). The proposed (TDPLA) model achieved higher accuracy than other studies. The model achieved 99.8% accuracy in training phase. In the validation phase, the performed system achieved an accuracy of 94.8% and a miss rate of 0.049%. <xref ref-type="fig" rid="fig_9">Figure 9</xref> illustrates the accuracy chart of the enhanced system (PDTLA) on 40 iterations for both the training and validation phase.</p>
    </sec>
    <sec sec-type="">
      <title>5. Comparative analysis</title>
      <p><xref ref-type="table" rid="table_6">Table 6</xref> illustrates a comprehensive review of diverse research efforts considered in our analysis phase. Our study demonstrated notably higher performance compared to these alternative neural network models. We conducted an extensive comparative analysis with recent research endeavors (<xref ref-type="bibr" rid="ref_11">Dhar et al., 2021</xref>). Similar to research conducted in <xref ref-type="bibr" rid="ref_21">Iqbal et al. (2022)</xref>âs study.</p>
      
        <table-wrap id="table_6">
          <label>Table 6</label>
          <caption>
            <title>Analysis of proposed model validation accuracy</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>Accuracy%</p></td><td colspan="1" rowspan="1"><p>Miss Rate%</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_1">Abdurahman &amp;amp; Yimer (2023)</xref></p></td><td colspan="1" rowspan="1"><p>93%</p></td><td colspan="1" rowspan="1"><p>-</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_17">Harmon et al. (2020)</xref></p></td><td colspan="1" rowspan="1"><p>91.7%</p></td><td colspan="1" rowspan="1"><p>6.57</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_12">El Asnaoui et al. (2021)</xref></p></td><td colspan="1" rowspan="1"><p>98.4%</p></td><td colspan="1" rowspan="1"><p>0.4</p></td></tr><tr><td colspan="1" rowspan="1"><p>A custom-designed 7-layered 3D (<xref ref-type="bibr" rid="ref_4">Aslam et al., 2020</xref>)</p></td><td colspan="1" rowspan="1"><p>96.6%</p></td><td colspan="1" rowspan="1"><p>-</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_8">Bhagat &amp;amp; Bhaumik (2019)</xref></p></td><td colspan="1" rowspan="1"><p>97.6%</p></td><td colspan="1" rowspan="1"><p>-</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_22">Islam et al. (2022)</xref></p></td><td colspan="1" rowspan="1"><p>94.5%</p></td><td colspan="1" rowspan="1"><p>-</p></td></tr><tr><td colspan="1" rowspan="1"><p>Purposed model</p></td><td colspan="1" rowspan="1"><p>98.43%</p></td><td colspan="1" rowspan="1"><p>0.04</p></td></tr></tbody></table>
        </table-wrap>
      
      <p><xref ref-type="table" rid="table_7">Table 7</xref> outlines the metrics employed to validate our study in comparison with other research endeavors. These metrics include specificity, sensitivity, precision, False positive rate (FPR), False negative rate (FNR), False discovery rate (FDR), and Matthews correlation coefficient (MCC).</p>
      
        <table-wrap id="table_7">
          <label>Table 7</label>
          <caption>
            <title>Depth analysis of proposed model with state art methods</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Authors</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>NDR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td><td colspan="1" rowspan="1"><p>MCC</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_17">Harmon et al. (2020)</xref></p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_12">El Asnaoui et al. (2021)</xref></p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_8">Bhagat &amp;amp; Bhaumik (2019)</xref></p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td></tr><tr><td colspan="1" rowspan="1"><p><xref ref-type="bibr" rid="ref_22">Islam et al. (2022)</xref></p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td></tr><tr><td colspan="1" rowspan="1"><p>Proposed Model</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td><td colspan="1" rowspan="1"><p>â</p></td></tr></tbody></table>
        </table-wrap>
      
    </sec>
    <sec sec-type="">
      <title>6. Conclusion</title>
      <p>Classification problems always require a lot of data, software, and hardware resources. These problems always cause difficulty to be fixed completely. In the latest updated work, the model will move towards a more enhanced system which does not depend on a single system. model that will embed cloud process servers to hold large containers of data to create a virtualized application with more classes. By the development of such a tool that uses deep learning to solve the fast detection of pneumonia will render help to the medical professionals to detect and treat the particular infection which the patient is suffering from. The smart detection system will be able to handle different types of non-colored and RGB images to detect pneumonia or normal chest X-ray images. The model created in our research uses a Convolutional network based AlexNet deep learning model to classify the images in to either normal or pneumonia. Our smart detection system leverages AlexNet as the foundational model for transfer learning. Following training on our dataset, the model achieved a remarkable accuracy of 98.43% on both the testing and validation datasets, surpassing the performance of other models. This proposed model holds potential to enhance clinical diagnosis by assisting in medical analysis, serving as a preliminary step in the detection process.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>67-72</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H. S.</given-names>
              <surname>Abdurahman</surname>
            </name>
            <name>
              <given-names>A. K.</given-names>
              <surname>Yimer</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ict4da59526.2023.10302262</pub-id>
          <article-title>Application of machine learning algorithms for pneumonia detection and classification</article-title>
          <source>, http://dx.doi.org/10.1109/ICT4DA59526.2023.10302262</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>98-104</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>R. E.</given-names>
              <surname>Al Mamlook</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Chen</surname>
            </name>
            <name>
              <given-names>H. F.</given-names>
              <surname>Bzizi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/eit48999.2020.9208232</pub-id>
          <article-title>Investigation of the performance of machine learning classifiers for pneumonia detection in chest X-ray images</article-title>
          <source>, http://dx.doi.org/10.1109/EIT48999.2020.9208232</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>2023</volume>
          <page-range>1-12</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ali</surname>
              <given-names>M. U.</given-names>
            </name>
            <name>
              <surname>Kallu</surname>
              <given-names>K. D.</given-names>
            </name>
            <name>
              <surname>Masood</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Tahir</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Gopi</surname>
              <given-names>Chandu V. V. Muralee</given-names>
            </name>
            <name>
              <surname>Zafar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>S. W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2023/6850772</pub-id>
          <article-title>A CNN-based chest infection diagnostic model: A multistage multiclass isolated and developed transfer learning framework</article-title>
          <source>International Journal of Intelligent Systems</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>185619-185628</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Aslam</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ramay</surname>
              <given-names>W. Y.</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2020.302963</pub-id>
          <article-title>Convolutional neural network-based classification of app reviews</article-title>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="webpage">
          <source>, https://www.kaggle.com/balnyaupane/pneumonia-chest-xray-dataset-200-by-200-image</source>
          <year>2021</year>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Barakat</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Awad</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Abu-Nabah</surname>
              <given-names>B.A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1177/20552076231180008</pub-id>
          <article-title>A machine learning approach on chest X-rays for pediatric pneumonia detection</article-title>
          <source>DIGITAL HEALTH</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>1-6</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Berrimi</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Hamdi</surname>
            </name>
            <name>
              <given-names>R. Y.</given-names>
              <surname>Cherif</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Moussaoui</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Oussalah</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Chabane</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/widstaif52235.2021.9430229</pub-id>
          <article-title>COVID-19 detection from Xray and CT scans using transfer learning</article-title>
          <source>, http://dx.doi.org/10.1109/WiDSTaif52235.2021.9430229</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>574-579</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>V.</given-names>
              <surname>Bhagat</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Bhaumik</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/iciip47207.2019.8985892</pub-id>
          <article-title>Data augmentation using generative adversarial networks for pneumonia classification in chest X-rays</article-title>
          <source>, http://dx.doi.org/10.1109/ICIIP47207.2019.8985892</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>559</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chouhan</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Khamparia</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Tiwari</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Moreira</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>DamaÅ¡eviÄius</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>de Albuquerque</surname>
              <given-names>Victor Hugo C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app10020559</pub-id>
          <article-title>A novel transfer learning based approach for pneumonia detection in chest X-ray Images</article-title>
          <source>Applied Sciences</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>121</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chow</surname>
              <given-names>L. S.</given-names>
            </name>
            <name>
              <surname>Tang</surname>
              <given-names>G. S.</given-names>
            </name>
            <name>
              <surname>Solihin</surname>
              <given-names>M. I.</given-names>
            </name>
            <name>
              <surname>Gowdh</surname>
              <given-names>N. M.</given-names>
            </name>
            <name>
              <surname>Ramli</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Rahmat</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s42979-022-01545-8</pub-id>
          <article-title>Quantitative and qualitative analysis of 18 deep convolutional neural network (CNN) models with transfer learning to diagnose COVID-19 on chest X-ray (CXR) images</article-title>
          <source>SN Computer Science</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>63</volume>
          <page-range>102142</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dhar</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Dutta</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mukherjee</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.bspc.2020.102142</pub-id>
          <article-title>Cross-wavelet assisted convolution neural network (AlexNet) approach for phonocardiogram signals classification</article-title>
          <source>Biomedical Signal Processing and Control</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>El Asnaoui</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Chawki</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Idri</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Automated methods for detection and classification pneumonia based on X-ray images using deep learning</article-title>
          <source>Artificial Intelligence and Blockchain for Future Cybersecurity Applications</source>
          <publisher-name>Cham: Springer International Publishing</publisher-name>
          <year>2021</year>
          <page-range>257-284</page-range>
          <pub-id pub-id-type="doi">10.1007/978-3-030-74575-214</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>137</volume>
          <page-range>104857</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Fu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compbiomed.2021.104857</pub-id>
          <article-title>Densely connected attention network for diagnosing COVID-19 based on chest CT</article-title>
          <source>Computers in Biology and Medicine</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>350-351</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>T.</given-names>
              <surname>Gabruseva</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Poplavskiy</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Kalinin</surname>
            </name>
          </person-group>
          <article-title>Deep learning for automatic pneumonia detection</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>81</volume>
          <page-range>30615-30645</page-range>
          <issue>21</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Haghanifar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Majdabadi</surname>
              <given-names>M. M.</given-names>
            </name>
            <name>
              <surname>Choi</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Deivalakshmi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ko</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-022-12156-z</pub-id>
          <article-title>COVID-CXNet: Detecting COVID-19 in frontal chest X-ray images using deep learning</article-title>
          <source>Multimedia Tools and Applications</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>2021</volume>
          <page-range>1-18</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hameed</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Bajwa</surname>
              <given-names>I. S.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Anwar</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Mushtaq</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Rashid</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2021/8814364</pub-id>
          <article-title>Integration of 5G and block-chain technologies in smart telemedicine using IoT</article-title>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>4080</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Harmon</surname>
              <given-names>Stephanie A.</given-names>
            </name>
            <name>
              <surname>Sanford</surname>
              <given-names>Thomas H.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Turkbey</surname>
              <given-names>Evrim B.</given-names>
            </name>
            <name>
              <surname>Roth</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Myronenko</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Anderson</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Amalou</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Blain</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kassin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Long</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Varble</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Walker</surname>
              <given-names>Stephanie M.</given-names>
            </name>
            <name>
              <surname>Bagci</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Ierardi</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Stellato</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Plensich</surname>
              <given-names>G. G.</given-names>
            </name>
            <name>
              <surname>Franceschelli</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Girlando</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Irmici</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Labella</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Hammoud</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Malayeri</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Summers</surname>
              <given-names>Ronald M.</given-names>
            </name>
            <name>
              <surname>Choyke</surname>
              <given-names>Peter L.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Flores</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Tamura</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Obinata</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Mori</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Patella</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Cariati</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Carrafiello</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>An</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Wood</surname>
              <given-names>Bradford J.</given-names>
            </name>
            <name>
              <surname>Turkbey</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s41467-020-17971-2</pub-id>
          <article-title>Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets</article-title>
          <source>Nature Communications</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>417</page-range>
          <issue>6</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hashmi</surname>
              <given-names>M. F.</given-names>
            </name>
            <name>
              <surname>Katiyar</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Keskar</surname>
              <given-names>A. G.</given-names>
            </name>
            <name>
              <surname>Bokde</surname>
              <given-names>N. D.</given-names>
            </name>
            <name>
              <surname>Geem</surname>
              <given-names>Z. W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/diagnostics10060417</pub-id>
          <article-title>Efficient pneumonia detection in chest X-ray images using deep transfer learning</article-title>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>8275-8290</page-range>
          <issue>10</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hurtik</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Molek</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Hula</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Vajgl</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Vlasanek</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Nejezchleba</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s00521-021-05978-9</pub-id>
          <article-title>Poly-YOLO: Higher speed, more precise detection and instance segmentation for YOLOv3</article-title>
          <source>Neural Computing and Applications</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Iparraguirre-Villanueva</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Guevara-Ponce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Paredes</surname>
              <given-names>O. R.</given-names>
            </name>
            <name>
              <surname>Sierra-LiÃ±an</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Zapata-Paulini</surname>
              <given-names>J. E.</given-names>
            </name>
            <name>
              <surname>Cabanillas-Carbonell</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Convolutional neural networks with transfer learning for pneumonia detection</article-title>
          <source>Int. J. Adv. Comput. Sci. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>59-75</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Iqbal</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Farooq</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ashraf</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Irshad</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.32350/bsr.0401.04</pub-id>
          <article-title>Prediction of breast cancer using machine learning techniques</article-title>
          <source>BioScientific Review</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>32</volume>
          <page-range>41-54</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Islam</surname>
              <given-names>S. R.</given-names>
            </name>
            <name>
              <surname>Maity</surname>
              <given-names>Santi P.</given-names>
            </name>
            <name>
              <surname>Ray</surname>
              <given-names>A. K.</given-names>
            </name>
            <name>
              <surname>Mandal</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1002/ima.22651</pub-id>
          <article-title>Deep learning on compressed sensing measurements in pneumonia detection</article-title>
          <source>International Journal of Imaging Systems and Technology</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>35</volume>
          <page-range>200-212</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Key</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Baygin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Demir</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Dogan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tuncer</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10278-022-00581-3</pub-id>
          <article-title>Meniscal tear and ACL injury detection model based on AlexNet and iterative ReliefF</article-title>
          <source>Journal of Digital Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>334â350</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Z.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Peng</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Yu</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Deng</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Sun</surname>
            </name>
          </person-group>
          <article-title>Detnet: Design backbone for object detection</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <volume>187</volume>
          <page-range>104964</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liang</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.cmpb.2019.06.023</pub-id>
          <article-title>A transfer learning method with deep residual network for pediatric pneumonia diagnosis</article-title>
          <source>Computer Methods and Programs in Biomedicine</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="conf-paper">
          <volume>11318</volume>
          <page-range>130-139</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>B. N.</given-names>
              <surname>Narayanan</surname>
            </name>
            <name>
              <given-names>V. S. P.</given-names>
              <surname>Davuluru</surname>
            </name>
            <name>
              <given-names>R. C.</given-names>
              <surname>Hardie</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1117/12.2547635</pub-id>
          <article-title>Two-stage deep learning architecture for pneumonia detection and its diagnosis in chest radiographs</article-title>
          <source>Medical Imaging 2020: Imaging Informatics for Healthcare, Research, and Applications</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="conference-proceedings">
          <volume>2</volume>
          <page-range>432-442</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Nasir</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Ahsan</surname>
            </name>
            <name>
              <given-names>N. et al.</given-names>
              <surname>Sarwar</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-981-15-5232-8_37</pub-id>
          <article-title>Classification and prediction analysis of diseases and other datasets using machine learning</article-title>
          <source>, http://doi.org/10.1007/978-981-15-5232-8_37</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>252-261</page-range>
          <issue>10</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Patel</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sojitra</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Bohara</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Pneumonia detection using transfer learning</article-title>
          <source>Int. J. Eng. Res. Tech.</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>147-152</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Phankokkruad</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3414274.3414496</pub-id>
          <article-title>COVID-19 pneumonia detection in chest X-ray images using transfer learning of convolutional neural networks</article-title>
          <source>, http://dx.doi.org/10.1145/3414274.3414496</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>3233</page-range>
          <issue>9</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rahman</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Chowdhury</surname>
              <given-names>Muhammad E. H.</given-names>
            </name>
            <name>
              <surname>Khandakar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Islam</surname>
              <given-names>Khandaker R.</given-names>
            </name>
            <name>
              <surname>Islam</surname>
              <given-names>Khandaker F.</given-names>
            </name>
            <name>
              <surname>Mahbub</surname>
              <given-names>Zaid B.</given-names>
            </name>
            <name>
              <surname>Kadir</surname>
              <given-names>Muhammad A.</given-names>
            </name>
            <name>
              <surname>Kashem</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app10093233</pub-id>
          <article-title>Transfer learning with deep convolutional neural network (CNN) for pneumonia detection using chest X-ray</article-title>
          <source>Applied Sciences</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <page-range>1711.05225</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rajpurkar</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Irvin</surname>
              <given-names>J. A.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>K. et al.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1711.05225</pub-id>
          <article-title>CheXNet: Radiologist-level pneumonia detection on chest X-rays with deep learning</article-title>
          <source>arXiv preprint arXiv</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <volume>2019</volume>
          <page-range>1-20</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ramzan</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Bajwa</surname>
              <given-names>I. S.</given-names>
            </name>
            <name>
              <surname>Jamil</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Amin</surname>
              <given-names>R. U.</given-names>
            </name>
            <name>
              <surname>Ramzan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mirza</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2019/5941096</pub-id>
          <article-title>An Intelligent Data Analysis for Recommendation Systems Using Machine Learning</article-title>
          <source>Scientific Programming</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="journal">
          <volume>2020</volume>
          <page-range>1-17</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saleem</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Bajwa</surname>
              <given-names>I. S.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Anwar</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Ashraf</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2020/8882378</pub-id>
          <article-title>IoT healthcare: Design of smart and cost-effective sleep quality monitoring system</article-title>
          <source>Journal of Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>703-718</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Salem</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Wen</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Backes</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Ma</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Zhang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/eurosp53844.2022.00049</pub-id>
          <article-title>Dynamic backdoor attacks against machine learning models</article-title>
          <source>, http://dx.doi.org/10.1109/EuroSP53844.2022.00049</source>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>3150</page-range>
          <issue>14</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sarwar</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Bajwa</surname>
              <given-names>I. S.</given-names>
            </name>
            <name>
              <surname>Jamil</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ramzan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s19143150</pub-id>
          <article-title>An intelligent fire warning application using IoT and an adaptive neuro-fuzzy inference system</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>78-93</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Noreen</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Irshad</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Development of the tumor diagnosis application for medical practitioners using transfer learning</article-title>
          <source>BioSci. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>144500-144515</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sattar</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Bajwa</surname>
              <given-names>I. S.</given-names>
            </name>
            <name>
              <surname>Amin</surname>
              <given-names>R. U.</given-names>
            </name>
            <name>
              <surname>Sarwar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Jamil</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Malik</surname>
              <given-names>M. G. Abbas</given-names>
            </name>
            <name>
              <surname>Mahmood</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shafi</surname>
              <given-names>U.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/access.2019.2940622</pub-id>
          <article-title>An IoT-based intelligent wound monitoring system</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="journal">
          <volume>81</volume>
          <page-range>8309-8316</page-range>
          <issue>6</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sethy</surname>
              <given-names>P. K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-022-12286-4</pub-id>
          <article-title>Identification of wheat tiller based on AlexNet-feature fusion</article-title>
          <source>Multimedia Tools and Applications</source>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Vardhan</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Makhnevich</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Omprakash</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Hirschorn</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Barish</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cohen</surname>
              <given-names>Stuart L.</given-names>
            </name>
            <name>
              <surname>Zanos</surname>
              <given-names>Theodoros P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1186/s42234-022-00103-0</pub-id>
          <article-title>A radiographic, deep transfer learning framework, adapted to estimate lung opacities from chest X-rays</article-title>
          <source>Bioelectronic Medicine</source>
        </element-citation>
      </ref>
      <ref id="ref_40">
        <label>40.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>1-6</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>D.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Arzhaeva</surname>
            </name>
            <name>
              <given-names>L. et al.</given-names>
              <surname>Devnath</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/DICTA51227.2020.9363416</pub-id>
          <article-title>Automated pneumoconiosis detection on chest X-rays using cascaded learning with real and synthetic radiographs.</article-title>
          <source>, https://doi.org/10.1109/DICTA51227.2020.9363416</source>
        </element-citation>
      </ref>
      <ref id="ref_41">
        <label>41.</label>
        <element-citation publication-type="journal">
          <volume>51</volume>
          <page-range>1010-1021</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zebin</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Rezvy</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10489-020-01867-1</pub-id>
          <article-title>COVID-19 detection and disease progression visualization: Deep learning on chest X-rays for classification and coarse localization</article-title>
          <source>Applied Intelligence</source>
        </element-citation>
      </ref>
      <ref id="ref_42">
        <label>42.</label>
        <element-citation publication-type="journal">
          <volume>181</volume>
          <page-range>1423-1433</page-range>
          <issue>6</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Sang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zha</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Ye</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Cai</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Cai</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yin</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Deng</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Wei</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Lau</surname>
              <given-names>J. Y.</given-names>
            </name>
            <name>
              <surname>Fok</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.cell.2020.04.045</pub-id>
          <article-title>Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography</article-title>
          <source>Cell</source>
        </element-citation>
      </ref>
      <ref id="ref_43">
        <label>43.</label>
        <element-citation publication-type="journal">
          <volume>109</volume>
          <page-range>43-76</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhuang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Qi</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Duan</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Xi</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Xiong</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>Q.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/jproc.2020.3004555</pub-id>
          <article-title>A comprehensive survey on transfer learning</article-title>
          <source>Proc. IEEE</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>