<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-O-XefG8MDA_0xx2fFkgy9tKRX-xHdEy1</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml030302</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Integrating Long Short-Term Memory and Multilayer Perception for an Intelligent Public Aﬀairs Distribution Model</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0000-2863-3801</contrib-id>
          <name>
            <surname>Fang</surname>
            <given-names>Hong</given-names>
          </name>
          <email>3502963417@qq.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4398-8728</contrib-id>
          <name>
            <surname>Peng</surname>
            <given-names>Minjing</given-names>
          </name>
          <email>peng.mj@wyu.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-9638-2427</contrib-id>
          <name>
            <surname>Du</surname>
            <given-names>Xiaotian</given-names>
          </name>
          <email>1139548637@qq.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-2329-6188</contrib-id>
          <name>
            <surname>Lin</surname>
            <given-names>Baisheng</given-names>
          </name>
          <email>bobbylinam@163.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-3573-2868</contrib-id>
          <name>
            <surname>Jiang</surname>
            <given-names>Mingjun</given-names>
          </name>
          <email>13424945449@163.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0008-2425-6306</contrib-id>
          <name>
            <surname>Hu</surname>
            <given-names>Jieyi</given-names>
          </name>
          <email>jykithu@163.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-7818-497X</contrib-id>
          <name>
            <surname>Long</surname>
            <given-names>Zhenjiang</given-names>
          </name>
          <email>353319754@qq.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0008-6344-6858</contrib-id>
          <name>
            <surname>Hu</surname>
            <given-names>Qiaoxian</given-names>
          </name>
          <email>roseywoo@foxmail.com</email>
        </contrib>
        <aff id="aff_1">Department of Economics and Management, Wuyi University, 529020 Jiangmen, China</aff>
        <aff id="aff_2">Department of Project Management Center, Jiangmen City Domain Social Wisdom Governance Technology Innovation Center, 529040 Jiangmen, China</aff>
        <aff id="aff_3">Jiangmen Jianghai District Branch, China Telecom Co. Ltd., 529030 Jiangmen, China</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>01</day>
        <month>08</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>3</issue>
      <fpage>148</fpage>
      <lpage>161</lpage>
      <page-range>148-161</page-range>
      <history>
        <date date-type="received">
          <day>07</day>
          <month>05</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>24</day>
          <month>07</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>In the realm of urban public affairs management, the necessity for accurate and intelligent distribution of resources has become increasingly imperative for effective social governance. This study, drawing on crime data from Chicago in 2022, introduces a novel approach to public affairs distribution by employing Long Short-Term Memory (LSTM), Multilayer Perceptron (MLP), and their integration. By extensively preprocessing textual, numerical, boolean, temporal, and geographical data, the proposed models were engineered to discern complex interrelations among multidimensional features, thereby enhancing their capability to classify and predict public affairs events. Comparative analysis reveals that the hybrid LSTM-MLP model exhibits superior prediction accuracy over the individual LSTM or MLP models, evidencing enhanced proficiency in capturing intricate event patterns and trends. The effectiveness of the model was further corroborated through a detailed examination of training and validation accuracies, loss trajectories, and confusion matrices. This study contributes a robust methodology to the field of intelligent public affairs prediction and resource allocation, demonstrating significant practical applicability and potential for widespread implementation.</p></abstract>
      <kwd-group>
        <kwd>Long Short-Term Memory</kwd>
        <kwd>Multilayer Perceptron</kwd>
        <kwd>Public affairs prediction</kwd>
        <kwd>Intelligent distribution</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="8"/>
        <fig-count count="11"/>
        <table-count count="3"/>
        <ref-count count="33"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>In today's era of information explosion, the frequent occurrence and rapid spread of public events pose severe challenges to social stability and public safety. Public events typically include natural disasters (such as earthquakes, floods and hurricanes), public health incidents (such as epidemic outbreaks), social security incidents (such as crime and violence), and sudden public safety incidents (such as fires and explosions) [<xref ref-type="bibr" rid="ref_1">1</xref>]. Among these, the timely and accurate distribution of affairs is crucial for decision-making and emergency response, especially in sudden public events [<xref ref-type="bibr" rid="ref_2">2</xref>].</p><p>In recent years, the development of machine learning technology, particularly the widespread application of deep learning, has provided substantial support for acquiring and utilizing public affairs information. Neural Networks (NNs), a form of machine learning based on the functionality of the human brain and its cognitive processing, have become one of the most powerful and accurate clustering technologies available today [<xref ref-type="bibr" rid="ref_3">3</xref>]. To effectively address the complex and diverse data features in public affairs, this study employs the LSTM and MLP models within NN technology.</p><p>Relevant studies have demonstrated that LSTM outperforms other statistical and machine learning methods [<xref ref-type="bibr" rid="ref_4">4</xref>]. It is renowned for its superior time-series processing capabilities and effectively captures time dependencies in data. Public events often have significant sequential characteristics. LSTM, through its unique memory units and gating mechanisms, can retain and manage important information flows over long periods, making it particularly adept at handling sequential data. MLP is a classical feedforward NN suitable for handling high-dimensional feature data and capturing complex feature relationships. Public affairs data usually include multidimensional features such as geographical location, event type, and related numerical indicators. MLP, through its multi-layer structure and nonlinear activation functions, can capture these complex relationships between features. Moreover, hybrid models are increasingly popular and widely applied across various fields [<xref ref-type="bibr" rid="ref_5">5</xref>]. For instance, the Convolutional LSTM (ConvLSTM) model, initially proposed for predicting rainfall intensity [<xref ref-type="bibr" rid="ref_6">6</xref>], has since been successfully applied in various fields such as predicting wind speed and direction [<xref ref-type="bibr" rid="ref_7">7</xref>], epidemic diagnosis [<xref ref-type="bibr" rid="ref_8">8</xref>] and crime prediction [<xref ref-type="bibr" rid="ref_9">9</xref>]. This demonstrates that the hybrid model can mitigate or eliminate the limitations of individual models by combining their advantages, further validating the broad applicability and practicality of hybrid models in addressing complex prediction tasks. Therefore, this study also proposes a hybrid model combining LSTM and MLP to fully utilize the strengths of both models, providing more comprehensive feature extraction and pattern recognition capabilities, thereby further enhancing model predictive performance and generalization capability.</p><p>This study details and compares the performance of the LSTM model, the MLP model, and the hybrid model combining LSTM and MLP in the task of public affairs distribution. Through experiments, the prediction accuracy and loss rates of each model were validated, analyzing their effectiveness and superiority in handling complex public affairs distribution tasks. Ultimately, this study aims to provide a novel, practically valuable solution for intelligent public affairs distribution, offering new ideas and technical support for public affairs management and optimization.</p><p>The structure of this study is as follows: the first part introduces the research background; the second part reviews related work, summarizing existing intelligent public affairs distribution technologies and methods; the third part describes the design and implementation of Word2Vec, LSTM, MLP, and the hybrid model; the fourth part elaborates on the experimental process; the fifth part conducts a result analysis, comparing the performance of each model; the sixth part summarizes this study; the seventh part discusses the shortcomings and improvements of the model in practical applications, as well as future research directions.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related work</title>
      
        <sec>
          
            <title>2.1. Application of deep learning in intelligent public affairs distribution</title>
          
          <p>Currently, an increasing number of scholars are utilizing deep learning to study intelligent public affairs distribution, including Convolutional Neural Networks (CNNs) [<xref ref-type="bibr" rid="ref_10">10</xref>] and Recurrent Neural Networks (RNNs) [<xref ref-type="bibr" rid="ref_11">11</xref>]. These technologies have shown immense potential in various fields.</p><p>In the field of natural disasters, deep learning is applied to predict and detect them in real time, aiding government departments in disaster management [<xref ref-type="bibr" rid="ref_12">12</xref>]. In public health, artificial intelligence (AI), machine learning, and deep learning technologies are widely used in epidemic prevention and control, enhancing the capability to respond to sudden health incidents [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. Additionally, in the realm of social security, integrated deep learning methods are used to enhance cybersecurity [<xref ref-type="bibr" rid="ref_15">15</xref>]. Deep learning models based on Swin Transformer are utilized to identify and analyze crowd behavior [<xref ref-type="bibr" rid="ref_16">16</xref>], ensuring social safety and stability. Lastly, in sudden public safety incidents, deep learning demonstrates its unique research value. Whether for traffic accidents [<xref ref-type="bibr" rid="ref_17">17</xref>], fires [<xref ref-type="bibr" rid="ref_18">18</xref>], or other emergencies, deep learning can rapidly and accurately analyze large amounts of data. It can conduct real-time monitoring and prediction, significantly improving the efficiency and effectiveness of emergency response.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Application of lstm and mlp in public affairs</title>
          
          <p>In public affairs management, the LSTM model, with its excellent sequential processing capabilities, can accurately predict the occurrence of public events, achieving timely warning through intelligent distribution [<xref ref-type="bibr" rid="ref_19">19</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>]. In disaster and emergency response, the combined application of CNN and Bidirectional LSTM (BiLSTM) can precisely identify key information from Twitter posts. This provides a critical base for emergency decision-making and assists relevant personnel in the reasonable allocation and dispatch of resources [<xref ref-type="bibr" rid="ref_21">21</xref>]. Furthermore, the LSTM model can effectively predict public sentiment changes during sudden public events. It improves prediction accuracy through the adaptive moment estimation (Adam) optimization algorithm, thereby guiding online public opinion and maintaining social stability [<xref ref-type="bibr" rid="ref_22">22</xref>]. The application of the LSTM model not only enhances the efficiency of public affairs management but also strengthens the capability to respond to sudden events.</p><p>The MLP model also demonstrates significant application value. For instance, by analyzing accident and weather data, the MLP model can accurately predict the severity of accidents, constructing automatic emergency braking systems to reduce traffic accidents [<xref ref-type="bibr" rid="ref_23">23</xref>]. Additionally, the MLP model shows high accuracy in predicting different types of crimes (such as theft and assault) [<xref ref-type="bibr" rid="ref_24">24</xref>]. In the field of epidemic prevention and control, the COVID-19 diagnosis model developed based on MLP-NN can effectively distinguish whether patients are infected with COVID-19, improving diagnostic accuracy and efficiency [<xref ref-type="bibr" rid="ref_25">25</xref>].</p><p>Meanwhile, the hybrid model combining LSTM and MLP is also applied in medical [<xref ref-type="bibr" rid="ref_26">26</xref>], transportation [<xref ref-type="bibr" rid="ref_27">27</xref>] and cybersecurity fields [<xref ref-type="bibr" rid="ref_28">28</xref>], but is still absent in the crime domain. Therefore, this study introduces the LSTM and MLP hybrid model into the crime prediction field. This study also explores and compares the performance of the LSTM model, MLP model, and LSTM+MLP hybrid model in crime prediction tasks, aiming to further improve and optimize the intelligent public affairs distribution system.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      <p>To achieve intelligent prediction and resource allocation of crime events, this study employs Word2Vec to transform textual data into vector representations and designs three different models: the LSTM model, the MLP model, and the LSTM+MLP hybrid model. These models predict crime data by capturing data features and patterns through different structures. Below is the detailed design of these components.</p>
      
        <sec>
          
            <title>3.1. Word2vec</title>
          
          <p>Current researchers have extensively studied Word2Vec and its applications in various fields, demonstrating its effectiveness in capturing semantic relationships between words. Recent studies have shown that Word2Vec can significantly improve the performance of natural language processing tasks by providing meaningful vector representations of words [<xref ref-type="bibr" rid="ref_29">29</xref>], [<xref ref-type="bibr" rid="ref_30">30</xref>]. Given its proven capability, Word2Vec has been widely adopted for tasks requiring detailed text analysis.</p><p>To effectively handle and represent the textual data in crime descriptions, Word2Vec was used in this study to convert words into dense vector representations. Word2Vec is a model used to map words into vector space, including two training strategies: Skip-gram and Continuous Bag of Words (CBOW). Skip-gram aims to predict the context words based on a given word, while CBOW predicts the current word based on its context words. Skip-gram is particularly useful for capturing detailed relationships between words, especially in situations where the context is sparse or varied. The Skip-gram model was adopted in this study because it is better suited for capturing the precise semantic relationships in the crime description texts, which often contain important nuances and context-specific information that need to be understood at a granular level.</p><p>In the Skip-gram model, given a word <inline-formula>
  <mml:math id="mcnmvcic5z">
    <mml:msub>
      <mml:mi>w</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula>, the model attempts to maximize the probability of the context words <inline-formula>
  <mml:math id="mwgqqis685">
    <mml:msub>
      <mml:mi>w</mml:mi>
      <mml:mrow>
        <mml:mi>t</mml:mi>
        <mml:mi>k</mml:mi>
        <mml:mo>−</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula>, ..., <inline-formula>
  <mml:math id="mmczybfgkw">
    <mml:msub>
      <mml:mi>w</mml:mi>
      <mml:mrow>
        <mml:mi>t</mml:mi>
        <mml:mi>k</mml:mi>
        <mml:mo>+</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula>, where $k$ is the window size. The Skip-gram model is trained through the following objective function:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mkmligk15g">
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mi>T</mml:mi>
                </mml:mfrac>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>t</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>T</mml:mi>
                </mml:munderover>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mo>≤</mml:mo>
                    <mml:mo>≤</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>≠</mml:mo>
                    <mml:mi>k</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mstyle scriptlevel="0">
                      <mml:mspace width="0.167em"/>
                    </mml:mstyle>
                    <mml:mn>0</mml:mn>
                  </mml:mrow>
                </mml:munder>
                <mml:mi>log</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>∣</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>w</mml:mi>
                    <mml:mrow>
                      <mml:mi>t</mml:mi>
                      <mml:mi>j</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>w</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where, $T<inline-formula>
  <mml:math id="mcsl2bgvun">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>P\left(w_{t+j}\right) \mid w_t<inline-formula>
  <mml:math id="m5vkn1eke7">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>w_{t+j}<inline-formula>
  <mml:math id="mag6cpnq7g">
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>w_t$. By maximizing this objective function, the Word2Vec model can learn the vector representation of each word.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Architecture of the lstm model</title>
          
          <p>LSTM is a special type of RNN proposed by Hochreiter and Schmidhuber [<xref ref-type="bibr" rid="ref_31">31</xref>] in 1997 to address the issues of gradient vanishing and explosion in traditional RNNs when processing long sequences. Recently, LSTM has achieved remarkable success in various time series data analysis fields, including speech recognition, natural language processing, financial market prediction and medical data analysis.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>LSTM principle</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_8-fm6O4RuLP0aPF2.png"/>
            </fig>
          
          <p>The core components of the LSTM network include three gates: the forget gate, the input gate and the output gate. These gates control the forgetting, inflow, and output of information, respectively, thereby dynamically adjusting the state in the memory unit. The principle of LSTM is shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>.</p><p>The function of the forget gate is to decide which information to forget from the memory unit. By using the sigmoid activation function, the output is a value between 0 and 1 , where 1 means “completely keep” and 0 means “completely discard.” The forget gate <inline-formula>
  <mml:math id="m72rjv0oxv">
    <mml:msub>
      <mml:mi>f</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula>, weights <inline-formula>
  <mml:math id="mflym94adc">
    <mml:msub>
      <mml:mi>W</mml:mi>
      <mml:mi>f</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and bias <inline-formula>
  <mml:math id="m63i6jrh9n">
    <mml:msub>
      <mml:mi>b</mml:mi>
      <mml:mi>f</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are used, with the hidden state <inline-formula>
  <mml:math id="m4gqy8q6fi">
    <mml:msub>
      <mml:mi>h</mml:mi>
      <mml:mrow>
        <mml:mi>t</mml:mi>
        <mml:mo>−</mml:mo>
        <mml:mn>1</mml:mn>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> and current input <inline-formula>
  <mml:math id="mun4yvgbg6">
    <mml:msub>
      <mml:mi>x</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula>.</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="mv6qu65b3g">
                <mml:msub>
                  <mml:mi>f</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>σ</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>f</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>f</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The input gate determines which new information will be stored in the memory unit. It consists of two parts: the sigmoid activation function, which decides the update portion, and the tanh activation function, which generates candidate values. The input gate <inline-formula>
  <mml:math id="mahrfnalp0">
    <mml:msub>
      <mml:mi>i</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and candidate memory unit <inline-formula>
  <mml:math id="m4zihqod2n">
    <mml:msub>
      <mml:mrow>
        <mml:mover>
          <mml:mi>C</mml:mi>
          <mml:mo>~</mml:mo>
        </mml:mover>
      </mml:mrow>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are calculated as follows:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mdx1k74k6s">
                <mml:msub>
                  <mml:mi>i</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>σ</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="majhwj45ka">
                <mml:msub>
                  <mml:mrow>
                    <mml:mover>
                      <mml:mi>C</mml:mi>
                      <mml:mo>~</mml:mo>
                    </mml:mover>
                  </mml:mrow>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>⁡</mml:mo>
                <mml:mi>tanh</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>C</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>c</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The memory unit, which is the core of LSTM, can retain information over long periods in a time series. It interacts through the forget gate and input gate, allowing it to selectively remember or forget information. The next cell state <inline-formula>
  <mml:math id="mylsj6mckf">
    <mml:msub>
      <mml:mi>C</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is given as follows:</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="m95h605aom">
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>f</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mrow>
                    <mml:mi>t</mml:mi>
                    <mml:mo>−</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mi>i</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>∗</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>∗</mml:mo>
                <mml:mrow>
                  <mml:mover>
                    <mml:msub>
                      <mml:mi>C</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                    <mml:mo>~</mml:mo>
                  </mml:mover>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The output gate decides the next hidden state (i.e., the output at the next time step). Firstly, the output gate uses the sigmoid activation function to determine which parts of the memory unit will be output. Then, this value is multiplied by the tanh-activated memory unit value to get the final output. The output gate <inline-formula>
  <mml:math id="mbilv0ulcl">
    <mml:msub>
      <mml:mi>o</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and next hidden state <inline-formula>
  <mml:math id="mhfiy5n35d">
    <mml:msub>
      <mml:mi>h</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are given as follows:</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="munx37tymh">
                <mml:msub>
                  <mml:mi>o</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>σ</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>o</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>o</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="mn57dbmxln">
                <mml:msub>
                  <mml:mi>h</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>o</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>∗</mml:mo>
                <mml:mo>⁡</mml:mo>
                <mml:mi>tanh</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>C</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>Through these well-designed gates and memory units, LSTM achieves precise control of information, enabling it to capture complex dependencies and long-term dependencies in sequences, significantly outperforming traditional RNNs. Therefore, this study uses the LSTM model to predict crime events, with the specific structure shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref>. </p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Structure of the LSTM model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_R8lapD4vnFWZjpud.png"/>
            </fig>
          
          <p>The preprocessing involves converting textual data into dense vector representations using Word2Vec and integrating numerical, boolean, temporal, and geographical features into a PyTorch tensor. The processed data is fed into the LSTM model's input layer. The LSTM layer captures sequential dependencies and time-series features through its memory cells and gates, effectively managing the flow of information. The hidden layer further refines these features, and the final output of the LSTM layer aggregates all sequential information. This output is passed through a final layer, mapping the aggregated information to the target prediction, thus forecasting crime events. This structure enables the LSTM to utilize diverse features and capture complex temporal patterns, making it suitable for intelligent crime prediction.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Architecture of the mlp model</title>
          
          <p>MLP is widely used in classification and regression tasks [<xref ref-type="bibr" rid="ref_32">32</xref>]. It consists of an input layer, multiple hidden layers, and an output layer, where each node in a layer is connected to all nodes in the previous layer, forming a fully connected layer. By applying nonlinear activation functions, MLP can capture complex feature relationships, making it suitable for handling high-dimensional static feature data. The principle of MLP is shown in <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>MLP principle</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_TuzhCopSbgrCqEim.png"/>
            </fig>
          
          <p>Assuming the input layer is represented by vector $X<inline-formula>
  <mml:math id="mbve1rflae">
    <mml:mo>,</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>f\left(W_1 X+b_1\right)<inline-formula>
  <mml:math id="m264z0l97k">
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>W_1<inline-formula>
  <mml:math id="mooyg05teh">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>b_1<inline-formula>
  <mml:math id="mm59amfg04">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>f<inline-formula>
  <mml:math id="mypnfeipl1">
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>L</mml:mi>
    <mml:mi>U</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>f(x)=\max (0, x)<inline-formula>
  <mml:math id="m9s97jdtac">
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mi>F</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>x</mml:mi>
  </mml:math>
</inline-formula>\left(W_2 X_1+b_2\right)<inline-formula>
  <mml:math id="m0okogq33k">
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>W_2<inline-formula>
  <mml:math id="mbgxhszn5n">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>X_1<inline-formula>
  <mml:math id="mg3knt64kz">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>b_2$ is the bias of the output layer.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Structure of the MLP model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_vKC_qR_POeVAfsWR.png"/>
            </fig>
          
          <p>Based on the above principles, the specific structure of the MLP model used to predict crime events is shown in <xref ref-type="fig" rid="fig_4">Figure 4</xref>. As with the LSTM model structure, the preprocessing step involves converting textual data into dense vector representations using Word2Vec and integrating numerical, boolean, temporal, and geographical features into a unified PyTorch tensor. The processed data is then fed into the MLP model's input layer. The MLP model consists of an input layer, two hidden layers with ReLU activation functions, and an output layer. The input layer receives the combined features and passes them through the first hidden layer, where ReLU activation introduces non-linearity and helps capture complex patterns in the data. The data then flows into the second hidden layer, which also employs ReLU activation to further refine the learned features. The output from the second hidden layer is finally passed to the output layer, which generates the predictions for the crime events.</p><p>This structure allows the MLP model to effectively utilize the processed features, leveraging its multiple layers and ReLU activations to capture intricate relationships within the data, making it a robust tool for intelligent crime prediction.</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Architecture of the lstm+mlp hybrid model</title>
          
          <p>The LSTM+MLP hybrid model combines the advantages of LSTM and MLP to handle two different types of input data: text data and other feature data. The model structure is shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>.</p><p>Research has shown that utilizing Word2Vec and LSTM to process text features can significantly enhance the effectiveness of text processing tasks [<xref ref-type="bibr" rid="ref_33">33</xref>]. Consequently, this study employs LSTM to handle text data. The output of the last time step of the LSTM was extracted as a high-level feature representation of the text data, ensuring the comprehensiveness and temporal dependency of the information. Simultaneously, the MLP was used to process other feature data. The MLP consists of two hidden layers, and employs the ReLU activation function to enhance nonlinearity. The design of these two components remains consistent with their individual model structures, simplifying the process of hyperparameter tuning and enhancing the interpretability and comparability of the model. Finally, the feature representations from the LSTM and MLP were concatenated to form a comprehensive feature vector. This vector was then mapped to the output through a fully connected layer to achieve the final prediction.</p><p>By integrating the strengths of both LSTM and MLP, this hybrid model is able to effectively leverage sequential dependencies in the text data and complex patterns in the other feature data, resulting in a robust and accurate predictive model for intelligent crime prediction.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>Structure of the LSTM+MLP model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_u5GmPpPt3iD98YTX.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Experiment</title>
      
        <sec>
          
            <title>4.1. Data processing</title>
          
          <p>The data used in this study was sourced from the publicly available crime records database of the city of Chicago, focusing on crime records from 2022. The dataset contained 219,042 crime records, covering information such as the time, location, and type of crime. The specific field descriptions are provided in <xref ref-type="table" rid="table_1">Table 1</xref>. To ensure data quality and meet model requirements, operations such as deduplication, missing value imputation, and standardization were performed on the data.</p><p>(a) Duplicate records were identified and removed to ensure each record is unique.</p><p>(b) Columns with many missing values were deleted. Columns with a few missing values were handled using interpolation.</p><p>(c) Numerical features (IUCR, Beat, District, Community_Area) were standardized to eliminate the influence of different feature value ranges on model training.</p><p>(d) Boolean features (Arrest, Domestic) were converted to integer values 0 and 1 to facilitate model processing and calculation.</p><p>(e) In this study, the label field is FBI_Code, representing different types of crimes. According to the conversion rules provided in <xref ref-type="table" rid="table_2">Table 2</xref>, the 26 crime types in FBI_Code were mapped to integers 0 to 25. This conversion process not only simplifies the data format but also assists subsequent machine learning models in recognizing and handling labels. Additionally, <xref ref-type="table" rid="table_2">Table 2</xref> provides a clear understanding of the distribution of various crime types, which is useful for subsequent data analysis and model tuning.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Data field description</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Attribute</p></td><td colspan="1" rowspan="1"><p>Description</p></td></tr><tr><td colspan="1" rowspan="1"><p>ID</p></td><td colspan="1" rowspan="1"><p>Unique identifier of the crime event</p></td></tr><tr><td colspan="1" rowspan="1"><p>Case_Number</p></td><td colspan="1" rowspan="1"><p>Case number</p></td></tr><tr><td colspan="1" rowspan="1"><p>Date</p></td><td colspan="1" rowspan="1"><p>Date and time the crime occurred</p></td></tr><tr><td colspan="1" rowspan="1"><p>Block</p></td><td colspan="1" rowspan="1"><p>Block where the crime occurred</p></td></tr><tr><td colspan="1" rowspan="1"><p>IUCR</p></td><td colspan="1" rowspan="1"><p>Crime report code</p></td></tr><tr><td colspan="1" rowspan="1"><p>Primary_Type</p></td><td colspan="1" rowspan="1"><p>The primary category of the crime</p></td></tr><tr><td colspan="1" rowspan="1"><p>Description</p></td><td colspan="1" rowspan="1"><p>A detailed description of the crime</p></td></tr><tr><td colspan="1" rowspan="1"><p>Location_Description</p></td><td colspan="1" rowspan="1"><p>Description of the crime location</p></td></tr><tr><td colspan="1" rowspan="1"><p>Arrest</p></td><td colspan="1" rowspan="1"><p>Whether there was an arrest</p></td></tr><tr><td colspan="1" rowspan="1"><p>Domestic</p></td><td colspan="1" rowspan="1"><p>Whether it was a domestic crime</p></td></tr><tr><td colspan="1" rowspan="1"><p>Beat</p></td><td colspan="1" rowspan="1"><p>Police patrol area number</p></td></tr><tr><td colspan="1" rowspan="1"><p>District</p></td><td colspan="1" rowspan="1"><p>Police district number</p></td></tr><tr><td colspan="1" rowspan="1"><p>Ward</p></td><td colspan="1" rowspan="1"><p>City council ward number</p></td></tr><tr><td colspan="1" rowspan="1"><p>Community_Area</p></td><td colspan="1" rowspan="1"><p>Community area number</p></td></tr><tr><td colspan="1" rowspan="1"><p>FBI_Code</p></td><td colspan="1" rowspan="1"><p>FBI-defined crime type</p></td></tr><tr><td colspan="1" rowspan="1"><p>Latitude</p></td><td colspan="1" rowspan="1"><p>Latitude of the crime location</p></td></tr><tr><td colspan="1" rowspan="1"><p>Longitude</p></td><td colspan="1" rowspan="1"><p>Longitude of the crime location</p></td></tr><tr><td colspan="1" rowspan="1"><p>Location</p></td><td colspan="1" rowspan="1"><p>Combined geographical location description</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>FBI_Code data conversion rule</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Original Data</p></td><td colspan="1" rowspan="1"><p>Converted Data</p></td><td colspan="1" rowspan="1"><p>Sample Size</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>50077</p></td></tr><tr><td colspan="1" rowspan="1"><p>27</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>16476</p></td></tr><tr><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>1532</p></td></tr><tr><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>11662</p></td></tr><tr><td colspan="1" rowspan="1"><p>28</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>31851</p></td></tr><tr><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>636</p></td></tr><tr><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>25237</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>7024</p></td></tr><tr><td colspan="1" rowspan="1"><p>26</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>14423</p></td></tr><tr><td colspan="1" rowspan="1"><p>30</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>7114</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>19269</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>1625</p></td></tr><tr><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>13</p></td></tr><tr><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>8461</p></td></tr><tr><td colspan="1" rowspan="1"><p>22</p></td><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>195</p></td></tr><tr><td colspan="1" rowspan="1"><p>29</p></td><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>6848</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>8299</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>18</p></td><td colspan="1" rowspan="1"><p>393</p></td></tr><tr><td colspan="1" rowspan="1"><p>110</p></td><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>670</p></td></tr><tr><td colspan="1" rowspan="1"><p>18</p></td><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>3711</p></td></tr><tr><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>21</p></td><td colspan="1" rowspan="1"><p>2143</p></td></tr><tr><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>22</p></td><td colspan="1" rowspan="1"><p>1027</p></td></tr><tr><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>23</p></td><td colspan="1" rowspan="1"><p>66</p></td></tr><tr><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>278</p></td></tr><tr><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>25</p></td><td colspan="1" rowspan="1"><p>10</p></td></tr><tr><td colspan="1" rowspan="1"><p>111</p></td><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>2</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>4.2. Feature extraction</title>
          
          <p>In this study, various features were extracted from the crime data to provide comprehensive information for model training. These features include time features, geographical features, and text features.</p>
          
            <sec>
              
                <title>4.2.1 Time features</title>
              
              <p>Temporal features can reflect the time distribution patterns of criminal behavior. The recorded crime timestamp (Date) was converted to date-time format, and four key temporal features were extracted: year, month, day, and hour. Finally, all extracted temporal features were standardized to ensure model validity.</p>
            </sec>
          
          
            <sec>
              
                <title>4.2.2 Geographical features</title>
              
              <p>Geographical features help identify crime hotspots and provide geographical information. This study extracted longitude and latitude information (Longitude, Latitude), community area number (Community_Area), police district number (District), and other relevant information to help the model recognize crime patterns and trends in specific areas. Additionally, to ensure consistent feature weights during model training, location features were standardized.</p>
            </sec>
          
          
            <sec>
              
                <title>4.2.3 Text features</title>
              
              <p>Text features provide information on crime types and specific details. This study extracted the primary category (Primary_Type) and detailed description (Description) from the dataset and used the Word2Vec model to convert them into vector representations, capturing semantic relationships between text features. During training, the vector dimension was set to 100, the window size to 5, the minimum word frequency to 1, and the number of parallel processing threads to 4, ensuring effective capture of semantic information in text features. After training, each text feature was converted into a vector representation, and these vectors were combined into the original feature set, generating text feature representations rich in semantic information.</p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>4.3. Data partitioning</title>
          
          <p>The dataset was divided into a training set and a validation set, with 80% of the data allocated for training and the remaining 20% for validation. This partitioning ensures that the model can learn from the training data while using the validation data for performance evaluation and hyperparameter tuning, thereby verifying the model's generalization ability. The training set was primarily utilized for learning model parameters, whereas the validation set was used to evaluate the model's performance on unseen data. The results from the validation set were then employed to adjust the model's hyperparameters to optimize its performance.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Hyperparameter tuning</title>
          
          <p>This study selected appropriate hyperparameters for training the LSTM model, MLP model, and LSTM+MLP hybrid model to optimize their performance for intelligent crime prediction. </p><p>For the LSTM model, the hidden layer dimension was set to 64 units, balancing model complexity and computational efficiency, and capturing temporal dependencies in the data. The MLP model employs two hidden layers, each with 64 neurons, using ReLU activation functions to introduce non-linearity and capture complex patterns. The LSTM+MLP hybrid model has an LSTM component with an input dimension of 100 and a hidden layer dimension of 64 units, capturing temporal dependencies. The MLP component consists of two hidden layers, each with 64 neurons and ReLU activation functions, to process other features.</p><p>To ensure uniformity and facilitate performance comparison, the models were configured with consistent hyperparameters. The cross-entropy loss function was used as the loss function, a common loss function in classification problems, which effectively measures the difference between the model's predicted values and the true labels. The Adam optimizer was selected as the optimizer, which combines the advantages of momentum and adaptive learning rate, enabling quick convergence and avoiding local optima. The learning rate was set to 0.001, and the number of training epochs was set to 50, ensuring the model was sufficiently trained while avoiding overfitting and improving generalization ability.</p><p>By standardizing these hyperparameters, the study aims to create a controlled environment for evaluating the effectiveness of each model in leveraging the processed features for accurate crime prediction. This approach ensures that any differences in model performance are attributable to the model architectures themselves, rather than variations in hyperparameter settings.</p>
        </sec>
      
      
        <sec>
          
            <title>4.5. Training steps</title>
          
          <p>During model training, lists for storing training and validation accuracy and loss were initialized, and the number of training epochs was set. In each training epoch, the model enters training mode, performing forward propagation and loss calculation by iterating through the training dataset, followed by backpropagation to update model parameters. Additionally, the loss and correct prediction count for each batch were accumulated to calculate the overall training loss and accuracy. Next, the model switches to evaluation mode, iterating through the validation dataset without gradient calculation to perform forward propagation and loss calculation, similarly accumulating the loss and correct prediction count for each batch to calculate the average validation loss and accuracy. At the end of each training epoch, the training and validation loss and accuracy were recorded and output to monitor the model's training process and performance.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Experimental results and analysis</title>
      
        <sec>
          
            <title>5.1. Analysis of accuracy and loss</title>
          
          <p>The performance of the LSTM model, MLP model and LSTM+MLP hybrid model in crime prediction tasks in this experiment was compared. The analysis of accuracy and loss rates on the training and validation sets for each model is presented below.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Accuracy and loss rates</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>Training Accuracy</p></td><td colspan="1" rowspan="1"><p>Validation Accuracy</p></td><td colspan="1" rowspan="1"><p>Training Loss</p></td><td colspan="1" rowspan="1"><p>Validation Loss</p></td></tr><tr><td colspan="1" rowspan="1"><p>LSTM</p></td><td colspan="1" rowspan="1"><p>0.9668</p></td><td colspan="1" rowspan="1"><p>0.9647</p></td><td colspan="1" rowspan="1"><p>0.0788</p></td><td colspan="1" rowspan="1"><p>0.0870</p></td></tr><tr><td colspan="1" rowspan="1"><p>MLP</p></td><td colspan="1" rowspan="1"><p>0.9671</p></td><td colspan="1" rowspan="1"><p>0.9666</p></td><td colspan="1" rowspan="1"><p>0.0773</p></td><td colspan="1" rowspan="1"><p>0.0851</p></td></tr><tr><td colspan="1" rowspan="1"><p>LSTM + MLP</p></td><td colspan="1" rowspan="1"><p>0.9719</p></td><td colspan="1" rowspan="1"><p>0.9714</p></td><td colspan="1" rowspan="1"><p>0.0584</p></td><td colspan="1" rowspan="1"><p>0.0608</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The LSTM model performs well on both the training and validation sets. As shown in <xref ref-type="table" rid="table_3">Table 3</xref>, the highest training accuracy reaches 0.9668, with the lowest training loss of 0.0788. The highest validation accuracy is 0.9647, and the lowest validation loss is 0.0870. <xref ref-type="fig" rid="fig_6">Figure 6</xref> shows that the training accuracy and loss curves of the LSTM model stabilize after the initial few epochs. However, the validation accuracy curve shows some fluctuations, and the validation loss curve fluctuates slightly more than the training loss, indicating slight overfitting.</p>
          
            <fig id="fig_6">
              <label>Figure 6</label>
              <caption>
                <title>Training and validation accuracy and loss (LSTM)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_wvF2i3EDJFWQHj7D.png"/>
            </fig>
          
          <p>The MLP model also performs well, with the highest training accuracy reaching 0.9671 and the lowest training loss being 0.0773. The highest validation accuracy is 0.9666, and the lowest validation loss is 0.0851. As shown in <xref ref-type="fig" rid="fig_7">Figure 7</xref>, the training accuracy curve of the MLP model is similar to that of the LSTM model, stabilizing after a rapid increase. The validation accuracy and loss curves of the MLP model fluctuate slightly less than those of the LSTM model, indicating that the MLP model's simpler structure leads to more stable performance on the validation set.</p>
          
            <fig id="fig_7">
              <label>Figure 7</label>
              <caption>
                <title>Training and validation accuracy and loss (MLP)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_rfMLfeXiorEBBKaz.png"/>
            </fig>
          
          <p>The LSTM+MLP hybrid model performs best on both the training and validation sets. Its highest training accuracy reaches 0.9719, with the lowest training loss being 0.0584. The highest validation accuracy is 0.9714, and the lowest validation loss is 0.0608. As shown in <xref ref-type="fig" rid="fig_8">Figure 8</xref>, the hybrid model achieves the highest accuracy and the lowest loss during training and validation, with very stable training and validation loss curves, indicating that the model not only has strong learning ability but also good generalization ability, effectively avoiding overfitting. The hybrid model combines the ability of LSTM to capture text data features and the ability of MLP to process structured data, making full use of data features and performing best in crime prediction tasks.</p>
          
            <fig id="fig_8">
              <label>Figure 8</label>
              <caption>
                <title>Training and validation accuracy and loss (LSTM+MLP)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_knC586zgJgq-1DW-.png"/>
            </fig>
          
          <p>Overall, the LSTM+MLP hybrid model performs best in this experiment, demonstrating its effectiveness and stability in handling complex data features. This model's comprehensive performance makes it suitable for intelligent public affairs distribution tasks requiring high accuracy and good generalization ability.</p>
        </sec>
      
      
        <sec>
          
            <title>5.2. Confusion matrix analysis</title>
          
          <p>In this study, the impact of different models on the task of crime type distribution was thoroughly compared by plotting confusion matrices for the top 10 most frequent crime types, as shown in <xref ref-type="fig" rid="fig_9">Figure 9</xref>, <xref ref-type="fig" rid="fig_10">Figure 10</xref>, and <xref ref-type="fig" rid="fig_11">Figure 11</xref>. The results show that all three models exhibit fairly high classification accuracy overall but demonstrate certain differences in performance when dealing with specific categories.</p><p>Notably, the classification performance for categories 8 and 1 is less satisfactory across all models, exhibiting relatively lower accuracy compared to other categories. Specifically, the hybrid model, despite leveraging the strengths of LSTM and MLP, achieves only 0.84 and 0.85 in accuracy in categories 8 and 1, respectively. In comparison, the LSTM model performs slightly better in category 8, reaching an accuracy of 0.91, but drops to 0.81 in category 1. The MLP model achieves 0.85 and 0.82 in accuracy in these two categories, respectively. These results indicate that the data features of these two crime types may be more complex and overlapping, challenging the models' discriminative abilities.</p><p>Consequently, further exploration of the intrinsic characteristics of these two crime types is necessary to develop more effective feature representation methods. Innovations and optimizations in model architecture, learning algorithms, and data preprocessing are required to enhance the models' discriminative power and generalization performance in complex, overlapping feature spaces.</p>
          
            <fig id="fig_9">
              <label>Figure 9</label>
              <caption>
                <title>Confusion matrix with accuracy for the top 10 classes (LSTM)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_ZS6QUmoOR9GeXDb0.png"/>
            </fig>
          
          
            <fig id="fig_10">
              <label>Figure 10</label>
              <caption>
                <title>Confusion matrix with accuracy for the top 10 classes (MLP)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_nwhMNBLljNparZf0.png"/>
            </fig>
          
          
            <fig id="fig_11">
              <label>Figure 11</label>
              <caption>
                <title>Confusion matrix with accuracy for the top 10 classes (LSTM+MLP)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_ceLm6OPRtycJuyFD.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>5.3. Summary of experimental results</title>
          
          <p>In this experiment, a comparative analysis of the LSTM model, MLP model, and LSTM+MLP hybrid model reveals that the LSTM+MLP hybrid model performs best in handling complex time-series data and nonlinear mappings. It demonstrates higher training and validation accuracy, coupled with lower loss rates, indicating its overall superiority over single models. Additionally, the confusion matrix analysis shows that while all three models achieve high classification accuracy across most categories, they exhibit lower accuracy in certain complex categories. This suggests that the data features of these categories may be more intricate or overlapping, thereby affecting the models' discriminative abilities. Overall, the LSTM+MLP hybrid model exhibits better performance, yet further optimization is necessary to enhance classification capabilities in specific complex categories. This could involve refining model architectures, improving learning algorithms, and developing advanced data preprocessing techniques to better address the challenges presented by complex, overlapping feature spaces.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Conclusion</title>
      <p>This study aims to enhance the precision of intelligent public affairs distribution. Utilizing crime data from Chicago in 2022, three different machine learning models were proposed and compared in this study, i.e., the LSTM model, the MLP model, and a hybrid model combining both. Through comprehensive data preprocessing, the models effectively capture the complex relationships among textual, numerical, boolean, temporal, and geographical features, ultimately achieving efficient classification and prediction of public affairs events. Experimental results indicate that the LSTM+MLP hybrid model outperforms the individual models in terms of accuracy and loss rates, exhibiting greater stability during both training and validation phases. This suggests that the hybrid model has a significant advantage in capturing complex patterns and trends in public affairs. However, the confusion matrix analysis reveals that, despite overall good performance, the prediction accuracy for certain complex categories (e.g., categories 8 and 1) remains low, suggesting that the model needs improvement in handling specific categories.</p>
    </sec>
    <sec sec-type="">
      <title>7. Strategies for enhancement and future directions</title>
      <p>To address the challenges in practical applications, the primary issue of data imbalance must be resolved. This can be effectively managed through the implementation of oversampling techniques, employing Generative Adversarial Networks (GANs) to generate samples for minority classes, and adjusting class weights during model training to balance class distribution. It is also paramount to optimize feature engineering. Integrating contextual features and developing sophisticated feature combinations can significantly enhance the model's ability to capture and analyze critical information. Moreover, in terms of model architecture, adding more hidden layers and incorporating attention mechanisms can improve the overall predictive performance and flexibility of the model. During the model deployment phase, it is essential to establish robust performance monitoring mechanisms to ensure stability and accuracy in real-world applications. Iterative optimizations based on continuous feedback are necessary for maintaining and enhancing the model's performance. Furthermore, it is important to adhere to ethical and legal requirements, thereby ensuring privacy protection during data processing and enhancing the model's fairness to avoid bias against different groups.</p><p>Future research should focus on further optimizing the model and integrating more data sources. The model's performance in practical applications can be improved by introducing more advanced deep learning technologies and algorithms. Additionally, extensive testing on different types of public affairs datasets, such as natural disaster data and public health incident data, is necessary to verify the model's generalization ability and robustness. Continuous refinement of data preprocessing methods and model architectures, tailored to specific business needs, will enhance the model's practicality and reliability. This approach will ultimately lead to efficient management and precise prediction in intelligent public affairs distribution systems. Through these efforts, intelligent public affairs distribution systems will be able to more accurately predict and allocate resources, improving social governance efficiency and achieving the goal of intelligent management.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      <p>This work was funded by the Guangdong Key Area R&amp;D Program (Grant No.: 2023B1111040001); National Natural Science Foundation of China (Grant No.: 71942003).</p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Williams</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Kemp</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Porter</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Healing</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Drury</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <source>Major Incidents, Pandemics and Mental Health: The Psychosocial Aspects of Health Emergencies, Incidents, Disasters and Disease Outbreaks</source>
          <publisher-name>Cambridge University Press</publisher-name>
          <year>2024</year>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Pine</surname>
              <given-names>J. C.</given-names>
            </name>
          </person-group>
          <source>Technology and Emergency Management</source>
          <publisher-name>John Wiley &amp; Sons</publisher-name>
          <year>2017</year>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mena</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <source>Machine Learning Forensics for Law Enforcement, Security, and Intelligence</source>
          <publisher-name>CRC Press</publisher-name>
          <year>2011</year>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>46</volume>
          <page-range>102809</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.frl.2022.102809</pub-id>
          <article-title>Carbon price prediction models based on online news information analytics</article-title>
          <source>Financ. Res. Lett.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>113</volume>
          <page-range>4055-4097</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Azevedo</surname>
              <given-names>B. F.</given-names>
            </name>
            <name>
              <surname>Rocha</surname>
              <given-names>A. M. A. C.</given-names>
            </name>
            <name>
              <surname>Pereira</surname>
              <given-names>A. I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10994-023-06467-x</pub-id>
          <article-title>Hybrid approaches to optimization and machine learning methods: A systematic literature review</article-title>
          <source>Mach. Learn.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shi</surname>
              <given-names>Xing Jian</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Zhou Rong</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Hao</given-names>
            </name>
            <name>
              <surname>Yeung</surname>
              <given-names>Dit Yan</given-names>
            </name>
            <name>
              <surname>Wong</surname>
              <given-names>Wai Kin</given-names>
            </name>
            <name>
              <surname>Woo</surname>
              <given-names>Wang Chun</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1506.04214</pub-id>
          <article-title>Convolutional LSTM network: A machine learning approach for precipitation nowcasting</article-title>
          <source>arXiv:1506.04214</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sari</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Yasuno</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Prasetya</surname>
              <given-names>D. A.</given-names>
            </name>
            <name>
              <surname>Al Haromainy</surname>
              <given-names>M. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ITIS59651.2023.10420216</pub-id>
          <article-title>Forecasting system of wind speed and direction by neural network</article-title>
          <source>2023 IEEE 9th Information Technology International Seminar (ITIS), Batu Malang, Indonesia</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>2250058</page-range>
          <issue>3</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>Yu Hao</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>Xian Wei</given-names>
            </name>
            <name>
              <surname>Miao</surname>
              <given-names>Qing</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1142/S0219691322500588</pub-id>
          <article-title>TFA-CLSTMNN: Novel convolutional network for sound-based diagnosis of COVID-19</article-title>
          <source>Int. J. Wavelets, Multiresolution Inf. Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1321-1326</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>K</surname>
              <given-names>J. T.</given-names>
            </name>
            <name>
              <surname>J</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>S</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICEARS56392.2023.10085123</pub-id>
          <article-title>A survey on prediction of risk related to theft activities in municipal areas using deep learning</article-title>
          <source>2023 Second International Conference on Electronics and Renewable Systems (ICEARS), Tuticorin, India</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>190-199</page-range>
          <issue>4</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lei</surname>
              <given-names>Han Lu</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Hu</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Lin Li</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>Yu Hang</given-names>
            </name>
            <name>
              <surname>Cheng</surname>
              <given-names>Jing Jie</given-names>
            </name>
            <name>
              <surname>Cai</surname>
              <given-names>Kui</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.4236/jcc.2023.114009</pub-id>
          <article-title>An analysis of the evolution of online public opinion on public health emergencies by combining CNN-BiLSTM+ attention and LDA</article-title>
          <source>J. Comput. Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>1-25</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kadri</surname>
              <given-names>Fethi</given-names>
            </name>
            <name>
              <surname>Abdennbi</surname>
              <given-names>Khalid</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1504/IJDS.2020.10031621</pub-id>
          <article-title>RNN-based deep-learning approach to forecasting hospital system demands: Application to an emergency department</article-title>
          <source>Int. J. Data Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-8</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nunavath</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Goodwin</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICT-DM47966.2019.9032935</pub-id>
          <article-title>The use of artificial intelligence in disaster management-A systematic literature review</article-title>
          <source>2019 International Conference on Information and Communication Technologies for Disaster Management, Paris, France</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>26</volume>
          <page-range>1183-1192</page-range>
          <issue>8</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Budd</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>S. B.</given-names>
            </name>
            <name>
              <surname>Manning et al.</surname>
              <given-names>E.M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s41591-020-1011-4</pub-id>
          <article-title>Digital technologies in the public-health response to COVID-19</article-title>
          <source>Nat. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>1100401</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wen</surname>
              <given-names>Cheng</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Wen</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>Zhihua H.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Chenyu Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/fpubh.2022.1100401</pub-id>
          <article-title>Research on emergency management of global public health emergencies driven by digital technology: A bibliometric analysis</article-title>
          <source>Front. Public Health</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <page-range>1-19</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yamarthy</surname>
              <given-names>Kumar</given-names>
            </name>
            <name>
              <surname>Koteswararao</surname>
              <given-names>Challa</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10586-024-04313-w</pub-id>
          <article-title>MDepthNet based phishing attack detection using integrated deep learning methodologies for cyber security enhancement</article-title>
          <source>Cluster Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>26474-26491</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Qaraqe</surname>
              <given-names>Marwa</given-names>
            </name>
            <name>
              <surname>Elzein</surname>
              <given-names>Almiqdad</given-names>
            </name>
            <name>
              <surname>Basaran</surname>
              <given-names>Emrah</given-names>
            </name>
            <name>
              <surname>others</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2024.3366693</pub-id>
          <article-title>PublicVision: A secure smart surveillance system for crowd behavior recognition</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Adewopo</surname>
              <given-names>Victor</given-names>
            </name>
            <name>
              <surname>Elsayed</surname>
              <given-names>Nelly</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2310.10038</pub-id>
          <article-title>Smart city transportation: Deep learning ensemble approach for traffic accident detection</article-title>
          <source>arXiv:2310.10038</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>73</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Avazov</surname>
              <given-names>Komil</given-names>
            </name>
            <name>
              <surname>Mukhiddinov</surname>
              <given-names>Murodjon</given-names>
            </name>
            <name>
              <surname>Makhmudov</surname>
              <given-names>Farhod</given-names>
            </name>
            <name>
              <surname>Cho</surname>
              <given-names>Yong II</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/electronics11010073</pub-id>
          <article-title>Fire detection method in smart city environments using a deep-learning-based approach</article-title>
          <source>Electronics</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>26</volume>
          <page-range>4013-4032</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nevo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Morin</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Rosenthal et al.</surname>
              <given-names>A. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.5194/hess-26-4013-2022</pub-id>
          <article-title>Flood forecasting with machine learning models in an operational framework</article-title>
          <source>Hydrol. Earth Syst. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>93</volume>
          <page-range>814-826</page-range>
          <issue>2A</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Chen Yang</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Tzu Chiang</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>Yi Ming</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1785/0220210197</pub-id>
          <article-title>Using LSTM neural networks for onsite earthquake early warning</article-title>
          <source>Seismol. Soc. America</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>83</volume>
          <page-range>41405-41439</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Koshy</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Elango</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-023-16766-z</pub-id>
          <article-title>Utilizing social media for emergency response: A Tweet classification system using attention-based BiLSTM and CNN for resource management</article-title>
          <source>Multimed. Tools Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>79</volume>
          <page-range>6452-6470</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>Min</given-names>
            </name>
            <name>
              <surname>Du</surname>
              <given-names>Wenhu H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11227-022-04900-x</pub-id>
          <article-title>The predicting public sentiment evolution on public emergencies under deep learning and Internet of Things</article-title>
          <source>J. Supercomput.</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>24</volume>
          <page-range>609-617</page-range>
          <issue>7</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Han</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Fang</surname>
              <given-names>R. Y.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>G. P.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>C. S.</given-names>
            </name>
            <name>
              <surname>Chi</surname>
              <given-names>R. F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/15389588.2023.2227304</pub-id>
          <article-title>Adaptive autonomous emergency braking model based on weather conditions</article-title>
          <source>Traffic Inj. Prev.</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="conf-paper">
          <page-range>725-741</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Alatrista-Salas</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Morzán-Samamé</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Nunez-del-Prado</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-3-030-12388-8_50</pub-id>
          <article-title>Crime alert! crime typification in news based on text mining</article-title>
          <source>Proceedings of the 2019 Future of Information and Communication Conference, San Francisco, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1526</page-range>
          <issue>9</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahsan</surname>
              <given-names>M. M.</given-names>
            </name>
            <name>
              <surname>Alam</surname>
              <given-names>T. E.</given-names>
            </name>
            <name>
              <surname>Trafalis</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Huebner</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/sym12091526</pub-id>
          <article-title>Deep MLP-CNN model using mixed-data to distinguish between COVID-19 and non-COVID-19 patients</article-title>
          <source>Symmetry</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>6884</page-range>
          <issue>10</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kompunt</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Yongjoh</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Aimtongkham</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Muneesawang</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Faksri</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>So-In</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48048/tis.2023.6884</pub-id>
          <article-title>A hybrid LSTM and MLP scheme for COVID-19 prediction: A case study in Thailand</article-title>
          <source>Trends Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>80-91</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>Wei Wei</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>Jing Lin</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Ting</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Jun Hua</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Jie</given-names>
            </name>
            <name>
              <surname>Shangguan</surname>
              <given-names>Qiang Qiang</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1108/JICV-03-2021-0004</pub-id>
          <article-title>Dynamic prediction of traffic incident duration on urban expressways: A deep learning approach based on LSTM and MLP</article-title>
          <source>J. Intell. Connect. Veh.</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>11992-12000</page-range>
          <issue>6</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Alshaya</surname>
              <given-names>S. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48084/etasr.6295</pub-id>
          <article-title>IoT device identification and cybersecurity: Advancements, challenges, and an LSTM-MLP Solution</article-title>
          <source>Eng. Technol. Appl. Sci. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <volume>157</volume>
          <page-range>160-167</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jatnika</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bijaksana</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Suryani</surname>
              <given-names>A. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.procs.2019.08.153</pub-id>
          <article-title>Word2vec model analysis for semantic similarities in English words</article-title>
          <source>Procedia Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>83</volume>
          <page-range>37979-38007</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Johnson</surname>
              <given-names>S. J.</given-names>
            </name>
            <name>
              <surname>Murty</surname>
              <given-names>M. R.</given-names>
            </name>
            <name>
              <surname>Navakanth</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-023-17007-z</pub-id>
          <article-title>A detailed review on word embedding techniques with emphasis on Word2Vec</article-title>
          <source>Multimed. Tools Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1735-1780</page-range>
          <issue>8</issue>
          <year>1997</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hochreiter</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Schmidhuber</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
          <article-title>Long short-term memory</article-title>
          <source>Neural Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Taud</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Mas</surname>
              <given-names>J. F.</given-names>
            </name>
          </person-group>
          <article-title>Multilayer perceptron (MLP)</article-title>
          <source>Geomatic Approaches for Modeling Land Change Scenarios</source>
          <publisher-name>Springer, Cham</publisher-name>
          <year>2018</year>
          <page-range>451-455</page-range>
          <pub-id pub-id-type="doi">10.1007/978-3-319-60801-3_27</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="conf-paper">
          <page-range>415-434</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sun</surname>
              <given-names>J. Z.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X. D.</given-names>
            </name>
            <name>
              <surname>Lei</surname>
              <given-names>S. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-981-99-2625-1_33</pub-id>
          <article-title>The evolution of public opinion and its emotion analysis in public health emergency based on Weibo data</article-title>
          <source>International Conference on Logistics, Informatics and Service Sciences, Beijing, China</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>