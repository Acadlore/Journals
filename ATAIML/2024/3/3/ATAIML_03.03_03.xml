<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-9oi6AvxeLaKUHezBDFgOjRKDr58PMcCd</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml030303</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Evaluating the Impact of Data Normalization on Rice Classification Using Machine Learning Algorithms</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6288-3182</contrib-id>
          <name>
            <surname>çElik</surname>
            <given-names>Ahmet</given-names>
          </name>
          <email>ahmet.celik@dpu.edu.tr</email>
        </contrib>
        <aff id="aff_1">Computer Technology Department, Tavsanli Vocational School, Kutahya Dumlupinar University, 43300 Kutahya, Turkey</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>19</day>
        <month>09</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>3</issue>
      <fpage>162</fpage>
      <lpage>171</lpage>
      <page-range>162-171</page-range>
      <history>
        <date date-type="received">
          <day>17</day>
          <month>07</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>11</day>
          <month>09</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Rice is a staple food for a significant portion of the global population, particularly in countries where it constitutes the primary source of sustenance. Accurate classification of rice varieties is critical for enhancing both agricultural yield and economic outcomes. Traditional classification methods are often inefficient, leading to increased costs, higher misclassification rates, and time loss. To address these limitations, automated classification systems employing machine learning (ML) algorithms have gained attention. However, when raw data is inadequately organized or scattered, classification accuracy can decline. To improve data organization, normalization processes are often employed. Despite its widespread use, the specific contribution of normalization to classification performance requires further validation. In this study, a dataset comprising two rice varieties Osmancik and Cammeo produced in Turkey was utilized to evaluate the impact of normalization on classification outcomes. The k-Nearest Neighbor (KNN) algorithm was applied to both normalized and non-normalized datasets, and their respective performances were compared across various training and testing ratios. The normalized dataset achieved a classification accuracy of 0.950, compared to 0.921 for the non-normalized dataset. This approximately 3% improvement demonstrates the positive effect of data normalization on classification accuracy. These findings underscore the importance of incorporating normalization in ML models for rice classification to optimize performance and accuracy.</p></abstract>
      <kwd-group>
        <kwd>Machine learning</kwd>
        <kwd>Image processing</kwd>
        <kwd>Normalization</kwd>
        <kwd>Data processing</kwd>
        <kwd>Rice classification</kwd>
        <kwd>Food quality determination</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="1"/>
        <fig-count count="5"/>
        <table-count count="7"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Due to the fact that about 67% of the world’s human population is related to the agricultural sector, the production of different varieties of cereals is of great importance. Sowing different varieties of seeds together in agriculture can reduce yield and cause economic loss. Rice classification is expensive, laborious and error-prone to manual work using traditional methods. However, the use of computer vision, image processing and data evaluation methods in classification offers an up-to-date and advanced technology [<xref ref-type="bibr" rid="ref_1">1</xref>].</p><p>Rice classification becomes very important as there are many types of rice produced today. Manually classifying rice grains according to rice types is not efficient and safe because it requires a lot of time compared with automatic classification [<xref ref-type="bibr" rid="ref_2">2</xref>]. It is possible to automatically identify and classify individual rice grains using an intelligent system according to the relevant species. Computer vision techniques form the basis of such systems [<xref ref-type="bibr" rid="ref_3">3</xref>].</p><p>Rice is an important source of consumption for humans, necessitating not only the quality classification of rice products but also the identification of diseased and weed-infested rice. Some researchers have conducted studies to detect diseases on rice using ML algorithms. Jena et al. [<xref ref-type="bibr" rid="ref_4">4</xref>] classified the diseases encountered on rice species such as BrownSpot, Hispa and LeafBlast using many ML-based methods. The study was conducted using the Orange 3.26.0 interface. Ruslan et al. [<xref ref-type="bibr" rid="ref_5">5</xref>] classified weeded rice using ML and image processing methods. Weed rice is a type of weed in rice production fields. The weed rice infestation has become a general problem as it has been reported worldwide. Therefore, it is very important to classify rice at the earliest so that it is possible to take preventive measures [<xref ref-type="bibr" rid="ref_4">4</xref>].</p><p>On the basis of ML methods, many studies have also classified other agricultural products. Ozkan et al. [<xref ref-type="bibr" rid="ref_6">6</xref>] classified peanut species, including feature extraction, size reduction and size weighting stages using the advanced KNN algorithm. High achievements were achieved by using artificial neural networks (ANNs) in the classification of such products [<xref ref-type="bibr" rid="ref_7">7</xref>]. Butuner et al. [<xref ref-type="bibr" rid="ref_8">8</xref>] classified lentil species using different learning algorithms and Çelik [<xref ref-type="bibr" rid="ref_9">9</xref>] classified wheat seeds using the KNN algorithm. Ayele and Tamiru [<xref ref-type="bibr" rid="ref_10">10</xref>] classified chickpea species using many algorithms and made performance comparisons.</p><p>In this study, Osmancik and Cammeo rice classification was conducted using the KNN ML algorithm. Variable training and test data of a dataset containing 3810 records were used, each representing seven attributes of rice grains derived from an imaging system. In addition, non-normalized (Method 1) and normalized (Method 2) datasets were tested and the effect on the classification success was measured on the proposed model. In addition, the min-max normalization process was used. The most important innovative aspect of this study, which distinguishes it from other studies in the literature, is that it proves that the data normalization process on the dataset increases the classification success.</p>
    </sec>
    <sec sec-type="">
      <title>2. Methodology</title>
      <p>ML methods have a major role for the classification, identification, and analysis of different data for various applications [<xref ref-type="bibr" rid="ref_4">4</xref>]. The dataset used in this study was downloaded from open source storage. The dataset [<xref ref-type="bibr" rid="ref_3">3</xref>] was created and recorded by capturing different rice images according to the relevant species in the first stage. In the second stage, the captured images were processed using image processing methods and the morphological features of the rice samples were extracted. In the third stage, the attributes of the samples belonging to the rice classes were recorded in the dataset [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>].</p><p>In this study, two different types of rice grown in Turkey were classified. Osmancik rice type has had a large cultivation area since 1997 and the weight of a thousand grains is 23-25 grams. The Cammeo rice type, on the other hand, first grown in 2014, has a thousand-grain weight of 29-32 grams [<xref ref-type="bibr" rid="ref_3">3</xref>]. These rice species structures are shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Osmancik and Cammeo rice structures</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_PJ8hvwNAOkvi4wt1.png"/>
        </fig>
      
      <p>In this study, the flow chart of the designed model is shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref>. In the study, in the first stage, normalization was performed on the attributes of rice classes on the dataset. Then, classification was carried out with the KNN algorithm according to 70% and 50% training rates. In the study, classification was performed on non-normalized data using the same algorithm. In the last stage, the effect of the normalization process on the classification process was measured.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Flow chart of the designed system</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_X5sWeuPKv0Jj-gi4.png"/>
        </fig>
      
      
        <sec>
          
            <title>2.1. Dataset</title>
          
          <p>In the open source dataset used, there are a total of 3810 records belonging to the Osmancik and Cammeo rice classes. The data have seven attributes for each record, i.e., area, perimeter, major axis length, minor axis length, eccentricity, convex area and extent. The examples of raw dataset records [<xref ref-type="bibr" rid="ref_3">3</xref>] are shown in <xref ref-type="table" rid="table_1">Table 1</xref>. The Osmancik and Cammeo rice varieties used in this study were produced in Turkey. Shape-based morphological features were used in feature selection. Therefore, it is thought that it can be used in many rice classifications. The attributes were created with the data obtained through the image processing steps.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Attribute (non-normalized) values of randomly selected rice from the dataset</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Area</p></td><td colspan="1" rowspan="1"><p>Perimeter</p></td><td colspan="1" rowspan="1"><p>Major Axis Length</p></td><td colspan="1" rowspan="1"><p>Minor Axis Length</p></td><td colspan="1" rowspan="1"><p>Eccentricity</p></td><td colspan="1" rowspan="1"><p>Convex Area</p></td><td colspan="1" rowspan="1"><p>Extent</p></td><td colspan="1" rowspan="1"><p>Class</p></td></tr><tr><td colspan="1" rowspan="1"><p>15231.00</p></td><td colspan="1" rowspan="1"><p>525.57897949</p></td><td colspan="1" rowspan="1"><p>229.7498779</p></td><td colspan="1" rowspan="1"><p>85.09378815</p></td><td colspan="1" rowspan="1"><p>0.928882003</p></td><td colspan="1" rowspan="1"><p>15617.00</p></td><td colspan="1" rowspan="1"><p>0.572895527</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>14656.00</p></td><td colspan="1" rowspan="1"><p>494.31100464</p></td><td colspan="1" rowspan="1"><p>206.0200653</p></td><td colspan="1" rowspan="1"><p>91.73097229</p></td><td colspan="1" rowspan="1"><p>0.895404994</p></td><td colspan="1" rowspan="1"><p>15072.00</p></td><td colspan="1" rowspan="1"><p>0.615436316</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>14634.00</p></td><td colspan="1" rowspan="1"><p>501.12200928</p></td><td colspan="1" rowspan="1"><p>214.1067810</p></td><td colspan="1" rowspan="1"><p>87.76828766</p></td><td colspan="1" rowspan="1"><p>0.912118077</p></td><td colspan="1" rowspan="1"><p>14954.00</p></td><td colspan="1" rowspan="1"><p>0.693258822</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>13447.00</p></td><td colspan="1" rowspan="1"><p>455.64801025</p></td><td colspan="1" rowspan="1"><p>183.9575806</p></td><td colspan="1" rowspan="1"><p>94.45813751</p></td><td colspan="1" rowspan="1"><p>0.858102858</p></td><td colspan="1" rowspan="1"><p>13867.00</p></td><td colspan="1" rowspan="1"><p>0.625907660</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr><tr><td colspan="1" rowspan="1"><p>13233.00</p></td><td colspan="1" rowspan="1"><p>459.85900879</p></td><td colspan="1" rowspan="1"><p>192.5907135</p></td><td colspan="1" rowspan="1"><p>88.34671783</p></td><td colspan="1" rowspan="1"><p>0.888576806</p></td><td colspan="1" rowspan="1"><p>13436.00</p></td><td colspan="1" rowspan="1"><p>0.588735163</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr><tr><td colspan="1" rowspan="1"><p>12538.00</p></td><td colspan="1" rowspan="1"><p>452.66000366</p></td><td colspan="1" rowspan="1"><p>188.8052826</p></td><td colspan="1" rowspan="1"><p>86.10971832</p></td><td colspan="1" rowspan="1"><p>0.889940381</p></td><td colspan="1" rowspan="1"><p>12846.00</p></td><td colspan="1" rowspan="1"><p>0.684164584</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>In addition, the descriptions of the rice attributes within the dataset [<xref ref-type="bibr" rid="ref_3">3</xref>] are shown in <xref ref-type="table" rid="table_2">Table 2</xref>. Rice attributes and images of each rice grain were calculated after image processing methods were applied and recorded in the dataset.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Explanations of rice attributes [<xref ref-type="bibr" rid="ref_3">3</xref>]</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Explanation</p></td><td colspan="1" rowspan="1"><p>Attribute</p></td></tr><tr><td colspan="1" rowspan="1"><p>The total number of pixels within the boundaries of a rice grain image</p></td><td colspan="1" rowspan="1"><p>Area</p></td></tr><tr><td colspan="1" rowspan="1"><p>Circumference of the image of a rice grain</p></td><td colspan="1" rowspan="1"><p>Perimeter</p></td></tr><tr><td colspan="1" rowspan="1"><p>The largest radius of the image of a rice grain</p></td><td colspan="1" rowspan="1"><p>Major axis length</p></td></tr><tr><td colspan="1" rowspan="1"><p>The smallest radius of the image of a rice grain</p></td><td colspan="1" rowspan="1"><p>Minor axis length</p></td></tr><tr><td colspan="1" rowspan="1"><p>The roundness ratio of the rice grain image relative to an ellipse having the same moments</p></td><td colspan="1" rowspan="1"><p>Eccentricity</p></td></tr><tr><td colspan="1" rowspan="1"><p>On the region formed by the image of a rice grain, the total number of pixels of the smallest convex shell</p></td><td colspan="1" rowspan="1"><p>Convex area</p></td></tr><tr><td colspan="1" rowspan="1"><p>The ratio of the region formed by a rice grain image to the bounding box pixels</p></td><td colspan="1" rowspan="1"><p>Extent</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>2.2. Min-max normalization</title>
          
          <p>The normalization process was used to organize, improve and simplify scattered data in the dataset. Thus, it is thought that it may affect classification and prediction successes [<xref ref-type="bibr" rid="ref_11">11</xref>]. The normalization process can also be used in deep learning methods [<xref ref-type="bibr" rid="ref_12">12</xref>]. In computer vision applications used for product classification, normalization operations are also performed on images [<xref ref-type="bibr" rid="ref_1">1</xref>]. </p><p>In ML methods, normalization is used to reduce the impact of the attribute data range of each record. In this study, the min-max normalization process was used, with 0 selected as the minimum and 1 as the maximum. Thus, it is intended to arrange the values in the dataset between 0 and 1. In the study, the Z-score method was not chosen because there was no negative attribute value. </p><p>The calculation of the normalization process is shown as follows [<xref ref-type="bibr" rid="ref_13">13</xref>]:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mcbsz8typo">
                <mml:mi>y</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>x</mml:mi>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mrow>
                        <mml:mi>m</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mrow>
                        <mml:mi>m</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mrow>
                        <mml:mi>m</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p> where, $x<inline-formula>
  <mml:math id="mzavc7z2el">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y<inline-formula>
  <mml:math id="m25ioftp40">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>x_{max}<inline-formula>
  <mml:math id="m93vw0r9fe">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>x_{min}$ is the smallest data value of the basic data. In the study, the attribute values concerning area, perimeter, major axis length, minor axis length and convex area were normalized. No normalization was performed for the attributes of eccentricity and extent, as their values already ranged between 0 and 1 in the raw data. Examples of records belonging to the normalized dataset are shown in <xref ref-type="table" rid="table_3">Table 3</xref>.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Attribute (normalized) values of randomly selected rice from the dataset</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Area</p></td><td colspan="1" rowspan="1"><p>Perimeter</p></td><td colspan="1" rowspan="1"><p>Major Axis Length</p></td><td colspan="1" rowspan="1"><p>Minor Axis Length</p></td><td colspan="1" rowspan="1"><p>Eccentricity</p></td><td colspan="1" rowspan="1"><p>Convex Area</p></td><td colspan="1" rowspan="1"><p>Extent</p></td><td colspan="1" rowspan="1"><p>Class</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.6759373</p></td><td colspan="1" rowspan="1"><p>0.87923163</p></td><td colspan="1" rowspan="1"><p>0.9012159</p></td><td colspan="1" rowspan="1"><p>0.5324174</p></td><td colspan="1" rowspan="1"><p>0.928882003</p></td><td colspan="1" rowspan="1"><p>0.693917018</p></td><td colspan="1" rowspan="1"><p>0.572895527</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.6253300</p></td><td colspan="1" rowspan="1"><p>0.71409491</p></td><td colspan="1" rowspan="1"><p>0.6480872</p></td><td colspan="1" rowspan="1"><p>0.6706631</p></td><td colspan="1" rowspan="1"><p>0.895404994</p></td><td colspan="1" rowspan="1"><p>0.646009142</p></td><td colspan="1" rowspan="1"><p>0.615436316</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.6233938</p></td><td colspan="1" rowspan="1"><p>0.75006612</p></td><td colspan="1" rowspan="1"><p>0.7343491</p></td><td colspan="1" rowspan="1"><p>0.5881245</p></td><td colspan="1" rowspan="1"><p>0.912118077</p></td><td colspan="1" rowspan="1"><p>0.635636428</p></td><td colspan="1" rowspan="1"><p>0.693258822</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.5189227</p></td><td colspan="1" rowspan="1"><p>0.50990259</p></td><td colspan="1" rowspan="1"><p>0.4127440</p></td><td colspan="1" rowspan="1"><p>0.7274672</p></td><td colspan="1" rowspan="1"><p>0.858102858</p></td><td colspan="1" rowspan="1"><p>0.540084388</p></td><td colspan="1" rowspan="1"><p>0.625907660</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.5000880</p></td><td colspan="1" rowspan="1"><p>0.53214229</p></td><td colspan="1" rowspan="1"><p>0.5048347</p></td><td colspan="1" rowspan="1"><p>0.6001726</p></td><td colspan="1" rowspan="1"><p>0.888576806</p></td><td colspan="1" rowspan="1"><p>0.502197609</p></td><td colspan="1" rowspan="1"><p>0.588735163</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr><tr><td colspan="1" rowspan="1"><p>0.4389192</p></td><td colspan="1" rowspan="1"><p>0.49412192</p></td><td colspan="1" rowspan="1"><p>0.4644550</p></td><td colspan="1" rowspan="1"><p>0.5535782</p></td><td colspan="1" rowspan="1"><p>0.889940381</p></td><td colspan="1" rowspan="1"><p>0.450334037</p></td><td colspan="1" rowspan="1"><p>0.684164584</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>2.3. Knn ml algorithm</title>
          
          <p>The KNN is a widely used supervised ML algorithm. In this algorithm, analysis of records with well-defined classes and attributes is performed. The class of the new sample record is calculated by measuring the distances to the existing classes with distance metrics and is determined according to the majority of the class to which the nearest $k<inline-formula>
  <mml:math id="m6fqr80atu">
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mn>13</mml:mn>
    <mml:mn>14</mml:mn>
  </mml:math>
</inline-formula>k<inline-formula>
  <mml:math id="m3pmf0hbxg">
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>k<inline-formula>
  <mml:math id="mcgerc998p">
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mn>3</mml:mn>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>k<inline-formula>
  <mml:math id="m9sxwb6b4j">
    <mml:mo>−</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>K</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>K</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>K</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mn>3</mml:mn>
    <mml:mn>9</mml:mn>
    <mml:mn>15</mml:mn>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>k<inline-formula>
  <mml:math id="m7r55v4mxc">
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>k$ neighborhood value can increase the classification success [<xref ref-type="bibr" rid="ref_14">14</xref>]. Euclid, Chebyshev, Manhattan and Mahalanobis distance metric methods have been used with the KNN algorithm [<xref ref-type="bibr" rid="ref_9">9</xref>]. The most common Euclidean distance metric has been used and its calculation is shown as follows [<xref ref-type="bibr" rid="ref_15">15</xref>]:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="muu9t8zfyg">
                <mml:msub>
                  <mml:mi>d</mml:mi>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi>E</mml:mi>
                      <mml:mi>u</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>d</mml:mi>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:msqrt>
                  <mml:munderover>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mi>n</mml:mi>
                  </mml:munderover>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>y</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                </mml:msqrt>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="m6geguy6nc">
    <mml:msub>
      <mml:mi>x</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is new sample value, <inline-formula>
  <mml:math id="mkr9rzjba5">
    <mml:msub>
      <mml:mi>y</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is a previously stored sample value in the database, $n<inline-formula>
  <mml:math id="mp4c2paspi">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>d_{Euclid}<inline-formula>
  <mml:math id="mdxhea83mn">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
  </mml:math>
</inline-formula>x_i<inline-formula>
  <mml:math id="mj8kxu3ltq">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>y_i$.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Experimental results</title>
      <p>In this study, classification successes were measured with the KNN algorithm using non-normalized (Method 1) and normalized (Method 2) datasets, taking into account the variable training and testing data. Accuracy, F1-score, precision and recall were chosen, which are widely used as success measurement metrics. Two configurations were tested: one with 70% training and 30% testing data, and another with a 50% split for both training and testing. The classification success rates for each configuration are presented in <xref ref-type="table" rid="table_4">Table 4</xref> and <xref ref-type="table" rid="table_5">Table 5</xref>.</p>
      
        <table-wrap id="table_4">
          <label>Table 4</label>
          <caption>
            <title>Success of the KNN algorithm on the non-normalized dataset (Method 1)</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Training &amp;amp; Testing Rates</p></td><td colspan="1" rowspan="1"><p>AUC</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Recall</p></td></tr><tr><td colspan="1" rowspan="1"><p>70% training &amp;amp; 30% testing</p></td><td colspan="1" rowspan="1"><p>0.921</p></td><td colspan="1" rowspan="1"><p>0.875</p></td><td colspan="1" rowspan="1"><p>0.875</p></td><td colspan="1" rowspan="1"><p>0.875</p></td></tr><tr><td colspan="1" rowspan="1"><p>50% training &amp;amp; 50% testing</p></td><td colspan="1" rowspan="1"><p>0.917</p></td><td colspan="1" rowspan="1"><p>0.869</p></td><td colspan="1" rowspan="1"><p>0.869</p></td><td colspan="1" rowspan="1"><p>0.869</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <table-wrap id="table_5">
          <label>Table 5</label>
          <caption>
            <title>Success of the KNN algorithm on the normalized dataset (Method 2)</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Training &amp;amp; Testing Rates</p></td><td colspan="1" rowspan="1"><p>AUC</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Recall</p></td></tr><tr><td colspan="1" rowspan="1"><p>70% training &amp;amp; 30% testing</p></td><td colspan="1" rowspan="1"><p>0.950</p></td><td colspan="1" rowspan="1"><p>0.92</p></td><td colspan="1" rowspan="1"><p>0.921</p></td><td colspan="1" rowspan="1"><p>0.92</p></td></tr><tr><td colspan="1" rowspan="1"><p>50% training &amp;amp; 50% testing</p></td><td colspan="1" rowspan="1"><p>0.949</p></td><td colspan="1" rowspan="1"><p>0.906</p></td><td colspan="1" rowspan="1"><p>0.907</p></td><td colspan="1" rowspan="1"><p>0.906</p></td></tr></tbody></table>
        </table-wrap>
      
      <p><xref ref-type="table" rid="table_4">Table 4</xref> illustrates the classification performance using the raw, non-normalized attribute data. The highest accuracy, achieved with 70% training and 30% testing, was 0.921. According to the F1-score, precision and recall success metrics, classification success rates ranging from 0.869 to 0.875 were obtained.</p><p>The classification performance measurement performed on normalized attribute data is shown in <xref ref-type="table" rid="table_5">Table 5</xref>. In this case, the highest accuracy of 0.950 was obtained with 70% training and 30% testing. According to the F1-score, precision and recall success metrics, classification achievements ranging from 0.906 to 0.921 were obtained.</p>
      <p>The results demonstrate that increasing the proportion of training data in the model led to improved classification success. Additionally, the classification accuracy of the KNN algorithm was significantly enhanced when the normalized dataset was employed. <xref ref-type="fig" rid="fig_3">Figure 3</xref> compares the classification performance between the normalized and non-normalized datasets. The performance graph of the model designed by selecting 70% training and 30% testing rate on the normalized and non-normalized datasets is shown in subgraph (a) of <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p><p>Subgraph (b) of <xref ref-type="fig" rid="fig_3">Figure 3</xref> shows the performance graph of the model designed by selecting 50% training and 50% testing rate on the normalized and non-normalized datasets. In the figure, it can be observed that the normalization process had a positive effect on the classification performance. Specifically, the use of normalization resulted in a 3.2% increase in classification success, as measured by the accuracy metric, and a 4.6% improvement in the F1-score metric when 50% training data was used.</p><p>According to the model in which the highest classification achievements were obtained in the study (normalized dataset +70% training and 30% test data rates), the classification success of each class was evaluated separately. According to the results obtained, it can be observed that Cammeo rice was classified with a higher success rate than Osmancik rice.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Classification performance using the model on the normalized and non-normalized datasets: (a) Success values based on 70% training and 30% testing data rates; (b) Success values based on 50% training and 50% test data rates</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_bx4FXdnIf6QsCrg_.png"/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_DzowMKp-Ub3-36DV.png"/>
        </fig>
      
      <p><xref ref-type="fig" rid="fig_4">Figure 4</xref> shows the Receiver Operating Characteristic (ROC) curve graph, indicating the classification success rates of the two types of rice. On the designed model, subgraph (a) of <xref ref-type="fig" rid="fig_4">Figure 4</xref> shows the classification success graph of the Cammeo rice, and subgraph (b) of <xref ref-type="fig" rid="fig_4">Figure 4</xref> shows that of the Osmancik rice.</p>
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>Classification success graphs (ROC curves) of two types of rice: (a) Cammeo rice; (b) Osmancik rice</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_Ze4tg6OJiMn5aTbj.png"/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_x-JM-RjdXo75XYJV.png"/>
        </fig>
      
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Convolution matrix of the model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_mtaGsFyn57KtsKtS.png"/>
        </fig>
      
      <p>The correct and incorrect classification results of the designed model can be analyzed by using convolution matrices. In this study, the highest success rate was obtained from the convolution matrix of the model using Method 2, as shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>. On the model, 2667 pieces of rice were used for training (70% rate) and 1143 pieces of rice for testing (30% rate).</p><p>In the figure, 493 Cammeo and 650 Osmancik rice classes were tested on the model. In the test process, 440 of the 493 rices belonging to the Cammeo class were classified correctly, but 53 were classified incorrectly (as Osmancik rice). In addition, in the test process, 610 of the 650 rices belonging to the Osmancik class were classified correctly, but 40 were classified incorrectly (as Cammeo rice).</p>
      
        <sec>
          
            <title>3.1. Correlation analysis of attributes</title>
          
          <p>Correlation analysis was performed on the developed model to show the relationship and direction of each attribute between classes. The correlation value levels of the attributes show the effects of the classification process. Positive correlation values are represented by +1, while negative values are represented by -1. When the correlation values are close to the limit values (-1 and +1), it is determined that there is a high-level correlation. When the values are close to 0, there is a low-level correlation. The correlation value of the attribute used has a great impact on the classification process when it is at a high level. If the correlation value is at a low level, it has little effect on the classification process. <xref ref-type="table" rid="table_6">Table 6</xref> shows the correlation values and levels of the attributes of each class used in the dataset. It can be seen that the highest correlation value is in the major axis length attribute and the lowest one is in the extent attribute. In addition, the medium correlation value is in the eccentricity attribute.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Correlation values of dataset attributes</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Attribute</p></td><td colspan="1" rowspan="1"><p>Osmancik</p></td><td colspan="1" rowspan="1"><p>Cammeo</p></td><td colspan="1" rowspan="1"><p>Correlation Level</p></td></tr><tr><td colspan="1" rowspan="1"><p>Major axis length</p></td><td colspan="1" rowspan="1"><p>-0.992</p></td><td colspan="1" rowspan="1"><p>+0.892</p></td><td colspan="1" rowspan="1"><p>High</p></td></tr><tr><td colspan="1" rowspan="1"><p>Perimeter</p></td><td colspan="1" rowspan="1"><p>-0.879</p></td><td colspan="1" rowspan="1"><p>+0.879</p></td><td colspan="1" rowspan="1"><p>High</p></td></tr><tr><td colspan="1" rowspan="1"><p>Convex area</p></td><td colspan="1" rowspan="1"><p>-0.837</p></td><td colspan="1" rowspan="1"><p>+0.837</p></td><td colspan="1" rowspan="1"><p>High</p></td></tr><tr><td colspan="1" rowspan="1"><p>Area</p></td><td colspan="1" rowspan="1"><p>-0.835</p></td><td colspan="1" rowspan="1"><p>+0.835</p></td><td colspan="1" rowspan="1"><p>High</p></td></tr><tr><td colspan="1" rowspan="1"><p>Eccentricity</p></td><td colspan="1" rowspan="1"><p>-0.676</p></td><td colspan="1" rowspan="1"><p>+0.676</p></td><td colspan="1" rowspan="1"><p>High</p></td></tr><tr><td colspan="1" rowspan="1"><p>Minor axis length</p></td><td colspan="1" rowspan="1"><p>-0.439</p></td><td colspan="1" rowspan="1"><p>+0.439</p></td><td colspan="1" rowspan="1"><p>Medium</p></td></tr><tr><td colspan="1" rowspan="1"><p>Extent</p></td><td colspan="1" rowspan="1"><p>+0.170</p></td><td colspan="1" rowspan="1"><p>-0.170</p></td><td colspan="1" rowspan="1"><p>Low</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="discussion">
      <title>4. Discussion</title>
      <p>Some research on rice classifications has been conducted using different methods in classification processes. The success rates vary depending on the used methods. The comparison between the model developed in this study and other studies is shown in <xref ref-type="table" rid="table_7">Table 7</xref>.</p>
      
        <table-wrap id="table_7">
          <label>Table 7</label>
          <caption>
            <title>Comparison between the proposed model in this study and other studies</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Research</p></td><td colspan="1" rowspan="1"><p>Algorithms and Methods Used</p></td><td colspan="1" rowspan="1"><p>Dataset Used</p></td><td colspan="1" rowspan="1"><p>Success Rates</p></td></tr><tr><td colspan="1" rowspan="1"><p>Cinar and Koklu [<xref ref-type="bibr" rid="ref_3">3</xref>]</p></td><td colspan="1" rowspan="1"><p>LR, MLP, SVM, DT, RF, NB and KNN</p></td><td colspan="1" rowspan="1"><p>Dataset containing 3810 rice sample data</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>LR=93.02%</p><p>MLP=092.86%</p><p>SVM=92.83%</p><p>DT=92.49%</p><p>RF=92.39%</p><p>NB=91.71%</p><p>KNN=88.58%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Hong et al. [<xref ref-type="bibr" rid="ref_16">16</xref>]</p></td><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>Six Vietnam rice seed datasets</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>RF=90.54%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Nga et al. [<xref ref-type="bibr" rid="ref_17">17</xref>]</p></td><td colspan="1" rowspan="1"><p>SVM combined with binary particle swarm optimization</p></td><td colspan="1" rowspan="1"><p>Dataset containing 3400 rice sample data</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>SVM=93.94%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Nga et al. [<xref ref-type="bibr" rid="ref_18">18</xref>]</p></td><td colspan="1" rowspan="1"><p>Modified VGG16 and modified ResNet50</p></td><td colspan="1" rowspan="1"><p>Dataset containing 3400 rice sample data</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>Modified VGG16=96.41%</p><p>Modified ResNet50=97.88%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Nusrat et al. [<xref ref-type="bibr" rid="ref_1">1</xref>]</p></td><td colspan="1" rowspan="1"><p>RiceNet, InceptionV3 and ResNetInceptionV2</p></td><td colspan="1" rowspan="1"><p>Sher-eKashmir University of Agriculture Sciences and Technology (SKUAST) Srinagar. The dataset used in this study consisted of 4748 rice image data.</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>RiceNet=94%</p><p>InceptionV3=84% ResNetInceptionV2=81%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Proposed model in this study</p></td><td colspan="1" rowspan="1"><p>Min-max normalization and KNN</p></td><td colspan="1" rowspan="1"><p>Dataset containing 3810 rice sample data</p></td><td colspan="1" rowspan="1"><p>According to the accuracy success metric:</p><p>KNN =95.0%</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>In the study by Cinar and Koklu [<xref ref-type="bibr" rid="ref_3">3</xref>], a total of 3810 rice grains belonging to Osmancik and Cammeo classes were imaged. Then they were processed by image processing methods and the attributes of each rice grain were created. Seven morphological attributes were used for each grain of rice. In the study, models were created using Logistic Regression (LR), Multilayer Perceptron (MLP), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Naive Bayes (NB) and KNN ML algorithms. Classification performance measurement values were obtained for each algorithm. According to the results, the highest classification success rate was measured at 93.02% with the LR algorithm.</p><p>Hong et al. [<xref ref-type="bibr" rid="ref_16">16</xref>] used six datasets, with one of them containing the highest number of 4152 rice data records. The RF model was used to classify the rice in the datasets. According to the results, they measured a classification success rate of 90.54% for the RF algorithm. Nga et al. [<xref ref-type="bibr" rid="ref_17">17</xref>] used an optimized SVM model to classify the rice within the dataset containing 3400 rice data records and achieved a classification success rate of 93.94%. Using the same dataset, Nga et al. [<xref ref-type="bibr" rid="ref_18">18</xref>] performed the classification process using improved convolutional neural network (CNN) models. According to the results, they measured 96.41% classification success rate with modified VGG16 and 97.88% with modified ResNet50 algorithm. Nusrat et al. [<xref ref-type="bibr" rid="ref_1">1</xref>] used RiceNet, InceptionV3, and ResNetInceptionV2 models of CNN to classify the rice in the dataset containing 4748 rice data records. According to the results, the classification success rates with RiceNet, InceptionV3 and ResNetInceptionV2 were 94%, 84% and 81%, respectively. In addition, Koklu et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] conducted a research comparing the classification success of rice varieties using different deep learning methods.</p>
      <p>A dataset containing 3810 records was used in this study, which belong to the Osmancik and Cammeo rice classes and were shared as open source at the University of California, Irvine (UCI) [<xref ref-type="bibr" rid="ref_20">20</xref>]. In order to classify the rice in the dataset, min-max normalization was performed in the first stage. Then the classification success rates were measured on the proposed model using the KNN algorithm according to the variable training dimensions (50% and 70%). A classification success rate of 95% was obtained with the KNN algorithm on the normalized dataset. In this developed model, unlike other studies, the normalization preprocessing step was performed in the dataset. In addition, this study reveals that the min-max normalization of the dataset increases the classification success rate, which is its innovative strength.</p>
    </sec>
    <sec sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>In this study, different types of rice, an important food type in the world and widely used by humans, were classified. Osmancik and Cammeo rice species cultivated and consumed in Turkey were selected for classification. The dataset was downloaded from the UCI repository, which is available as open source. A model was designed using the KNN ML algorithm with variable training and test data rates. Before the classification process, the min-max normalization was performed on the existing dataset records, thereby arranging the attribute data of the records. The normalized dataset and non-normalized datasets were tested on the proposed model. In the testing processing, it was observed that the classification success rate increased in the normalized data. As a result, this study proves that the min-max data normalization process performed on the datasets can increase the classification success rate of intelligent systems. In future studies, classification performance could be measured by applying normalization processes on different datasets and various learning algorithms, thereby proving the success of normalization processes on different models.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author declares no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>235</volume>
          <page-range>121214</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nusrat</surname>
              <given-names>M. U. D.</given-names>
            </name>
            <name>
              <surname>Assif</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rayees</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Muzafar</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Saqib</surname>
              <given-names>U. S.</given-names>
            </name>
            <name>
              <surname>Tabasum</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zahir</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Wahid</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Aamir</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.eswa.2023.121214</pub-id>
          <article-title>RiceNet: A deep convolutional neural network approach for classification of rice varieties</article-title>
          <source>Expert Syst. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="conf-paper">
          <page-range>205-208</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Arora</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Bhagat</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Saritha</surname>
              <given-names>L. R.</given-names>
            </name>
            <name>
              <surname>Arcot</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICICT48043.2020.9112418</pub-id>
          <article-title>Rice grain classification using image processing machine learning techniques</article-title>
          <source>2020 International Conference on Inventive Computation Technologies (ICICT), Coimbatore, India</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>188-194</page-range>
          <issue>3</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Cinar</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Koklu</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18201/ijisae.2019355381</pub-id>
          <article-title>Classification of rice varieties using artificial intelligence methods</article-title>
          <source>Int. J. Intell. Syst. Appl. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="conf-paper">
          <page-range>328-333</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jena</surname>
              <given-names>K. K.</given-names>
            </name>
            <name>
              <surname>Bhoi</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Mohapatra</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Mallick</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Swain</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/I-SMAC52330.2021.9641054</pub-id>
          <article-title>Rice disease classification using supervised machine learning approach</article-title>
          <source>2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), Palladam, India</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>645</page-range>
          <issue>5</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ruslan</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Khairunniza-Bejo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Jahari</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ibrahim</surname>
              <given-names>M. F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/agriculture12050645</pub-id>
          <article-title>Weedy rice classification using image processing and a machine learning approach</article-title>
          <source>Agriculture</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>e2021044</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ozkan</surname>
              <given-names>I. A.</given-names>
            </name>
            <name>
              <surname>Koklu</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Saracoglu</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.23751/pn.v23i2.9686</pub-id>
          <article-title>Classification of pistachio species using improved KNN classifier</article-title>
          <source>Prog. Nutr.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>1-14</page-range>
          <issue>981</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Taspinar</surname>
              <given-names>Y. S.</given-names>
            </name>
            <name>
              <surname>Kursun</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Cinar</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Koklu</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ozkan</surname>
              <given-names>I. A.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>H. N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/electronics11070981</pub-id>
          <article-title>Classification and analysis of pistachio species with pre-trained deep learning models</article-title>
          <source>Electronics</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>249</volume>
          <page-range>1303-1316</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Butuner</surname>
              <given-names>Recep</given-names>
            </name>
            <name>
              <surname>Cinar</surname>
              <given-names>Ibrahim</given-names>
            </name>
            <name>
              <surname>Taspinar</surname>
              <given-names>Yasin Sinan</given-names>
            </name>
            <name>
              <surname>Kursun</surname>
              <given-names>Remzi</given-names>
            </name>
            <name>
              <surname>Calp</surname>
              <given-names>M. Hayrunnisa</given-names>
            </name>
            <name>
              <surname>Koklu</surname>
              <given-names>Murat</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s00217-023-04214-z</pub-id>
          <article-title>Classification of deep image features of lentil varieties with machine learning techniques</article-title>
          <source>Eur Food Res. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>1142-1149</page-range>
          <issue>5</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Çelik</surname>
              <given-names>Ahmet</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.35414/akufemubid.1263900</pub-id>
          <article-title>Determination of the classification success of KNN algorithm distance metric methods on wheat seeds dataset</article-title>
          <source>Afyon Kocatepe Üniversitesi Fen Ve Mühendislik Bilimleri Dergisi</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>5-11</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ayele</surname>
              <given-names>Nigus Asres</given-names>
            </name>
            <name>
              <surname>Tamiru</surname>
              <given-names>Hailemichael Kefie</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.35940/ijitee.A8057.1110120</pub-id>
          <article-title>Developing classification model for chickpea types using machine learning algorithms</article-title>
          <source>Int. J. Innov. Technol. Explor. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>148</volume>
          <page-range>3155-3177</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Karunamurthy</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Janvekar</surname>
              <given-names>Abhinandan A.</given-names>
            </name>
            <name>
              <surname>Palaniappan</surname>
              <given-names>P.L.</given-names>
            </name>
            <name>
              <surname>Adhitya</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Lokeswar</surname>
              <given-names>T. T. K.</given-names>
            </name>
            <name>
              <surname>Harish</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10973-022-11896-2</pub-id>
          <article-title>Prediction of IC engine performance and emission parameters using machine learning: A review</article-title>
          <source>J. Therm. Anal. Calorim.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="conf-paper">
          <page-range>245-259</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shah</surname>
              <given-names>Mohit</given-names>
            </name>
            <name>
              <surname>Banker</surname>
              <given-names>Kushal</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>Jay</given-names>
            </name>
            <name>
              <surname>Rao</surname>
              <given-names>Durga</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-3-031-61471-2_18</pub-id>
          <article-title>Comparative analysis of deep learning architectures for rice crop image classification</article-title>
          <source>Proceedings of 4th International Conference on Artificial Intelligence and Smart Energy, Coimbatore, India</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>312</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Yong</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Qing Fang</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Xiao Feng</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>Yun Cong</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Ren Ming</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Zhi Tao</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Jing Hui</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/pr10020312</pub-id>
          <article-title>The prediction of spark-ignition engine performance and emissions based on the SVR algorithm</article-title>
          <source>Processes</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>23-30</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Çelik</surname>
              <given-names>Ahmet</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.53608/estudambilisim.1071335</pub-id>
          <article-title>Improving iris dataset classification prediction achievement by using optimum k value of kNN algorithm</article-title>
          <source>J. ESTUDAM Inf.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>355-366</page-range>
          <issue>4</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Guru</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Sathyapriya</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rajandran</surname>
              <given-names>K. V. R.</given-names>
            </name>
            <name>
              <surname>Bhuvaneswari</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Parimala</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Product sales forecasting and prediction using machine learning algorithm</article-title>
          <source>Int. J. Intell. Syst. Appl. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="conf-paper">
          <page-range>377-382</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hong</surname>
              <given-names>Thi Thi</given-names>
            </name>
            <name>
              <surname>Thanh Hai</surname>
              <given-names>Tran Thi</given-names>
            </name>
            <name>
              <surname>Lan</surname>
              <given-names>Le Thi</given-names>
            </name>
            <name>
              <surname>Hoang</surname>
              <given-names>Vu Tuan</given-names>
            </name>
            <name>
              <surname>Hai</surname>
              <given-names>Vu</given-names>
            </name>
            <name>
              <surname>Nguyen</surname>
              <given-names>Thi Thanh</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/KSE.2015.46</pub-id>
          <article-title>Comparative study on vision based rice seed varieties identification</article-title>
          <source>IEEE Seventh International Conference on Knowledge and Systems Engineering (KSE), Ho Chi Minh City, Vietnam</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>66062-66078</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nga</surname>
              <given-names>Tran Thi Kim</given-names>
            </name>
            <name>
              <surname>Tuan</surname>
              <given-names>Pham Viet</given-names>
            </name>
            <name>
              <surname>Tam</surname>
              <given-names>Dinh Mao</given-names>
            </name>
            <name>
              <surname>Koo</surname>
              <given-names>Insoo</given-names>
            </name>
            <name>
              <surname>Mariano</surname>
              <given-names>Vladimir Y.</given-names>
            </name>
            <name>
              <surname>Tuan</surname>
              <given-names>Do Hong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3076130</pub-id>
          <article-title>Combining binary particle swarm optimization with support vector machine for enhancing rice varieties classification accuracy</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>150-160</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nga</surname>
              <given-names>Tran Thi Kim</given-names>
            </name>
            <name>
              <surname>Tuan</surname>
              <given-names>Pham Viet</given-names>
            </name>
            <name>
              <surname>Tam</surname>
              <given-names>Dinh Mao</given-names>
            </name>
            <name>
              <surname>Koo</surname>
              <given-names>Insoo</given-names>
            </name>
            <name>
              <surname>Mariano</surname>
              <given-names>Vladimir Y.</given-names>
            </name>
            <name>
              <surname>Tuan</surname>
              <given-names>Do Hong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18178/ijeetc.12.2.150-160</pub-id>
          <article-title>Enhancing the classification accuracy of rice varieties by using convolutional neural networks</article-title>
          <source>Int. J. Electr. Electron. Eng. Telecommun.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>187</volume>
          <page-range>106285</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Koklu</surname>
              <given-names>Murat</given-names>
            </name>
            <name>
              <surname>Cinar</surname>
              <given-names>Ibrahim</given-names>
            </name>
            <name>
              <surname>Taspinar</surname>
              <given-names>Yasin Sinan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compag.2021.106285</pub-id>
          <article-title>Classification of rice varieties with deep learning methods</article-title>
          <source>Comput. Electron. Agric.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="webpage">
          <article-title>UCI Machine Learning Repository. University of California, School of Information and Computer Science, Irvine, CA</article-title>
          <source>, https://archive.ics.uci.edu</source>
          <year>2023</year>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>