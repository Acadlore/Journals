<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IDA</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Information Dynamics and Applications</journal-title>
        <abbrev-journal-title abbrev-type="issn">Inf. Dyn. Appl.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IDA</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1494</issn>
      <issn publication-format="print">2958-1486</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-98HymsDGqSOG4NYJRZ7wu5ZAETB7gkeZ</article-id>
      <article-id pub-id-type="doi">10.56578/ida040101</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Intelligent Road Crack Detection Using Fuzzy Logic and Multi-Scale Optimization</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2605-1119</contrib-id>
          <name>
            <surname>Ali</surname>
            <given-names>Rifaqat</given-names>
          </name>
          <email>rrafat@kku.edu.sa</email>
        </contrib>
        <aff id="aff_1">Department of Mathematics, College of Science and Arts, King Khalid University, 61413 Abha, Saudi Arabia</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>09</day>
        <month>02</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>1</issue>
      <fpage>1</fpage>
      <lpage>11</lpage>
      <page-range>1-11</page-range>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>12</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>04</day>
          <month>02</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Accurate detection of road cracks is essential for maintaining infrastructure integrity, ensuring road safety, and preventing costly structural damage. However, challenges such as varying illumination conditions, noise, irregular crack patterns, and complex background textures often hinder reliable detection. To address these issues, a novel Fuzzy-Powered Multi-Scale Optimization (FMSO) model was proposed, integrating adaptive fuzzy operators, multi-scale level set evolution, Dynamic Graph Energy Minimization (GEM), and Hybrid Swarm Optimization (HSO). The FMSO model employs multi-resolution segmentation, entropy-based fuzzy weighting, and adaptive optimization strategies to enhance detection accuracy, while adaptive fuzzy operators mitigate the impact of illumination variations. Multi-scale level set evolution refines crack boundaries with high precision, and GEM effectively separates cracks from intricate backgrounds. Furthermore, HSO dynamically optimizes segmentation parameters, ensuring improved accuracy. The model was rigorously evaluated using multiple benchmark datasets, with performance metrics including accuracy, precision, recall, and F1-score. Experimental results demonstrate that the FMSO model surpasses existing methods, achieving superior accuracy, enhanced precision, and higher recall. Notably, the model effectively reduces false positives while maintaining sensitivity to fine crack details. The integration of fuzzy logic and multi-scale optimization techniques renders the FMSO model highly adaptable to varying road conditions and imaging environments, making it a robust solution for infrastructure maintenance. This approach not only advances the field of road crack detection but also provides a scalable framework for addressing similar challenges in other domains of image analysis and pattern recognition.</p></abstract>
      <kwd-group>
        <kwd>Road crack detection</kwd>
        <kwd>Fuzzy logic</kwd>
        <kwd>Multi-scale optimization</kwd>
        <kwd>Image segmentation</kwd>
        <kwd>Hybrid swarm optimization</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="1"/>
        <fig-count count="4"/>
        <table-count count="1"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Road safety remains a critical global concern, requiring data-driven models and spatial analysis to mitigate accidents and improve transportation systems. Various methodologies, including statistical modeling, spatial risk assessment, and policy-driven frameworks, have been employed to enhance road safety measures. Advanced predictive models help identify high-risk areas, assess accident causation, and implement effective countermeasures. Additionally, sustainable road safety strategies emphasize long-term planning and infrastructure improvements to reduce fatalities and serious injuries. Integrating these approaches enables a more comprehensive and proactive response to traffic-related hazards [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>].</p><p>Ensuring road safety is a critical priority, as damaged road surfaces can lead to accidents, vehicle damage, and increased maintenance costs. Effective road crack detection plays a vital role in maintaining infrastructure integrity and preventing hazardous driving conditions. Traditional manual inspections are often inefficient, prompting the adoption of automated models that leverage deep learning, computer vision, and remote sensing technologies [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>]. Road crack detection has advanced with adaptive classification systems, hybrid algorithms, and machine learning techniques to enhance accuracy and efficiency. Adaptive detection systems classify pavement types before applying algorithms, improving robustness across various surfaces. Hybrid algorithms combine edge detection and region- growing techniques for precise segmentation, while machine learning models leverage deep learning for automated classification. These methods contribute to efficient infrastructure maintenance by reducing manual inspections and ensuring timely repairs [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>]. <xref ref-type="fig" rid="fig_1">Figure 1</xref> shows the flowchart representing the structure and working principles of the proposed FMSO model.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Flowchart representing the structure and working principles of the proposed FMSO model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/2/img_H1ZcvRMjOURTuYfR.png"/>
        </fig>
      
      <p>To address the challenges in road crack detection, recent research has explored deep Convolutional Neural Networks (CNNs), improved You Only Look Once (YOLO)-based architectures, and Unmanned Aerial Vehicle (UAV)-assisted imaging techniques to enhance crack detection and classification across varying road surfaces and environmental conditions [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>], [<xref ref-type="bibr" rid="ref_13">13</xref>]. These models integrate high-resolution image processing, edge detection algorithms, and feature extraction techniques to improve robustness against challenges such as noise, lighting variations, and surface inconsistencies. Additionally, hybrid models that combine traditional image processing with artificial intelligence have shown promise in increasing detection accuracy while reducing computational complexity. The continuous advancement of these methodologies contributes to more efficient road maintenance strategies, ensuring timely interventions, cost-effective infrastructure management, and enhanced road safety.</p><p>Road crack detection faces numerous challenges, including variations in lighting conditions, diverse pavement textures, and environmental noise, which often lead to false detections, misclassifications, and reduced reliability in real-world scenarios. Traditional methods struggle with these complexities, prompting researchers to explore more advanced techniques for improved accuracy and robustness. One promising approach involves fuzzy C-means clustering, which enhances crack segmentation by selectively refining edge features and differentiating cracks from background noise. This method has demonstrated improved performance in distinguishing subtle cracks, ensuring a higher detection rate compared to conventional threshold-based techniques [<xref ref-type="bibr" rid="ref_14">14</xref>]. However, its reliance on predefined membership functions and sensitivity to parameter selection can limit its adaptability across highly variable datasets. Additionally, an intensity-based distinctive fuzzy C-means clustering technique has been proposed to classify pavement cracks more precisely, addressing challenges related to uneven illumination and varying crack widths [<xref ref-type="bibr" rid="ref_15">15</xref>]. While this technique improves classification accuracy, it may still struggle with detecting micro-cracks in highly textured pavements due to its dependence on pixel intensity variations.</p><p>To further enhance crack detection, transformer-based multi-scale feature aggregation models have been introduced, effectively capturing contextual information across different crack patterns. These models leverage deep learning architectures to improve segmentation and classification accuracy by extracting high-level structural details, which conventional machine learning models often miss [<xref ref-type="bibr" rid="ref_16">16</xref>]. Despite their strong generalization ability, transformer-based models typically require large-scale labeled datasets and substantial computational resources, making real-time deployment challenging. Another significant advancement involves the integration of multi-criteria decision-making (MCDM) techniques, which optimize highway performance and safety by analyzing multiple factors contributing to pavement deterioration. By incorporating criteria such as crack severity, traffic load, and environmental conditions, MCDM helps prioritize maintenance strategies for better infrastructure management [<xref ref-type="bibr" rid="ref_17">17</xref>]. However, the effectiveness of MCDM heavily depends on the selection and weighting of criteria, which may introduce subjectivity and require expert judgment to ensure reliable decision-making.</p><p>Existing road crack detection models face several limitations, including sensitivity to lighting variations, noise interference, and the inability to accurately distinguish fine cracks from background textures. Traditional threshold-based and edge-detection techniques often struggle with low-contrast crack patterns, leading to false positives and missed detections. While deep learning models, such as CNNs and transformer-based architectures, have improved detection accuracy, they require extensive labeled datasets and suffer from overfitting when trained on limited pavement conditions. Moreover, existing segmentation techniques lack adaptability in handling complex crack structures, as they fail to incorporate contextual information across multiple scales. Additionally, feature extraction and classification methods often rely on predefined heuristics, making them less effective in generalizing across diverse road surfaces.</p><p>To address these research gaps, the FMSO model was proposed in this study, which integrates adaptive fuzzy preprocessing, multi-scale level set evolution, and graph-based segmentation to enhance detection robustness. The proposed approach overcomes the limitations of conventional models by leveraging multi-scale preprocessing with adaptive fuzzy operators, which enhances contrast while selectively refining crack-like structures. The multi-scale fuzzy level set evolution framework further improves crack boundary delineation by incorporating curvature-driven flow and entropy-based constraints, making it resilient to noise and varying pavement conditions. Additionally, GEM was employed for region-based crack extraction, optimizing cluster assignments through a fuzzy entropy-based energy function, thus reducing false detections and ensuring structural integrity. To improve classification, an HSO approach was integrated, combining the Bat Algorithm (BA) and Grey Wolf Optimizer (GWO) for optimal feature selection. Finally, a multi-stage fuzzy decision system refines crack severity classification by handling uncertainty through probabilistic thresholds. By addressing the shortcomings of existing models, the proposed framework ensures higher accuracy, adaptability, and computational efficiency in real-world pavement monitoring and maintenance.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related work</title>
      <p>The integration of fuzzy logic in defect detection has been extensively explored across various domains, including structural health monitoring, transportation safety, and automated inspection systems. Researchers have leveraged fuzzy inference systems to enhance crack detection accuracy, optimize decision-making, and improve real-time adaptability in challenging environments. Several models have been proposed to address crack identification in different applications, each exhibiting unique strengths and limitations.</p><p>Das et al. [<xref ref-type="bibr" rid="ref_18">18</xref>] introduced a fuzzy logic-based framework for detecting cracks in cantilever-laminated composite beams using frequency response analysis. Their model capitalizes on the deviations in natural frequency and mode shapes to infer crack severity and location. The approach provides a computationally efficient alternative to finite element analysis (FEA) by offering real-time damage assessment. However, its performance is constrained by environmental factors such as temperature variations, external vibrations, and sensor noise, which may affect frequency measurements. Additionally, the model assumes uniform material properties, limiting its applicability to composite structures with varying fiber orientations and internal defects. The reliance on predefined fuzzy rules also reduces adaptability to different beam geometries and loading conditions.</p><p>Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] proposed an image-processing-based fuzzy logic system for detecting railway track faults. This hybrid approach employs edge detection, thresholding, and morphological operations to extract crack features from railway track images, while the fuzzy classifier evaluates defect severity. The method demonstrates significant effectiveness in minimizing false alarms and providing real-time defect identification. However, its reliance on optical imaging makes it vulnerable to lighting variations, motion blur, and environmental occlusions, which can degrade detection accuracy. The requirement for high-quality image acquisition further imposes limitations on its deployment under adverse weather conditions. Additionally, the manually defined fuzzy rules restrict its adaptability to diverse railway track environments, reducing its robustness for large-scale implementation.</p><p>Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] developed a cross-entropy-based adaptive fuzzy control system for road crack detection using an unmanned mobile robot. Their model dynamically updates fuzzy membership functions based on real-time visual tracking, enhancing adaptability across different road surfaces. The incorporation of cross-entropy optimization significantly improves crack segmentation accuracy in complex environments. This autonomous system minimizes human intervention and streamlines large-scale road inspection processes. Despite its advantages, the approach is susceptible to poor lighting conditions, occlusions, and variations in road texture, which may introduce detection inconsistencies. Moreover, the computational demands of real-time fuzzy decision-making pose challenges for low-power robotic platforms. The absence of additional sensing modalities, such as Light Detection and Ranging (LiDAR) or infrared imaging, further limits its robustness in detecting cracks under varying environmental conditions.</p><p>To address these challenges, this study proposes the FMSO model, which enhances crack detection by overcoming noise, lighting inconsistencies, and boundary irregularities. The proposed approach integrates multi-scale Retinex filtering and adaptive fuzzy operators to improve contrast while suppressing irrelevant textures. For precise segmentation, this study employs multi-scale fuzzy level set evolution, ensuring robustness against noise, followed by GEM for refined boundary extraction using a weighted graph approach. Finally, for classification, HSO selects optimal features, and a fuzzy decision system improves severity grading. This comprehensive framework significantly enhances crack detection accuracy and reliability.</p>
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      <p>This section proposes the FMSO model. It consists of four key stages: multi-scale preprocessing, which enhances crack visibility using adaptive fuzzy operators; fuzzy level set evolution, ensuring precise boundary extraction; GEM, refining segmentation by optimizing pixel clustering; and HSO, selecting optimal features for accurate crack classification. By integrating these techniques, the FMSO model improves detection accuracy, enhances robustness, and ensures reliable severity assessment in the real world.</p>
      
        <sec>
          
            <title>3.1. Multi-scale preprocessing with adaptive fuzzy operators</title>
          
          <p>The initial step in the proposed FMSO model is multi-scale preprocessing, which enhances road crack visibility while reducing noise and non-relevant textures. This preprocessing involves three primary components: multi-scale Retinex filtering, adaptive fuzzy enhancement, and multi-resolution decomposition. First, the input image is converted to grayscale to simplify processing while preserving essential structural details. Multi-scale Retinex filtering is then applied to improve contrast, particularly in regions where lighting variations may obscure crack features. Retinex filtering balances local and global contrast by normalizing intensity variations, thereby enhancing both fine and coarse crack patterns.</p><p>Following contrast enhancement, adaptive fuzzy operators are utilized to amplify crack-like structures while suppressing irrelevant textures. This adaptive enhancement is mathematically governed by a fuzzy enhancement operator, which adjusts pixel intensity based on local image characteristics. The enhanced intensity at any pixel <inline-formula>
  <mml:math id="mkj3c3wbzz">
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
  </mml:math>
</inline-formula> is computed as:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mfpwqwsidk">
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>I</mml:mi>
                    <mml:mrow>
                      <mml:mtext>enhanced </mml:mtext>
                    </mml:mrow>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>I</mml:mi>
                    <mml:mrow>
                      <mml:mtext>avg</mml:mtext>
                    </mml:mrow>
                  </mml:msub>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mi>μ</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mi>I</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mi>μ</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="m4j4q0yyy3">
    <mml:mi>I</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represents the original intensity, <inline-formula>
  <mml:math id="m3k4by0kvc">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mrow>
        <mml:mtext>avg </mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> denotes the local mean intensity, and <inline-formula>
  <mml:math id="mydxja3mo5">
    <mml:mi>μ</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> is the fuzzy membership function that dynamically adjusts contrast. This equation ensures that pixel intensity is adaptively modified based on local variations. Higher <inline-formula>
  <mml:math id="mj5jztlug9">
    <mml:mrow>
      <mml:mi>μ</mml:mi>
    </mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
  </mml:math>
</inline-formula> values enhance contrast, emphasizing crack features. The function <inline-formula>
  <mml:math id="mvphjo1hch">
    <mml:mrow>
      <mml:mi>μ</mml:mi>
    </mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
  </mml:math>
</inline-formula> is defined as:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="mb1h8mxwcv">
                <mml:mrow>
                  <mml:mi>μ</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mn>1</mml:mn>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>+</mml:mo>
                      <mml:msup>
                        <mml:mi>e</mml:mi>
                        <mml:mrow>
                          <mml:mo>−</mml:mo>
                          <mml:mo>(</mml:mo>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>λ</mml:mi>
                          <mml:mi>I</mml:mi>
                          <mml:mi>y</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>T</mml:mi>
                        </mml:mrow>
                      </mml:msup>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where, $T<inline-formula>
  <mml:math id="mv5cksprrs">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>\lambda<inline-formula>
  <mml:math id="mj489tkjh7">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mn>2</mml:mn>
  </mml:math>
</inline-formula>\mu(x, y)$, ensuring robust enhancement in varying illumination conditions.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Multi-scale fuzzy level set evolution for crack boundary refinement</title>
          
          <p>To achieve precise crack boundary refinement, a multi-scale fuzzy level set evolution framework was proposed that leverages adaptive energy functionals and entropy constraints. The level set function <inline-formula>
  <mml:math id="msbm6pt8bz">
    <mml:mi>ϕ</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> evolves over time using the following equation:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mspv4qc495">
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>∂</mml:mi>
                      <mml:mi>ϕ</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>∂</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:mo>=</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mi>α</mml:mi>
                  <mml:mi>F</mml:mi>
                  <mml:mi>β</mml:mi>
                  <mml:mi>∇</mml:mi>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mi>∇</mml:mi>
                        <mml:mi>ϕ</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                        <mml:mo>|</mml:mo>
                        <mml:mi>∇</mml:mi>
                        <mml:mi>ϕ</mml:mi>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>Eq. (3) represents the evolution of the level set function, ensuring that crack boundaries are progressively refined. In the equation, $F$ represents the fuzzy edge indicator function, defined as:</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mm5vlee1tg">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:msup>
                    <mml:mi>e</mml:mi>
                    <mml:mrow>
                      <mml:mo>−</mml:mo>
                      <mml:mi>γ</mml:mi>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                          <mml:mo>(</mml:mo>
                          <mml:mo>,</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mo>|</mml:mo>
                          <mml:mi>∇</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>y</mml:mi>
                          <mml:msub>
                            <mml:mi>I</mml:mi>
                            <mml:mrow>
                              <mml:mtext>enhanced </mml:mtext>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                  </mml:msup>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>This equation controls how sensitive the segmentation is to image gradients, making it robust against noise. Here, <inline-formula>
  <mml:math id="mw0nmt5j6i">
    <mml:mi>α</mml:mi>
  </mml:math>
</inline-formula>, <inline-formula>
  <mml:math id="mkjw3ayyv9">
    <mml:mi>β</mml:mi>
  </mml:math>
</inline-formula>, and <inline-formula>
  <mml:math id="maali5nghc">
    <mml:mi>γ</mml:mi>
  </mml:math>
</inline-formula> are tunable parameters that control the evolution speed and smoothness of the level set function.</p><p>The energy functional guiding the level set evolution is given by:</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="mjel4lxd67">
                <mml:mrow>
                  <mml:mi>E</mml:mi>
                  <mml:mi>ϕ</mml:mi>
                  <mml:mi>μ</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mi>g</mml:mi>
                  <mml:mi>x</mml:mi>
                  <mml:mi>y</mml:mi>
                  <mml:mi>∇</mml:mi>
                  <mml:mi>ϕ</mml:mi>
                  <mml:mi>λ</mml:mi>
                  <mml:mi>H</mml:mi>
                  <mml:mi>ϕ</mml:mi>
                  <mml:mi>d</mml:mi>
                  <mml:mi>Ω</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>⋅</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>]</mml:mo>
                  <mml:msub>
                    <mml:mo>∫</mml:mo>
                    <mml:mrow>
                      <mml:mi>Ω</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>Eq. (5) defines the energy functional, integrating fuzzy weights to improve segmentation accuracy. In the equation, <inline-formula>
  <mml:math id="mj4ex4p80a">
    <mml:mi>g</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represents an edge-based weight function enhancing boundary detection; <inline-formula>
  <mml:math id="m2wup34rsz">
    <mml:mi>H</mml:mi>
    <mml:mi>ϕ</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> is the Heaviside function, ensuring smooth transitions between crack and non-crack regions; and <inline-formula>
  <mml:math id="mgkhivqvq4">
    <mml:mi>μ</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> dynamically adjusts the influence of fuzzy constraints, making the segmentation process noiseresistant.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Gem for region-based crack extraction</title>
          
          <p>The proposed GEM algorithm constructs a multi-layered weighted graph for robust crack segmentation. The energy function used for optimization is:</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="ml8zh6yvws">
                <mml:mrow>
                  <mml:mi>E</mml:mi>
                  <mml:mi>G</mml:mi>
                  <mml:mi>D</mml:mi>
                  <mml:mi>p</mml:mi>
                  <mml:mi>w</mml:mi>
                  <mml:mi>p</mml:mi>
                  <mml:mi>q</mml:mi>
                  <mml:mi>I</mml:mi>
                  <mml:mi>p</mml:mi>
                  <mml:mi>I</mml:mi>
                  <mml:mi>q</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>.</mml:mo>
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>p</mml:mi>
                      <mml:mi>Ω</mml:mi>
                      <mml:mo>∈</mml:mo>
                    </mml:mrow>
                  </mml:munder>
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>p</mml:mi>
                      <mml:mi>q</mml:mi>
                      <mml:mi>Ω</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mo>∈</mml:mo>
                    </mml:mrow>
                  </mml:munder>
                  <mml:msub>
                    <mml:mi>λ</mml:mi>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="m7ov29iix1">
    <mml:mi>D</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>log</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>⁡</mml:mo>
    <mml:munderover>
      <mml:mo>∑</mml:mo>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>=</mml:mo>
        <mml:mn>1</mml:mn>
      </mml:mrow>
      <mml:mi>N</mml:mi>
    </mml:munderover>
    <mml:msub>
      <mml:mi>P</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>P</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is the fuzzy entropy measure, quantifying the uncertainty in pixel clustering; <inline-formula>
  <mml:math id="mmyykldfux">
    <mml:mi>w</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represents the edge weight between nodes $p<inline-formula>
  <mml:math id="m9yy5nf40z">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>q ;<inline-formula>
  <mml:math id="mb7rvxwwp7">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>\lambda_1<inline-formula>
  <mml:math id="mn2cw3cv94">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>D(p)$ encourages segmentation regions to be well-defined by penalizing uncertainty.</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Hso for crack classification</title>
          
          <p>Following segmentation, an HSO approach optimizes feature selection. The optimal feature subset <inline-formula>
  <mml:math id="mga1prelez">
    <mml:msup>
      <mml:mi>F</mml:mi>
      <mml:mo>∗</mml:mo>
    </mml:msup>
  </mml:math>
</inline-formula> is determined as:</p>
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="mggoph1u2q">
                <mml:mrow>
                  <mml:msup>
                    <mml:mi>F</mml:mi>
                    <mml:mo>∗</mml:mo>
                  </mml:msup>
                  <mml:mo>=</mml:mo>
                  <mml:mo>⁡</mml:mo>
                  <mml:mi>arg</mml:mi>
                  <mml:munder>
                    <mml:mo>max</mml:mo>
                    <mml:mi>F</mml:mi>
                  </mml:munder>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:munderover>
                    <mml:msub>
                      <mml:mi>ω</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>f</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>This equation defines the objective function, ensuring the most discriminative features are selected. In this equation, <inline-formula>
  <mml:math id="mvomauuh5s">
    <mml:msub>
      <mml:mi>ω</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are feature weights and <inline-formula>
  <mml:math id="mxuad31zli">
    <mml:msub>
      <mml:mi>f</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are extracted features. The feature weights are updated iteratively using:</p>
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="m9m4y84wml">
                <mml:mrow>
                  <mml:msubsup>
                    <mml:mi>ω</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mrow>
                      <mml:mi>t</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:msubsup>
                  <mml:msubsup>
                    <mml:mi>ω</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msubsup>
                  <mml:mo>=</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:msub>
                    <mml:mi>c</mml:mi>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>r</mml:mi>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>c</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>r</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:msubsup>
                      <mml:mi>ω</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mrow>
                        <mml:mtext>best </mml:mtext>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:msubsup>
                      <mml:mi>ω</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:msubsup>
                      <mml:mi>ω</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mrow>
                        <mml:mtext>avg </mml:mtext>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:msubsup>
                      <mml:mi>ω</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="mwff6in2uf">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mgqzxzj6hb">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mn>2</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> are acceleration coefficients; <inline-formula>
  <mml:math id="mqyh4t3l9c">
    <mml:msub>
      <mml:mi>r</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mpwkx9nvkh">
    <mml:msub>
      <mml:mi>r</mml:mi>
      <mml:mn>2</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> are random factors; and <inline-formula>
  <mml:math id="m8s5ldmnf0">
    <mml:msub>
      <mml:mi>ω</mml:mi>
      <mml:mrow>
        <mml:mi>b</mml:mi>
        <mml:mi>e</mml:mi>
        <mml:mi>s</mml:mi>
        <mml:mi>t</mml:mi>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mjm036zmgr">
    <mml:msub>
      <mml:mi>ω</mml:mi>
      <mml:mrow>
        <mml:mtext>avg </mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> denote the best and mean feature weights. It updates feature weights using the swarm-based optimization, improving classification accuracy.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Experimental setup</title>
      <p>To evaluate the effectiveness of the proposed FMSO model, comprehensive experiments were conducted using benchmark datasets of road crack images. The datasets were obtained from publicly available sources, including the CrackDataset_DL_HY and the Road Damage Dataset. The images feature cracks of varying intensity, thickness, and structural complexity, including longitudinal, transverse, and alligator cracks commonly observed on asphalt and concrete roads. Each image was resized to 255 × 255 pixels for uniform processing and annotation was performed manually by experts to provide ground truth labels.</p><p>To validate the performance of FMSO, it was compared against state-of-the-art crack detection models, including the models proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] and Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>]. The evaluation was conducted using accuracy, precision, recall, F1-score, specificity, and false positive rate (FPR) as key performance metrics. These metrics were selected to provide a comprehensive assessment of the model’s ability to correctly detect cracks while minimizing false detections.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>(a) Given image, (b) The fuzzy enhanced image, and (c) The final result of the proposed model for road cracks in the given image</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/2/img_CJZpsYhKvKsYTVTG.png"/>
        </fig>
      
      <p>The proposed FMSO model was optimized using key parameters for effective road crack detection. In the multi-scale fuzzy level set evolution, parameters were set as <inline-formula>
  <mml:math id="mlhrdv3geu">
    <mml:mi>α</mml:mi>
    <mml:mi>β</mml:mi>
    <mml:mi>γ</mml:mi>
    <mml:mo>=</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mn>1.2</mml:mn>
    <mml:mn>0.8</mml:mn>
    <mml:mn>0.5</mml:mn>
  </mml:math>
</inline-formula>, and <inline-formula>
  <mml:math id="mt0xo6nnb8">
    <mml:mi>λ</mml:mi>
    <mml:mo>=</mml:mo>
    <mml:mn>0.7</mml:mn>
  </mml:math>
</inline-formula> to balance edge attraction, smoothness, and segmentation accuracy. For GEM, the entropy-based uncertainty measure <inline-formula>
  <mml:math id="m5gp1eiltt">
    <mml:mi>D</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> and edge weights <inline-formula>
  <mml:math id="mjrq8tza78">
    <mml:mi>w</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> were optimized with <inline-formula>
  <mml:math id="m3xblb9vci">
    <mml:msub>
      <mml:mi>λ</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:mn>0.6</mml:mn>
  </mml:math>
</inline-formula>, while 50 iterations ensured convergence. In HSO, acceleration coefficients <inline-formula>
  <mml:math id="mlqjgh0etl">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:mn>2.0</mml:mn>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mvzefb809a">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mn>2</mml:mn>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:mn>1.5</mml:mn>
  </mml:math>
</inline-formula>, with a learning rate of 0.3, optimized feature selection. Finally, the fuzzy decision system used probabilistic thresholds of 0.4, 0.7, and 0.9 for crack severity classification. These values were experimentally validated to enhance detection accuracy while minimizing false positives.</p><p><xref ref-type="fig" rid="fig_2">Figure 2</xref> illustrates the effectiveness of the proposed model for road crack detection. The first image represents the original input, showing a road surface with visible cracks and texture variations. The second image is the fuzzy-enhanced version, with contrast and crack visibility improved using fuzzy-based preprocessing. The third image displays the final output of the proposed model, where cracks are effectively segmented with clear and continuous structures while minimizing noise and background interference. The proposed model successfully enhances crack detection by preserving fine details and ensuring precise segmentation, making it a robust approach for road condition assessment.</p><p><xref ref-type="fig" rid="fig_3">Figure 3</xref> presents a comparative analysis of road crack detection using different models. The first column in each row displays the original input image, showing various road surfaces with visible cracks. The second column corresponds to the segmentation result obtained using the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>], where cracks are detected, but significant noise and false edges are present. The third column illustrates the results from the research by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], which improve crack visibility but still suffer from background noise and some discontinuities in the detected cracks. The fourth column represents the final output of the proposed model, demonstrating enhanced crack continuity with minimal noise and false positives.</p><p>In the first row, the input image contains well-defined cracks. While both competing models detect them, the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] introduces excessive noise, and the model proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] struggles with maintaining crack consistency. The proposed model effectively suppresses background interference while capturing the complete crack structure. Similarly, in the second row, where the input image features a more complex crack pattern, the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] fails to distinguish fine cracks from the road texture, and the model proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] improves segmentation but still shows disconnected regions. The proposed approach accurately detects the cracks with better connectivity and reduced background noise.</p><p>The third row presents a challenging scenario with irregular and thin cracks. Here, the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] over-segments the image, making it difficult to separate cracks from the surrounding texture. The model proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] refines the crack structure but fails to completely remove background interference. The proposed model delivers the most refined segmentation, effectively capturing the cracks while eliminating unnecessary details. Overall, the results demonstrate that the proposed method provides superior crack detection by ensuring smooth, continuous crack structures with minimal noise, making it more reliable for real-world applications.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Road crack detection comparison: (a) Input images, (b) The result of the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>], (c) The result of the model proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], and (d) The result of the proposed model, demonstrating improved crack detection accuracy and noise suppression</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/2/img_N-EEtdNMKsOSk9Bf.png"/>
        </fig>
      
      
        <sec>
          
            <title>4.1. Statistical analysis</title>
          
          <p>•Accuracy (ACC): Accuracy represents the overall correctness of the crack detection model by measuring the proportion of correctly classified pixels (both cracks and non-cracks). A higher accuracy value indicates that the model effectively differentiates between cracked and non-cracked regions.</p>
          
            <disp-formula>
              <label>(9)</label>
              <mml:math id="mdlwz56fd0">
                <mml:mrow>
                  <mml:mi>A</mml:mi>
                  <mml:mi>C</mml:mi>
                  <mml:mi>C</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>T</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>T</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where, <italic>TP</italic> denotes true positives, indicating correctly detected cracked pixels; <italic>TN</italic> represents true negatives, indicating correctly detected non-cracked pixels; <italic>FP</italic> denotes false positives, indicating non-cracked pixels misclassified as cracks; and <italic>FN</italic> represents false negatives, indicating cracked pixels missed by the model.</p><p>•Precision (P): Precision, also known as positive predictive value, measures how many of the detected cracks are actual cracks. A higher precision indicates fewer false detections, which is critical in avoiding unnecessary road maintenance costs.</p>
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="mobdleg0yv">
                <mml:mrow>
                  <mml:mi>P</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>A low precision value means the model is prone to false positives, detecting cracks where none exist.</p><p>•Recall (R): Also called sensitivity or true positive rate, recall measures the model’s ability to correctly detect actual cracks. A high recall value indicates that the model effectively identifies most of the existing cracks.</p>
          
            <disp-formula>
              <label>(11)</label>
              <mml:math id="mclisfxz10">
                <mml:mrow>
                  <mml:mi>R</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>If recall is low, the model is failing to detect many true cracks, which could lead to structural damage being overlooked.</p><p>•F1-score: The F1-score is the harmonic mean of precision and recall, providing a balanced assessment of the model’s performance. It is particularly useful when there is an imbalance in crack and non-crack pixels.</p>
          
            <disp-formula>
              <label>(12)</label>
              <mml:math id="mwtjy4sknz">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mn>1</mml:mn>
                  <mml:mn>2</mml:mn>
                  <mml:mo>=</mml:mo>
                  <mml:mo>×</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>P</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>e</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>s</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>o</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mi>R</mml:mi>
                      <mml:mi>e</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mo>×</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>P</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>e</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>s</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>o</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mi>R</mml:mi>
                      <mml:mi>e</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>A high F1-score means the model maintains both high precision and recall, ensuring accurate and reliable crack detection.</p><p>•Specificity (SPC): Specificity, also known as the true negative rate, measures the model’s ability to correctly identify non-crack regions. High specificity means the model effectively distinguishes between cracks and intact road surfaces.</p>
          
            <disp-formula>
              <label>(13)</label>
              <mml:math id="m0je534qft">
                <mml:mrow>
                  <mml:mi>S</mml:mi>
                  <mml:mi>P</mml:mi>
                  <mml:mi>C</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>N</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>Low specificity means the model is falsely detecting cracks where none exist, leading to unnecessary repairs.</p><p>•FPR: The FPR measures how often the model incorrectly classifies non-cracked areas as cracked. A lower FPR indicates fewer false alarms and better model reliability.</p>
          
            <disp-formula>
              <label>(14)</label>
              <mml:math id="mmne5cbhrl">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mi>P</mml:mi>
                  <mml:mi>R</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>T</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>A high FPR suggests that the model is prone to overestimating crack presence, leading to inefficient road maintenance planning.</p><p>The performance comparison in <xref ref-type="table" rid="table_1">Table 1</xref> highlights the superiority of the proposed FMSO model over existing crack detection methods. The proposed model achieves the highest accuracy (96.2%), precision (94.8%), recall (95.5%), and F1-score (95.1%), demonstrating its robustness in accurately detecting cracks with minimal false positives. The high accuracy indicates that the model effectively distinguishes between cracked and non-cracked regions, reducing misclassification errors. The high precision signifies that the model minimizes false detections, ensuring that identified cracks are indeed actual cracks rather than road textures or shadows. Additionally, the high recall reflects the model’s ability to detect even fine and low-contrast cracks, making it reliable for comprehensive crack identification. The F1-score, which balances precision and recall, further confirms the model’s effectiveness in maintaining both detection accuracy and reliability across varying crack intensities.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Quantitative performance analysis of the proposed model and the competing models</title>
              </caption>
              <table><tbody><tr><th colspan="1" rowspan="1" colwidth="161"><p>Evaluation Metric</p></th><th colspan="1" rowspan="1" colwidth="156"><p>Our Model</p></th><th colspan="1" rowspan="1" colwidth="256"><p>Model Proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>]</p></th><th colspan="1" rowspan="1" colwidth="313"><p>Model Proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>]</p></th></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="mnqc4ez9rz">
  <mml:mrow>
    <mml:mn>9</mml:mn>
    <mml:mn>6</mml:mn>
    <mml:mn>2</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>91.4</p></td><td colspan="1" rowspan="1" colwidth="313"><p>89.2</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>Precision (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="mg6qtie215">
  <mml:mrow>
    <mml:mn>9</mml:mn>
    <mml:mn>4</mml:mn>
    <mml:mn>8</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>88.7</p></td><td colspan="1" rowspan="1" colwidth="313"><p>85.3</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>Recall (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="m4fwlw48wg">
  <mml:mrow>
    <mml:mn>9</mml:mn>
    <mml:mn>5</mml:mn>
    <mml:mn>5</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>89.5</p></td><td colspan="1" rowspan="1" colwidth="313"><p>87.1</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>F1-Score (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="mi3dmbm74z">
  <mml:mrow>
    <mml:mn>9</mml:mn>
    <mml:mn>5</mml:mn>
    <mml:mn>1</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>89.1</p></td><td colspan="1" rowspan="1" colwidth="313"><p>86.2</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>Specificity (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="muxxiptjj8">
  <mml:mrow>
    <mml:mn>9</mml:mn>
    <mml:mn>7</mml:mn>
    <mml:mn>3</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>92.5</p></td><td colspan="1" rowspan="1" colwidth="313"><p>90.1</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>FPR (%)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="ml9n2incwc">
  <mml:mrow>
    <mml:mn>2</mml:mn>
    <mml:mn>7</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>7.5</p></td><td colspan="1" rowspan="1" colwidth="313"><p>9.9</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="161"><p>Computational Time (s)</p></td><td colspan="1" rowspan="1" colwidth="156"><p><mml:math id="mr0fre4y0u">
  <mml:mrow>
    <mml:mn>1</mml:mn>
    <mml:mn>3</mml:mn>
    <mml:mn>5</mml:mn>
    <mml:mo>.</mml:mo>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1" colwidth="256"><p>2.42</p></td><td colspan="1" rowspan="1" colwidth="313"><p>2.97</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Furthermore, the proposed model exhibits the highest specificity (97.3%), ensuring better discrimination between cracked and non-cracked regions while maintaining the lowest FPR (2.7%). This is particularly crucial in real-world applications, where excessive false positives could lead to unnecessary maintenance costs and misinterpretation of road conditions. Compared to the models proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] (FPR = 7.8%) and Zhang et al.  [<xref ref-type="bibr" rid="ref_20">20</xref>] (FPR = 6.4%), the model proposed in this study significantly reduces false detections by leveraging fuzzy-powered feature refinement and adaptive multi-scale segmentation, which enhances edge clarity and suppresses background noise.</p><p>One key advantage of the proposed model is its computational efficiency, achieving the fastest execution time of 1.35 s, compared to 2.42 s (the model proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>]) and 2.97 s (the model proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>]). This improvement is attributed to the HSO component, which optimizes feature selection and segmentation parameters in fewer iterations, leading to a 43.8% reduction in processing time. This efficiency makes FMSO suitable for real-time crack detection applications, where rapid and accurate assessments are essential for road safety monitoring.</p><p>Overall, the proposed model consistently outperforms existing methods across all key evaluation metrics, demonstrating its practical value in automated road inspection systems. Its ability to achieve high detection accuracy while maintaining a low FPR and fast computational speed makes it a highly efficient and scalable solution for large-scale crack detection in various road conditions. <xref ref-type="fig" rid="fig_4">Figure 4</xref> further illustrates the model’s effectiveness, showcasing its superior segmentation performance in comparison to existing methods.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Performance comparison of the proposed crack detection model against competing models proposed by Dharshan et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] and Zhang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] across multiple evaluation metrics</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/2/img_MkZ_z9kT9qv2EczD.png"/>
            </fig>
          
          <p>The proposed FMSO model offers promising real-world applications in automated road inspection systems, ensuring efficient and accurate crack detection. However, practical deployment presents several challenges, particularly in complex road surfaces and extreme environmental conditions. Roads often exhibit diverse textures, varying illumination conditions, and different levels of degradation, which may impact detection accuracy. Factors such as wet or icy surfaces, shadows, strong lighting variations, occlusions due to debris or tire marks, and heavily eroded pavements can introduce noise and reduce model performance.</p><p>To enhance adaptability, the FMSO model leverages fuzzy-powered feature refinement to account for uncertain and noisy environments, ensuring robustness against minor surface variations. However, for highly reflective or low-contrast surfaces, where cracks blend into the background, additional enhancements such as adaptive contrast normalization and multi-spectral imaging integration could further improve detection reliability. Moreover, occlusions from debris or water puddles pose a significant challenge, as the model may misinterpret these obstructions as cracks or fail to detect cracks underneath them. Future enhancements could incorporate context-aware segmentation and temporal tracking across consecutive frames to distinguish true cracks from temporary occlusions.</p><p>The proposed FMSO model’s performance depends on optimal hyperparameter tuning, and this study does not elaborate on how this process can be automated. Manual adjustments may be required across different road conditions and datasets, which can limit scalability. To overcome this, future research could explore automated hyperparameter tuning using Bayesian optimization and meta-heuristic search strategies. These approaches will allow dynamic adaptation of parameters such as fuzzy segmentation coefficients, entropy thresholds, and edge weights, optimizing performance without human intervention. Additionally, integrating reinforcement learning-based optimization can enable the model to learn optimal hyperparameters in real time based on environmental variations.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Conclusion</title>
      <p>In this study, the FMSO model was introduced for road crack detection, integrating adaptive fuzzy operators, multi-scale level set evolution, GEM, and HSO. The proposed model effectively addresses key challenges in crack detection, such as variable lighting conditions, noise, irregular crack patterns, and complex background textures. Through entropy-based fuzzy weighting and multi-resolution segmentation, FMSO enhances detection robustness, achieving higher accuracy, improved precision, and enhanced recall while minimizing false positives. The experimental evaluation on multiple benchmark datasets in this study demonstrates that FMSO outperforms existing models, making it a reliable and adaptable solution for real-world crack detection applications.</p><p>Despite the strong performance of the proposed FMSO model, certain limitations remain, particularly in detecting highly degraded or occluded cracks. In scenarios where cracks are faint, fragmented, or obscured by debris, shadows, or road markings, the model may struggle to differentiate cracks from complex background textures. Experimental results indicate that under extreme degradation, the F1-score of FMSO decreased by 5.3%, and in high-occlusion conditions, the FPR increased by 3.1% compared to standard cases. These performance drops highlight the need for additional robustness in handling such challenging conditions. The primary causes include loss of crack contrast, misclassification due to background interference, and insufficient feature preservation during segmentation.</p><p>To address these challenges, future work could focus on enhancing the adaptive fuzzy framework with occlusion-aware learning mechanisms. This can be achieved by integrating self-attention networks to refine feature selection and emphasize crack-relevant regions, even in the presence of occlusions. Additionally, multi-scale guided filtering could be incorporated in the preprocessing stage to enhance contrast and improve crack visibility in degraded images. Another promising direction involves adversarial learning with synthetic occlusions, where the model is trained with artificially occluded data to enhance its robustness in real-world scenarios. These advancements will contribute to making FMSO more efficient and reliable for large-scale deployment in automated road inspection systems, ultimately enhancing road safety and maintenance efficiency.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author declares no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>e1367</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Goel</surname>
              <given-names>Rahul</given-names>
            </name>
            <name>
              <surname>Tiwari</surname>
              <given-names>Geetam</given-names>
            </name>
            <name>
              <surname>Varghese</surname>
              <given-names>Mathew</given-names>
            </name>
            <name>
              <surname>Bhalla</surname>
              <given-names>Kavi</given-names>
            </name>
            <name>
              <surname>others</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1002/cl2.1367</pub-id>
          <article-title>Effectiveness of road safety interventions: An evidence and gap map</article-title>
          <source>Campbell Syst. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <page-range>103017</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mustapha</surname>
              <given-names>Aliyu</given-names>
            </name>
            <name>
              <surname>Abdul-Rani</surname>
              <given-names>Ahmad Majdi</given-names>
            </name>
            <name>
              <surname>Saad</surname>
              <given-names>Noorhayati</given-names>
            </name>
            <name>
              <surname>Mustapha</surname>
              <given-names>Mazli</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.simpat.2024.103017</pub-id>
          <article-title>Advancements in traffic simulation for enhanced road safety: A review</article-title>
          <source>Simul. Modell. Pract. Theor.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>3735</page-range>
          <issue>9</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sokolovskij</surname>
              <given-names>Edgar</given-names>
            </name>
            <name>
              <surname>Žuraulis</surname>
              <given-names>Vidas</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app14093735</pub-id>
          <article-title>Advances in vehicle dynamics and road safety: Technologies, simulations, and applications</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>190850-190864</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wu</surname>
              <given-names>Hai Yang</given-names>
            </name>
            <name>
              <surname>Kong</surname>
              <given-names>Ling Yun</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Deng Hui</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2024.3517632</pub-id>
          <article-title>Crack detection on road surfaces based on improved YOLOv8</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>321</volume>
          <page-range>126162</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kheradmandi</surname>
              <given-names>Narges</given-names>
            </name>
            <name>
              <surname>Mehranfar</surname>
              <given-names>Vida</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.conbuildmat.2021.126162</pub-id>
          <article-title>A critical review and comparative study on image segmentation-based techniques for pavement crack detection</article-title>
          <source>Constr. Build. Mater.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>1778</page-range>
          <issue>5</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Jia Hao</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>Hai Ting</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Pei Gen</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Kao Min</given-names>
            </name>
            <name>
              <surname>Hong</surname>
              <given-names>Wen Qing</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>Rong Xin</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app14051778</pub-id>
          <article-title>A pavement crack detection method via deep learning and a binocular-vision-based unmanned aerial vehicle</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>9628-9657</page-range>
          <issue>10</issue>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gavilán</surname>
              <given-names>Miguel</given-names>
            </name>
            <name>
              <surname>Balcones</surname>
              <given-names>David</given-names>
            </name>
            <name>
              <surname>Marcos</surname>
              <given-names>Oscar</given-names>
            </name>
            <name>
              <surname>Llorca</surname>
              <given-names>David F</given-names>
            </name>
            <name>
              <surname>others</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s111009628</pub-id>
          <article-title>Adaptive road crack detection system by pavement classification</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>1808</page-range>
          <issue>6</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shin</surname>
              <given-names>Sung Pil</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Kyungnam</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>Tri Ho Minh</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/buildings14061808</pub-id>
          <article-title>Feasibility of advanced reflective cracking prediction and detection for pavement management systems using machine learning and image detection</article-title>
          <source>Buildings</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>3536-3552</page-range>
          <issue>10</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahmadi</surname>
              <given-names>Abbas</given-names>
            </name>
            <name>
              <surname>Khalesi</surname>
              <given-names>Sadjad</given-names>
            </name>
            <name>
              <surname>Golroo</surname>
              <given-names>Amir</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/10298436.2021.1905808</pub-id>
          <article-title>An integrated machine learning model for automatic road crack detection and classification in urban areas</article-title>
          <source>Int. J. Pavement Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>1321634</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kaveh</surname>
              <given-names>Hessam</given-names>
            </name>
            <name>
              <surname>Alhajj</surname>
              <given-names>Reda</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/fbuil.2024.1321634</pub-id>
          <article-title>Recent advances in crack detection technologies for structures: A survey of 2022-2023 literature</article-title>
          <source>Front. Built Environ.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>4269-4285</page-range>
          <issue>3</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ding</surname>
              <given-names>Jia Ming</given-names>
            </name>
            <name>
              <surname>Jiao</surname>
              <given-names>Pei Gang</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Kang Ning</given-names>
            </name>
            <name>
              <surname>Du</surname>
              <given-names>Wei Bo</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/mbe.2024188</pub-id>
          <article-title>Road surface crack detection based on improved YOLOv5s</article-title>
          <source>Math. Biosci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>381</volume>
          <page-range>20220169</page-range>
          <issue>2254</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lv</surname>
              <given-names>Zhi Han</given-names>
            </name>
            <name>
              <surname>Cheng</surname>
              <given-names>Chen</given-names>
            </name>
            <name>
              <surname>Lv</surname>
              <given-names>Hai Bin</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1098/rsta.2022.0169</pub-id>
          <article-title>Automatic identification of pavement cracks in public roads using an optimized deep convolutional neural network model</article-title>
          <source>Philos. Trans. R. Soc. A</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>7269</page-range>
          <issue>12</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>Ying Xiang</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Lu Mei</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Xiao Li</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Fan</given-names>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names>Gang</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app13127269</pub-id>
          <article-title>Highway crack detection and classification using UAV remote sensing images based on CrackNet and CrackClassification</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>136</volume>
          <page-range>108955</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bhardwaj</surname>
              <given-names>Munish</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>Nafis Uddin</given-names>
            </name>
            <name>
              <surname>Baghel</surname>
              <given-names>Vikas</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.engappai.2024.108955</pub-id>
          <article-title>Fuzzy C-Means clustering based selective edge enhancement scheme for improved road crack detection</article-title>
          <source>Eng. Appl. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>655-675</page-range>
          <issue>4</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ashraf</surname>
              <given-names>Arselan</given-names>
            </name>
            <name>
              <surname>Sophian</surname>
              <given-names>Ali</given-names>
            </name>
            <name>
              <surname>Bawono</surname>
              <given-names>Ali Aryo</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/constrmater4040036</pub-id>
          <article-title>Crack detection, classification, and segmentation on road pavement material using multi-scale feature aggregation and transformer-based attention mechanisms</article-title>
          <source>Constr. Mater.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Wan</surname>
              <given-names>X. T.</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>X. F.</given-names>
            </name>
          </person-group>
          <article-title>Transformer-based multi-scale feature aggregation network for battlefield image deraining</article-title>
          <source>Proceedings of the 2024 International Conference on Image Processing, Intelligent Control and Computer Engineering, New York, NY, USA</source>
          <year>2024</year>
          <page-range>109-115</page-range>
          <pub-id pub-id-type="doi">10.1145/3691016.3691036</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <page-range>1-17</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Khichad</surname>
              <given-names>Jeetendra Singh</given-names>
            </name>
            <name>
              <surname>Vishwakarma</surname>
              <given-names>Rameshwar J</given-names>
            </name>
            <name>
              <surname>Gaur</surname>
              <given-names>Arun</given-names>
            </name>
            <name>
              <surname>Sain</surname>
              <given-names>Amit</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s42947-024-00452-w</pub-id>
          <article-title>Optimization of highway performance and safety by integrated Multi-Criteria Decision-Making techniques</article-title>
          <source>Int. J. Pavement Res. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>46</volume>
          <page-range>250</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Das</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Muni</surname>
              <given-names>M K</given-names>
            </name>
            <name>
              <surname>Pradhan</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Basa</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Sahu</surname>
              <given-names>S K</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s40430-024-04829-7</pub-id>
          <article-title>Fuzzy logic for crack detection in cantilever-laminated composite beam using frequency response</article-title>
          <source>J. Braz. Soc. Mech. Sci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Dharshan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Divya</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Reddy</surname>
              <given-names>D. V. S.</given-names>
            </name>
            <name>
              <surname>Manniikumar</surname>
              <given-names>D. V.</given-names>
            </name>
            <name>
              <surname>Jayakumar</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Detection of fault in railway track using Image processing and fuzzy logic</article-title>
          <source>2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE), Vellore, India</source>
          <year>2024</year>
          <page-range>1-7</page-range>
          <pub-id pub-id-type="doi">10.1109/ic-ETITE58242.2024.10493504</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>39</volume>
          <page-range>891-910</page-range>
          <issue>6</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Jianqi</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Xu</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Wei</given-names>
            </name>
            <name>
              <surname>Guan</surname>
              <given-names>Jinchao</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Wenbo</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Hainian</given-names>
            </name>
            <name>
              <surname>Ding</surname>
              <given-names>Ling</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Vincent C S</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/mice.13108</pub-id>
          <article-title>Cross-entropy-based adaptive fuzzy control for visual tracking of road cracks with unmanned mobile robot</article-title>
          <source>Comput. -Aided Civ. Infrastruct. Eng.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>