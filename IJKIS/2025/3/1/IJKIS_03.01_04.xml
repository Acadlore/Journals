<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IJKIS</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>International Journal of Knowledge and Innovation Studies</journal-title>
        <abbrev-journal-title abbrev-type="issn">Int J. Knowl. Innov Stud.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IJKIS</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">3005-6101</issn>
      <issn publication-format="print">3005-6098</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-cOsxh86oEK4zi5pVvhJOpYwkjHKB_oQC</article-id>
      <article-id pub-id-type="doi">10.56578/ijkis030104</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>AMBERT-DWPM: An Adaptive Masking and Dynamic Prototype Learning Framework for Few-Shot Text Classification</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0000-2845-8169</contrib-id>
          <name>
            <surname>Li</surname>
            <given-names>Junyu</given-names>
          </name>
          <email>212206560635@hyit.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3612-5051</contrib-id>
          <name>
            <surname>Ma</surname>
            <given-names>Jialin</given-names>
          </name>
          <email>majl@hyit.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7715-3070</contrib-id>
          <name>
            <surname>Khadka</surname>
            <given-names>Ashim</given-names>
          </name>
          <email>ashim.khadka@ncit.edu.np</email>
        </contrib>
        <aff id="aff_1">Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, 223003 Huaian, China</aff>
        <aff id="aff_2">Nepal College of Information Technology, Pokhara University, 44700 Lalitpur, Nepal</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>30</day>
        <month>03</month>
        <year>2025</year>
      </pub-date>
      <volume>3</volume>
      <issue>1</issue>
      <fpage>37</fpage>
      <lpage>49</lpage>
      <page-range>37-49</page-range>
      <history>
        <date date-type="received">
          <day>10</day>
          <month>02</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>20</day>
          <month>03</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Transformer-based language models have demonstrated remarkable success in few-shot text classification; however, their effectiveness is often constrained by challenges such as high intraclass diversity and interclass similarity, which hinder the extraction of discriminative features. To address these limitations, a novel framework, Adaptive Masking Bidirectional Encoder Representations from Transformers with Dynamic Weighted Prototype Module (AMBERT-DWPM), is introduced, incorporating adaptive masking and dynamic weighted prototypical learning to enhance feature representation and classification performance. The standard BERT architecture is refined by integrating an adaptive masking mechanism based on Layered Integrated Gradients (LIG), enabling the model to dynamically emphasize salient text segments and improve feature discrimination. Additionally, a DWPM is designed to assign adaptive weights to support samples, mitigating inaccuracies in prototype construction caused by intraclass variability. Extensive evaluations conducted on six publicly available benchmark datasets demonstrate the superiority of AMBERT-DWPM over existing few-shot classification approaches. Notably, under the 5-shot setting on the DBpedia14 dataset, an accuracy of 0.978±0.004 is achieved, highlighting significant advancements in feature discrimination and generalization capabilities. These findings suggest that AMBERT-DWPM provides an efficient and robust solution for few-shot text classification, particularly in scenarios characterized by limited and complex textual data.</p></abstract>
      <kwd-group>
        <kwd>Few-shot text classification</kwd>
        <kwd>Dynamic Weighted Prototype Module (DWPM)</kwd>
        <kwd>Adaptive Masking Bidirectional Encoder Representations from Transformers (AMBERT)</kwd>
        <kwd>Contrastive learning</kwd>
        <kwd>Feature discrimination</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="3"/>
        <fig-count count="4"/>
        <table-count count="4"/>
        <ref-count count="38"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>In the field of Natural Language Processing (NLP) and others, models based on the Transformer architecture [<xref ref-type="bibr" rid="ref_1">1</xref>] have become mainstream and have achieved significant performance in various tasks. However, their dependence on large amounts of labeled data [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>] limits their effectiveness in few-shot learning (FSL) environments where resources are scarce. This has given rise to the research need for few-shot text classification. Few-shot text classification requires models to learn new categories from a limited number of labeled instances, which poses challenges to the models' generalization ability and feature discrimination capabilities.</p><p>Few-shot text classification [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>] has experienced several significant developmental stages. Early research primarily depended on transfer learning and meta-learning strategies [<xref ref-type="bibr" rid="ref_7">7</xref>],  [<xref ref-type="bibr" rid="ref_8">8</xref>], acquiring general knowledge representations by pretraining models on large-scale datasets. Subsequently, the introduction of prototypical networks and other metric learning methods enabled models to better capture the similarities between categories. Prototypical networks mainly construct decision boundaries by calculating the mean vectors of categories. However, when there are variations in the expressions of the same category, such as the “logistics service” category containing expressions with different semantic focuses like “fast delivery speed” and “beautiful packaging” the mean prototype can be diluted by diverse features, leading to insufficient intra-class consistency.</p><p>The emergence of pre-trained language models has further propelled the development of this field [<xref ref-type="bibr" rid="ref_9">9</xref>]. Models such as BERT [<xref ref-type="bibr" rid="ref_10">10</xref>] have acquired robust language comprehension capabilities through self-supervised learning, providing a better foundation for feature representation in few-shot scenarios. Recent studies have shown that although pre-trained language models can offer rich semantic representations, they still have limitations when dealing with complex scenarios. Some studies have attempted to enhance the few-shot ability of models through prompt learning [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>], [<xref ref-type="bibr" rid="ref_13">13</xref>] and prompt tuning. However, their performance heavily relies on the domain adaptability of manually designed prompts. For instance, in medical text classification, if the prompt template does not cover professional terms such as “diagnosis results” and instead uses general expressions like “medical conclusions”, the model may completely overlook key semantic clues. Other studies have explored contrastive learning and adaptive feature extraction to improve the discriminability of features. However, these methods are limited in scenarios with high inter-class similarity. For example, in legal text classification tasks, the semantic boundary between “breach of contract” and “negligence in contract formation” is so blurred that it leads to significant increases in negative sampling errors in contrastive learning, further confusing the feature space.</p><p>Traditional FSL methods, despite their successes across various scenarios, often struggle to extract discriminative features from limited samples when confronted with the aforementioned challenges. The inherent complexity of natural language, compounded by the scarcity of labeled samples, makes it particularly difficult to establish clear inter-class decision boundaries while preserving intra-class expression diversity. For instance, distinguishing between “anxiety” and “depression” in psychological state classification tasks requires capturing subtle differences in semantic intensity, which traditional methods fail to model due to their over-reliance on surface-level lexical statistical features.</p><p>To address these challenges, this paper proposes a novel framework called AMBERT-DWPM, which integrates an adaptive masking strategy [<xref ref-type="bibr" rid="ref_14">14</xref>] and DWPM [<xref ref-type="bibr" rid="ref_15">15</xref>]. The adaptive masking strategy is used to fine-tune the BERT model [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>] by selectively masking irrelevant information, guiding the model to focus on discriminative text segments in the classification task, thereby enhancing feature extraction. The DWPM module dynamically weights sample features through cross-attention, effectively addressing the issue of inaccurate category distribution caused by high intraclass diversity and high interclass similarity [<xref ref-type="bibr" rid="ref_17">17</xref>].</p><p>The AMBERT-DWPM framework integrates an adaptive masking strategy and a DWPM to enhance feature extraction and discrimination in few-shot text classification. This study not only improves the feature extraction capabilities but also optimizes the model's generalization performance through a hybrid loss function combining contrastive learning and prototypical learning. Experimental results demonstrate that the AMBERT-DWPM framework achieves excellent performance across multiple datasets [<xref ref-type="bibr" rid="ref_18">18</xref>]. Specifically, on the DBpedia14 dataset, the accuracy reaches 0.978±0.004 under the 5-shot setting, approaching the performance levels of fully supervised learning. Additionally, the framework exhibits strong robustness and generalization on other challenging datasets, such as AG News and Symptoms. These findings validate the effectiveness of the adaptive masking strategy and DWPM in addressing high intraclass diversity and high interclass similarity [<xref ref-type="bibr" rid="ref_17">17</xref>]. The proposed framework offers an efficient and reliable solution for few-shot text classification tasks [<xref ref-type="bibr" rid="ref_19">19</xref>], showcasing significant potential for practical applications.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related work</title>
      
        <sec>
          
            <title>2.1. Few-shot text classification</title>
          
          <p>Few-shot text classification methods can generally be categorized into five types: non-parametric methods, data augmentation methods, prompt-based methods, meta-learning methods, and fine-tuning-based methods. The model we propose belongs to the fine-tuning-based methods [<xref ref-type="bibr" rid="ref_11">11</xref>].</p><p>Among non-parametric methods, compressor-based text classification has achieved considerable success. This approach leverages compressor techniques to estimate entropy or approximate Kolmogorov complexity and information distance for text classification. Jiang et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] proposed a method for few-shot text classification that combines lossless compressors with compressor-based distance metrics and employs the k-nearest neighbors (KNN) classifier for text classification [<xref ref-type="bibr" rid="ref_11">11</xref>]. However, these non-parametric methods rely on information-theoretic distances (such as compression rates or entropy) to measure the similarity between texts. The semantic similarity of texts cannot be fully characterized by compression rates, which severely limits their application value in complex classification scenarios.</p><p>Data augmentation methods address the few-shot problem by expanding existing datasets to generate additional data. For example, Aug GPT [<xref ref-type="bibr" rid="ref_21">21</xref>] uses ChatGPT to rewrite texts, thereby enhancing the performance of few-shot classification tasks. Piedboeuf and Langlais [<xref ref-type="bibr" rid="ref_22">22</xref>] proposed that directly leveraging large language models to generate texts aligned with corresponding categories can effectively improve the performance of few-shot classification. However, data augmentation methods face challenges in ensuring that the synthesized data maintains the same distribution as the original dataset [<xref ref-type="bibr" rid="ref_11">11</xref>]. If the distribution of the generated data does not match that of the real task data, it may lead to model bias and even affect classification performance.</p><p>Prompt-based methods have made significant progress in FSL in recent years. These methods construct task-specific prompts that enable models to better leverage the knowledge of pre-trained language models [<xref ref-type="bibr" rid="ref_23">23</xref>]. For example, token-level prompting relies on masked language models (MLMs), with PET [<xref ref-type="bibr" rid="ref_24">24</xref>] being a method of this type; sentence-level prompting relies on the next sentence prediction task (NSP), such as the NSP-BERT sentence-level prompting method proposed by Sun et al. [<xref ref-type="bibr" rid="ref_25">25</xref>]. Although prompt-based methods can fully utilize pre-trained language models, they are highly dependent on prompt templates, which need to be adjusted specifically for different tasks. Moreover, models are highly sensitive to prompts, and different prompts can lead to significantly different classification results, affecting the stability of the model.</p><p>The core idea of meta-learning methods is to enhance a model’s adaptability to new tasks by learning from multiple few-shot tasks. The main strategies include metric-based meta-learning and optimization-based meta-learning. Metric-based meta-learning methods, such as Siamese neural networks [<xref ref-type="bibr" rid="ref_26">26</xref>], prototypical networks [<xref ref-type="bibr" rid="ref_27">27</xref>], and matching networks [<xref ref-type="bibr" rid="ref_28">28</xref>], construct a metric space across tasks to enhance class separability, enabling models to classify by computing similarities between samples without large-scale parameter updates. In contrast, optimization-based meta-learning [<xref ref-type="bibr" rid="ref_9">9</xref>] (such as MAML) learns an optimal model initialization that allows the model to quickly adapt to new tasks under few-shot conditions, thereby improving training efficiency and generalization ability. Müller et al. [<xref ref-type="bibr" rid="ref_29">29</xref>] proposed a model that combines Siamese networks with label fine-tuning, which achieved good results in few-shot text classification tasks. However, meta-learning methods typically rely on a large number of auxiliary tasks for training, and their generalization ability may significantly decrease if the target task distribution differs greatly from the training tasks. Moreover, metric-based meta-learning has limited discriminability in scenarios with high inter-class similarity, leading to potential misclassification issues when dealing with complex semantic categories. Therefore, despite the advantages of meta-learning in FSL, its requirement for consistency in task distribution is high, making it less applicable to real-world scenarios with significant task differences.</p><p>Fine-tuning-based methods achieve efficient few-shot classification by replacing the output layer on the basis of pre-trained language models and fine-tuning on a small number of samples. Compared with data augmentation and prompt-based methods, this approach is more concise and efficient, as it does not require additional data generation or complex prompt design, and it inherits the powerful feature representation capabilities of pre-trained language models [<xref ref-type="bibr" rid="ref_9">9</xref>], which gives it better adaptability in few-shot tasks. However, traditional fine-tuning methods struggle to learn discriminative features from limited samples when confronted with tasks that have high intra-class diversity and high inter-class similarity, thus restricting their classification performance.</p><p>To address this issue, we propose adding an adaptive masking operation to BERT and combining it with a DWPM for fine-tuning. Since BERT is pre-trained on open-domain datasets, which have different data distributions compared to the target domain of specific tasks, further pre-training BERT on target-domain data can also help with domain adaptation. However, in the FSL setting with extremely limited samples, it is challenging to train the BERT parameters. In contrast, our proposed model only adds an adaptive masking operation to BERT and combines it with the DWPM for further fine-tuning. It directly inherits the parameters of the pre-trained model without the need for additional expensive pre-training.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Prototype learning</title>
          
          <p>Prototype learning, as an important method of metric learning, is based on the idea of representing the overall feature distribution of each category by calculating class prototypes and classifying samples based on the distance between samples and prototypes. In FSL scenarios, prototype learning has attracted widespread attention due to its simplicity and effectiveness.</p><p>Basic prototypical networks construct class prototypes by simply averaging the features of support set samples and perform classification predictions by calculating the Euclidean distance between query samples and class prototypes. They also introduce cosine similarity to improve the distance metric. These methods are characterized by their simple structural design, ease of implementation and extension, and low computational overhead. However, since the prototypes are constructed using simple averaging, they fail to fully account for the heterogeneity of sample features. As a result, they perform poorly when dealing with data that have uneven intraclass distributions. This is especially true when the number of samples is extremely small, as the constructed prototypes tend to lack representativeness.</p><p>In recent years, researchers have proposed various methods to enhance the performance of prototype learning. Ragno et al. [<xref ref-type="bibr" rid="ref_30">30</xref>] explored prototype learning based on Graph Neural Networks (GNNs). By modeling the relationships between samples, these methods optimize prototype representations, enabling class prototypes to better capture the structural information between samples. These approaches significantly enhance feature-representation capabilities by deeply exploring the structural information between samples. However, they also bring higher computational complexity, which notably reduces training efficiency on large-scale datasets. Moreover, when the number of samples is extremely limited, the stability of graph structure construction is poor, which can easily affect the overall performance of the model.</p><p>Gogoi et al. [<xref ref-type="bibr" rid="ref_31">31</xref>] proposed the Adaptive Prototypical Network, which introduces an attention mechanism to dynamically adjust the contributions of different support samples in the prototype construction process. This effectively enhances the model's ability to adapt to sample heterogeneity. TPN [<xref ref-type="bibr" rid="ref_32">32</xref>] alleviates the problem of distribution differences of NOTA in cross-domain tasks by dynamically adjusting the representation of NOTA prototypes. However, it still has shortcomings in dealing with sample heterogeneity. Especially when the number of samples is small, it is difficult to fully capture the complex relationships between samples, which limits the representativeness of prototypes. RAPL [<xref ref-type="bibr" rid="ref_33">33</xref>] further optimizes the prototype learning method. It improves the model's performance in cross-domain tasks through instance-level prototype construction and relation-weighted contrastive learning. But its computational complexity is still high, and the sensitivity to differences in data distribution across domains has not been fundamentally solved. Additionally, Wu et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] introduced a dynamic prototype update mechanism, which adaptively adjusts the prototype update strategy based on the distribution characteristics of samples during training, thereby improving the representation capability of prototypes. However, the integration with triplet loss is relatively loose, and it fails to effectively utilize the relationship information between other sample pairs within the batch [<xref ref-type="bibr" rid="ref_9">9</xref>].</p><p>To address the above issues, we propose the AMBERT-DWPM architecture, a prototype learning method centered on the DWPM. By combining adaptive feature weighting and an improved contrastive learning strategy, it effectively enhances the model's ability to model complex text distributions while maintaining computational efficiency. This approach optimizes the feature space structure by mining multi-granular relationship information between sample pairs within a batch. On the basis of retaining the original advantages of triplet loss, it introduces intra-class and inter-class contrastive constraints, thereby significantly enhancing the model's discriminative power.</p>
        </sec>
      
    </sec>
    <sec sec-type="methods">
      <title>3. Methods</title>
      <p>We propose the overall architecture of AMBERT-DWPM for few-shot classification, as shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>, which consists of two main components: the mask-guided BERT model and the DWPM.</p><p> <xref ref-type="fig" rid="fig_1">Figure 1</xref> illustrates the proposed AMBERT-DWPM framework. The BERT model extracts features from both support and query data. When computing classification prototypes, the DWPM module dynamically assigns weights to the limited support samples. The model is optimized using a hybrid loss function.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Overall architecture</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_yIqkJn4tzH6ln9F1.png"/>
        </fig>
      
      
        <sec>
          
            <title>3.1. Feature extraction based on mask guidance</title>
          
          <p>Traditional Mask-BERT enhances the model's focus on key features and improves feature extraction by applying predefined masking operations to the input text. However, its masking strategy lacks dynamic adjustment capabilities, as mask generation often relies on fixed rules and cannot adaptively adjust according to the specific characteristics of each input sample. Therefore, when dealing with few-shot tasks that have high intraclass diversity or high interclass similarity, the model's feature discrimination is often insufficient, making it difficult to fully leverage the advantages of its masking mechanism.</p><p>The adaptive masking strategy is based on the LIG method, which calculates the importance of each token to the final classification output, thereby determining whether to mask the token. Let the input text sequence be <inline-formula>
  <mml:math id="mehmskdaz1">
    <mml:mi>X</mml:mi>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>{</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>…</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>}</mml:mo>
      <mml:msub>
        <mml:mi>x</mml:mi>
        <mml:mn>1</mml:mn>
      </mml:msub>
      <mml:msub>
        <mml:mi>x</mml:mi>
        <mml:mn>2</mml:mn>
      </mml:msub>
      <mml:msub>
        <mml:mi>x</mml:mi>
        <mml:mi>n</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula>, with the corresponding token embedding representation <inline-formula>
  <mml:math id="myhmgdalyb">
    <mml:mi>E</mml:mi>
    <mml:mi>X</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>{</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>…</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>}</mml:mo>
      <mml:msub>
        <mml:mi>e</mml:mi>
        <mml:mn>1</mml:mn>
      </mml:msub>
      <mml:msub>
        <mml:mi>e</mml:mi>
        <mml:mn>2</mml:mn>
      </mml:msub>
      <mml:msub>
        <mml:mi>e</mml:mi>
        <mml:mi>n</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula>. A reference input X' is selected, with the token embedding representation <inline-formula>
  <mml:math id="mrt4180464">
    <mml:mrow>
      <mml:mi>E</mml:mi>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msup>
        <mml:mrow>
          <mml:mi>X</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
      </mml:msup>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>{</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>…</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>}</mml:mo>
      <mml:msup>
        <mml:mrow>
          <mml:mi>e</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
      </mml:msup>
      <mml:msup>
        <mml:mrow>
          <mml:mi>e</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
      </mml:msup>
      <mml:msup>
        <mml:mrow/>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
      </mml:msup>
      <mml:msubsup>
        <mml:mrow>
          <mml:mi>e</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
        <mml:mn>2</mml:mn>
      </mml:msubsup>
    </mml:mrow>
    <mml:mo>=</mml:mo>
  </mml:math>
</inline-formula>, where the reference input can be chosen as a zero vector to measure the contribution of each token. The contribution of tokens at different levels is calculated using the integrated gradients method:</p><p style="text-align: center"><inline-formula>
  <mml:math id="m0801c0gam">
    <mml:mi>IG</mml:mi>
    <mml:mi>α</mml:mi>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mrow>
        <mml:mi>X</mml:mi>
      </mml:mrow>
      <mml:msup>
        <mml:mrow>
          <mml:mi>X</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>′</mml:mi>
        </mml:mrow>
      </mml:msup>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>(</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mo>−</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mrow>
        <mml:mi>E</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mi>X</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mi>E</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mo>)</mml:mo>
        <mml:msup>
          <mml:mrow>
            <mml:mi>X</mml:mi>
          </mml:mrow>
          <mml:mrow>
            <mml:mi>′</mml:mi>
          </mml:mrow>
        </mml:msup>
      </mml:mrow>
    </mml:mrow>
    <mml:mrow>
      <mml:mi>d</mml:mi>
    </mml:mrow>
    <mml:mo>=</mml:mo>
    <mml:mo>×</mml:mo>
    <mml:mfrac>
      <mml:mrow>
        <mml:mi>∂</mml:mi>
        <mml:mi>α</mml:mi>
        <mml:mrow>
          <mml:mi>f</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mo>(</mml:mo>
          <mml:mo>)</mml:mo>
          <mml:mrow>
            <mml:mi>E</mml:mi>
          </mml:mrow>
          <mml:mrow>
            <mml:mo>(</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>′</mml:mi>
              </mml:mrow>
            </mml:msup>
          </mml:mrow>
        </mml:mrow>
        <mml:mrow>
          <mml:mo>(</mml:mo>
          <mml:mo>(</mml:mo>
          <mml:mo>)</mml:mo>
          <mml:mo>−</mml:mo>
          <mml:mo>)</mml:mo>
          <mml:mrow>
            <mml:mi>E</mml:mi>
          </mml:mrow>
          <mml:mrow>
            <mml:mi>X</mml:mi>
          </mml:mrow>
          <mml:mrow>
            <mml:mi>E</mml:mi>
          </mml:mrow>
          <mml:mrow>
            <mml:mo>(</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>X</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>′</mml:mi>
              </mml:mrow>
            </mml:msup>
          </mml:mrow>
        </mml:mrow>
        <mml:mo>+</mml:mo>
      </mml:mrow>
      <mml:mrow>
        <mml:mi>∂</mml:mi>
        <mml:mrow>
          <mml:mi>E</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>X</mml:mi>
        </mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mo>)</mml:mo>
      </mml:mrow>
    </mml:mfrac>
  </mml:math>
</inline-formula></p><p>where, $f<inline-formula>
  <mml:math id="m7f4g1sqvz">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>\alpha<inline-formula>
  <mml:math id="mgfeoxgafl">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>L</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>G</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mn>34</mml:mn>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{S}\left(\chi_i\right)=\sum_{\mathrm{l}=1}^{\mathrm{L}} \mathrm{IG}_{\mathrm{l}}\left(\chi_i, \chi_i^{\prime}\right)<inline-formula>
  <mml:math id="m3o9f018xs">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>L<inline-formula>
  <mml:math id="mx3gavuszj">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>S(xi)<inline-formula>
  <mml:math id="mtic4o8xoi">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
  </mml:math>
</inline-formula>x_i<inline-formula>
  <mml:math id="m126lglpn7">
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>S(xi)<inline-formula>
  <mml:math id="m84z1188ix">
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>L</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>G</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{O}({n} \cdot {L} \cdot {F})<inline-formula>
  <mml:math id="mgbaxc3tkx">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>n<inline-formula>
  <mml:math id="mqeapgw5ee">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>L<inline-formula>
  <mml:math id="mi42h7jo2k">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>F<inline-formula>
  <mml:math id="mkh447019f">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>S(xi)<inline-formula>
  <mml:math id="mr5nc0ode9">
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>:</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>\tau<inline-formula>
  <mml:math id="m65ixf2vvb">
    <mml:mo>,</mml:mo>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>S(xi)<inline-formula>
  <mml:math id="mpbp4tzaxk">
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>\tau<inline-formula>
  <mml:math id="maf55ivo04">
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>K</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>−</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{O}({n} \cdot \log \cdot {n})<inline-formula>
  <mml:math id="m28ahybpbu">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>X_{\text {masked }}<inline-formula>
  <mml:math id="ma2g77e33p">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{P}\left(\mathrm{y} \mid{X}_{\text {masked }}\right)=\operatorname{softmax}\left({Wh}_{\text {BERT }}\left({X}_{\text {masked }}\right)\right)<inline-formula>
  <mml:math id="m9jcm3dw9o">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>W<inline-formula>
  <mml:math id="m90vu59eqp">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>h_{\mathrm{BERT}}\left(X_{\text {masked }}\right)<inline-formula>
  <mml:math id="mlusksqb7s">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>\mathcal{L}=-\sum_{i=1}^{\mathrm{N}} {y}_i \log \mathrm{P}\left({y}_i \mid \mathrm{x}_{\text {masked }}\right)<inline-formula>
  <mml:math id="m0gtqypu8z">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>N<inline-formula>
  <mml:math id="mfultuprlq">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y_i<inline-formula>
  <mml:math id="mvpy94y083">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{O}\left({n}^2 {d}\right)<inline-formula>
  <mml:math id="mswuoikehf">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>d<inline-formula>
  <mml:math id="mtieaxna56">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{O}\left({T}\left({n} \cdot {L} \cdot {F}+n \mathrm{log} {n}+{n}^2 {d}\right)\right)<inline-formula>
  <mml:math id="m6hgvpgw6u">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>T$ represents the number of training epochs.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Structure of the dwpm module</title>
          
          <p>Prototypical networks have demonstrated remarkable capabilities in few-shot classification tasks, thanks to their simple model structure and computational efficiency. However, they have limitations when dealing with high intraclass diversity and high interclass similarity [<xref ref-type="bibr" rid="ref_17">17</xref>]. They struggle to fully capture the varying contributions of different samples to prototype generation, which affects the accuracy of the class prototypes.</p><p>To address this issue, this study proposes a DWPM. This module aims to dynamically assign weights to each support sample to accurately construct class prototypes. Combined with a contrastive learning module to further optimize query samples, the DWPM enhances intraclass consistency and interclass discriminability through a hybrid loss function that integrates contrastive and prototypical losses. This approach improves classification performance.</p><p>As shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref>, the DWPM module maps the feature representations of samples through a projection head, projecting them from the original feature space to an attention space. It uses an n-layer cross-attention block based on the Transformer structure to facilitate information interaction between support samples and query samples.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Diagram of the DWPM</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_s23ERsKlTjioSbmp.png"/>
            </fig>
          
          <p>In the DWPM module, a 4-layer Transformer structure is adopted. Each layer consists of Multi-Head Attention, Feed-Forward Network (FFN), and Residual Connection to enhance the ability of information aggregation. The hidden layer dimension of the Transformer layer is set to 512, and the number of attention heads is set to 8, to balance computational efficiency and feature representation capability. Moreover, in the cross-attention mechanism, by calculating the correlations between query samples and support samples of each category, the classification prototype assigns higher weights to more discriminative samples. The strength of the attention weights is controlled by the hyperparameter <inline-formula>
  <mml:math id="m7f9yn7fqq">
    <mml:mi>λ</mml:mi>
  </mml:math>
</inline-formula>. When <inline-formula>
  <mml:math id="mf5j3i7gbi">
    <mml:mi>λ</mml:mi>
  </mml:math>
</inline-formula> is set to 0, the prototype calculation uses average weighting, similar to traditional prototype learning. As the value of <inline-formula>
  <mml:math id="mwu3k1sskn">
    <mml:mi>λ</mml:mi>
  </mml:math>
</inline-formula> increases, the effect of attention weights becomes stronger. The formula for calculating the category prototype <inline-formula>
  <mml:math id="mno4fel72q">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mi>k</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is as follows:</p><p style="text-align: center"><inline-formula>
  <mml:math id="mh5cnn6utg">
    <mml:msub>
      <mml:mi>c</mml:mi>
      <mml:mi>k</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>f</mml:mi>
      <mml:mi>θ</mml:mi>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:munder>
      <mml:mo>∑</mml:mo>
      <mml:mrow>
        <mml:mrow>
          <mml:mo>(</mml:mo>
          <mml:mo>,</mml:mo>
          <mml:mo>)</mml:mo>
          <mml:msub>
            <mml:mi>x</mml:mi>
            <mml:mi>i</mml:mi>
          </mml:msub>
          <mml:msub>
            <mml:mi>y</mml:mi>
            <mml:mi>i</mml:mi>
          </mml:msub>
        </mml:mrow>
        <mml:mo>∈</mml:mo>
        <mml:msub>
          <mml:mi>S</mml:mi>
          <mml:mi>k</mml:mi>
        </mml:msub>
      </mml:mrow>
    </mml:munder>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>⋅</mml:mo>
      <mml:mo>+</mml:mo>
      <mml:mo>(</mml:mo>
      <mml:mo>−</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mo>⋅</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mi>λ</mml:mi>
      <mml:mi>λ</mml:mi>
      <mml:msubsup>
        <mml:mi>w</mml:mi>
        <mml:mi>i</mml:mi>
        <mml:mrow>
          <mml:mrow>
            <mml:mi>a</mml:mi>
            <mml:mi>t</mml:mi>
            <mml:mi>t</mml:mi>
            <mml:mi>n</mml:mi>
          </mml:mrow>
        </mml:mrow>
      </mml:msubsup>
      <mml:msubsup>
        <mml:mi>w</mml:mi>
        <mml:mi>i</mml:mi>
        <mml:mrow>
          <mml:mrow>
            <mml:mi>a</mml:mi>
            <mml:mi>v</mml:mi>
            <mml:mi>g</mml:mi>
          </mml:mrow>
        </mml:mrow>
      </mml:msubsup>
      <mml:mn>1</mml:mn>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msub>
        <mml:mi>x</mml:mi>
        <mml:mi>i</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula></p><p>where, <inline-formula>
  <mml:math id="mi1b4dky86">
    <mml:msub>
      <mml:mi>S</mml:mi>
      <mml:mi>k</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> denotes the set of support samples for a class, <inline-formula>
  <mml:math id="mg6m44rb69">
    <mml:msub>
      <mml:mi>f</mml:mi>
      <mml:mi>θ</mml:mi>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
  </mml:math>
</inline-formula> represents the features extracted by the feature extractor,and <inline-formula>
  <mml:math id="m6g2he8r8x">
    <mml:msubsup>
      <mml:mi>w</mml:mi>
      <mml:mi>i</mml:mi>
      <mml:mrow>
        <mml:mrow>
          <mml:mi>a</mml:mi>
          <mml:mi>t</mml:mi>
          <mml:mi>t</mml:mi>
          <mml:mi>n</mml:mi>
        </mml:mrow>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mezc1lnk0y">
    <mml:msubsup>
      <mml:mi>w</mml:mi>
      <mml:mi>i</mml:mi>
      <mml:mrow>
        <mml:mrow>
          <mml:mi>a</mml:mi>
          <mml:mi>v</mml:mi>
          <mml:mi>g</mml:mi>
        </mml:mrow>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> represent the attention weights and average weights, respectively. After obtaining the prototype representation, the distance between the query sample and the prototype is measured using Euclidean distance. The probability that the query sample $x<inline-formula>
  <mml:math id="m8p4mlrkul">
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>k<inline-formula>
  <mml:math id="m6z1cmn4xi">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>,</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mn>35</mml:mn>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>\mathrm{p}_\theta({y}={k} \mid {x})=\frac{\exp \left(-{d}\left({f}_\theta({x}), {c}_{{k}}\right)\right)}{\sum_{{k}^{\prime}} \exp \left(-{d}\left({f}_\theta({x}), {c}_{{k}^{\prime}}\right)\right)}<inline-formula>
  <mml:math id="mwkim332n2">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>d\left(f_{\theta}(x), c_k\right)<inline-formula>
  <mml:math id="mvu5bsq8el">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>f_\theta(x)<inline-formula>
  <mml:math id="mli5hbmont">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>c_k<inline-formula>
  <mml:math id="m8i2oniqmo">
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>[</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mn>36</mml:mn>
    <mml:mn>37</mml:mn>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>C</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>W</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
  </mml:math>
</inline-formula>L_{c l s}=-\frac{1}{|Q|} \sum_{\left(x_i, y_i\right) \in Q} \log P_{\emptyset}\left(y=y_i \mid x_i\right)<inline-formula>
  <mml:math id="m3dz5n6ick">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>|</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>|</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>Q</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>x_i<inline-formula>
  <mml:math id="mt09wtvhfx">
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y_i<inline-formula>
  <mml:math id="mk003imngt">
    <mml:mo>)</mml:mo>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>x_i<inline-formula>
  <mml:math id="m0k5wbriw8">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>y_i<inline-formula>
  <mml:math id="m3gpdsuz4q">
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>P_{\emptyset}\left(y=y_j \mid x_i\right)<inline-formula>
  <mml:math id="msq44rguoh">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>x_i<inline-formula>
  <mml:math id="m699c9g159">
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>y_i<inline-formula>
  <mml:math id="mxhrj40lq5">
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>x_q<inline-formula>
  <mml:math id="m3l04c7fxk">
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>c_{+}<inline-formula>
  <mml:math id="mct78vvswd">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>c_{-}<inline-formula>
  <mml:math id="m737fbveqa">
    <mml:mo>.</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>{L}_{ {contrastive }}=\frac{1}{|\mathrm{B}|} \sum_{\left({x}_{{q}}, {c}\right)}\left[{y} \cdot {d}\left({x}_{{q}}, c_{+}\right)+(1-{y}) \cdot \max \left(0, {m}-{d}\left({x}_{{q}}, c_{-}\right)\right)\right]<inline-formula>
  <mml:math id="mpsx503vhm">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>|\mathrm{B}|<inline-formula>
  <mml:math id="m8agy8e9yb">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y<inline-formula>
  <mml:math id="m0lw0pcik7">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>W</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>x_q<inline-formula>
  <mml:math id="mstgyous0v">
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y<inline-formula>
  <mml:math id="mzfeabnri8">
    <mml:mo>=</mml:mo>
    <mml:mo>;</mml:mo>
    <mml:mn>0</mml:mn>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>x_q<inline-formula>
  <mml:math id="mxgsqgime2">
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>y<inline-formula>
  <mml:math id="m4jp9bvc62">
    <mml:mo>=</mml:mo>
    <mml:mn>1.</mml:mn>
  </mml:math>
</inline-formula>m<inline-formula>
  <mml:math id="mi3x0sb9v8">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>m<inline-formula>
  <mml:math id="mrznpsyj68">
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>L_{ {hybrid }}=\alpha \cdot L_{ {proto }}+(1-\alpha) \cdot L_{ {contrastive }}<inline-formula>
  <mml:math id="m7x685818g">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>\alpha<inline-formula>
  <mml:math id="m2fdm3xhwo">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>W</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>\alpha<inline-formula>
  <mml:math id="mkfhofk5w4">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>,</mml:mo>
    <mml:mo>;</mml:mo>
  </mml:math>
</inline-formula>\alpha$ is small, the model emphasizes enhancing class discriminability through the contrastive loss.</p><p>This hybrid loss fine-tunes the BERT model, bringing significant advantages to few-shot text classification tasks. By minimizing the distance between query samples and their correct class prototypes [<xref ref-type="bibr" rid="ref_38">38</xref>], the prototypical classification loss enhances intraclass consistency, making samples from the same class more clustered in the feature space and effectively reducing the impact of intraclass variations. Meanwhile, the contrastive learning loss, by pushing query samples away from incorrect class prototypes, improves interclass discriminability and avoids the overlap of features from different classes. During fine-tuning, the hybrid loss further optimizes the shared weights of the BERT model, making its feature extraction capabilities more adaptive to the feature distribution in few-shot tasks. This allows the model to quickly adapt to new classes and improve classification accuracy. Additionally, by adjusting the weighted ratio between the prototypical and contrastive losses, the hybrid loss achieves an effective balance between intraclass consistency and interclass discriminability, enabling the model to exhibit stronger generalization and robustness across various few-shot scenarios.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Experiments</title>
      
        <sec>
          
            <title>4.1. Dataset</title>
          
          <p>The experiments used six publicly available datasets, including three open-domain datasets and three medical-domain datasets. Each dataset was divided into base classes and novel classes according to their categories, forming the base dataset and the novel dataset, respectively [<xref ref-type="bibr" rid="ref_14">14</xref>]. <xref ref-type="table" rid="table_1">Table 1</xref> summarizes the average length of samples in each dataset, as well as the number of classes in the base and novel datasets.</p><p>-AG news: A text classification dataset containing 4 news categories, including World, Sports, Business, and Tech.</p><p>-DBpedia14: A text classification dataset with 14 categories.</p><p>-Snippets: A text dataset containing web snippets from Google search.</p><p>-Symptoms: This dataset, available on Kaggle, contains over 8 hours of audio data describing common medical symptoms. We used the text transcriptions of the audio data and removed duplicates. After preprocessing, the dataset contains 231 samples divided into 7 symptom categories.</p><p>-PubMed20k: A sequence classification dataset based on PubMed.</p><p>-NICTA-PIBOSO: A dataset based on the ALTA 2012 Shared Task, used for classifying sentences from biomedical abstracts into predefined categories [<xref ref-type="bibr" rid="ref_14">14</xref>].</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Statistics of sample length and class numbers in each dataset</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Dataset</p></td><td colspan="1" rowspan="1"><p>Avg. Length</p></td><td colspan="1" rowspan="1"><p><mml:math id="mx92zhtdpc">
  <mml:mrow>
    <mml:mo>|</mml:mo>
    <mml:mo>|</mml:mo>
    <mml:msub>
      <mml:mi>Y</mml:mi>
      <mml:mi>b</mml:mi>
    </mml:msub>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>|</mml:mo>
    <mml:mo>|</mml:mo>
    <mml:msub>
      <mml:mi>Y</mml:mi>
      <mml:mi>n</mml:mi>
    </mml:msub>
  </mml:mrow>
</mml:math></p></td><td colspan="1" rowspan="1"><p>Domain</p></td></tr><tr><td colspan="1" rowspan="1"><p>AG news</p></td><td colspan="1" rowspan="1"><p>39</p></td><td colspan="1" rowspan="1"><p>$2 / 2<mml:math id="miz0rl6ij0">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>O</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>D</mml:mi>
  <mml:mi>B</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>14</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>50</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>8 / 6<mml:math id="m1q37u69rc">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>O</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>18</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>4 / 4<mml:math id="mlxbmzmq7r">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>O</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>y</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>11</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>4 / 3<mml:math id="m3vqpdgtmu">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>M</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>P</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>M</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>k</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>20</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>26</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>3 / 2<mml:math id="mksgfge1ov">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>M</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>N</mml:mi>
  <mml:mi>I</mml:mi>
  <mml:mi>C</mml:mi>
  <mml:mi>T</mml:mi>
  <mml:mi>A</mml:mi>
  <mml:mi>P</mml:mi>
  <mml:mi>I</mml:mi>
  <mml:mi>B</mml:mi>
  <mml:mi>O</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>O</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>24</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>3 / 2$</p></td><td colspan="1" rowspan="1"><p>Medical-domain</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>4.2. Experimental settings</title>
          
          <p>In the experiments, all models were initialized with the pre-trained BERT-base-cased model. Our method employed a hybrid loss function that combines prototypical loss and contrastive learning loss for optimization. During training, the batch size for the base dataset was set to 64, while the batch size for the novel dataset was set to 32. The learning rates were set to $2 \times 10^{-5}<inline-formula>
  <mml:math id="mrd9h8uki8">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>4 \times 10^{-5}<inline-formula>
  <mml:math id="my6iblhbth">
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>W</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
  </mml:math>
</inline-formula>\alpha<inline-formula>
  <mml:math id="mi6tl3ycj5">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mrow>
      <mml:mn>0.2</mml:mn>
      <mml:mn>0.4</mml:mn>
      <mml:mn>0.6</mml:mn>
      <mml:mn>0.8</mml:mn>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
    </mml:mrow>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mn>0.6</mml:mn>
  </mml:math>
</inline-formula>\tau<inline-formula>
  <mml:math id="m4pv5yo0tu">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mn>0.15</mml:mn>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>L<inline-formula>
  <mml:math id="m044cy5u46">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mn>12</mml:mn>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>F<inline-formula>
  <mml:math id="mau6cm71h5">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>W</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>N</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mn>50</mml:mn>
    <mml:mn>4</mml:mn>
    <mml:mn>8</mml:mn>
    <mml:mn>512.</mml:mn>
    <mml:mn>32</mml:mn>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>4 \times 10^{-5}$, and the number of training epochs is set to 10, to ensure a fair comparison with the method proposed in this paper. Each set of experiments is repeated five times, and the average accuracy and standard deviation are reported to ensure the stability and fairness of the results.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Experimental results and analysis</title>
          
          <p>To validate the effectiveness of our proposed method, we compared it with several few-shot classification models on six publicly available datasets. The comparison methods included standard BERT, further pre-trained BERT (FPT-BERT), sentence prompt-based NSP-BERT, contrastive learning-based CPFT, and some mainstream few-shot classification models such as Prototypical Networks (SN-FT) and Siamese Networks (SN-FT). Experiments were conducted under both 5-shot and 8-shot settings to comprehensively evaluate the performance of each method under different sample sizes.</p><p>The main results of the performance comparison are listed in <xref ref-type="table" rid="table_2">Table 2</xref> and <xref ref-type="table" rid="table_3">Table 3</xref>. Overall, our method outperformed the comparison methods on both open-domain and medical-domain datasets [<xref ref-type="bibr" rid="ref_14">14</xref>]. On open-domain datasets (such as AG News and DBpedia14), our method achieved performance comparable to the state-of-the-art, demonstrating strong generalizability. On medical-domain datasets (such as Symptoms and PubMed20k), our method showed significant advantages, proving its effectiveness in handling few-shot classification problems in more challenging scenarios (e.g., domain-specific tasks).</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Comparison results under the 5-shot setting</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>K-short</p></td><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>AG news</p></td><td colspan="1" rowspan="1"><p>DBpedia14</p></td><td colspan="1" rowspan="1"><p>Snippets</p></td><td colspan="1" rowspan="1"><p>Symptoms</p></td><td colspan="1" rowspan="1"><p>PubMed20k</p></td><td colspan="1" rowspan="1"><p>NICTA-</p><p>PIBOSO</p></td></tr><tr><td colspan="1" rowspan="7"><p>5-short</p></td><td colspan="1" rowspan="1"><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.752±0.098</p></td><td colspan="1" rowspan="1"><p>0.947±0.028</p></td><td colspan="1" rowspan="1"><p>0.854±0.025</p></td><td colspan="1" rowspan="1"><p>0.782±0.040</p></td><td colspan="1" rowspan="1"><p>0.845±0.027</p></td><td colspan="1" rowspan="1"><p>0.696±0.054</p></td></tr><tr><td colspan="1" rowspan="1"><p>FPT-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.779±0.035</p></td><td colspan="1" rowspan="1"><p>0.963±0.026</p></td><td colspan="1" rowspan="1"><p>0.888±0.028</p></td><td colspan="1" rowspan="1"><p>0.800±0.112</p></td><td colspan="1" rowspan="1"><p>0.864±0.030</p></td><td colspan="1" rowspan="1"><p>0.727±0.042</p></td></tr><tr><td colspan="1" rowspan="1"><p>Re-init-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.762±0.024</p></td><td colspan="1" rowspan="1"><p>0.941±0.029</p></td><td colspan="1" rowspan="1"><p>0.799±0.061</p></td><td colspan="1" rowspan="1"><p>0.830±0.047</p></td><td colspan="1" rowspan="1"><p>0.862±0.019</p></td><td colspan="1" rowspan="1"><p>0.702±0.063</p></td></tr><tr><td colspan="1" rowspan="1"><p>CPFT</p></td><td colspan="1" rowspan="1"><p>0.768±0.047</p></td><td colspan="1" rowspan="1"><p>0.965±0.013</p></td><td colspan="1" rowspan="1"><p>0.853±0.029</p></td><td colspan="1" rowspan="1"><p>0.876±0.044</p></td><td colspan="1" rowspan="1"><p>0.848±0.028</p></td><td colspan="1" rowspan="1"><p>0.723±0.068</p></td></tr><tr><td colspan="1" rowspan="1"><p>SN-FT</p></td><td colspan="1" rowspan="1"><p>0.768±0.055</p></td><td colspan="1" rowspan="1"><p>0.971±0.003</p></td><td colspan="1" rowspan="1"><p>0.867±0.024</p></td><td colspan="1" rowspan="1"><p>0.858±0.059</p></td><td colspan="1" rowspan="1"><p>0.782±0.031</p></td><td colspan="1" rowspan="1"><p>0.736±0.041</p></td></tr><tr><td colspan="1" rowspan="1"><p>NSP-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.820±0.016</p></td><td colspan="1" rowspan="1"><p>0.973±0.002</p></td><td colspan="1" rowspan="1"><p>0.885±0.016</p></td><td colspan="1" rowspan="1"><p>0.870±0.043</p></td><td colspan="1" rowspan="1"><p>0.883±0.043</p></td><td colspan="1" rowspan="1"><p>0.732±0.047</p></td></tr><tr><td colspan="1" rowspan="1"><p>our</p></td><td colspan="1" rowspan="1"><p>0.824±0.022</p></td><td colspan="1" rowspan="1"><p>0.978±0.004</p></td><td colspan="1" rowspan="1"><p>0.891±0.013</p></td><td colspan="1" rowspan="1"><p>0.884±0.025</p></td><td colspan="1" rowspan="1"><p>0.881±0.015</p></td><td colspan="1" rowspan="1"><p>0.752±0.033</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Comparison results under the 8-shot setting</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>K-short</p></td><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>AG news</p></td><td colspan="1" rowspan="1"><p>DBpedia14</p></td><td colspan="1" rowspan="1"><p>Snippets</p></td><td colspan="1" rowspan="1"><p>Symptoms</p></td><td colspan="1" rowspan="1"><p>PubMed20k</p></td><td colspan="1" rowspan="1"><p>NICTA-</p><p>PIBOSO</p></td></tr><tr><td colspan="1" rowspan="7"><p>8-short</p></td><td colspan="1" rowspan="1"><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.790±0.063</p></td><td colspan="1" rowspan="1"><p>0.979±0.004</p></td><td colspan="1" rowspan="1"><p>0.888±0.021</p></td><td colspan="1" rowspan="1"><p>0.855±0.066</p></td><td colspan="1" rowspan="1"><p>0.875±0.024</p></td><td colspan="1" rowspan="1"><p>0.714±0.038</p></td></tr><tr><td colspan="1" rowspan="1"><p>FPT-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.801±0.035</p></td><td colspan="1" rowspan="1"><p>0.978±0.012</p></td><td colspan="1" rowspan="1"><p>0.903±0.023</p></td><td colspan="1" rowspan="1"><p>0.848±0.094</p></td><td colspan="1" rowspan="1"><p>0.870±0.014</p></td><td colspan="1" rowspan="1"><p>0.726±0.048</p></td></tr><tr><td colspan="1" rowspan="1"><p>Re-init-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.789±0.026</p></td><td colspan="1" rowspan="1"><p>0.964±0.011</p></td><td colspan="1" rowspan="1"><p>0.863±0.028</p></td><td colspan="1" rowspan="1"><p>0.882±0.046</p></td><td colspan="1" rowspan="1"><p>0.880±0.008</p></td><td colspan="1" rowspan="1"><p>0.738±0.034</p></td></tr><tr><td colspan="1" rowspan="1"><p>CPFT</p></td><td colspan="1" rowspan="1"><p>0.816±0.021</p></td><td colspan="1" rowspan="1"><p>0.978±0.002</p></td><td colspan="1" rowspan="1"><p>0.888±0.017</p></td><td colspan="1" rowspan="1"><p>0.936±0.029</p></td><td colspan="1" rowspan="1"><p>0.871±0.022</p></td><td colspan="1" rowspan="1"><p>0.776±0.046</p></td></tr><tr><td colspan="1" rowspan="1"><p>SN-FT</p></td><td colspan="1" rowspan="1"><p>0.817±0.024</p></td><td colspan="1" rowspan="1"><p>0.986±0.002</p></td><td colspan="1" rowspan="1"><p>0.881±0.020</p></td><td colspan="1" rowspan="1"><p>0.876±0.081</p></td><td colspan="1" rowspan="1"><p>0.796±0.044</p></td><td colspan="1" rowspan="1"><p>0.757±0.033</p></td></tr><tr><td colspan="1" rowspan="1"><p>NSP-</p><p>BERT</p></td><td colspan="1" rowspan="1"><p>0.833±0.009</p></td><td colspan="1" rowspan="1"><p>0.986±0.003</p></td><td colspan="1" rowspan="1"><p>0.898±0.018</p></td><td colspan="1" rowspan="1"><p>0.897±0.031</p></td><td colspan="1" rowspan="1"><p>0.761±0.051</p></td><td colspan="1" rowspan="1"><p>0.749±0.040</p></td></tr><tr><td colspan="1" rowspan="1"><p>our</p></td><td colspan="1" rowspan="1"><p>0.834±0.026</p></td><td colspan="1" rowspan="1"><p>0.987±0.001</p></td><td colspan="1" rowspan="1"><p>0.908±0.011</p></td><td colspan="1" rowspan="1"><p>0.938±0.047</p></td><td colspan="1" rowspan="1"><p>0.899±0.005</p></td><td colspan="1" rowspan="1"><p>0.779±0.034</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Under the 5-shot setting, our method achieves an accuracy of 0.891±0.013 on the Snippets dataset and 0.884±0.025 on the Symptoms dataset, showing significant improvements compared to methods such as NSP-BERT and CPFT. The performance improvement is primarily attributed to the introduction of the Adaptive Masking strategy. This strategy dynamically and selectively masks irrelevant information, enabling the model to focus on the key feature segments that are crucial for the classification task, thereby significantly enhancing the discriminability of feature extraction. This advantage is particularly evident on the Snippets dataset, which comprises short texts of various categories. Within this dataset, the expression styles of texts within the same category are highly diverse, while texts from different categories may overlap in certain keywords or expressions. For instance, for the “movie review” category, sentences may cover multiple different focuses such as actors, plot, and ratings. Similarly, texts in the “news report” category may also involve related social events, making it difficult for traditional methods to distinguish between them. Without Adaptive Masking, the model may be distracted by redundant information and struggle to extract features with high inter-class discriminability. Adaptive Masking, however, identifies and masks the most discriminative tokens through gradient integration, allowing the model to concentrate on the information in the text that truly aids classification (for example, words like “box office” and “director” are more representative of movie reviews, while “government” and “policy” are more indicative of news reports). This approach enhances intra-class consistency, reduces inter-class confusion, and ultimately improves classification performance.</p><p>Data in the medical field typically exhibits high terminological density and semantic complexity. For instance, in the symptoms dataset, symptom descriptions of certain categories such as “headache” and “migraine,” or “influenza” and “cold,” are highly similar. Moreover, cases within the same category may be described using different medical terminologies. This makes traditional text classification methods susceptible to noise and challenges in effectively distinguishing between similar categories. In contrast, our method, through the dynamic weighted prototype learning mechanism of the DWPM module, assigns dynamic weights to support samples, enabling the category prototypes to more accurately describe the characteristics of each category. Unlike fixed-weight methods, DWPM adjusts the weights of category prototypes through cross-attention mechanisms, so that features with stronger discriminative power for certain categories are assigned higher weights, thereby optimizing the construction of category prototypes. Specifically, in the symptoms dataset, DWPM assigns higher attention weights to key medical terms such as “fever” and “cough,” while reducing the weights of potentially cross-category irrelevant information. This enables the model to more precisely capture subtle differences between categories in the face of high inter-class similarity tasks, thereby enhancing classification performance.</p><p>At the same time, under the 8-shot setting, as the number of support samples increases, the method proposed in this paper maintains a high accuracy rate on all datasets, demonstrating strong stability. On the DBpedia14 dataset, the accuracy of the proposed method under the 8-shot setting reaches 0.987±0.001, close to the optimal performance. This performance improvement is mainly attributed to the design of the hybrid loss function. This loss function combines contrastive loss and prototype loss, thereby performing well in optimizing the structure of the feature space. In traditional few-shot classification tasks, the feature representations of categories are easily influenced by the limited number of samples, leading to unstable prototype distributions. Particularly when category boundaries are ambiguous, the model's discriminative ability may decline. However, the hybrid loss function, by incorporating contrastive learning to bring similar samples closer and push dissimilar samples farther apart, while also combining prototype loss to enhance intra-class consistency, ultimately optimizes the geometric structure of the feature space. For example, on the DBpedia14 dataset, under the 8-shot setting, the model is able to better leverage the additional samples, causing samples of the same category to cluster more tightly in the feature space, while increasing the feature distances between different categories. This improves classification accuracy and reduces category confusion. Moreover, the hybrid loss function further balances intra-class consistency and inter-class discriminability, enabling the model to exhibit excellent performance across different datasets and task settings.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Ablation study</title>
          
          <p>In this section, we conducted experiments on the AG News dataset under the 5-shot setting to investigate the specific impacts of the adaptive encoding strategy (A) and contrastive learning (B) within the DWPM on the performance of DWPM. This study aims to address the challenges of high intraclass diversity and high interclass similarity in few-shot text classification tasks [<xref ref-type="bibr" rid="ref_17">17</xref>].</p><p>The starting point of the ablation study was a baseline BERT model integrated with the DWPM without contrastive learning (B). At this stage, DWPM focused solely on optimizing the class center feature representations through prototypical loss, without leveraging contrastive learning to enhance feature discrimination. The accuracy achieved by this baseline model was 0.745±0.063. In the second stage, when only the adaptive encoding strategy (A) was introduced to the baseline model, the accuracy improved to 0.769±0.048, an increase of 1.79 percentage points compared to the baseline model.g This improvement can be attributed to the strategy's ability to optimize the BERT model by selectively masking text information irrelevant to the classification task, thereby prompting the model to focus more on features critical to classification.</p><p>In the third stage, contrastive learning (B) was introduced into the DWPM module based on the baseline model to combine with the prototypical loss, forming a new hybrid loss function. This step aims to evaluate how contrastive learning works in synergy with the DWPM module and its specific impact on model performance. The experimental accuracy further increased to 0.794±0.057.</p><p>Ultimately, when both the adaptive encoding strategy (A) and the contrastive learning mechanism (B) were integrated into the baseline model, the precision reached its highest level at 0.824±0.022, demonstrating the model's robust performance across various evaluation metrics. The main results are summarized in <xref ref-type="table" rid="table_4">Table 4</xref>. These findings fully substantiate the advantages of our proposed model in optimizing interclass distances, enhancing intraclass consistency, and improving feature discriminability. The adaptive masking strategy significantly enhances the extraction of key features, while the DWPM module further optimizes model performance by dynamically adjusting the feature distribution of samples. The hybrid loss function ensures a balance between interclass separation and intraclass aggregation. The synergistic action of these modules markedly improves the model's performance in few-shot text classification tasks, providing a solid foundation for classification and relationship mining tasks. Through this structured experimental design, we are able to clearly demonstrate the specific contributions of each module to the performance of DWPM and how they collectively enhance the overall performance in few-shot text classification tasks.</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Ablation study results</title>
              </caption>
              <table><tbody><tr><td colspan="3" rowspan="1"><p>Methods</p></td><td colspan="1" rowspan="1"><p>Dataset</p></td></tr><tr><td colspan="1" rowspan="1"><p>BERT</p></td><td colspan="1" rowspan="1"><p>A</p></td><td colspan="1" rowspan="1"><p>B</p></td><td colspan="1" rowspan="1"><p>AG news</p></td></tr><tr><td colspan="1" rowspan="1"><p><mml:math id="m13cnmswf6">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>0.745±0.063</p></td></tr><tr><td colspan="1" rowspan="1"><p><mml:math id="mzghfzcp32">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"><p><mml:math id="mbc76erx7e">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>0.769±0.048</p></td></tr><tr><td colspan="1" rowspan="1"><p><mml:math id="mi0zmojekn">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p><mml:math id="m28oyq5h59">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"><p>0.794±0.057</p></td></tr><tr><td colspan="1" rowspan="1"><p><mml:math id="mkzfwveav7">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"><p><mml:math id="m7lb0u3v76">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"><p><mml:math id="m5b9pada4o">
  <mml:mi>✓</mml:mi>
</mml:math></p></td><td colspan="1" rowspan="1"><p>0.824±0.022</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>In the previous ablation studies, we analyzed the contributions of the adaptive encoding strategy (A) and the contrastive learning mechanism (B) to model performance, demonstrating the advantages of these two modules in optimizing intraclass consistency and interclass distances. </p><p>To more intuitively illustrate the effects of the model at different stages, we mapped the 5-shot training iteration results on the Snippets dataset to two dimensions using UMAP and colored the results according to class labels, as shown in <xref ref-type="fig" rid="fig_3">Figure 3</xref>. In Snippets, the label IDs for the base dataset range from 0 to 7, while those for the novel dataset range from 8 to 13. For comparison, we also visualized the training processes of BERT and AMBERT-DWPM. The visualization results indicate that although both BERT and our module can effectively separate samples from different classes, our module achieves a more uniform class distribution, avoiding the clustering of samples observed in BERT during training. This characteristic is crucial for the effectiveness of FSL. </p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Visualization of training iterations on the snippets dataset</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_zgAI0mx_tDEbwBuz.png"/>
            </fig>
          
          <p>During the UMAP dimensionality reduction process, we set $n<inline-formula>
  <mml:math id="mj1faf86cm">
    <mml:msub>
      <mml:mi/>
      <mml:mi>n</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>n</mml:mi>
      <mml:mi>d</mml:mi>
    </mml:msub>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>=</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mn>15</mml:mn>
    <mml:mn>0.1</mml:mn>
  </mml:math>
</inline-formula>n$_components=2, and random_state=42 to ensure the stability of the experimental settings. First, we extracted the hidden states of the last Transformer layer from the BERT and AMBERT-DWPM models as feature vectors and performed dimensionality reduction using UMAP to map them onto a two-dimensional plane. Subsequently, to further evaluate the feature distribution of the models on the test set, we randomly selected 200 test samples from the novel dataset and visualized them using the same method, ensuring a balanced number of samples from each class to avoid the impact of uneven data distribution on the visualization results. As shown in <xref ref-type="fig" rid="fig_4">Figure 4</xref>, the results reveal that BERT struggles to separate certain classes, especially those that are similar. In contrast, AMBERT-DWPM effectively addresses this issue and enhances the compactness of samples within the same class, thereby improving the model's discriminative power.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Visualization of the test set on snippets</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_qb8p23uxdK4l9SWb.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Conclusion</title>
      <p>This paper proposes AMBERT-DWPM, a novel few-shot text classification framework that effectively improves classification accuracy and stability by integrating an adaptive masking strategy and a DWPM. The adaptive masking strategy dynamically guides the feature extraction process of BERT, enabling the model to focus on discriminative features critical to classification tasks. Simultaneously, the DWPM module dynamically weights the contributions of support samples, effectively addressing challenges associated with high intraclass diversity and high interclass similarity. Comprehensive experimental results demonstrate that AMBERT-DWPM significantly outperforms existing baseline methods, achieving notable improvements across multiple open-domain and domain-specific datasets. Nevertheless, the model may face limitations when encountering extremely imbalanced or noisy datasets. Future research directions include further exploration of adaptive masking strategies tailored for noisy data, enhancement of DWPM's robustness to data imbalance, and applying the proposed method to cross-domain and unsupervised FSL scenarios.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare that they have no conflicts of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="conf-paper">
          <page-range>6000-6010</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Vaswani</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shazeer</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Parmar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Uszkoreit</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Gomez</surname>
              <given-names>A. N.</given-names>
            </name>
            <name>
              <surname>Kaiser</surname>
              <given-names>Ł.</given-names>
            </name>
            <name>
              <surname>Polosukhi</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Attention is all you need</article-title>
          <source>Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17), Long Beach, CA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dosovitskiy</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Beyer</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Kolesnikov</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Weissenborn</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Zhai</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Unterthiner</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Dehghani</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Minderer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Heigold</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Gelly</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Uszkoreit</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Houlsby</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2010.11929</pub-id>
          <article-title>An image is worth 16×16 words: Transformers for image recognition at scale</article-title>
          <source>arXiv preprint arXiv:2010.11929</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Parnami</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2203.04291</pub-id>
          <article-title>Learning from few examples: A summary of approaches to few-shot learning</article-title>
          <source>arXiv preprint arXiv:2203.04291</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>755</page-range>
          <issue>12</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mienye</surname>
              <given-names>Ibomoiye Domor</given-names>
            </name>
            <name>
              <surname>Swart</surname>
              <given-names>Thomas G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/info15120755</pub-id>
          <article-title>A comprehensive review of deep learning: Architectures, recent advances, and applications</article-title>
          <source>Information</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wei</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Vosoughi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Cheng</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.2103.07552</pub-id>
          <article-title>Few-shot text classification with triplet networks, data augmentation, and curriculum learning</article-title>
          <source>arXiv preprint arXiv:2103.07552</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Fang</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Khabsa</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Mao</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.2104.14690</pub-id>
          <article-title>Entailment as few-shot learner</article-title>
          <source>arXiv preprint arXiv:2104.14690</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yin</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2007.09604</pub-id>
          <article-title>Meta-learning for few-shot natural language processing: A survey</article-title>
          <source>arXiv preprint arXiv:2007.09604</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>H. Y.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>S. W.</given-names>
            </name>
            <name>
              <surname>Vu</surname>
              <given-names>N. T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2205.01500</pub-id>
          <article-title>Meta learning for natural language processing: A survey</article-title>
          <source>arXiv preprint arXiv:2205.01500</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>154</volume>
          <page-range>102904</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Luo</surname>
              <given-names>X. D.</given-names>
            </name>
            <name>
              <surname>Deng</surname>
              <given-names>Z. Q.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>B. X.</given-names>
            </name>
            <name>
              <surname>Luo</surname>
              <given-names>M. Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.artmed.2024.102904</pub-id>
          <article-title>Pre-trained language models in medicine: A survey</article-title>
          <source>Artificial Intelligence in Medicine</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="conf-paper">
          <page-range>4171–4186</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Devlin</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>M. W.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Toutanova</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1810.04805</pub-id>
          <article-title>BERT: Pre-training of deep bidirectional transformers for language understanding</article-title>
          <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Minneapolis, Minnesota</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>182-192</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Han</surname>
              <given-names>Xu</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Weilin</given-names>
            </name>
            <name>
              <surname>Ding</surname>
              <given-names>Ning</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Zhiyuan</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>Maosong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.aiopen.2022.11.003</pub-id>
          <article-title>PTR: Prompt tuning with rules for text classification</article-title>
          <source>AI Open</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>284</volume>
          <page-range>111347</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sun</surname>
              <given-names>Shubin</given-names>
            </name>
            <name>
              <surname>Pan</surname>
              <given-names>Xiaoman</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Tao</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>Jian</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.knosys.2023.111347</pub-id>
          <article-title>STID-Prompt: Prompt learning for sentiment-topic-importance detection in financial news</article-title>
          <source>Knowl.-Based Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Jia Ning</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Cheng Yu</given-names>
            </name>
            <name>
              <surname>Luo</surname>
              <given-names>Fan Liang</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>Chao Qun</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>Ming Hui</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Feng</given-names>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names>Qiu Hui</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Song Fang</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>Ming</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2205.05313</pub-id>
          <article-title>Towards unified prompt tuning for few-shot text classification</article-title>
          <source>arXiv preprint arXiv:2205.05313</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>610</volume>
          <page-range>128576</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liao</surname>
              <given-names>Wen Xin</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Ze Long</given-names>
            </name>
            <name>
              <surname>Dai</surname>
              <given-names>Hong Xiang</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>Zhi Hao</given-names>
            </name>
            <name>
              <surname>al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neucom.2024.128576</pub-id>
          <article-title>Mask-guided BERT for few-shot text classification</article-title>
          <source>Neurocomputing</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>1-5</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wu</surname>
              <given-names>C. W.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>J. Y.</given-names>
            </name>
            <name>
              <surname>Shang</surname>
              <given-names>Y. Z.</given-names>
            </name>
            <name>
              <surname>Pei</surname>
              <given-names>J. F.</given-names>
            </name>
            <name>
              <surname>al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/LGRS.2024.3365147</pub-id>
          <article-title>Dynamically weighted prototypical learning method for few-shot SAR ATR</article-title>
          <source>IEEE Geosci. Remote Sens. Lett.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="conf-paper">
          <page-range>497–501</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ren</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CISCE62493.2024.10653360</pub-id>
          <article-title>Enhancing Seq2Seq models for role-oriented dialogue summary generation through adaptive feature weighting and dynamic statistical conditioninge</article-title>
          <source>2024 6th International Conference on Communications, Information System and Computer Engineering (CISCE), Guangzhou, China</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>61</volume>
          <page-range>1-14</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>Y. B.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>J. J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>J. L.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>Z. B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TGRS.2023.3262840</pub-id>
          <article-title>EMSCNet: Efficient multisample contrastive network for remote sensing image scene classification</article-title>
          <source>IEEE Trans. Geosci. Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="conf-paper">
          <volume>37</volume>
          <page-range>136361–136392</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jung</surname>
              <given-names>Y. H.</given-names>
            </name>
            <name>
              <surname>Bellot</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Efficient policy evaluation across multiple different experimental datasets</article-title>
          <source>38th Conference on Neural Information Processing Systems (NeurIPS 2024)</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>53</volume>
          <page-range>8061-8072</page-range>
          <issue>7</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Pang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Yue</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10489-022-03880-y</pub-id>
          <article-title>Few-shot short-text classification with language representations and centroid similarity</article-title>
          <source>Appl. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conf-paper">
          <page-range>6810-6828</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jiang</surname>
              <given-names>Z. J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Tsirlin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Tang</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Dai</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2023.findings-acl.426</pub-id>
          <article-title>"Low-resource'' text classification: A parameter-free classification method with compressors</article-title>
          <source>Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>1-12</page-range>
          <issue>1</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dai</surname>
              <given-names>Hongxiang</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Zelong</given-names>
            </name>
            <name>
              <surname>Liao</surname>
              <given-names>Wenxin</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Xiankai</given-names>
            </name>
            <name>
              <surname>al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TBDATA.2025.3536934</pub-id>
          <article-title>AugGPT: Leveraging ChatGPT for text data augmentation</article-title>
          <source>IEEE Trans. Big Data</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Piedboeuf</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Langlais</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2402.14895</pub-id>
          <article-title>Data augmentation is dead, long live data augmentation</article-title>
          <source>arXiv preprints arXiv:2402.14895</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="thesis">
          <person-group person-group-type="author">
            <name>
              <surname>Chakraborty</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Analysis of textual-based reviews with minimal supervision</article-title>
          <year>2024</year>
          <publisher-name>Ph.D. dissertation, Iowa State University, Ames, Iowa</publisher-name>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Schick</surname>
              <given-names>Timo</given-names>
            </name>
            <name>
              <surname>Schütze</surname>
              <given-names>Hinrich</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2001.07676</pub-id>
          <article-title>Exploiting cloze questions for few shot text classification and natural language inference</article-title>
          <source>arXiv preprint arXiv:2001.07676</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sun</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Hao</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2109.03564</pub-id>
          <article-title>NSP-BERT: A prompt-based few-shot learner through an original pre-training task–next sentence prediction</article-title>
          <source>arXiv preprint arXiv:2109.03564</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="conf-paper">
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Koch</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Zemel</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Salakhutdinov</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Siamese neural networks for one-shot image recognition</article-title>
          <source>Proceedings of the 32nd International Conference on Machine Learning, Lille, France</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="conf-paper">
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Snell</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Swersky</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zemel</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1703.05175</pub-id>
          <article-title>Prototypical networks for few-shot learning</article-title>
          <source>31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Geng</surname>
              <given-names>Ruiying</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Bohan</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Yongbin</given-names>
            </name>
            <name>
              <surname>al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1902.10482</pub-id>
          <article-title>Induction networks for few-shot text classification</article-title>
          <source>arXiv preprint arXiv:1902.10482</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Müller</surname>
              <given-names>Thomas</given-names>
            </name>
            <name>
              <surname>Pérez-Torró</surname>
              <given-names>Guillermo</given-names>
            </name>
            <name>
              <surname>Franco-Salvador</surname>
              <given-names>Marc</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2203.14655</pub-id>
          <article-title>Few-shot learning with siamese networks and label tuning</article-title>
          <source>arXiv preprint arXiv:2203.14655</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>1486-1495</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ragno</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>La Rosa</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Capobianco</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TAI.2022.3222618</pub-id>
          <article-title>Prototype-based interpretable graph neural networks</article-title>
          <source>IEEE Transactions on Artificial Intelligence</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gogoi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Tiwari</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Verma</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2211.12479</pub-id>
          <article-title>Adaptive prototypical networks</article-title>
          <source>arXiv preprint arXiv:2211.12479</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-9</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Kang</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/IJCNN60899.2024.10650913</pub-id>
          <article-title>TPN: Transferable Proto-Learning Network towards few-shot document-level relation extraction</article-title>
          <source>2024 International Joint Conference on Neural Networks (ĲCNN), Yokohama, Japan</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tran</surname>
              <given-names>T. K.</given-names>
            </name>
            <name>
              <surname>Tran</surname>
              <given-names>H. P.</given-names>
            </name>
            <name>
              <surname>T. L. Le</surname>
            </name>
            <name>
              <surname>et al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/MAPR63514.2024.10660707</pub-id>
          <article-title>FedNTProto: A prototype-based approach for personalized federated learning</article-title>
          <source>2024 International Conference on Multimedia Analysis and Pattern Recognition (MAPR), Da Nang, Vietnam</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gong</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Non-exemplar domain incremental learning via cross-domain concept integration</article-title>
          <source>European Conference on Computer Vision</source>
          <publisher-name>Cham: Springer Nature Switzerland</publisher-name>
          <year>2024</year>
          <page-range>144-162</page-range>
          <pub-id pub-id-type="doi">10.1007/978-3-031-72967-6_9</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>015202</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Duan</surname>
              <given-names>Guofeng</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>Yonggang</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Zhiyong</given-names>
            </name>
            <name>
              <surname>Ling</surname>
              <given-names>Shiqing</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>Jianrong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1361-6501/ac90de</pub-id>
          <article-title>Cross-domain few-shot defect recognition for metal surfaces</article-title>
          <source>Meas. Sci. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="journal">
          <volume>54</volume>
          <page-range>5097-5116</page-range>
          <issue>6</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Hao</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Hao</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>Linlin</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>Weilong</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Dan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10489-024-05440-y</pub-id>
          <article-title>BiLSTM-TANet: An adaptive diverse scenes model with context embeddings for few-shot learning</article-title>
          <source>Appl. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>3334</page-range>
          <issue>5</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hu</surname>
              <given-names>Tiankuang</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Zhiqiang</given-names>
            </name>
            <name>
              <surname>Ge</surname>
              <given-names>Jinkun</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Zhixian</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>Jiancheng</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app13053334</pub-id>
          <article-title>A Chinese few-shot text classification method utilizing improved prompt learning and unlabeled data</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="journal">
          <volume>176</volume>
          <page-range>106344</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sun</surname>
              <given-names>Zhe</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>Wei</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Mingyang</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neunet.2024.106344</pub-id>
          <article-title>SLTRN: Sample-level transformer-based relation network for few-shot classification</article-title>
          <source>Neural Netw.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>