<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IDA</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Information Dynamics and Applications</journal-title>
        <abbrev-journal-title abbrev-type="issn">Inf. Dyn. Appl.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IDA</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1494</issn>
      <issn publication-format="print">2958-1486</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-hIfep7Jhp91gjeNNjgiaPfqkukCeBStR</article-id>
      <article-id pub-id-type="doi">10.56578/ida030404</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Leveraging Artificial Intelligence for Blackhole Attack Detection in MANETs: A Comparative Study</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0009-7779-3858</contrib-id>
          <name>
            <surname>Ibrahim</surname>
            <given-names>Zainab Bashar</given-names>
          </name>
          <email>Zainab.en1384@student.uomosul.edu.iq</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1252-4402</contrib-id>
          <name>
            <surname>Ghanim</surname>
            <given-names>Mayada Faris</given-names>
          </name>
          <email>mayada.faris@uomosul.edu.iq</email>
        </contrib>
        <aff id="aff_1">Computer Engineering Department, University of Mosul, 41001 Mosul, Iraq</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>20</day>
        <month>12</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>4</issue>
      <fpage>245</fpage>
      <lpage>257</lpage>
      <page-range>245-257</page-range>
      <history>
        <date date-type="received">
          <day>07</day>
          <month>11</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>15</day>
          <month>12</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Blackhole attacks represent a significant threat to the security of communication networks, particularly in emerging network architectures such as Mobile Ad Hoc Networks (MANETs). These attacks, characterized by their ability to obscure malicious behavior, evade conventional detection methods due to their loosely defined signatures and their ability to bypass traditional filtering mechanisms. This study investigates the application of machine learning techniques, specifically Support Vector Machine (SVM), Convolutional Neural Network (CNN), and Decision Tree (DT), for the detection and mitigation of blackhole attacks in MANETs. Simulations conducted in MATLAB 2023a examined network configurations with node densities of 50, 100, 250, and 500 nodes to assess the performance of these classifiers in comparison to conventional detection approaches. The results demonstrated that both SVM and CNN achieved near-perfect detection accuracy of 100% across all network configurations, outperforming traditional methods. SVM was chosen due to its efficacy in handling high-dimensional data, CNN for its ability to learn complex, nonlinear hierarchical features, and DT for its interpretability. The findings underscore the potential of these machine learning models in enhancing the precision of blackhole attack detection, thereby improving network security. Future research is recommended to explore the scalability and training efficiency of these models, particularly through the integration of advanced techniques such as model fusion and deep learning architectures. This study contributes to the growing body of literature on radar wave radio (RWR)-based and machine learning-based attack detection and highlights the potential of artificial intelligence (AI) solutions in transforming traditional emitter identification methods, offering significant improvements to network protection systems.</p></abstract>
      <kwd-group>
        <kwd>MANET</kwd>
        <kwd>AODV</kwd>
        <kwd>Blackhole</kwd>
        <kwd>AI</kwd>
        <kwd>Security</kwd>
        <kwd>Machine learning</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="2"/>
        <fig-count count="9"/>
        <table-count count="6"/>
        <ref-count count="28"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>MANETs are wireless networks without fixed infrastructure and do not have centralized packet routing administration [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>]. Because of these unique characteristics, MANETs are vulnerable to a range of security threats, such as blackhole attacks [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>], where hostile nodes discard packets on purpose, seriously disrupting connectivity. Maintaining the availability, confidentiality, and integrity of network services and data depends on MANET security [<xref ref-type="bibr" rid="ref_6">6</xref>]. When two nodes are within range of one another, single-hop direct communication takes place; otherwise, multi-hop communication takes place via intermediary nodes. Routing protocols for MANETs are often separated into three categories: proactive, reactive, and hybrid [<xref ref-type="bibr" rid="ref_7">7</xref>]. For this reason, the most used reactive protocol for packet transmission is the classic Ad-hoc On-demand Distance Vector (AODV) routing protocol. Since AODV incorporates both route identification and repair methods, it is widely used in MANETs for the distribution of multimedia and emergency information. However, because of wireless communication and finite energy resources, security remains an important factor. As a result, several types of attacks, such as blackhole, wormhole, grayhole, etc., can significantly impair the performance of MANETs [<xref ref-type="bibr" rid="ref_3">3</xref>]. By enabling hostile nodes to propagate erroneous pathways to the source node as viable routes, black hole attacks take advantage of the AODV route discovery process. They indicate a new path to the target by sending an route reply (RREP) with a destination sequence number greater than the route request (RREQ) message. The most prevalent kind of attack on MANETs is this one because routing algorithms frequently deliver packets by mistakenly trusting their nearby nodes, which causes packet loss. It’s challenging to distinguish between a packet loss caused by a blackhole assault and regular network activity [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>].</p><p>Network security is one area where AI has shown to be revolutionary. The increasing sophistication and frequency of cyberattacks need the use of advanced defense-oriented technologies. Traditional security methods sometimes fail to detect new and evolving threats because they rely on pre-established rules and signatures. AI offers many solutions for these issues because of its ability to learn from the data and adapt to new patterns [<xref ref-type="bibr" rid="ref_10">10</xref>]. Recent studies have indicated that AI techniques are not only capable of detecting cyberattacks but can also mitigate them in real time, thereby enhancing the resilience of network infrastructures. Furthermore, the incorporation of AI into current security frameworks has resulted in considerable improvements in threat detection accuracy and reaction times [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>].</p>
      
        <sec>
          
            <title>1.1. Blackhole attack</title>
          
          <p>Blackhole attack is one type of attack that is common in MANETs. The attacker node claims that it is the shortest and best path for the destination to drop all the packet data and then it decides to send them to the destination or delete them, which creates a “black hole” where the data just disappears [<xref ref-type="bibr" rid="ref_12">12</xref>], [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. The network could stop and the performance could reduce because of the loss of the data packets. This type of attack takes advantage of how routing systems find routes like in the AODV protocol [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. When the source node doesn’t have the data about the destination and the path, it sends a RREQ message to all the nodes in AODV. The RREP message is sent by the attacker node to the source that claims it is the shortest and has a lower hop count to show that is the best path. The source node believes this and sends its data based on that information [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. Blackhole attacks can cause damage to the networks, which is why it is important to understand and stop them. These attacks can cause data loss, more delay, and lower network performance. MANETs are used in areas like disaster recovery, military missions, and vehicle communication, and it’s really important to protect and secure these networks [<xref ref-type="bibr" rid="ref_14">14</xref>], [<xref ref-type="bibr" rid="ref_15">15</xref>]. Blackhole attacks are still important today, despite being a well-known attack vector. To deal with the growing complexity of these attacks, researchers have been creating new methods. Many improvements to the AODV protocol and other techniques have been proposed in recent studies to make MANETs more secure against blackhole attacks [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>1.2. Key ai techniques in network security</title>
          
          <p style="text-align: justify">A variety of AI approaches have been used for network security as follows:</p><p style="text-align: justify">• SVM: A supervised learning model that classifies data by finding the best hyperplane to separate different classes. In network security, SVM uses features extracted from network traffic to classify whether the behavior is normal (benign) or harmful (malicious) [<xref ref-type="bibr" rid="ref_17">17</xref>]. SVM is a useful tool in detecting network threats and other security risks due to its ability to handle high-dimensional data and its efficacy in finding patterns [<xref ref-type="bibr" rid="ref_18">18</xref>], [<xref ref-type="bibr" rid="ref_19">19</xref>].</p><p style="text-align: justify">• CNN: A type of deep learning model that focuses on pattern recognition. CNNs may detect anomalies and intrusions in network security by examining traffic patterns as features and identifying complex attack signatures [<xref ref-type="bibr" rid="ref_20">20</xref>]. Recent developments have demonstrated CNNs’ ability to analyze real-time network traffic data efficiently, increasing the security infrastructure’s overall efficacy and boosting the detection accuracy of anomalous activity.</p><p style="text-align: justify">• DT: DTs are used to create models that predict the values of target variables by starting with different input variables. Depending on the characteristics of the data, DTs may be used in network security to classify network traffic as benign or malicious by following a tree-like structure of decision rules [<xref ref-type="bibr" rid="ref_21">21</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>1.3. Problem statement</title>
          
          <p>The increased reliance on networked systems and the rapid development of technology itself have shifted cybersecurity to the fore. Blackhole attacks are cyber threats that severely compromise network security, particularly in MANETs. Blackhole attacks are a form of malicious nodes in which they claim to be the fastest route to the target node only to absorb data packets and throw them away. They destructively affect network communication and cause huge delays. Because of their complexity and fluidity in nature, traditional detection mechanisms based on established criteria and signatures are unfitting in the case of new or complex blackhole assault recognition and these approaches fail in many cases. This limitation highlights the necessity of mechanization and flexibility. Such methods include AI methods as they can faster and more accurately improve the detection of blackhole attacks because of their ability to detect models and learn from data.</p>
          
            <sec>
              
                <title>1.3.1 Research objectives</title>
              
              <p>The primary objective of this research is to develop and evaluate AI-based models for the detection of blackhole attacks in network security. Specifically, the research aims at:</p><p>• Checking in AI techniques: Checking how to identify blackhole attacks using different AI techniques, such as SVM, CNN, and DT.</p><p>• Feature selection and extraction: From network traffic data, pertinent information may be located and extracted to train AI models that can discriminate between benign and malevolent behavior.</p><p>• Model development: Utilizing SVM, CNN, and DT algorithms to create AI-based detection models. These models can be improved to get low false-positive rates and high accuracy.</p><p>• Performance evaluation: Measuring the AI models’ performance using a range of measures, including computational efficiency, accuracy, precision, recall, and F1-score. The outcomes can be analyzed using conventional detection techniques.</p><p>This study is expected to advance the creation of more adaptable and efficient network security solutions to strengthen cybersecurity generally and better defend against blackhole assaults.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>2. Literature review</title>
      <p>Blackhole attacks are a significant threat in network security, particularly in MANETs and wireless sensor networks (WSNs). Several methods have been proposed to detect and mitigate these attacks. Rani et al. [<xref ref-type="bibr" rid="ref_22">22</xref>] found black holes in Internet of Things (IoT)-MANET routes and channeled them through protected nodes using an improved AODV routing protocol with SVM and Artificial Neural Network (ANN). The primary objective of the research is to improve data packet transmission efficiency based on node location, energy consumption, and data transmission delay. The AODV with Artificial Bee Colony (ABC), ANN, and SVM approach performed well, with an average PDR, throughput, and latency of 97.96%, 92.78 Kbps, and 0.04 s, respectively. A CNN-based intrusion detection method has been recommended for automatically performing complex feature extraction in constantly changing environments, which is essential for network Intrusion Detection System (IDS). Deep Neural Network (DNN)-IDS boosts user confidence and communication, as the black-box nature of DNNs limits visibility, but the IDS is vital for building trust. By training DNN-IDS, the input features are optimized for identifying any type of intrusion [<xref ref-type="bibr" rid="ref_23">23</xref>].</p><p>Shafi et al. [<xref ref-type="bibr" rid="ref_3">3</xref>] proposed an effective machine learning-based secure AODV routing system to detect floods and blackhole attacks in MANETs. The method improved secure communication by using an ANN with a SVM classifier to increase intrusion detection accuracy and throughput. The MLAODV is suitable for information exchange in semi-urban areas but not in completely urban ones due to its dynamic node density and speeds. The efficacy was assessed against the current AODV processes, which are trust-based and conventional.</p><p>Furthermore, a proposal has been made for an IDS to prevent sinkhole attacks in mobile sink MANETs [<xref ref-type="bibr" rid="ref_24">24</xref>]. A hacked node that advertises fictitious routing changes in an attempt to draw in network traffic is called a sinkhole. This system classifies data using different machine learning methods, such as SVM, CNN, K-Nearest Neighbor (KNN), and DT. After gathering 3,997 distinct samples, including 256 malicious and 3,604 normal, the study discovered that CNN had the best accuracy of 98.6%. DT, SVM, and KNN came in second and third, with accuracies of 98.4%, 97.8%, and 96.7%, respectively.</p>
      
        <sec>
          
            <title>2.1. Survey of ai techniques used in network security</title>
          
          <p>AI algorithms can learn from data and recognize intricate patterns so that they have become more popular in the field of network security. The following AI methods are frequently used:</p><p>• Machine learning</p><p>– SVM: SVMs use the optimal hyperplane to divide and classify the data into groups. Through the examination of network traffic patterns, they are successful in identifying intrusions [<xref ref-type="bibr" rid="ref_25">25</xref>].</p><p>– DT: DTs use a sequence of decisions based on the characteristics of the data to classify the data. They are helpful in developing comprehensible intrusion detection models.</p><p>• Deep learning</p><p>– CNN: CNNs work very well for pattern and picture recognition. They are employed in network security to identify abnormalities and intrusions through the analysis of traffic patterns as 1D feature vectors [<xref ref-type="bibr" rid="ref_26">26</xref>].</p><p>– Recurrent Neural Network (RNN): Network traffic flows and other time-series data patterns can be found in RNNs [<xref ref-type="bibr" rid="ref_27">27</xref>].</p><p>• Hybrid approaches</p><p>– Many AI approaches can improve detection performance. For instance, hybrid models that combine SVM and deep learning methods have demonstrated enhanced efficacy in identifying complex assaults [<xref ref-type="bibr" rid="ref_28">28</xref>].</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      <p>This section descries the network environment and attack scenarios. In this research, MATLAB 2023a was used to simulate a network environment representative of a typical MANET. The network consists of a varying number of nodes (50, 100, 250, 500) deployed over a defined area of 1000 m × 1000 m. Nodes communicated with each other using the AODV routing protocol. The simulation code was programmed to produce a MANET with nodes placed randomly within a given area, including the dynamics of blackhole attacks. The simulation gathered information regarding its behavior at normal and under attack mode.</p><p>Attack scenarios:</p><p>• Normal scenario: All nodes functioned correctly, without any malicious activities in the routing data packets. <xref ref-type="fig" rid="fig_1">Figure 1</xref> shows the random distribution of the nodes.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Network topology of a MANET with 50 nodes</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_aZrWmQ-kJ0PgS8F2.png"/>
        </fig>
      
      <p>• Blackhole attack scenario: One or more malicious nodes were introduced into the network. These nodes advertised the shortest path to the destination node but dropped all received packets, disrupting the network’s communication. The red links in <xref ref-type="fig" rid="fig_2">Figure 2</xref> are the attacks. Simulation parameters included the simulation time of 500 seconds and the transmission range of 500 meters. To detect blackhole attacks, several AI techniques were employed as follows:</p><p>• SVM: A supervised learning model that classifies data by finding the optimal hyperplane separating different classes. SVM was chosen for its robustness and effectiveness in handling high-dimensional data.</p><p>• CNN: A deep learning model particularly effective for image and pattern recognition. CNNs were used to detect anomalies by treating network traffic data as 1D feature vectors, enabling the identification of complex patterns indicative of blackhole attacks.</p><p>• DT: A model that predicts the value of a target variable based on several input features. DTs were utilized for their interpretability and ease of use in classifying network traffic as normal or malicious.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Network topology of a MANET with 50 nodes under blackhole attack</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_rKPOco6qFYRvjpYh.png"/>
        </fig>
      
      
        <sec>
          
            <title>3.1. Data collection and preprocessing methods</title>
          
          <p>The simulation gathered information regarding its behavior at normal and under attack mode, which is useful in cases of detection. The detection process was conducted separately using classification algorithms written in MATLAB for each algorithm. These algorithms then proceeded to categorize the activities in the network – normal or malicious – based on the features generated from the simulation. In the next formative stage, the currently trained models, including the SVM, CNN and DT, may be integrated into an IDS so as to detect real-time attacks within actual networks. This approach connected the gap in between offline training and active implementation where these AI models can be applied to for dynamic and adaptive networks security.</p>
          
            <sec>
              
                <title>3.1.1 Data collection</title>
              
              <p>Data was collected from the simulated network environment under both normal and attack scenarios. The collected data includes ‘SentPackets,’ ‘ReceivedPackets,’ ‘LostPackets,’ ‘TotalEnergy,’ and ‘TotalDelay.’</p>
            </sec>
          
          
            <sec>
              
                <title>3.1.2 Preprocessing methods</title>
              
              <p>The data preprocessing steps include loading the data, extracting features and labels, converting labels to categorical type, handling missing values, and splitting the data into training and testing sets.</p>
            </sec>
          
          
            <sec>
              
                <title>3.1.3 Normalization</title>
              
              <p>The features were scaled to a standard range (e.g., [0, 1]) to improve the performance of machine learning algorithms.</p>
            </sec>
          
          
            <sec>
              
                <title>3.1.4 Labeling</title>
              
              <p>Labels were assigned to the data instances based on the scenario (e.g., normal or blackhole attack).</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Proposed ai-based detection model</title>
      <p>The proposed AI-based detection model employs three different machine learning algorithms to detect blackhole attacks in a network environment: SVM, CNN, and DT. Each model was designed to analyze network traffic data and classify it as either normal or indicative of a blackhole attack.</p>
      
        <sec>
          
            <title>4.1. Architecture of the ai model and the rationale of choosing it</title>
          
          
            <sec>
              
                <title>4.1.1 Svm</title>
              
              <p>• Architecture: The SVM model uses a radial basis function (RBF) kernel to handle non-linear data. The model was trained to find the optimal hyperplane that separates different classes in high-dimensional space.</p><p>• Rationale: SVM was chosen for its robustness in handling high-dimensional data and its effectiveness in binary classification tasks. It is particularly suitable for scenarios with clear margin separation between classes, as shown in <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
              
                <fig id="fig_3">
                  <label>Figure 3</label>
                  <caption>
                    <title>Diagram of the SVM process using an RBF kernel</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_g4oNzswg-K8GWyK6.png"/>
                </fig>
              
            </sec>
          
          
            <sec>
              
                <title>4.1.2 Cnn</title>
              
              <p>The CNN architecture is a custom CNN. The architecture (<xref ref-type="fig" rid="fig_4">Figure 4</xref>) is simpler and was designed to work with non-image data (1D feature vectors) rather than images.</p><p>• Architecture: The CNN model includes the following layers:</p><p>– Input layer: Accepts input data with dimensions [1, 1, numFeatures] (1x1 spatial dimensions with numFeatures channels).</p><p>– Convolutional layers: Extracts features from the input data using 32 filters and ‘same’ padding.</p><p>– Batch normalization layer: Normalizes the output of the convolutional layers to speed up training and improve stability.</p><p>– ReLU activation layer: Introduces non-linearity into the model.</p><p>– Fully connected layers: Aggregates the features and performs classification, 64 neurons, connected to all neurons in the previous layer.</p><p>– Softmax layer: Applies the softmax function to convert the final layer outputs to probabilities.</p><p>– Classification layer: Final layer that classifies the input data.</p><p>• Rationale: CNNs are effective for detecting complex patterns in data. By treating network traffic data as images, CNNs can identify intricate patterns indicative of blackhole attacks, providing high accuracy in classification.</p>
              
                <fig id="fig_4">
                  <label>Figure 4</label>
                  <caption>
                    <title>Diagram of the CNN architecture</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_02p3w9aE3Y0W-hUh.png"/>
                </fig>
              
            </sec>
          
          
            <sec>
              
                <title>4.1.3 Dt</title>
              
              <p>• Architecture: The DT model uses a tree-like structure (<xref ref-type="fig" rid="fig_5">Figure 5</xref>) where nodes represent decisions based on the values of input features, and branches represent the outcomes of those decisions.</p><p>• Rationale: DTs are easy to interpret and implement. They can handle both numerical and categorical data and are capable of capturing non-linear relationships between features.</p><p><xref ref-type="table" rid="table_1">Table 1</xref> shows the summary of feature extraction and engineering techniques for AI models.</p>
              
                <fig id="fig_5">
                  <label>Figure 5</label>
                  <caption>
                    <title>Diagram of the DT architecture</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_-4T4pk0P8EgsIWVJ.png"/>
                </fig>
              
              
                <table-wrap id="table_1">
                  <label>Table 1</label>
                  <caption>
                    <title>Summary of feature extraction and engineering techniques for AI models</title>
                  </caption>
                  <table><tbody><tr><td colspan="3" rowspan="1" colwidth="110,341,401"><p>Summary of analysis</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="110"><p>Algorithm</p></td><td colspan="1" rowspan="1" colwidth="341"><p>Feature Extraction</p></td><td colspan="1" rowspan="1" colwidth="401"><p>Network Architecture</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="110"><p>SVM</p></td><td colspan="1" rowspan="1" colwidth="341"><p>Extracted features:  SentPackets, ReceivedPackets, LostPackets, TotalEnergy, TotalDelay</p></td><td colspan="1" rowspan="1" colwidth="401"><p>-      Ensure no zero or negative values before taking log transformation.</p><p>-      Combine original features with engineered features such as logarithmic and squared values, and interaction terms.</p><p>-       Normalize and rescale features to standardize the input data.</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="110"><p>CNN</p></td><td colspan="1" rowspan="1" colwidth="341"><p>-      Similar features to SVM extracted from network traffic data.</p><p>-      Features reshaped and normalized to fit the input requirements of the CNN model.</p></td><td colspan="1" rowspan="1" colwidth="401"><p>-      Input layer for 1D feature vectors</p><p>-      Convolutional layers</p><p>-      Batch normalization</p><p>-      ReLU activation</p><p>-      Fully connected layers</p><p>-      Softmax layer</p><p>-      Classification layer</p><p>-       Training with Adam optimizer, specific parameters for epochs and batch size.</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="110"><p>DT</p></td><td colspan="1" rowspan="1" colwidth="341"><p>Key features: SentPackets,</p><p>ReceivedPackets, LostPackets, TotalEnergy.</p></td><td colspan="1" rowspan="1" colwidth="401"><p>-      Data preprocessed by normalizing and ensuring quality through removal of anomalies.</p><p>-       Model trained by partitioning data into training and testing sets.</p><p>-      Optimization using cross-validation.</p></td></tr></tbody></table>
                </table-wrap>
              
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>4.2. Training and testing procedures</title>
          
          
            <sec>
              
                <title>4.2.1 Data splitting</title>
              
              <p>The code uses a 70-30 split for training and testing data. As the number of nodes increases, the following considerations become important:</p><p>• Training data size: A larger number of nodes results in more training data, which can improve the model’s ability to generalize. However, it also requires more computational resources for model training.</p><p>• Testing data size: Similarly, more nodes lead to a larger testing dataset, providing a more robust evaluation of the model’s performance.</p>
            </sec>
          
          
            <sec>
              
                <title>4.2.2 Models</title>
              
              <p>• SVM: The SVM model was trained by the dataset with hyperparameter optimization to find the best RBF kernel parameters.</p><p>• CNN: The CNN model was trained with certain batch size and epoch values using the Adam optimizer. The architecture of the model was built to optimize the accuracy.</p><p>• DT: The data was split into training and testing sets. Therefore, the DT model was trained. The model was also improved by cross-validation to avoid overfitting.</p>
            </sec>
          
          
            <sec>
              
                <title>4.2.3 Evaluation</title>
              
              <p>Each model was evaluated based on its accuracy, precision, recall, and F1-score. The performance metrics were compared to determine the most effective model for detecting blackhole attacks.</p><p> <xref ref-type="table" rid="table_2">Table 2</xref> summarizes the performance of each model for different node counts.</p>
              
                <table-wrap id="table_2">
                  <label>Table 2</label>
                  <caption>
                    <title>Accuracy of DT, CNN, and SVM models for different node counts</title>
                  </caption>
                  <table><tbody><tr><th colspan="4" rowspan="1" colwidth="121,119,126,104"><p>Accuracy of Algorithms</p></th></tr><tr><td colspan="1" rowspan="1" colwidth="121"><p>No. of Nodes</p></td><td colspan="1" rowspan="1" colwidth="119"><p>DT Accuracy</p></td><td colspan="1" rowspan="1" colwidth="126"><p>CNN Accuracy</p></td><td colspan="1" rowspan="1" colwidth="104"><p>SVM Accuracy</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="121"><p>50</p></td><td colspan="1" rowspan="1" colwidth="119"><p>99.33%</p></td><td colspan="1" rowspan="1" colwidth="126"><p>100.00%</p></td><td colspan="1" rowspan="1" colwidth="104"><p>100.00%</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="121"><p>100</p></td><td colspan="1" rowspan="1" colwidth="119"><p>98.33% </p></td><td colspan="1" rowspan="1" colwidth="126"><p>99.00%</p></td><td colspan="1" rowspan="1" colwidth="104"><p>99.00%</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="121"><p>250</p></td><td colspan="1" rowspan="1" colwidth="119"><p>91.70%</p></td><td colspan="1" rowspan="1" colwidth="126"><p>88.62%</p></td><td colspan="1" rowspan="1" colwidth="104"><p>91.00%</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="121"><p>500</p></td><td colspan="1" rowspan="1" colwidth="119"><p>79.62%</p></td><td colspan="1" rowspan="1" colwidth="126"><p>80.26%</p></td><td colspan="1" rowspan="1" colwidth="104"><p>79.62%</p></td></tr></tbody></table>
                </table-wrap>
              
            </sec>
          
          
            <sec>
              
                <title>4.2.4 Confusion matrix</title>
              
              <p>A table of confusion matrix was used to describe the performance of a classification model when applied to a set of test data whose real values are known. For a binary classification problem, the confusion matrix looks like <xref ref-type="table" rid="table_3">Table 3</xref>.</p><p>The computation of several performance measures, including accuracy, precision, recall, and F1-score, which offer a thorough assessment of the classification model’s performance, depends on these concepts.</p>
              
                <table-wrap id="table_3">
                  <label>Table 3</label>
                  <caption>
                    <title>Confusion matrix</title>
                  </caption>
                  <table><tbody><tr><td colspan="1" rowspan="1" colwidth="111"></td><td colspan="1" rowspan="1" colwidth="345"><p>Predicted Positive</p></td><td colspan="1" rowspan="1" colwidth="343"><p>Predicted Negative</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>Actual Positive</p></td><td colspan="1" rowspan="1" colwidth="345"><p>True positive (TP): Correctly predicted positive cases.</p></td><td colspan="1" rowspan="1" colwidth="343"><p>False negative (FN): Incorrectly predicted negative cases.</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>Actual Negative</p></td><td colspan="1" rowspan="1" colwidth="345"><p>False positive (FP): Incorrectly predicted positive cases.</p></td><td colspan="1" rowspan="1" colwidth="343"><p>True negative (TN): Correctly predicted negative cases.</p></td></tr></tbody></table>
                </table-wrap>
              
              <p>The accuracy of the model is given by:</p>
              
                <disp-formula>
                  <label>(1)</label>
                  <mml:math id="m6eeeyci7e">
                    <mml:mrow>
                      <mml:mi>A</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>u</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mi>y</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>T</mml:mi>
                          <mml:mi>P</mml:mi>
                          <mml:mi>T</mml:mi>
                          <mml:mi>N</mml:mi>
                          <mml:mo>+</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>F</mml:mi>
                          <mml:mi>P</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>N</mml:mi>
                          <mml:mi>T</mml:mi>
                          <mml:mi>P</mml:mi>
                          <mml:mi>T</mml:mi>
                          <mml:mi>N</mml:mi>
                          <mml:mo>+</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>+</mml:mo>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              <p>The accuracy of the DT, CNN, and SVM models for the dataset node counts is shown in <xref ref-type="table" rid="table_2">Table 2</xref>. The quantity of characteristics in the dataset grows in tandem with the number of nodes. The precise count of features for every number of nodes is provided as follows:</p><p>• 50 nodes = 250 reads</p><p>• 100 nodes = 500 reads</p><p>• 250 nodes = 1,100 reads</p><p>• 500 nodes = 1,260 reads</p><p>All three models obtained highly accurate accuracy when there were 50 nodes. The CNN and SVM models attained flawless accuracy. The reduced data amount and comparatively simple patterns, which facilitate the models’ ability to learn and generalize, are responsible for this excellent performance. The accuracy was still good for all models at 100 nodes, although it was somewhat lower than it was at 50 nodes.</p><p>All models showed a more pronounced fall in accuracy at 250 nodes. The complexity of the data was significantly increased by the number of readings (1,100), making it harder for the models to maintain good accuracy. Specifically, the CNN model exhibited a notable decline, suggesting it may be having trouble processing the higher volume and complexity of input. Upon reaching 500 nodes, the accuracy of all models significantly decreased. The data got extremely complicated with 1,260 readings, making it difficult for the algorithms to distinguish between legitimate and malicious traffic. Due to its complexity, there may be issues with underfitting or overfitting, where the models, respectively, don’t generalize well to new data or fit too closely to the training set.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Results and analysis</title>
      
        <sec>
          
            <title>5.1. Presentation of the experimental results</title>
          
          <p> <xref ref-type="fig" rid="fig_6">Figure 6</xref> displays the experimental findings for the suggested AI models (SVM, CNN, and DT) in the detection of blackhole assaults. The performance metrics were calculated for different numbers of nodes (50, 100, 250, and 500) in the network.</p><p>In comparison to these conventional techniques, the suggested AI models—in particular, CNN and SVM—showed better accuracy and resilience, especially for lower node counts.</p>
        </sec>
      
      
        <sec>
          
            <title>5.2. Analysis of the performance metrics</title>
          
          <p>The AI models’ performance measurements consist of F1-score, recall, accuracy, and precision. These measurements are essential for evaluating how well the models identify blackhole assaults.</p><p>• Accuracy: Measures the proportion of correctly classified instances out of the total instances. Both CNN and SVM achieved 100% accuracy for 50 nodes, indicating perfect classification.</p><p>• Precision: The ratio of true positive instances to the sum of true positive and false positive instances. High precision indicates that the model does not falsely identify normal nodes as malicious.</p><p>• Recall: The ratio of true positive instances to the sum of true positive and false negative instances. High recall signifies the model’s ability to detect all actual blackhole attacks.</p><p>• F1-score: The harmonic mean of precision and recall, providing a balanced measure of the model’s performance.</p><p><xref ref-type="fig" rid="fig_6">Figure 6</xref> shows the chart accuracy of different models (DT, CNN, and SVM) over varying numbers of nodes.</p><p><xref ref-type="table" rid="table_4">Table 4</xref> visualizes the precision, recall, and F1-score for the SVM model at different node counts (50, 100, 250, and 500).</p><p>Precision is the ratio of correctly predicted positive observations to the total predicted positives. Therefore, high precision indicates that there are few false positives, meaning that when the classifier predicts a positive class, it is usually correct. The precision of the model is given by:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="mql4ujadk8">
                <mml:mrow>
                  <mml:mi>P</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>n</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Performance metrics of the SVM model for different node counts</title>
              </caption>
              <table><tbody><tr><th colspan="5" rowspan="1" colwidth="111,85,87,92,98"><p>Performance Metrics for SVM</p></th></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>No. of Nodes</p></td><td colspan="1" rowspan="1" colwidth="85"><p>Accuracy</p></td><td colspan="1" rowspan="1" colwidth="87"><p>Precision</p></td><td colspan="1" rowspan="1" colwidth="92"><p>Recall</p></td><td colspan="1" rowspan="1" colwidth="98"><p>F1-score</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>50</p></td><td colspan="1" rowspan="1" colwidth="85"><p>100.00%</p></td><td colspan="1" rowspan="1" colwidth="87"><p>1.0000</p></td><td colspan="1" rowspan="1" colwidth="92"><p>1.0000</p></td><td colspan="1" rowspan="1" colwidth="98"><p>1.0000</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>100</p></td><td colspan="1" rowspan="1" colwidth="85"><p>98.67%</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.9870</p></td><td colspan="1" rowspan="1" colwidth="92"><p>0.9867</p></td><td colspan="1" rowspan="1" colwidth="98"><p>0.9867</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>250</p></td><td colspan="1" rowspan="1" colwidth="85"><p>90.01%</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.9170</p></td><td colspan="1" rowspan="1" colwidth="92"><p>0.9000</p></td><td colspan="1" rowspan="1" colwidth="98"><p>0.9000</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="111"><p>500</p></td><td colspan="1" rowspan="1" colwidth="85"><p>80.16%</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.8598</p></td><td colspan="1" rowspan="1" colwidth="92"><p>0.8000</p></td><td colspan="1" rowspan="1" colwidth="98"><p>0.7919</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Recall, also known as sensitivity or true positive rate. Therefore, high recall indicates that there are few false negatives, meaning the classifier successfully identifies most of the actual positive instances. The recall of the model is given by:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mlwmx6j9lj">
                <mml:mrow>
                  <mml:mi>R</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>a</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>P</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>N</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The F1-score is the harmonic mean of precision and recall. The F1-score is useful when precision and recall need to be balanced. It gives a better measure of the classifier’s performance when there is an uneven class distribution. The F1-score of the model is given by:</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mxs3drlycf">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mi>S</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mn>1</mml:mn>
                  <mml:mn>2</mml:mn>
                  <mml:mo>=</mml:mo>
                  <mml:mo>×</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi>P</mml:mi>
                        <mml:mi>r</mml:mi>
                        <mml:mi>e</mml:mi>
                        <mml:mi>c</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>s</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>o</mml:mi>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>R</mml:mi>
                        <mml:mi>e</mml:mi>
                        <mml:mi>c</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>l</mml:mi>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                      <mml:mo>×</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi>P</mml:mi>
                        <mml:mi>r</mml:mi>
                        <mml:mi>e</mml:mi>
                        <mml:mi>c</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>s</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>o</mml:mi>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>R</mml:mi>
                        <mml:mi>e</mml:mi>
                        <mml:mi>c</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>l</mml:mi>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The SVM model demonstrated impeccable performance with 50 nodes. The model seems to be quite effective at this size, based on the perfect scores for all criteria, perhaps because the volume and complexity of the data are manageable. The model continued to function quite well at 100 nodes, despite a minor decline in accuracy and other measures that point to a slight rise in complexity. The model continued to identify positive events with low mistake rates. The model’s performance started to dramatically deteriorate after 250 nodes. The SVM’s capacity to retain high accuracy was put to the test by the volume and complexity of the additional data. Although recall and accuracy remained good, they exhibited a significant decline, which is indicative of the growing challenge of class distinction. With 500 nodes, the SVM model faced considerable challenges in maintaining performance. The complexity and volume of data likely introduced significant variability, leading to increased false positives and false negatives.</p><p>The SVM classifier’s performance metrics show how effective it is at smaller sizes (between 50 and 100 nodes), when it attains almost flawless accuracy. Nevertheless, the classifier’s efficiency decreases with increasing node count, suggesting difficulties with bigger and more complicated datasets. This pattern emphasizes how crucial it is to take scalability into account when developing and implementing AI models. In order to effectively manage the increasing data complexity and sustain good performance over greater datasets, future study may require investigating more sophisticated methods or hybrid models.</p><p>The SVM classifier’s performance is shown in <xref ref-type="fig" rid="fig_7">Figure 7</xref>. Classification benefits greatly from the use of SVMs, especially when there is a distinct margin of difference between classes. They perform well on smaller datasets with distinct class separations, attaining excellent recall, accuracy, precision, and F1-scores. SVMs are good for smaller datasets with a large number of features since they also perform well in high-dimensional spaces when the number of dimensions is greater than the that of samples. By enabling the method to handle non-linearly separable data by transferring it to a higher-dimensional space, the kernel technique improves the flexibility of SVM and improves its performance on complicated datasets. However, SVM performance may suffer as dataset size and complexity rise because of scaling problems and the growing challenge of identifying the ideal hyperplane.</p>
          
            <fig id="fig_7">
              <label>Figure 7</label>
              <caption>
                <title>Precision, recall, and F1-score for the SVM across different node counts</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_e1eiEHVgmd0UFDJC.png"/>
            </fig>
          
          
            <fig id="fig_8">
              <label>Figure 8</label>
              <caption>
                <title>Macro-averaged precision, recall, and F1-score for CNN across different node counts</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_FUp5d5sgODO-u1Q8.png"/>
            </fig>
          
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>Performance metrics of the CNN model for different node counts</title>
              </caption>
              <table><tbody><tr><th colspan="5" rowspan="1" colwidth="106,123,93,88,85"><p>Performance Metrics for CNN</p></th></tr><tr><td colspan="1" rowspan="1" colwidth="106"><p>No. of Nodes</p></td><td colspan="1" rowspan="1" colwidth="123"><p>Accuracy</p></td><td colspan="1" rowspan="1" colwidth="93"><p>Precision</p></td><td colspan="1" rowspan="1" colwidth="88"><p>Recall</p></td><td colspan="1" rowspan="1" colwidth="85"><p>F1-score</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="106"><p>50</p></td><td colspan="1" rowspan="1" colwidth="123"><p>100.00%</p></td><td colspan="1" rowspan="1" colwidth="93"><p>1.0000</p></td><td colspan="1" rowspan="1" colwidth="88"><p>1.0000</p></td><td colspan="1" rowspan="1" colwidth="85"><p>1.0000</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="106"><p>100</p></td><td colspan="1" rowspan="1" colwidth="123"><p>99.33%</p></td><td colspan="1" rowspan="1" colwidth="93"><p>0.9934</p></td><td colspan="1" rowspan="1" colwidth="88"><p>0.9933</p></td><td colspan="1" rowspan="1" colwidth="85"><p>0.9934</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="106"><p>250</p></td><td colspan="1" rowspan="1" colwidth="123"><p>89.75%</p></td><td colspan="1" rowspan="1" colwidth="93"><p>0.9149</p></td><td colspan="1" rowspan="1" colwidth="88"><p>0.8974</p></td><td colspan="1" rowspan="1" colwidth="85"><p>0.8964</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="106"><p>500</p></td><td colspan="1" rowspan="1" colwidth="123"><p>81.19%</p></td><td colspan="1" rowspan="1" colwidth="93"><p>0.8635</p></td><td colspan="1" rowspan="1" colwidth="88"><p>0.8117</p></td><td colspan="1" rowspan="1" colwidth="85"><p>0.8049</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The performance metrics of the CNN classifier tested on datasets with different node counts are shown in <xref ref-type="table" rid="table_5">Table 5</xref>. The four main performance indicators for classifiers are F1-Score, recall, accuracy, and precision. CNNs are appropriate for intricate network patterns, such as those from attacked MANETs, since they can extract pertinent characteristics from raw input data. While pooling layers lower spatial dimensions and manage overfitting, convolutional layers use filters to identify different patterns. CNNs are versatile and potent because fully connected layers include convolutional information for classification. These metrics offer a thorough assessment of the performance of the classifier at various data sizes.</p><p>CNNs have more manageable complexity, clearer separation of classes, and lower computational load with smaller dataset sizes. Since they contain fewer nodes, instances and class boundaries, this assists the model with collecting and employing the properties of the network. In addition, they also lend the higher accuracy, precision, recall and F1-scores due to the demand for less computing power during training and inference in much smaller datasets. In contrast, the inclusion of more nodes introduces noise into the data, resulting in class overlap. This impairs the model’s ability to learn efficient patterns, ultimately leading to reduced accuracy and making CNNs more challenging to optimize. When CNNs overfit the training set, they run the risk of overfitting, which results in subpar generalization on fresh data. In addition, the large datasets take a lot of memory, processing power, and time to train on. This might result in less-than-ideal training, slower convergence times, and worse performance. When the dataset is big and complicated, CNNs may find it difficult to identify global patterns, which lowers performance metrics like accuracy, recall, and F1-score, as seen in <xref ref-type="fig" rid="fig_8">Figure 8</xref>.</p><p>The DT classifier’s performance characteristics, tested on datasets with different node counts, are shown in <xref ref-type="table" rid="table_6">Table 6</xref>. Accuracy, precision, recall, and F1-score are the key metrics that were determined. These metrics offer a thorough assessment of the classifier’s effectiveness at various data sizes. DT models are commonly utilized for classification and regression applications due to their power and intuitiveness. They generate a DT-like model by iteratively dividing the data into subsets according to feature values. However, depending on the amount and complexity of the information, DT performance might vary greatly. Features taken from a MANET in both normal and attack settings make up the data in this context. Accuracy, precision, recall, and F1-score are the primary metrics disclosed. These metrics provide a comprehensive evaluation of the classifier’s performance across different scales of data.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Performance metrics of the DT model for different node counts</title>
              </caption>
              <table><tbody><tr><th colspan="5" rowspan="1" colwidth="116,102,110,87,100"><p>Performance Metrics for DT</p></th></tr><tr><td colspan="1" rowspan="1" colwidth="116"><p>No. of Nodes</p></td><td colspan="1" rowspan="1" colwidth="102"><p>Accuracy</p></td><td colspan="1" rowspan="1" colwidth="110"><p>Precision</p></td><td colspan="1" rowspan="1" colwidth="87"><p>Recall</p></td><td colspan="1" rowspan="1" colwidth="100"><p>F1-score</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="116"><p>50</p></td><td colspan="1" rowspan="1" colwidth="102"><p>99.33%</p></td><td colspan="1" rowspan="1" colwidth="110"><p>0.9930</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.9935</p></td><td colspan="1" rowspan="1" colwidth="100"><p>0.9932</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="116"><p>100</p></td><td colspan="1" rowspan="1" colwidth="102"><p>98.33%</p></td><td colspan="1" rowspan="1" colwidth="110"><p>0.9830</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.9835</p></td><td colspan="1" rowspan="1" colwidth="100"><p>0.9832</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="116"><p>250</p></td><td colspan="1" rowspan="1" colwidth="102"><p>91.70%</p></td><td colspan="1" rowspan="1" colwidth="110"><p>0.9170</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.9170</p></td><td colspan="1" rowspan="1" colwidth="100"><p>0.9170</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="116"><p>500</p></td><td colspan="1" rowspan="1" colwidth="102"><p>79.62%</p></td><td colspan="1" rowspan="1" colwidth="110"><p>0.7960</p></td><td colspan="1" rowspan="1" colwidth="87"><p>0.7965</p></td><td colspan="1" rowspan="1" colwidth="100"><p>0.7962</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <fig id="fig_9">
              <label>Figure 9</label>
              <caption>
                <title>Macro-averaged precision, recall, and F1-score for DT across different node counts</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/1/img_2nTDCWhac-P36eLy.png"/>
            </fig>
          
          <p>Less complicated datasets allow effective data processing without overfitting. They also allow the DT to be easily fitted to lower noise data and have more clearly defined class limits which makes it easier to draw cutoffs of the classes. In addition, since the shallow tree is able to solve the unknown datatypes and is also a good generalizer, a lesser number of data points reduces the chance of model overfitting. The complexity of the data goes up with the increase in the count of the nodes, which makes it even harder for DTs to learn the optimal splits while increasing the number of misclassifications. When the depth of the tree goes up, the possibility of overfitting also goes up, which means bad generalization on unseen data. Datasets that are large for DTs are completely efficient since the increase in computing costs leads to inefficiencies and poor performance. The more complicated the dataset, the more complex the decision boundaries become, making it harder for DTs to capture, which in turn cause the decrease in the accuracy, a precision, recall and F1-score to decrease, as shown in <xref ref-type="fig" rid="fig_9">Figure 9</xref>.</p>
        </sec>
      
      
        <sec>
          
            <title>5.3. Discussion</title>
          
          <p>The experimental findings show how well the suggested AI models—SVM, CNN, and DT—detect blackhole assaults in a range of network setups. Important findings from the analysis consist of the following:</p><p>• High accuracy: For smaller node counts (50 and 100 nodes), the CNN and SVM models achieve almost 100% accuracy, showing their ability to correctly classify network traffic as malicious or benign.</p><p>• Scalability: The models continue to function at a high level even when the accuracy marginally drops as the number of nodes rises. This implies that the models are scalable to bigger networks, albeit networks with more nodes could need further optimization.</p><p>• Robustness: The models can withstand changing blackhole assault tactics, adjust to novel patterns, and guarantee a high detection rate.</p><p>• Comparison with traditional methods: The AI models outperform traditional detection methods in terms of accuracy, precision, recall, and F1-score, highlighting the potential of AI-based approaches in enhancing network security.</p><p style="text-align: justify">The conventional RWR systems have limitations in accurately identifying emitters due to their geometric-based rules, which cannot capture temporal dependencies in adversary networks. This study introduces machine learning models such as SVM, CNN, and DT to improve accuracy and efficiency. These data-driven methods use data insights and feature pattern recognition to differentiate between packet loss due to ordinary circumstances and attacks. The SVM model demonstrated 98.67% precision and 98.33% recall, particularly in cases with 100 nodes.</p><p style="text-align: justify">However, these models struggle in dense scenarios with higher rate of overlaps and dynamic factors, resulting in increased misidentification and processing times. This suggests the need for better feature extraction methods, larger databases, superior AI techniques, and online learning to function under high radar density. The study assumes random distribution of nodes, arbitrary blackhole attack behavior, and optimal communication environment. Implementation in real settings is challenging due to non-ideal assumptions such as signal overlapping in crowded regions, large system dimensions, and decreased efficiency in noisy or dynamic environments.</p><p>To overcome these limitations, future work could focus on building new datasets, setting noisy and interfered conditions, developing improved machine learning techniques, and testing the effectiveness of the proposed model in a MANET environment. These steps aim to enhance the reliability and feasibility of implementing these solutions in practical applications, addressing the drawbacks of classical RWR systems and real-world challenges.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Conclusion</title>
      <p>This study presents AI as a strong tool for tackling the issue of blackhole attacks, highlighting the efficiency of models like CNN and SVM which are better than existing methods and provide accuracy, precision, recall and F1-score. The results underline how these AI-based approaches can be of better use for enhancing the network security frameworks by providing accurate and adaptive solutions for detection.</p><p>AI has significantly accelerated the progress in the sphere of network security, developing novel solutions for the detection and preventing blackhole attacks. It has also become customary to define AI models with great significance in the modern cybersecurity landscape as they learn from data, identify emerging patterns and provide detection in real time.</p><p>These models can be integrated with an IDS to enable real-time or dynamic detection of attacks. Their adaptability and efficiency make them suitable for identifying malicious activities as they occur, enhancing the system’s ability to respond promptly to evolving threats.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>113</volume>
          <page-range>189-222</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Salam</surname>
              <given-names>Taspia</given-names>
            </name>
            <name>
              <surname>Hossen</surname>
              <given-names>Md Sharif</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11277-020-07185-6</pub-id>
          <article-title>Performance analysis on homogeneous LEACH and EAMMH protocols in wireless sensor network</article-title>
          <source>Wirel. Pers. Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>108</volume>
          <page-range>839-851</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hossen</surname>
              <given-names>Md Sharif</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11277-019-06431-w</pub-id>
          <article-title>DTN routing protocols on two distinct geographical regions in an opportunistic network: An analysis</article-title>
          <source>Wirel. Pers. Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>218</volume>
          <page-range>2309-2318</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shafi</surname>
              <given-names>Shaik</given-names>
            </name>
            <name>
              <surname>Mounika</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Velliangiri</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.procs.2023.01.206</pub-id>
          <article-title>Machine learning and trust based AODV routing protocol to mitigate flooding and blackhole attacks in MANET</article-title>
          <source>Procedia Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Gotti</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Polagani</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Posina</surname>
              <given-names>G. S. L.</given-names>
            </name>
            <name>
              <surname>Veerapaneni</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Prasanth</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Detection and analysis of single blackhole node with TCP connection in MANETs using machine learning algorithms</article-title>
          <source>2023 International Conference on Inventive Computation Technologies (ICICT), Lalitpur, Nepal</source>
          <year>2023</year>
          <page-range>1704-1710</page-range>
          <pub-id pub-id-type="doi">10.1109/ICICT57646.2023.10134058</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1956</page-range>
          <issue>9</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eltahlawy</surname>
              <given-names>Ahmed M</given-names>
            </name>
            <name>
              <surname>Aslan</surname>
              <given-names>Heba K</given-names>
            </name>
            <name>
              <surname>Abdallah</surname>
              <given-names>Eslam G</given-names>
            </name>
            <name>
              <surname>Elsayed</surname>
              <given-names>Mahmoud Said</given-names>
            </name>
            <name>
              <surname>Jurcut</surname>
              <given-names>Anca D</given-names>
            </name>
            <name>
              <surname>Azer</surname>
              <given-names>Marianne A</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/electronics12091956</pub-id>
          <article-title>A survey on parameters affecting MANET performance</article-title>
          <source>Electron.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>412</volume>
          <page-range>01094</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Moumen</surname>
              <given-names>Idriss</given-names>
            </name>
            <name>
              <surname>Rafalia</surname>
              <given-names>Najat</given-names>
            </name>
            <name>
              <surname>Abouchabaka</surname>
              <given-names>Jaafar</given-names>
            </name>
            <name>
              <surname>Chatoui</surname>
              <given-names>Youssef</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1051/e3sconf/202341201094</pub-id>
          <article-title>AODV-based defense mechanism for mitigating blackhole attacks in MANET</article-title>
          <source>E3S Web Conf.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Hameed</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Al-Omary</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Survey of blackhole attack on MANET</article-title>
          <source>2nd Smart Cities Symposium (SCS 2019)</source>
          <year>2019</year>
          <pub-id pub-id-type="doi">10.1049/cp.2019.0224</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>658-672</page-range>
          <issue>4</issue>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Djahel</surname>
              <given-names>Soufiene</given-names>
            </name>
            <name>
              <surname>Nait-Abdesselam</surname>
              <given-names>Farid</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Zong Hua</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/SURV.2011.072210.0002</pub-id>
          <article-title>Mitigating packet dropping problem in mobile ad hoc networks: Proposals and challenges</article-title>
          <source>IEEE Commun. Surv. Tutorials</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>60-75</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ibrahim</surname>
              <given-names>Zainab Bashar</given-names>
            </name>
            <name>
              <surname>Ghanim</surname>
              <given-names>Mayada Faris</given-names>
            </name>
          </person-group>
          <article-title>A review of AI-based approaches against wormhole and blackhole attacks in AODV protocol</article-title>
          <source>Int. J. Adv. Nat. Sci. Eng. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Sarker</surname>
              <given-names>Iqbal H</given-names>
            </name>
          </person-group>
          <source>AI-Driven Cybersecurity and Threat Intelligence: Cyber Automation, Intelligent Decision-Making and Explainability</source>
          <publisher-name>Springer</publisher-name>
          <year>2024</year>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <issue>3</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Alalwan</surname>
              <given-names>Jaffar Ahmad Abdulkarim</given-names>
            </name>
          </person-group>
          <article-title>Roles and challenges of AI-based cybersecurity: A case study</article-title>
          <source>Jordan J. Bus. Admin.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>77</volume>
          <page-range>7718-7736</page-range>
          <issue>7</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Khalladi</surname>
              <given-names>Rachid</given-names>
            </name>
            <name>
              <surname>Rebbah</surname>
              <given-names>Mohammed</given-names>
            </name>
            <name>
              <surname>Smail</surname>
              <given-names>Omar</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11227-020-03596-1</pub-id>
          <article-title>A new efficient approach for detecting single and multiple black hole attacks</article-title>
          <source>J. Supercomput.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>2021</volume>
          <page-range>6693316</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Talukdar</surname>
              <given-names>Md Ibrahim</given-names>
            </name>
            <name>
              <surname>Hassan</surname>
              <given-names>Rosilah</given-names>
            </name>
            <name>
              <surname>Hossen</surname>
              <given-names>Md Sharif</given-names>
            </name>
            <name>
              <surname>Ahmad</surname>
              <given-names>Khaleel</given-names>
            </name>
            <name>
              <surname>Qamar</surname>
              <given-names>Faizan</given-names>
            </name>
            <name>
              <surname>Ahmed</surname>
              <given-names>Amjed Sid</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2021/6693316</pub-id>
          <article-title>Performance improvements of AODV by black hole attack detection using IDS and digital signature</article-title>
          <source>Wirel. Commun. Mob. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>48</volume>
          <page-range>190</page-range>
          <issue>4</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mankotia</surname>
              <given-names>Vivek</given-names>
            </name>
            <name>
              <surname>Sunkaria</surname>
              <given-names>Ramesh Kumar</given-names>
            </name>
            <name>
              <surname>Gurung</surname>
              <given-names>Shashi</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s12046-023-02227-8</pub-id>
          <article-title>DT-AODV: A dynamic threshold protocol against black-hole attack in MANET</article-title>
          <source>Sādhanā</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>263</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kaushik</surname>
              <given-names>Sheetal</given-names>
            </name>
            <name>
              <surname>Tripathi</surname>
              <given-names>Khushboo</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>Rashmi</given-names>
            </name>
            <name>
              <surname>Mahajan</surname>
              <given-names>Prerna</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s42979-023-02585-4</pub-id>
          <article-title>Enhancing reliability in mobile ad hoc networks (MANETs) through the K-AOMDV routing protocol to mitigate black hole attacks</article-title>
          <source>SN Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>15101-15111</page-range>
          <issue>18</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rani</surname>
              <given-names>Pooja</given-names>
            </name>
            <name>
              <surname>Kavita</surname>
            </name>
            <name>
              <surname>Verma</surname>
              <given-names>Sahil</given-names>
            </name>
            <name>
              <surname>Rawat</surname>
              <given-names>Danda B</given-names>
            </name>
            <name>
              <surname>Dash</surname>
              <given-names>Sonali</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s00521-022-06946-7</pub-id>
          <article-title>Mitigation of black hole attacks using firefly and artificial neural network</article-title>
          <source>Neural Comput. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>33789-33795</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahmad</surname>
              <given-names>Iftikhar</given-names>
            </name>
            <name>
              <surname>Basheri</surname>
              <given-names>Mohammad</given-names>
            </name>
            <name>
              <surname>Iqbal</surname>
              <given-names>Muhammad Javed</given-names>
            </name>
            <name>
              <surname>Rahim</surname>
              <given-names>Aneel</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2841987</pub-id>
          <article-title>Performance comparison of support vector machine, random forest, and extreme learning machine for intrusion detection</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>273-297</page-range>
          <year>1995</year>
          <person-group person-group-type="author">
            <name>
              <surname>Cortes</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Vapnik</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Support-vector networks</article-title>
          <source>Mach. Learn.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Li</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>Chun Hua</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>Jian Ping</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Guo Dong</given-names>
            </name>
          </person-group>
          <article-title>Network intrusion detection using support vector machine based on particle swarm optimization</article-title>
          <source>2015 International conference on Applied Science and Engineering Innovation</source>
          <publisher-name>Atlantis Press</publisher-name>
          <year>2015</year>
          <page-range>665-670</page-range>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Vinayakumar</surname>
              <given-names>Ravi</given-names>
            </name>
            <name>
              <surname>Soman</surname>
              <given-names>KP</given-names>
            </name>
            <name>
              <surname>Poornachandran</surname>
              <given-names>Prabaharan</given-names>
            </name>
          </person-group>
          <article-title>Applying deep learning approaches for network traffic prediction</article-title>
          <source>2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI), Udupi, India</source>
          <year>2017</year>
          <page-range>2353-2358</page-range>
          <pub-id pub-id-type="doi">10.1109/ICACCI.2017.8126198</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>376-381</page-range>
          <issue>5</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pathak</surname>
              <given-names>Ashwini</given-names>
            </name>
            <name>
              <surname>Pathak</surname>
              <given-names>Sakshi</given-names>
            </name>
          </person-group>
          <article-title>Study on decision tree and KNN algorithm for intrusion detection system</article-title>
          <source>Int. J. Eng. Res. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>251</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rani</surname>
              <given-names>Pooja</given-names>
            </name>
            <name>
              <surname>Kavita</surname>
            </name>
            <name>
              <surname>Verma</surname>
              <given-names>Sahil</given-names>
            </name>
            <name>
              <surname>Kaur</surname>
              <given-names>Navneet</given-names>
            </name>
            <name>
              <surname>Wozniak</surname>
              <given-names>Marcin</given-names>
            </name>
            <name>
              <surname>Shafi</surname>
              <given-names>Jana</given-names>
            </name>
            <name>
              <surname>Ijaz</surname>
              <given-names>Muhammad Fazal</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s22010251</pub-id>
          <article-title>Robust and secure data transmission using artificial intelligence techniques in Ad-hoc networks</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kocher</surname>
              <given-names>Geeta</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>Gulshan</given-names>
            </name>
          </person-group>
          <article-title>Analysis of machine learning algorithms with feature selection for intrusion detection using UNSW-NB15 dataset</article-title>
          <source>Int. J. Netw. Secur. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <issue>12</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sivanesan</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Archana</surname>
              <given-names>K. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.14569/IJACSA.2022.0131262</pub-id>
          <article-title>Performance analysis of machine learning-based detection of sinkhole network layer attack in MANET</article-title>
          <source>Int. J. Adv. Comput. Sci. Appl. (IJACSA)</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>1153-1176</page-range>
          <issue>2</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Buczak</surname>
              <given-names>Anna L</given-names>
            </name>
            <name>
              <surname>Guven</surname>
              <given-names>Erhan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/COMST.2015.2494502</pub-id>
          <article-title>A survey of data mining and machine learning methods for cyber security intrusion detection</article-title>
          <source>IEEE Commun. Surv. Tutor.</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>233-252</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Al-Turaiki</surname>
              <given-names>Isra</given-names>
            </name>
            <name>
              <surname>Altwaijry</surname>
              <given-names>Najwa</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1089/big.2020.0263</pub-id>
          <article-title>A convolutional neural network for improved anomaly-based network intrusion detection</article-title>
          <source>Big Data</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>100013</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ibrahim</surname>
              <given-names>Mariam</given-names>
            </name>
            <name>
              <surname>Elhafiz</surname>
              <given-names>Ruba</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.jer.2023.100013</pub-id>
          <article-title>Modeling an intrusion detection using recurrent neural networks</article-title>
          <source>J. Eng. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Norbu</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ramanathan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Dolkar</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>others</surname>
            </name>
          </person-group>
          <article-title>Advancing IoT security with a hybrid deep learning model for network intrusion detection</article-title>
          <source>2023 International Conference on Energy, Materials and Communication Engineering (ICEMCE), Madurai, India</source>
          <year>2023</year>
          <page-range>1-6</page-range>
          <pub-id pub-id-type="doi">10.1109/ICEMCE57940.2023.10434006</pub-id>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>