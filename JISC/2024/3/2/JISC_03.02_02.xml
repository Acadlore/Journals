<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JISC</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Journal of Intelligent Systems and Control</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Intell Syst. Control</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JISC</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9813</issn>
      <issn publication-format="print">2957-9805</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-4vrmtXpgRkmaXvkIeQwLVz6uuXtf235I</article-id>
      <article-id pub-id-type="doi">10.56578/jisc030202</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Evaluating the Usability and Effectiveness of a Special Education Campus Navigation System for Students with Visual Impairment</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-1501-3328</contrib-id>
          <name>
            <surname>Olaleye</surname>
            <given-names>Solomon Babatunde</given-names>
          </name>
          <email>olaleye.solomon1115@fcesoyo.edu.ng</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0009-9353-1460</contrib-id>
          <name>
            <surname>Adebiyi</surname>
            <given-names>Benedictus Adekunle</given-names>
          </name>
          <email>kunleodunbiyi@yahoo.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4370-3737</contrib-id>
          <name>
            <surname>Abdulsalaam</surname>
            <given-names>Aminat</given-names>
          </name>
          <email>abdul-salaam.aminat1070@fcesoyo.edu.ng</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-0531-6743</contrib-id>
          <name>
            <surname>Nwosu</surname>
            <given-names>Florence Chika</given-names>
          </name>
          <email>nwosu.fc@unilorin.edu.ng</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_4">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-5642-1308</contrib-id>
          <name>
            <surname>Adeyanju</surname>
            <given-names>Abosede Olayinka</given-names>
          </name>
          <email>adeyanjuabosede73@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_5">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-1331-9294</contrib-id>
          <name>
            <surname>Ambi</surname>
            <given-names>Hassana Mamman</given-names>
          </name>
          <email>hassanaamb222@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_6">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-8878-1272</contrib-id>
          <name>
            <surname>Omolayo</surname>
            <given-names>Clement</given-names>
          </name>
          <email>technoclem@gmail.com</email>
        </contrib>
        <aff id="aff_1">Department of Computer Science, Federal College of Education (Special), 211102 Oyo, Nigeria</aff>
        <aff id="aff_2">Department of Education for Learners with Visual Impairment, Federal College of Education (Special), 211102 Oyo, Nigeria</aff>
        <aff id="aff_3">Department of Linguistics and Nigerian Languages, University of Ilorin, 240003 Ilorin, Nigeria</aff>
        <aff id="aff_4">Department of Yoruba Language, Emmanuel Alayande College of Education, 211101 Oyo, Nigeria</aff>
        <aff id="aff_5">Department of Hausa, Federal College of Education (Special), 211102 Oyo, Nigeria</aff>
        <aff id="aff_6">Management Information System Unit, Federal College of Education (Special), 211102 Oyo, Nigeria</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>29</day>
        <month>06</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>2</issue>
      <fpage>84</fpage>
      <lpage>92</lpage>
      <page-range>84-92</page-range>
      <history>
        <date date-type="received">
          <day>15</day>
          <month>03</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>19</day>
          <month>06</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>This study evaluates the usability and effectiveness of a newly developed special education (SPED) campus navigation system designed for students with visual impairment (SVI) at the Federal College of Education (Special), Oyo, Oyo State, Nigeria. The primary objective was to assess the system's capability to facilitate self-navigation for SVI and identify challenges encountered in a campus environment. A mixed-methods approach, combining quantitative data from questionnaires and qualitative insights from interviews, was employed. Twenty SVI, selected through purposive sampling, participated in the study, using the system over a five-week period. The findings indicate significant improvements in the orientation and mobility of SVI, resulting in increased confidence in navigating the campus. Participants reported that the navigation system effectively aided in locating key areas, detecting obstacles, and ensuring safety. However, several critical challenges were identified, such as the system's voice being drowned out in noisy environments and the frequent need for battery recharging every five days. Participants suggested enhancements, including the incorporation of volume control to accommodate various environmental conditions and regular device charging to prevent battery depletion. These improvements are deemed essential for enhancing the system's reliability and usability for SVI.</p></abstract>
      <kwd-group>
        <kwd>Special education navigation system</kwd>
        <kwd>Visual impairment</kwd>
        <kwd>Special education campus</kwd>
        <kwd>Orientation</kwd>
        <kwd>Blind mobility</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="7"/>
        <fig-count count="6"/>
        <table-count count="1"/>
        <ref-count count="32"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>As published by the World Health Organization (WHO), approximately 2.2 billion people in the world have some form of visual impairment (VI) [<xref ref-type="bibr" rid="ref_1">1</xref>]. It should be noted that, out of all the tertiary institutions of higher learning that accommodate SVI, the most populated institution in this category is the Federal College of Education (Special), Oyo. Consequently, movement in such a typical college presents immense challenges to SVI. Large educational campuses use traditional navigation aids, namely common white canes, human guides, tactile maps and guide dogs, to aid SVI movement on their campuses. Nevertheless, technology improvement has brought about the imagining of a SPED campus navigation system, which improves the mobility of SVI. All the executives and members of the Nigeria Association of the Blind, Oyo State chapter, Nigeria, said they were interested and willing to support the research, emphasizing the necessity of the proposed SPED campus navigation system.</p><p>Effective navigation is a fundamental aspect of daily activities, including going to work and school, shopping, among others. There are few who would disagree that sight plays a very important role in the movement from one place to another. Familiar terrains like a bedroom or an office may easily be navigable even by a blind person; however, instructions on how to get from one new place to another largely pose a problem [<xref ref-type="bibr" rid="ref_2">2</xref>]. At the Federal College of Education (Special), Oyo, students with blindness rely on orientation and mobility skills acquired during their first semester in the 100-level course. These skills assist them in nurturing the ideal competent knowledge needed for the performance of safe and efficient mobility within the campus. Orientation involves understanding one's current location and intended destination, whether moving from one section of the college to another or locating a lecture room. However, mobility is defined in relation to the safe and efficient movement across places. It comprises moving around their hostel without tripping, how to safely walk across the streets within the campus, and ensuring efficiency when using public transport [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>]. The Federal College of Education (Special), Oyo, was chosen for the research field testing because it happens to be the only college of education with the largest concentration of SVI in Nigeria. This college was established on October 5, 1977, and is the only one of its kind in Nigeria and Sub-Saharan Africa, dedicated to training professionals to support individuals with various disabilities.</p><p>This study aims to assess a SPED campus navigation system that was designed for SVI at the Federal College of Education (Special), Oyo. Prior to the main research, a pilot study [<xref ref-type="bibr" rid="ref_5">5</xref>] was carried out on six SVI that were available and willingly selected. The pilot study focuses on a small portion of a larger future project. That is, it is a small-scale project to decide whether to launch a full-scale project. The creation of a novel supportive product, namely smart walking stick, equipped with a Global Positioning System (GPS) and voice directions, was described in this study. The desirable and culturally sensitive talking tool uses a voice command option with the accent of an indigenous Nigerian language. Focusing on the mobility concerns of SVI, especially those of the Federal College of Education (Special), Oyo State, Nigeria, usability testing and field performance evaluations of the device were conducted in this study, which demonstrated its effectiveness in assisting the SVI with navigation. The inclusion of GPS for precise location tracking and voice directions offers users greater flexibility and comfort during navigation [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>]. This study evaluates the developed SPED campus navigation system for SVI based on three research questions raised and answered through questionnaires, interviews and field experiences of users. Subsequent sections include related work, research questions, the methodology adopted, results of the work, discussion of findings, conclusions, and recommendations.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related work</title>
      <p>A mobile digital map can address many of the navigation challenges faced by individuals with VI. The digital map communicates with users through three primary methods: speech, vibration, and sound. The model features simple visuals and primarily uses speech to explain the content. It was evaluated using usability tests, which demonstrated its significant impact on users, who were supportive of map parts. Participants offered several suggestions to enhance usability, such as incorporating GPS to pinpoint the user's location [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>Many blind people rely on technology to perform their daily activities. These technologies are made-up devices that combine sensors, buzzers, speakers, software, etc. that can assist the blind in their daily routines [<xref ref-type="bibr" rid="ref_9">9</xref>]. A key challenge associated with such technologies is their usability, as blind individuals may struggle to use them due to unfamiliarity [<xref ref-type="bibr" rid="ref_10">10</xref>]. Several researchers highlighted three tools: a smart stick that notifies users of obstacles and aids in task performance [<xref ref-type="bibr" rid="ref_11">11</xref>], and an eye device designed to detect colors (pending medical evaluation) [<xref ref-type="bibr" rid="ref_12">12</xref>]. In addition, Griffin-Shirley et al. [<xref ref-type="bibr" rid="ref_13">13</xref>] aimed to understand how blind individuals use mobile devices to perceive the accessibility of their environment. The results of an online survey of 259 participants revealed that most participants found these applications useful, accessible, and satisfactory.</p><p>Individuals with VI often require guidance to travel or move into a new environment. To address this, Gintner et al. [<xref ref-type="bibr" rid="ref_14">14</xref>] designed a system that guides individuals with VI using geographical features and a technology device that translates text to voice. The system was evaluated using six individuals with VI, and the results indicated positive feedback regarding its accessibility and usability. Parker et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] described wayfinding devices for blind indoor and outdoor navigation. The investigation revealed participants’ characteristics in real-world environments. The results showed that smart technologies greatly assisted the blind during indoor and outdoor navigation. Several researchers used mixed methods to assess the effectiveness of smart technologies for blind movement [<xref ref-type="bibr" rid="ref_16">16</xref>], [<xref ref-type="bibr" rid="ref_17">17</xref>], [<xref ref-type="bibr" rid="ref_18">18</xref>], [<xref ref-type="bibr" rid="ref_19">19</xref>].</p><p>Shera et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] used a user-centred approach to assess the designed device for blind navigation. The use of both qualitative and quantitative data in the investigation aimed at assisting in establishing the best research approach. The process of the user-centred approach involved elements like sampling, developing prototypes, user experience, and general evaluation. A checklist was used to address and report substantive concerns about the study, highlighting the experiences of blind users. Based on this paradigm, parameters concerning blind users were validated, such as effectiveness, satisfaction, and efficiency. Totally, ten self-generated questions were posed to the blind participants following the task, and the post-task assessments were based on a Likert scale. The assessment benchmarks included above-average, set at 68; good, attributed to 72; and excellent, designated as 92 [<xref ref-type="bibr" rid="ref_21">21</xref>].</p><p>Messaoudi et al. [<xref ref-type="bibr" rid="ref_22">22</xref>] investigated various cellphone technologies designed for individuals with VI. After reviewing several assistive technology (AT) options, they suggested that future efforts should aim to integrate these tools into a cohesive system, providing comprehensive support for individuals with VI to navigate with ease like their sighted counterparts. They recommended producing a robust device that can provide optimal assistance and support for the blind. Several researchers [<xref ref-type="bibr" rid="ref_23">23</xref>], [<xref ref-type="bibr" rid="ref_24">24</xref>] further suggested the concept of using the smart cane navigation system, as shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>, which includes a camera, microcontrollers, and accelerometers that provide audio messages. It utilizes a cloud service to support blind navigation from one place to another. This system is primarily designed to assist individuals with VI in finding and following the shortest path. A smartly designed cane detects obstacles and uses a speaker to produce a sound within its intelligent system. Additionally, the cane assists in identifying whether the environment is dark or bright [<xref ref-type="bibr" rid="ref_24">24</xref>]. However, the concept was a proposal which was neither implemented in real life nor evaluated to determine how effective its functionalities were.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Smart cane navigation system [<xref ref-type="bibr" rid="ref_22">22</xref>]</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_1XoArhUqYwFlGnDi.png"/>
        </fig>
      
      <p>Numerous studies have explored various navigational systems designed to assist individuals with VI. Although most approaches are theoretically sound, they are excessively complicated or cumbersome in practice. Navigating through different environments is challenging for individuals with VI, who need to be aware of nearby objects and terrain. The inability to effectively navigate these situations negatively impacts their sense of freedom, limiting their ability to discover their way in new surroundings [<xref ref-type="bibr" rid="ref_22">22</xref>].</p><p>Several researchers [<xref ref-type="bibr" rid="ref_25">25</xref>], [<xref ref-type="bibr" rid="ref_26">26</xref>] reported that AT can assist blind navigation. However, many of these technologies face limitations regarding the human aspects of the user experience in terms of usability to evaluate their functionalities. Additionally, there are challenges in translating research models into real world solutions. According to Al-Ataby et al. [<xref ref-type="bibr" rid="ref_27">27</xref>], AT for blind navigation can be divided into two categories: traditional technology (such as eyeglasses and white canes) and mobile technology (such as blind navigation devices). Since individuals with VI face challenges with visually demanding devices, several researchers have explored alternative possibilities for AT development. Non-visual sensory modalities, such as speech recognition [<xref ref-type="bibr" rid="ref_28">28</xref>], text-to-speech [<xref ref-type="bibr" rid="ref_29">29</xref>], haptic feedback [<xref ref-type="bibr" rid="ref_30">30</xref>], multimodal feedback [<xref ref-type="bibr" rid="ref_31">31</xref>], and gesture identification [<xref ref-type="bibr" rid="ref_32">32</xref>], have been employed to make AT more accessible for individuals with VI. The usage of AT developed for individuals with VI is low because it was not evaluated for user experience. Therefore, any developed AT devices should be evaluated by the users (individuals with VI). The literature reviewed indicates that existing research predominantly focuses on ATs, which are foreign-based and feature foreign accents. In addition, there are no ATs with native accents. Hence, it is necessary to develop a SPED campus navigation system with a Nigerian accent to fill the identified research gap in a real-life scenario.</p>
    </sec>
    <sec sec-type="">
      <title>3. Research questions</title>
      <p>Three research questions were raised to evaluate the usability and effectiveness of a SPED campus navigation system for SVI at the Federal College of Education (Special), Oyo.</p><p>i. How does the SPED navigation system improve the daily campus mobility of SVI?</p><p>ii. What are the most common challenges faced by blind users when using the system?</p><p>iii. How can the challenges in the second research question be mitigated?</p>
    </sec>
    <sec sec-type="">
      <title>4. Methodology</title>
      <p>A pilot study was conducted prior to the main research, aiming to evaluate the initial usability and effectiveness of the SPED campus navigation system. The preliminary feedback helped the main research. After selecting six willing SVI, the pilot study was carried out for one week on the SPED campus. After being given adequate orientation on the usage of the device, the six participants were able to use the device, and their feedback and observatory issues were recorded and used to prepare for the main research. Questionnaires and interviews were used to collect feedback from those participants. The collected data were analysed qualitatively and quantitatively. The results significantly contributed to improvements in the device's voice functionality and the adjustment of the obstacle detection distance from 30 meters to 50 meters for the main study.</p><p>A mixed-methods approach was employed for the main research, involving quantitative surveys and qualitative interviews with the 20 SVI selected. A purposive sampling technique was used to select participants from various academic disciplines within the Federal College of Education (Special), Oyo. Participants were recruited through the college's SPED unit. Data were collected through a combination of questionnaires, field tests, and interviews. The surveys were carried out using pre-requirements and post-use of the developed device to assess participants' initial expectations and their experiences after using the device. For the field tests, the 20 participants were asked to navigate to predetermined locations on campus using the developed navigation system. Their routes, time taken, and difficulties encountered were recorded. In addition, semi-structured interviews were conducted to gather in-depth feedback on the device’s usability and effectiveness. The navigation device used can inform SVI about their locations. The integrated software announces this information at regular intervals as the user moves around the campus. The navigation device, which is called an object detection white cane, was utilized because SVI were accustomed to navigating with traditional white canes. The navigation system was developed using components such as a microcontroller, ultrasonic sensors, label surface detection, and a buzzer. Real-time obstacle detection was achieved through the embedded ultrasonic sensors, which identify the presence of obstacles. The collected data were recorded and analysed using simple percentages.</p><p><xref ref-type="fig" rid="fig_2">Figure 2</xref> shows the flowchart of the obstacle detection that was implemented in the real world. <xref ref-type="fig" rid="fig_3">Figure 3</xref> shows the flowchart of the Federal College of Education (Special), Oyo, as implemented. <xref ref-type="fig" rid="fig_4">Figure 4</xref> shows the coupled components consisting of an 8-GB memory card, a lithium-ion battery, a 5-watt speaker, an ultrasonic sensor, an Arduino nanomicro controller, a GPS antenna, etc. <xref ref-type="fig" rid="fig_5">Figure 5</xref> shows the SPED campus navigation system with the obstacle detection device during development, while <xref ref-type="fig" rid="fig_6">Figure 6</xref> shows the finished product of the SPED campus navigation system, which is ready for use. The device starts by putting on the switch button on the white box attached to the white cane (1 for ON and 0 for OFF).</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Flowchart of campus location</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_LfNBAlFLfcTpb6yg.png"/>
        </fig>
      
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Development of the SPED campus navigation system</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img__CSAz1HHkrNasB1g.png"/>
        </fig>
      
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>The finished SPED campus navigation system</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_4-FurgmLALm4ssgV.png"/>
        </fig>
      
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Development of the SPED campus navigation system</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_shte1_nL9dHC5qGY.png"/>
        </fig>
      
      
        <fig id="fig_6">
          <label>Figure 6</label>
          <caption>
            <title>The finished SPED campus navigation system</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/7/img_Z_qe2FVLLAsBSdMu.png"/>
        </fig>
      
      <p>Immediately after turning on the device, the written code in the Arduino microcontroller initializes and activates the GPS module, which is used to receive data from satellites. The GPS module provides location information and helps with real-time tracking. The GPS module is connected to the Arduino microcontroller through a Universal Asynchronous Receiver-Transmitter (UART) interface. The UART is a serial communication protocol that can be used to send data between an Arduino microcontroller and the GPS. The GPS receiver receives signals from satellites. These signals are in the National Marine Electronics Association (NMEA) format, and they contain location information in an American Standard Code for Information Interchange (ASCII) format. The Arduino microcontroller calculates the latitude and longitude obtained from the satellite and compares them to the threshold value stored in the database. If the calculated distance is less than or equal to the threshold value, the master controller gives a command to the slave controller, PIC18F4525, to activate the speaker to call out the location on campus. In addition, the device has the capacity to detect any obstacle within a range of 50 meters through the attached sensors [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>].</p>
    </sec>
    <sec sec-type="results">
      <title>5. Results</title>
      <p><xref ref-type="table" rid="table_1">Table 1</xref> shows the results of SVI’s experience with the developed SPED campus navigation system. The results show that 100% of the participants agreed the following: the navigation system is effective in identifying important places on campus; the device can easily identify obstacles while navigating on campus; they feel safe while using the navigation system on campus; the device has increased their independence on campus activities; and they are satisfied with the navigation system compared to other navigation aids they have used.</p><p>During the interviews with the 20 SVI, three challenges were mentioned.</p><p>i. When SVI used the system in a crowded environment, it was difficult for them to hear the system’s voice clearly.</p><p>ii. The battery was weak after five days.</p><p>iii. SVI wanted to know what could be done in case of any problems with the device.</p><p>To mitigate the challenges of the navigation system, several strategies can be implemented as follows:</p><p>i. A volume control function should be added to adjust the volume level, thereby meeting the users' needs.</p><p>ii. The device should be charged regularly to ensure its proper functionality.</p><p>iii. Support services should be offered to the SVI in a known centre to address maintenance issues promptly.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>SVI’s experience of the SPED campus navigation system</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>SN</p></td><td colspan="1" rowspan="1"><p>Item</p></td><td colspan="1" rowspan="1"><p>Yes (Quantity and Percentage)</p></td><td colspan="1" rowspan="1"><p>No (Quantity and Percentage)</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>Is the SPED campus navigation system effective in identifying important places on campus?</p></td><td colspan="1" rowspan="1"><p>20 (100%)</p></td><td colspan="1" rowspan="1"><p>0 (0%)</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>Can the device easily identify obstacles while navigating on campus?</p></td><td colspan="1" rowspan="1"><p>20 (100%)</p></td><td colspan="1" rowspan="1"><p>0 (0%)</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>Do you feel safe using the SPED campus navigation system on campus?</p></td><td colspan="1" rowspan="1"><p>20 (100%)</p></td><td colspan="1" rowspan="1"><p>0 (0%)</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>Has the SPED campus navigation system increased your independence in daily campus activities?</p></td><td colspan="1" rowspan="1"><p>20 (100%)</p></td><td colspan="1" rowspan="1"><p>0 (0%)</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>Are you satisfied with the SPED campus navigation system compared to other navigation aids you have used?</p></td><td colspan="1" rowspan="1"><p>20 (100%)</p></td><td colspan="1" rowspan="1"><p>0 (0%)</p></td></tr></tbody></table>
        </table-wrap>
      
    </sec>
    <sec sec-type="discussion">
      <title>6. Discussion</title>
      <p>The SPED campus navigation system shows great potential for enhancing the campus experience for SVI. Although the system effectively improves navigational independence and reduces anxiety, technical refinements and infrastructural improvements are necessary. The 20 SVI were trained for one day, which is sufficient for them to effectively use the system. Consistent feedback from users in terms of their experience enhanced the device’s reliability and functionality. For instance, during the field testing, there was no voice output from any of the devices. After checking, it was found that the speaker had stopped working. There was voice output after the speaker was replaced. In addition, two GPS modules did not output location information to SVI, but the sensors were working and could detect obstacles. After checking, it was found that the GPS modules were not properly fixed. During field testing, one of the devices fell down and the box was removed from the white cane. This issue was addressed by using adhesive to securely attach the device to the white cane.</p><p>According to the responses to the first research question, all the participants (SVI) supported the use of the SPED campus navigation system because it effectively identified important places and obstacles on campus. The participants further reported that they felt safe while using the navigation system and that the system increased their independence during campus activities. In addition, they were satisfied with the voice output during navigation compared to other navigation aids they had used. These results are consistent with several earlier studies [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>], [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>], [<xref ref-type="bibr" rid="ref_21">21</xref>], [<xref ref-type="bibr" rid="ref_22">22</xref>], [<xref ref-type="bibr" rid="ref_23">23</xref>], [<xref ref-type="bibr" rid="ref_25">25</xref>], [<xref ref-type="bibr" rid="ref_26">26</xref>], which reported that individuals with VI needed a smart stick to notify them of obstacles, aid in their navigation and provide instant feedback in real time. According to several studies [<xref ref-type="bibr" rid="ref_25">25</xref>], [<xref ref-type="bibr" rid="ref_32">32</xref>], usage of AT developed for individuals with VI was low because it was not evaluated by them for user experience. Hence, the AT should be evaluated by individuals with VI because they are the users. In view of this study, the developed SPED campus navigation system is an advancement in the field of AT, which enhances SVI navigation in Nigeria. The device is capable of assisting the SVI in identifying major places on campus as well as obstacles on their path.</p><p>As for the second research question, the 20 participants interviewed identified three primary challenges: difficulties in using the system in noisy environments, using the device's battery after five days of regular use, and a concern about device maintenance in case of malfunctions. The participants also suggested ways to mitigate these challenges. To address the noise issue, they recommended allowing users to adjust the volume to suit different noise levels. To handle the battery life problem, it was recommended to charge the device regularly. For maintenance issues, it was recommended to provide prompt support services to SVI to address any problems that arise. This method of evaluation was supported by the studies of several researchers [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>], [<xref ref-type="bibr" rid="ref_21">21</xref>], which enabled blind users to rate ATs to be used by them. The work of Griffin-Shirley et al. [<xref ref-type="bibr" rid="ref_13">13</xref>] was assessed using a survey that targeted 259 blind people online, while several researchers [<xref ref-type="bibr" rid="ref_20">20</xref>], [<xref ref-type="bibr" rid="ref_21">21</xref>] dealt with issues of assessing selected parameters concerning users with VI, posing ten questions to the participants.</p><p>The SPED campus navigation system cannot be used to identify locations outside the Federal College of Education (Special), Oyo, because it was specifically designed for SVI who are given admission to study at the college. However, the obstacle detection functionality of the device, which can successfully detect obstacles at a distance of 50 meters, is operational outside the college. In addition, to enable the device to identify locations outside its range, the longitude and latitude of the areas stored in the device’s database are needed.</p>
    </sec>
    <sec sec-type="conclusions">
      <title>7. Conclusions</title>
      <p>This study analyzed the effectiveness and ease of use of the SPED campus navigation system for SVI so as to determine the effectiveness of the AT. The findings confirm that the system enhances the freedom and maneuverability of SVI and subsequently helps them to navigate and function freely and optimistically in the Federal College of Education (Special), Oyo, Oyo State, Nigeria. Nevertheless, some specific restrictions were identified that should be addressed in future work for the tool to become more efficient. The limitations are as follows: The noisy environment on campus in one way or another limited the volume of the sounds produced by the speech output of the system. Another challenge is battery life because the system requires recharging after five days, based on average usage. Consequently, the implementation of the SPED campus navigation system greatly assisted the independent movement of SVI at the Federal College of Education (Special), Oyo, Oyo State, Nigeria.</p>
    </sec>
    <sec sec-type="">
      <title>8. Recommendations</title>
      <p>Therefore, in line with the assessment of the usability and effectiveness of the developed SPED campus navigation system for SVI, the following recommendations were made:</p><p>i. There should be comprehensive training sessions for SVI to familiarize themselves with the device's features and functionalities.</p><p>ii. There is a need to allow a robust feedback mechanism from SVI to continuously gather user input and make iterative improvements.</p><p>iii. There is a need to offer support services to the SVI in order to address maintenance issues promptly.</p><p>iv. The device works on a lithium battery and needs to be charged regularly.</p><p>v. The device is not water-proof; hence, it should not be used in the rain. Future work may look to see how the device can be made water-proof.</p><p>vi. There is a need to use a text-to-speech engine with options for different accents to ensure user preferences.</p><p>vii. There is a need to ensure that users are able to adjust the volume of voice.</p><p>viii. There is a need to incorporate future landmark-based navigation cues such as "turn right after school of science."</p><p>ix. Future development should incorporate robust error handling mechanisms to be able to manage situations where SVI deviate significantly from the known paths.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>This paper was supported by TETFund Nigeria through National Research Fund 2021 (Grant No.: TETF/ES/DR&amp;amp;D-CE/NRF-2021/SET1/ICT /00064/VOL.1). The authors also wish to appreciate the invaluable support of the Nigeria Association of the Blind, Oyo State Chapter, Nigeria.</p>
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflicts of interests.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="webpage">
          <article-title>Blind and vision impairment</article-title>
          <source>, http://who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment</source>
          <year>2024</year>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>39</volume>
          <page-range>1-16</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kuriakose</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Shrestha</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sandnes</surname>
              <given-names>F. E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/02564662.2020.1819893</pub-id>
          <article-title>Tools and technologies for blind and visually impaired navigation support: A review</article-title>
          <source>JETE Tech. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>67</volume>
          <page-range>89-109</page-range>
          <issue>2</issue>
          <year>1990</year>
          <person-group person-group-type="author">
            <name>
              <surname>Long</surname>
              <given-names>R. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/01619569009538683</pub-id>
          <article-title>Orientation and mobility research: What is known and what needs to be known</article-title>
          <source>Peabody J. Educ.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="conf-paper">
          <page-range>353-356</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sanchez</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Espinoza</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Campos</surname>
              <given-names>M. B.</given-names>
            </name>
            <name>
              <surname>Merabet</surname>
              <given-names>L. B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/2466627.2466673</pub-id>
          <article-title>Enhancing orientation and mobility skills in learners who are blind through video gaming</article-title>
          <source>Proceedings of the 9th ACM Conference on Creativity and Cognition, New York, NY, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>e0150205</page-range>
          <issue>3</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eldridge</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Lancaster</surname>
              <given-names>G. A.</given-names>
            </name>
            <name>
              <surname>Campbell</surname>
              <given-names>M. L.</given-names>
            </name>
            <name>
              <surname>Thabane</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Hopewell</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Coleman</surname>
              <given-names>C. L.</given-names>
            </name>
            <name>
              <surname>Bond</surname>
              <given-names>C. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0150205</pub-id>
          <article-title>Defining feasibility and pilot studies in preparation for randomised controlled trials: Development of a conceptual framework</article-title>
          <source>PLoS One</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>21-29</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Olaleye</surname>
              <given-names>S. B.</given-names>
            </name>
            <name>
              <surname>Adebiyi</surname>
              <given-names>B. A.</given-names>
            </name>
            <name>
              <surname>Abdulsalaam</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nwosu</surname>
              <given-names>F. C.</given-names>
            </name>
            <name>
              <surname>Adeyanju</surname>
              <given-names>A. O.</given-names>
            </name>
            <name>
              <surname>Ambi</surname>
              <given-names>H. M.</given-names>
            </name>
            <name>
              <surname>Omolayo</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22271/27103862.2024.v4.i1.67</pub-id>
          <article-title>Adaptation of global positioning system (GPS) in Nigerian language for orientation and mobility of students with visual impairment</article-title>
          <source>Int. J. Res. Spec. Educ.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>50-59</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Olaleye</surname>
              <given-names>S. B.</given-names>
            </name>
            <name>
              <surname>Adebiyi</surname>
              <given-names>B. A.</given-names>
            </name>
            <name>
              <surname>Abdulsalaam</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nwosu</surname>
              <given-names>F. C.</given-names>
            </name>
            <name>
              <surname>Adeyanju</surname>
              <given-names>A. O.</given-names>
            </name>
            <name>
              <surname>Ambi</surname>
              <given-names>H. M.</given-names>
            </name>
            <name>
              <surname>Omolayo</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.11648/j.ajset.20240902</pub-id>
          <article-title>Development of blind campus navigation system with obstacle detection device</article-title>
          <source>Am. J. Sci. Eng. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="conf-paper">
          <page-range>427-434</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Darvishy</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Grossenbacher</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Merz</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Touch explorer: Exploring digital maps for visually impaired people</article-title>
          <source>International Conference on Computers Helping People with Special Needs</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>1-36</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Al-Razgan</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Almoaiqel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Alrajhi</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Alhumejani</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Alshehri</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Alnefaie</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Alkhamiss</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rushdi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.7717/peerj-cs.771</pub-id>
          <article-title>A systematic literature review on the usability of mobile applications for visually impaired users</article-title>
          <source>Peer J. Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>275-286</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Csapo</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Wersenyi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Nagy</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Stockman</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s12193-015-0182-7</pub-id>
          <article-title>A survey of assistive technologies and applications for blind users on mobile platforms: A review and foundation for research</article-title>
          <source>J. Multimodal User Interfaces</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>20119</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bharatia</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Ambawane</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Rane</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/GCAT47503.2019.8978303</pub-id>
          <article-title>Smart electronic stick for visually impaired using android application and google’s cloud vision</article-title>
          <source>2019 Global Conference for Advancement in Technology (GCAT), Bangalore, India</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>86</volume>
          <page-range>654-659</page-range>
          <issue>9</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lewis</surname>
              <given-names>P. M.</given-names>
            </name>
            <name>
              <surname>Ayton</surname>
              <given-names>L. N.</given-names>
            </name>
            <name>
              <surname>Guymer</surname>
              <given-names>R. H.</given-names>
            </name>
            <name>
              <surname>Lowery</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Blamey</surname>
              <given-names>P. J.</given-names>
            </name>
            <name>
              <surname>Allen</surname>
              <given-names>P. J.</given-names>
            </name>
            <name>
              <surname>Luu</surname>
              <given-names>C. D.</given-names>
            </name>
            <name>
              <surname>Rosenfeld</surname>
              <given-names>J. V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/ans.13616</pub-id>
          <article-title>Advances in implantable bionic devices for blindness: A review</article-title>
          <source>ANZ J. Surg.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>111</volume>
          <page-range>307-323</page-range>
          <issue>4</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Griffin-Shirley</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Banda</surname>
              <given-names>D. R.</given-names>
            </name>
            <name>
              <surname>Ajawon</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Cheon</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Park</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Lyngdoh</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1177/0145482x1711100402</pub-id>
          <article-title>A survey on the use of mobile applications for people who are visually impaired</article-title>
          <source>J. Vis. Impair. Blind.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="conf-paper">
          <page-range>145–150</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gintner</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Balata</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Boksansky</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Mikovec</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CoginfoCom.8268232</pub-id>
          <article-title>Improving reverse geocoding: Localization of blind pedestrians using conversational ui</article-title>
          <source>2017 8th IEEE International Conference on Cognitive Infocommunications (CoginfoCom), Debrecen, Hungary</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>1-23</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Parker</surname>
              <given-names>A. T.</given-names>
            </name>
            <name>
              <surname>Swobodzinski</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wright</surname>
              <given-names>J. D.</given-names>
            </name>
            <name>
              <surname>Hansen</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Morton</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Schaller</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/feduc.2021.723816</pub-id>
          <article-title>Wayfinding tools for people with visual impairments in real world settings: A literature review of recent studies</article-title>
          <source>Front. Educ.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1-30</page-range>
          <issue>3</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Oh</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Guerreiro</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ahmetovic</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Naito</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Takagi</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3340319</pub-id>
          <article-title>NavCog3 in the wild: Large-scale blind indoor navigation assistant with semantic features</article-title>
          <source>ACM Trans. Access. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>29</volume>
          <page-range>181-202</page-range>
          <issue>2</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Abu Doush</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Alshatnawi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Al-Tamimi</surname>
              <given-names>A. K.</given-names>
            </name>
            <name>
              <surname>Alhasan</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Hamasha</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/iwc/iww016</pub-id>
          <article-title>ISAB: Integrated indoor navigation system for the blind</article-title>
          <source>Interact. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-7</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Van der Bie</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ben Allouch</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Jashinski</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3338286.3344419</pub-id>
          <article-title>Communicating multimodal wayfinding messages for visually impaired people via wearables</article-title>
          <source>Proceedings of the 21st International Conference on Human- Computer Interaction with Mobile Devices and Services, New York City, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <page-range>222–235</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saha</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Fiannaca</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kneisel</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cutrell</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>M. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3308561.3353776</pub-id>
          <article-title>Closing the gap</article-title>
          <source>21st International ACM SIGACCESS Conference on Computers and Accessibility, New York City, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shera</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Iqbal</surname>
              <given-names>M. W.</given-names>
            </name>
            <name>
              <surname>Naqvi</surname>
              <given-names>M. R.</given-names>
            </name>
            <name>
              <surname>Shahzad</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Sajjad</surname>
              <given-names>M. H.</given-names>
            </name>
            <name>
              <surname>Shafqat</surname>
              <given-names>A. R.</given-names>
            </name>
            <name>
              <surname>Saeed</surname>
              <given-names>M. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICIC53490.2021.9693084</pub-id>
          <article-title>Usability evaluation of blind and visually impaired interface in solving the accessibility problems</article-title>
          <source>2021 IEEE International Conference on Innovative Computing, Lahore, Pakistan</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Naqvi</surname>
              <given-names>M. R.</given-names>
            </name>
            <name>
              <surname>Aslam</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Iqbal</surname>
              <given-names>M. W.</given-names>
            </name>
            <name>
              <surname>Shahzad</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Malik</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Tahir</surname>
              <given-names>M. U.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/HORA49412.2020.9152846</pub-id>
          <article-title>Study of block chain and its impact on internet of health things (JOHT): Challenges and opportunities</article-title>
          <source>2020 International Congress on Human Computer Interaction, Optimization and Robotic Applications (HORA), Ankara, Turkey</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>1-29</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Messaoudi</surname>
              <given-names>M. D.</given-names>
            </name>
            <name>
              <surname>Menelas</surname>
              <given-names>B. A. J.</given-names>
            </name>
            <name>
              <surname>Mcheick</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s22207888</pub-id>
          <article-title>Review of navigation assistive tools and technologies for the visually impaired</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="conf-paper">
          <page-range>142-146</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3209914.3209944</pub-id>
          <article-title>Improving realsense by fusing color stereo vision and infrared stereo vision for the visually impaired</article-title>
          <source>Proceedings of the 1st International Conference on Information Science and Systems, Zhengzhou, China</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>13-22</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dian</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Kezhong</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Rui</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/cc.2015.7114062</pub-id>
          <article-title>A precise rfid indoor localization system with sensor network assistance</article-title>
          <source>China Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>135-156</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Muhsin</surname>
              <given-names>Z. J.</given-names>
            </name>
            <name>
              <surname>Qahwaji</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ghanchi</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Al-Taee</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s12193-023-00427-4</pub-id>
          <article-title>Review of substitutive assistive tools and technologies for people with visual impairments, recent advancements and prospects</article-title>
          <source>J. Multimodal User Interfaces</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="conf-paper">
          <volume>58</volume>
          <page-range>513-528</page-range>
          <issue>6</issue>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hakobyan</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Lumsden</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>O’Sullivan</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bartlett</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">j.survophthal.2012.10.004</pub-id>
          <article-title>Mobile assistive technologies for the visually impaired</article-title>
          <source>Surv. Ophthalmol.</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="conf-paper">
          <page-range>24-28</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Al-Ataby</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Younis</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Al-Nuaimy</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Al-Taee</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sharaf</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Al-Bander</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/DeSE.2016.6</pub-id>
          <article-title>Visual augmentation glasses for people with impaired vision</article-title>
          <source>2016 9th International Conference on Developments in eSystems Engineering (DeSE), Liverpool, UK</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1325–1330</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Edupuganti</surname>
              <given-names>S. A.</given-names>
            </name>
            <name>
              <surname>Koganti</surname>
              <given-names>V. D.</given-names>
            </name>
            <name>
              <surname>Lakshmi</surname>
              <given-names>C. S.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>R. N.</given-names>
            </name>
            <name>
              <surname>Paruchuri</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICOSEC51865.2021.9591829</pub-id>
          <article-title>Text and speed recognition for visually impaired people using google vision</article-title>
          <source>2021 2nd International Conference on Smart Electronics and Communication (ICOSEC), Trichy, India</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="conf-paper">
          <page-range>751–758</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ragavi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Radja</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Chithra</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-81-322-2671-0_71</pub-id>
          <article-title>Portable text to speech converter for the visually impaired</article-title>
          <source>Proceedings of the International Conference on Soft Computing Systems, New Delhi, India</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>361</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Khusro</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Shah</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Rahman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s22010361</pub-id>
          <article-title>Haptic feedback to assist blind people in indoor environment using vibration patterns</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>79</volume>
          <page-range>31931–31955</page-range>
          <issue>43</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Costa</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Duarte</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-020-09656-1</pub-id>
          <article-title>Alternative modalities for visually impaired users to control smart TVs</article-title>
          <source>Multimed. Tools Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="conf-paper">
          <page-range>19-24</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Porzi</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Messelodi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Modena</surname>
              <given-names>C. M.</given-names>
            </name>
            <name>
              <surname>Ricci</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/2505483.2505487</pub-id>
          <article-title>A smart watch-based gesture recognition system for assisting people with visual impairments</article-title>
          <source>Proceedings of the 3rd ACM International Workshop on Interactive Multimedia on Mobile &amp; Portable Devices, New York, NY, USA</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>