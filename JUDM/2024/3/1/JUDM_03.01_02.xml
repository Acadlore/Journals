<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JUDM</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Journal of Urban Development and Management</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Urban Dev. Manag.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JUDM</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9597</issn>
      <issn publication-format="print">2957-9589</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-yGxWpZHIfpwBdfjKSXJmL_tdPlm15KMQ</article-id>
      <article-id pub-id-type="doi">10.56578/judm030102</article-id>
      <title-group>
        <article-title>An Integrated Convolutional Neural Network-Bidirectional Long Short-Term Memory-Attention Mechanism Model for Enhanced Highway Traffic Flow Prediction</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Kan</surname>
            <given-names>Haoyuan</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true"> </contrib-id>
          <email>22023210030@cueb.edu.cn</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Li</surname>
            <given-names>Chang</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true"> </contrib-id>
          <email>lc02282001@163.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="2">2</xref>
          <name>
            <surname>Wang</surname>
            <given-names>Ziqi</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0000-6114-7960</contrib-id>
          <email>wangzw10@student.unimelb.edu.au</email>
        </contrib>
        <aff id="1">School of Management and Engineering, Capital University of Economics and Business, 100070 Beijing, China</aff>
        <aff id="2">Faculty of Engineering and Information Technology, The University of Melbourne, 1446535 Melbourne, Australia</aff>
      </contrib-group>
      <year>2024</year>
      <volume>3</volume>
      <issue>1</issue>
      <fpage>18</fpage>
      <lpage>33</lpage>
      <page-range>18-33</page-range>
      <history>
        <date date-type="received">
          <month>01</month>
          <day>22</day>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <month>03</month>
          <day>03</day>
          <year>2024</year>
        </date>
        <date date-type="pub">
          <month>03</month>
          <day>10</day>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license>. Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the <a href='https://creativecommons.org/licenses/by/4.0/' target='_blank' class='text-yellow-700 hover:underline'>CC BY 4.0 license</a>.</license>
      </permissions>
      <abstract><p>The burgeoning expansion of the Internet of Things (IoT) technology has propelled Intelligent Traffic Systems (ITS) to the forefront of IoT applications, with accurate highway traffic flow prediction models playing a pivotal role in their development. Such models are essential for mitigating highway traffic congestion, reducing accident rates, and informing city planning and traffic management strategies. Given the inherent periodicity, non-linearity, and variability of highway traffic data, an innovative model leveraging a Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Attention Mechanism (AM) is proposed. In this model, feature extraction is accomplished via the CNN, which subsequently feeds into the BiLSTM for processing temporal dependencies. The integration of an AM enhances the model by weighting and fusing the BiLSTM outputs, thereby refining the prediction accuracy. Through a series of experiments and the application of diverse evaluation metrics, it is demonstrated that the proposed CNN-BiLSTM-AM model surpasses existing models in prediction accuracy and explainability. This advancement positions the model as a significant contribution to the field, offering a robust and insightful tool for highway traffic flow prediction.</p></abstract>
      <kwd-group>
        <kwd>Traffic flow prediction</kwd>
        <kwd>Convolutional Neural Network (CNN)</kwd>
        <kwd>Bidirectional Long Short-Term Memory (BiLSTM)</kwd>
        <kwd>Attention Mechanism (AM)</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors">3</count>
        <fig-count>11</fig-count>
        <table-count>6</table-count>
        <ref-count>20</ref-count>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec disp-level="level1" sec-type="intro">
      <title>1. Introduction</title>
      <p>In today's society, the field of transportation is facing many severe challenges. With the development of the economy and logistics, as well as people's higher requirements for material life, the number of motor vehicles in various countries is increasing every year (see <xref ref-type="fig" rid="fig_1">Figure 1</xref> for an example of China), and the incidence of road congestion is increasing year by year. Compared with ordinary urban traffic roads, expressways have the characteristics of being relatively closed, fast speed, and large traffic flow, which assume the main role of traffic between cities. The operation efficiency of highways affects the country’s economic level and people’s quality of life [<xref ref-type="bibr" rid="ref_1">1</xref>]. Once congestion occurs, it will seriously affect the traffic capacity. It is more practical and effective to build a reasonable and effective traffic flow prediction model instead of expanding existing roads and rebuilding the roads based on the predicted future traffic flow.</p><p>Traffic flow refers to the number of participants actually participating in traffic through a certain place or section of the road in a unit time, which is a basic indicator to measure the traffic state of the road. Dynamic management of the traffic network depends on proper short- and mid-term forecasting of traffic states [<xref ref-type="bibr" rid="ref_2">2</xref>]. Predicting short-term traffic flow helps estimate travel time and the existing level of service on a route [<xref ref-type="bibr" rid="ref_3">3</xref>]. In the past, traffic managers were limited in their ability to formulate and deploy reactive traffic response plans to deal with traffic congestion [<xref ref-type="bibr" rid="ref_4">4</xref>]. If the traffic flow of the traffic section in the future can be predicted in advance, the traffic management department can better guide the traffic vehicles and improve the traffic efficiency of the highway. And the model can be used to select the time of less traffic flow to maintain the highway and to rebuild and expand the future highway that does not match the traffic flow in advance. A reasonable and accurate highway traffic flow prediction model is not only an important basis for the daily management and work plan of the traffic management department but also a key part of the national transportation network.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>Statistics of motor vehicle ownership in China</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_erb8wWlgtaQthnZD.png"/>
        </fig>
      
      <p>Nowadays, many scientists predict highway traffic flow through various algorithms, using the search mechanism of the K-nearest neighbor method to reconstruct the historical traffic flow time series that is similar to the current traffic state and then using the principle of support vector regression to achieve short-term traffic flow prediction [<xref ref-type="bibr" rid="ref_5">5</xref>]. The methods of using artificial neural network models to predict short-term traffic flow [<xref ref-type="bibr" rid="ref_6">6</xref>] all have the problem of low prediction accuracy. The urban highway flow prediction model that integrates graph convolutional neural networks and generative adaptive neural networks (GCN-GAN) has weak interpretability [<xref ref-type="bibr" rid="ref_7">7</xref>]. The traffic flow prediction model that integrates LSTM and GCN can only achieve short-term prediction [<xref ref-type="bibr" rid="ref_8">8</xref>]. The prediction method of average vehicle speed on urban roads based on CNN-LSTM cannot fully consider the impact of other factors such as weather and holidays on traffic flow [<xref ref-type="bibr" rid="ref_9">9</xref>], making it difficult to apply in real traffic environments [<xref ref-type="bibr" rid="ref_10">10</xref>]. At present, considerable research has been conducted on traffic flow prediction models by previous researchers, and each model has its own unique features, providing this paper with many ideas.</p><p>Although researchers have explored many methods for predicting traffic flow, existing models still have many problems in predicting highway traffic flow in large samples, high-dimensional data, and complex environments, making it difficult to achieve the expected prediction results. This paper aims to propose a new highway traffic flow prediction model that improves the accuracy and precision of prediction.</p><p>By analyzing the models and methods used by predecessors in predicting traffic flow on highways, it is not difficult to see that existing methods mainly use linear models and shallow machine learning models to predict the incoming traffic flow and cannot describe the non-linearity and uncertainty well due to the stochastic and non-linear nature of traffic flow [<xref ref-type="bibr" rid="ref_11">11</xref>]. Compared with the single model, the combined model makes good use of the merits of single models, and its prediction accuracy is higher and fitting ability is stronger. Therefore, this paper aims to build a combined model through CNN, BiLSTM, and AM, select the optimal combination by analyzing the model training results of various combinations of single models and the advantages and disadvantages of various evaluation indicators, and use this as the main model to study the prediction of traffic flow. The remainder of this paper is organized as follows: Section 2 introduces the experimental principles and methods as well as the model; Section 3 analyzes the experimental results; and Section 4 presents the conclusions and limitations of this study, as well as future research directions.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>2. Materials and methods</title>
      
        <sec disp-level="level2">
          
            <title>2.1. Theoretical basis</title>
          
          
            <sec disp-level="level3">
              
                <title>2.1.1 Cnn</title>
              
              <p>The basic structure of a CNN roughly includes: input layer, convolutional layer, pooling layer, fully connected layer, output layer, as shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p><p>The structure of CNN is relatively flexible, and the convolutional and pooling layers that belong to feature extraction can be stacked and used. The common combination is several convolutional and pooling layers. The structure of CNN is relatively flexible, and the convolutional and pooling layers that belong to feature extraction can be stacked and used. The common combination is several convolutional and pooling layers. The LeNet framework for handwritten digit recognition, developed based on the CNN model, consists of three convolutional layers and two pooling layers.</p><p>The most important concept in convolutional layers is the convolution kernel, which can be understood as a type of feature. The result of multiplying the input and convolution kernel is the projection of the input onto that feature, which can be called a feature map. Taking image recognition as an example, assuming there is a feature representing the contour of an object, multiplying the input image with this feature yields the contour map of the image. The convolution process is shown in subgraph (a) of <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
              
                <fig id="fig_2">
                  <label>Figure 2</label>
                  <caption>Basic structure of CNN</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_0EpbkxUEvoriHMtZ.png"/>
                </fig>
              
              
                <fig id="fig_3">
                  <label>Figure 3</label>
                  <caption>CNN convolutional and pooling layers</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_1VP0_eJfDEj6oOtZ.png"/>
                </fig>
              
              <p>Express the convolution process using mathematical formulas as follows:</p>
              
                <disp-formula>
                  <label>(1)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>S</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mi>x</mi>
                    <mi>w</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mi>b</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mi>b</mi>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mo stretchy="false">(</mo>
                    <mo>∗</mo>
                    <mo stretchy="false">)</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>+</mo>
                    <mo>=</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>+</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>k</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <msub>
                          <mi>n</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mo>−</mo>
                          </mrow>
                        </msub>
                        <mtext>in </mtext>
                      </mrow>
                    </munderover>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>∗</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>k</mi>
                      </msub>
                      <msub>
                        <mi>w</mi>
                        <mi>k</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>Among them, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>n</mi>
    <mi mathvariant="normal">_</mi>
    <mi>i</mi>
    <mi>n</mi>
  </math>
</inline-formula> is the number of input matrices or the dimension of the last dimension of the tensor. <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>x</mi>
      <mi>k</mi>
    </msub>
  </math>
</inline-formula> represents the k-th input matrix. The k-th subconvolutional kernel matrix representing the convolution kernel. <italic>S(i,j)</italic> is the value of the corresponding position element in the output matrix corresponding to the convolutional kernel w.</p><p>For the convolutional output, the ReLU activation function is usually used to convert the element values corresponding to positions less than 0 in the output tensor to 0.</p><p>The role of the pooling layer is to down-sample the output of the convolutional layer, which mainly includes Max pooling and mean pooling. It is possible to further reduce the data while maintaining the original salient features, as shown in subgraph (b) of <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p><p>The features obtained through convolution and pooling layers are classified in the fully connected layer. The fully connected layer is a fully connected neural network. Each neuron feedbacks in different proportions based on its weight. Finally, the classification result is obtained by adjusting the weight and network.</p><p>Previous studies have shown that one-dimensional CNN has strong feature extraction capabilities for time-series data [<xref ref-type="bibr" rid="ref_12">12</xref>]. Considering the temporal nature of traffic flow data, this paper adopts a one-dimensional CNN model for feature extraction.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.1.2 Lstm</title>
              
              <p>LSTM is a special type of recurrent neural network (RNN), commonly used for dynamically capturing time dependencies in data [<xref ref-type="bibr" rid="ref_13">13</xref>]. During training, the original RNN is prone to gradient explosion or vanishing as the training time increases and the number of network layers increases, resulting in the inability to process longer sequence data and obtain information from long-distance data. LSTM solves the above problems [<xref ref-type="bibr" rid="ref_14">14</xref>]. </p><p>The biggest difference between LSTM and RNN lies in their neuron structure, which is distributed in the hidden layer. In LSTM's model, cell states are added to preserve long-term states. The key to LSTM lies in the use of three gating units, namely the forget gate, input gate, and output gate, to update the historical information that needs to be saved and discard irrelevant historical information. The specific process is shown in <xref ref-type="fig" rid="fig_4">Figure 4</xref>.</p>
              
                <fig id="fig_4">
                  <label>Figure 4</label>
                  <caption>LSTM structure</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_zj7CNfIm1uCoPKse.png"/>
                </fig>
              
              <p>The first step of LSTM is to determine what information can be obtained through the cell state. This decision is controlled by the forget gate through sigmoid, which will pass or partially pass based on the output from the previous moment. Its expression is as follows:</p>
              
                <disp-formula>
                  <label>(2)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>f</mi>
                      <mi>t</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>σ</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>⋅</mo>
                      <mo>+</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>W</mi>
                        <mi>f</mi>
                      </msub>
                      <msub>
                        <mi>b</mi>
                        <mi>f</mi>
                      </msub>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">[</mo>
                        <mo>,</mo>
                        <mo data-mjx-texclass="CLOSE">]</mo>
                        <msub>
                          <mi>h</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>t</mi>
                            <mo>−</mo>
                            <mn>1</mn>
                          </mrow>
                        </msub>
                        <msub>
                          <mi>x</mi>
                          <mi>t</mi>
                        </msub>
                      </mrow>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>In the formula, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>w</mi>
      <mi>f</mi>
    </msub>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>b</mi>
      <mi>f</mi>
    </msub>
  </math>
</inline-formula> are the weight matrix and bias of, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>h</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>t</mi>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msub>
  </math>
</inline-formula> represents the hidden state of the previous moment; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>x</mi>
      <mi>t</mi>
    </msub>
  </math>
</inline-formula> represents the input information at the current time.</p><p>The second step of LSTM consists of two parts. The first part is to determine which values are used for updating through sigmoid in the input gate. The second part is the tanh layer used to generate new candidate values and add them together to obtain the candidate values. The combination of these two steps is the process of discarding unnecessary information and adding new information, which is expressed as follows:</p>
              
                <disp-formula>
                  <label>(3)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>C</mi>
                      <mi>t</mi>
                    </msub>
                    <msub>
                      <mi>f</mi>
                      <mi>t</mi>
                    </msub>
                    <msub>
                      <mi>C</mi>
                      <mrow data-mjx-texclass="ORD">
                        <mi>t</mi>
                        <mo>−</mo>
                        <mn>1</mn>
                      </mrow>
                    </msub>
                    <msub>
                      <mi>i</mi>
                      <mi>t</mi>
                    </msub>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mover>
                          <mi>C</mi>
                          <mo stretchy="false">~</mo>
                        </mover>
                      </mrow>
                      <mi>t</mi>
                    </msub>
                    <mo>=</mo>
                    <mo>⋅</mo>
                    <mo>+</mo>
                    <mo>⋅</mo>
                  </math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(4)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow data-mjx-texclass="ORD">
                      <mover>
                        <msub>
                          <mi>C</mi>
                          <mi>t</mi>
                        </msub>
                        <mo>~</mo>
                      </mover>
                    </mrow>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>⋅</mo>
                      <mo>+</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>W</mi>
                        <mi>c</mi>
                      </msub>
                      <msub>
                        <mi>b</mi>
                        <mi>c</mi>
                      </msub>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">[</mo>
                        <mo>,</mo>
                        <mo data-mjx-texclass="CLOSE">]</mo>
                        <msub>
                          <mi>h</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>t</mi>
                            <mo>−</mo>
                            <mn>1</mn>
                          </mrow>
                        </msub>
                        <msub>
                          <mi>x</mi>
                          <mi>t</mi>
                        </msub>
                      </mrow>
                    </mrow>
                    <mo>=</mo>
                    <mo data-mjx-texclass="NONE">⁡</mo>
                    <mi>tanh</mi>
                  </math>
                </disp-formula>
              
              <p>In the formula, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>f</mi>
      <mi>t</mi>
    </msub>
  </math>
</inline-formula>, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>i</mi>
      <mi>t</mi>
    </msub>
  </math>
</inline-formula> represent the weights of <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>C</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>t</mi>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msub>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mrow data-mjx-texclass="ORD">
        <mover>
          <mi>C</mi>
          <mo stretchy="false">~</mo>
        </mover>
      </mrow>
      <mi>t</mi>
    </msub>
  </math>
</inline-formula>, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>C</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>t</mi>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msub>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>C</mi>
      <mi>t</mi>
    </msub>
  </math>
</inline-formula> represent the unit states of the previous and current time, respectively.</p><p>The final step of LSTM is to determine the output of the model. Firstly, an initial output is obtained through the sigmoid layer. Then, the tanh function is used to scale the value between -1 and 1, and the output obtained from the sigmoid is multiplied pairwise to obtain the output of the model. Its expression is as follows:</p>
              
                <disp-formula>
                  <label>(5)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>O</mi>
                      <mi>t</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>σ</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>⋅</mo>
                      <mo>+</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>W</mi>
                        <mn>0</mn>
                      </msub>
                      <msub>
                        <mi>b</mi>
                        <mn>0</mn>
                      </msub>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">[</mo>
                        <mo>,</mo>
                        <mo data-mjx-texclass="CLOSE">]</mo>
                        <msub>
                          <mi>h</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>t</mi>
                            <mo>−</mo>
                            <mn>1</mn>
                          </mrow>
                        </msub>
                        <msub>
                          <mi>x</mi>
                          <mi>t</mi>
                        </msub>
                      </mrow>
                    </mrow>
                  </math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(6)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>h</mi>
                      <mi>t</mi>
                    </msub>
                    <msub>
                      <mi>o</mi>
                      <mi>t</mi>
                    </msub>
                    <mo>=</mo>
                    <mo>⋅</mo>
                    <mo data-mjx-texclass="NONE">⁡</mo>
                    <mi>tanh</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>c</mi>
                        <mi>t</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>In the formula, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>W</mi>
      <mn>0</mn>
    </msub>
  </math>
</inline-formula> represents the weight framework of the output layer; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>b</mi>
      <mn>0</mn>
    </msub>
  </math>
</inline-formula> is offset.</p><p>The application areas of LSTM include text generation, machine translation, speech recognition, image description generation, and video tagging, but its main application area is the analysis and prediction of time series data.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.1.3 Bilstm</title>
              
              <p>The LSTM model uses forward sequence information as input data for time prediction [<xref ref-type="bibr" rid="ref_15">15</xref>], making it difficult to perceive backward data during model training. BiLSTM solves the problem of lacking attention to backward information [<xref ref-type="bibr" rid="ref_16">16</xref>].</p><p>Each unit of BiLSTM contains two independent LSTM units, called forward LSTM units and backward LSTM units. The structure of each LSTM unit is the same as in <xref ref-type="fig" rid="fig_4">Figure 4</xref>, and the two LSTM units are independent of each other. The structure of BiLSTM is shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>.</p>
              
                <fig id="fig_5">
                  <label>Figure 5</label>
                  <caption>BiLSTM structure</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_OO-wnEEekTf391Tt.png"/>
                </fig>
              
              <p>BiLSTM is mainly used in semantic analysis, sentiment analysis, etc. Previous studies have shown that BiLSTM outperforms LSTM in predicting time series data [<xref ref-type="bibr" rid="ref_17">17</xref>].</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.1.4 Am</title>
              
              <p>The AM in neural networks is a resource allocation scheme that allocates computing resources to more important tasks and solves the problem of information overload when computing power is limited [<xref ref-type="bibr" rid="ref_18">18</xref>]. In the process of neural network learning, generally speaking, the more parameters a model has, the stronger its expressive power and the greater the amount of information stored by the model. However, this can lead to the problem of information overload. So, by introducing an AM, focusing on the more critical information for the current task among the numerous input information, reducing attention to other information, and even filtering out irrelevant information, the problem of information overload can be solved, and the efficiency and accuracy of task processing can be improved.</p><p>Using <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">X</mi>
    </mrow>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">[</mo>
      <mo>,</mo>
      <mo>…</mo>
      <mo data-mjx-texclass="CLOSE">]</mo>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="normal">x</mi>
        </mrow>
        <mn>1</mn>
      </msub>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="normal">x</mi>
        </mrow>
        <mn>2</mn>
      </msub>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="normal">x</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="normal">n</mi>
          </mrow>
        </mrow>
      </msub>
    </mrow>
    <mo>=</mo>
  </math>
</inline-formula> to represent n input information, in order to save computational resources, the neural network does not need to process these n inputs information but only needs to select some task-related information from X for calculation. The soft AM refers to the process of selecting information—not just selecting one out of n pieces of information, but calculating the weighted average of n input pieces of information, which are then input into a neural network for calculation. And hard attention refers to selecting information at a certain position in the input sequence, such as randomly selecting a piece of information or selecting the information with the highest probability [<xref ref-type="bibr" rid="ref_19">19</xref>]. Soft attention is generally used to handle neural network problems.</p><p>This paper selects the key value pair attention mode from the soft AM. In the key value pair attention mode, the AM is seen as a soft addressing operation that treats input information X as stored content in memory, where each element is composed of an address key and a value. The goal of this operation is to obtain the value corresponding to the query Key=Query from memory, which is the attention value. Unlike traditional hard addressing, in soft addressing, it is not necessary to satisfy the condition of Key=Query in order to retrieve storage information. Instead, the degree of extraction in the element value is determined by calculating the similarity between the query key and the address of the element in the storage, which is called attention weight. The values corresponding to each address will be extracted and then summed, which is equivalent to using the similarity between Query and Key to calculate the weight of each value, and then weighting and summing the values. The final value is the attention value, which is calculated by weighting the similarity between Query and Memory Key.</p><p>The above calculation can be divided into three processes (see <xref ref-type="fig" rid="fig_6">Figure 6</xref> for the process diagram):</p>
              
                <fig id="fig_6">
                  <label>Figure 6</label>
                  <caption>Key value pair attention pattern algorithm structure</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_bpQtt3R1zsIcHP1d.png"/>
                </fig>
              
              <p>1) Calculate the similarity between Query and Key. Attention score X can be calculated using similarity measurement methods such as the additive model, dot product, or mul-ti-layer perceptron (in this model, dot product are used):</p>
              
                <disp-formula>
                  <label>(7)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>S</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>F</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>,</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <mi>Q</mi>
                      <msub>
                        <mi>k</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>2) Use the SoftMax function to numerically convert attention scores. On the one hand, normalization can be performed to obtain a probability distribution where the sum of all weight coefficients is 1. On the other hand, the characteristics of the SoftMax function can be used to highlight the weights of important elements;</p>
              
                <disp-formula>
                  <label>(8)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>a</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>=</mo>
                    <mo>=</mo>
                    <mi>softmax</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>S</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                    <mfrac>
                      <mrow>
                        <mi>exp</mi>
                        <mo data-mjx-texclass="NONE">⁡</mo>
                        <mrow data-mjx-texclass="INNER">
                          <mo data-mjx-texclass="OPEN">(</mo>
                          <mo data-mjx-texclass="CLOSE">)</mo>
                          <msub>
                            <mi>S</mi>
                            <mi>i</mi>
                          </msub>
                        </mrow>
                      </mrow>
                      <mrow>
                        <munderover>
                          <mo data-mjx-texclass="OP">∑</mo>
                          <mrow data-mjx-texclass="ORD">
                            <mi>j</mi>
                            <mo>=</mo>
                            <mn>1</mn>
                          </mrow>
                          <mi>n</mi>
                        </munderover>
                        <mi>exp</mi>
                        <mo data-mjx-texclass="NONE">⁡</mo>
                        <mrow data-mjx-texclass="INNER">
                          <mo data-mjx-texclass="OPEN">(</mo>
                          <mo data-mjx-texclass="CLOSE">)</mo>
                          <msub>
                            <mi>S</mi>
                            <mi>i</mi>
                          </msub>
                        </mrow>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p>3) Weighted sum of values based on weight coefficients.</p>
              
                <disp-formula>
                  <label>(9)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>Attention</mi>
                    <mi>K</mi>
                    <mi>V</mi>
                    <mi>Q</mi>
                    <mo stretchy="false">(</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>n</mi>
                    </munderover>
                    <msub>
                      <mi>α</mi>
                      <mi>i</mi>
                    </msub>
                    <msub>
                      <mi>v</mi>
                      <mi>i</mi>
                    </msub>
                  </math>
                </disp-formula>
              
              <p>By combining and organizing the above formulas, we have obtained the key value pair attention pattern algorithm formula:</p>
              
                <disp-formula>
                  <label>(10)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>Attention</mi>
                    <mi>K</mi>
                    <mi>V</mi>
                    <mi>Q</mi>
                    <mo stretchy="false">(</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mo>=</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>n</mi>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>n</mi>
                    </munderover>
                    <msub>
                      <mi>α</mi>
                      <mi>i</mi>
                    </msub>
                    <msub>
                      <mi>v</mi>
                      <mi>i</mi>
                    </msub>
                    <msub>
                      <mi>v</mi>
                      <mi>i</mi>
                    </msub>
                    <mfrac>
                      <mrow>
                        <mi>exp</mi>
                        <mo data-mjx-texclass="NONE">⁡</mo>
                        <mrow data-mjx-texclass="INNER">
                          <mo data-mjx-texclass="OPEN">(</mo>
                          <mo data-mjx-texclass="CLOSE">)</mo>
                          <mi>s</mi>
                          <mrow data-mjx-texclass="INNER">
                            <mo data-mjx-texclass="OPEN">(</mo>
                            <mo>,</mo>
                            <mo data-mjx-texclass="CLOSE">)</mo>
                            <msub>
                              <mi>k</mi>
                              <mi>i</mi>
                            </msub>
                            <mi>q</mi>
                          </mrow>
                        </mrow>
                      </mrow>
                      <mrow>
                        <munderover>
                          <mo data-mjx-texclass="OP">∑</mo>
                          <mrow data-mjx-texclass="ORD">
                            <mi>j</mi>
                            <mo>=</mo>
                            <mn>1</mn>
                          </mrow>
                          <mi>n</mi>
                        </munderover>
                        <mi>exp</mi>
                        <mo data-mjx-texclass="NONE">⁡</mo>
                        <mrow data-mjx-texclass="INNER">
                          <mo data-mjx-texclass="OPEN">(</mo>
                          <mo data-mjx-texclass="CLOSE">)</mo>
                          <mi>s</mi>
                          <mrow data-mjx-texclass="INNER">
                            <mo data-mjx-texclass="OPEN">(</mo>
                            <mo>,</mo>
                            <mo data-mjx-texclass="CLOSE">)</mo>
                            <msub>
                              <mi>k</mi>
                              <mi>i</mi>
                            </msub>
                            <mi>q</mi>
                          </mrow>
                        </mrow>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p>Since the introduction of the AM, it has influenced the development of many artificial intelligence fields based on deep learning algorithms. The current AM has been successfully applied in areas such as image processing, natural language processing, and data prediction, and is in-creasingly closely integrated with other neural networks.</p>
            </sec>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.2. Experimental procedure</title>
          
          
            <sec disp-level="level3">
              
                <title>2.2.1 Data sources and preprocessing</title>
              
              <p>This paper selects the traffic flow data of a detector on the M25 highway in the UK as the dataset. As the busiest outer ring highway in the UK, the data of this highway has great reference value, and the detector is located near Heathrow Airport, with high daily traffic flow and high data reliability. The dataset is divided into three groups, namely the full-year data for 2022, 2021, and 2020. Taking the 2022 dataset as an example, the data was selected from January 1, 2022, to December 31, 2022, with a total of 34848 pieces of data recorded every 15 minutes. The first 80\% of the data was used as the model training set, the middle 10\% was used as the validation set to determine the network structure and adjust hyperparameters, and the last 10\% was used as the test set to evaluate the performance of the final model. The same applies to other datasets.</p><p>Next, the time series data will be preprocessed using max min normalization after removing irrelevant columns. The formula is as follows:</p>
              
                <disp-formula>
                  <label>(11)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msup>
                      <mi>x</mi>
                      <mrow data-mjx-texclass="ORD">
                        <mi data-mjx-alternate="1">′</mi>
                      </mrow>
                    </msup>
                    <mo>=</mo>
                    <mfrac>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                        <msub>
                          <mi>x</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>m</mi>
                            <mi>i</mi>
                            <mi>n</mi>
                          </mrow>
                        </msub>
                        <mo>−</mo>
                      </mrow>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>m</mi>
                            <mi>a</mi>
                            <mi>x</mi>
                          </mrow>
                        </msub>
                        <msub>
                          <mi>x</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mi>m</mi>
                            <mi>i</mi>
                            <mi>n</mi>
                          </mrow>
                        </msub>
                        <mo>−</mo>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p> where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msup>
      <mi>x</mi>
      <mrow data-mjx-texclass="ORD">
        <mi data-mjx-alternate="1">′</mi>
      </mrow>
    </msup>
  </math>
</inline-formula> represents the normalized data, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>x</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> represents the original data, and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>x</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>m</mi>
        <mi>a</mi>
        <mi>x</mi>
      </mrow>
    </msub>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>x</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>m</mi>
        <mi>i</mi>
        <mi>n</mi>
      </mrow>
    </msub>
  </math>
</inline-formula> represent the maximum and minimum values in the dataset, respectively. For outliers in the dataset, simple sum averaging is used to repair the difference.</p><p>For time series, taking the 2022 dataset as an example, the date and time columns are integrated and converted to timestamp format. Then, the first-time data, January 1, 2022, at 00:14:00, is used as the starting time as the 0 value, and the other times are normalized to relative time before input.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.2.2 Model architecture</title>
              
              <p>The model architecture used in this paper is shown in <xref ref-type="fig" rid="fig_7">Figure 7</xref>.</p>
              
                <fig id="fig_7">
                  <label>Figure 7</label>
                  <caption>CNN-BiLSTM-AM model architecture</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_S7gQOMVrHYeOSWiD.png"/>
                </fig>
              
              <p>This model consists of five parts: CNN layer, BiLSTM layer, AM layer, Dropout layer, and Fully connected layer.</p><p>The CNN layer consists of a one-dimensional convolutional layer, a batch normalization layer, and a one-dimensional max pooling layer. The CNN convolutional layer extracts features from the input data, preprocesses the feature data through the batch normalization layer, and then uses the max pooling layer to reduce the space size of the feature map, reducing the number of parameters and computational costs of the model and outputting it.</p><p>The BiLSTM layer is composed of two LSTM units, which are independent of each other. They perform forward and backward processing on the temporal feature data output by the pre-vious layer and output it.</p><p>The AM layer performs feature-weighted reoperation on the output data of the previous layer, dividing the features into important features and ordinary features, further enhancing the overall model's perception ability of key information before outputting.</p><p>The function of the Dropout layer is to randomly block 50\% of neurons without affecting the size of the output dimension, in order to reduce the risk of overfitting and enhance the model's adaptability.</p><p>The Fully connected layer consists of two fully connected layers. The first fully connected layer has an activation function of ReLU and an output dimension of 64. The second fully con-nected layer has no activation function and an output dimension of 1.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.2.3 Hyperparameter optimization</title>
              
              <p>Based on the model training results, optimize the relevant parameters of each layer through grid optimization methods, such as the number of filters in CNN and the number of BiLSTM neurons, to achieve the optimal parameter configuration.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.2.4 Model training</title>
              
              <p>This paper uses two indicators, mean absolute error (MAE) and mean square error (MSE), as evaluation indicators. The formula is as follows:</p>
              
                <disp-formula>
                  <label>(12)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>M</mi>
                    <mi>A</mi>
                    <mi>E</mi>
                    <mo>=</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mi>n</mi>
                    </mfrac>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>n</mi>
                    </munderover>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">|</mo>
                      <mo>−</mo>
                      <mo data-mjx-texclass="CLOSE">|</mo>
                      <msub>
                        <mi>q</mi>
                        <mi>i</mi>
                      </msub>
                      <msub>
                        <mrow data-mjx-texclass="ORD">
                          <mover>
                            <mi>q</mi>
                            <mo stretchy="false">^</mo>
                          </mover>
                        </mrow>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(13)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>M</mi>
                    <mi>S</mi>
                    <mi>E</mi>
                    <mo>=</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mi>n</mi>
                    </mfrac>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>n</mi>
                    </munderover>
                    <msup>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo>−</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>q</mi>
                          <mi>i</mi>
                        </msub>
                        <msub>
                          <mrow data-mjx-texclass="ORD">
                            <mover>
                              <mi>q</mi>
                              <mo stretchy="false">^</mo>
                            </mover>
                          </mrow>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                      <mn>2</mn>
                    </msup>
                  </math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(14)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>R</mi>
                    <mi>M</mi>
                    <mi>S</mi>
                    <mi>E</mi>
                    <mo>=</mo>
                    <msqrt>
                      <mfrac>
                        <mn>1</mn>
                        <mi>n</mi>
                      </mfrac>
                      <munderover>
                        <mo data-mjx-texclass="OP">∑</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mo>=</mo>
                          <mn>1</mn>
                        </mrow>
                        <mi>n</mi>
                      </munderover>
                      <msup>
                        <mrow data-mjx-texclass="INNER">
                          <mo data-mjx-texclass="OPEN">(</mo>
                          <mo>−</mo>
                          <mo data-mjx-texclass="CLOSE">)</mo>
                          <msub>
                            <mi>q</mi>
                            <mi>i</mi>
                          </msub>
                          <msub>
                            <mrow data-mjx-texclass="ORD">
                              <mover>
                                <mi>q</mi>
                                <mo stretchy="false">^</mo>
                              </mover>
                            </mrow>
                            <mi>i</mi>
                          </msub>
                        </mrow>
                        <mn>2</mn>
                      </msup>
                    </msqrt>
                  </math>
                </disp-formula>
              
              <p> where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>q</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> represents the normalized measured traffic flow value, and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mrow data-mjx-texclass="ORD">
        <mover>
          <mi>q</mi>
          <mo stretchy="false">^</mo>
        </mover>
      </mrow>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> represents the normalized predicted traffic flow value. The lower the MAE, MSE, and RMSE values, the better the predictive performance of the model, and the closer the predicted values are to the true values. The higher the MAE, MSE, and RMSE values, the worse the predictive performance of the model, and the more the predicted values deviate from the true values.</p><p>The optimization method of this model adopts the mini-batch gradient descent method. The Adam algorithm is selected as the model, and the loss function MSE, which has good performance in convergence speed and is also an evaluation index, is selected as the loss function. The batch size is set to 32, and the iteration is 100 generations. The learning rate has a significant impact on the convergence process, with an initial setting of 10<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msup>
      <mi/>
      <mrow data-mjx-texclass="ORD">
        <mo>−</mo>
        <mn>4</mn>
      </mrow>
    </msup>
  </math>
</inline-formula>. Two callback functions are defined. The first function is used to reduce the learning rate to one-fifth of its original value when the loss value no longer decreases or the decrease is not significant for five consecutive generations. The second function is used to stop iteration when the loss value no longer decreases or the decrease is not significant for ten consecutive generations to prevent overfitting of the model. The CNN convolution kernel size is set to 1, there are a total of 128 BiLSTM units, the activation function is sigmoid, and the Dropout layer ratio is set to 50\%. The AM layer adopts simple weighting processing.</p><p>Short-term traffic flow forecasting models rely on the regularity existing in historical data to predict traffic patterns in future time periods [<xref ref-type="bibr" rid="ref_20">20</xref>]. Considering the strong periodicity of the time series data (see <xref ref-type="fig" rid="fig_8">Figure 8</xref>), it fluctuates on a daily basis. Two parameters, the sine function and the cosine function, were added during data input to reflect periodic characteristics. The formulas are as follows:</p>
              
                <disp-formula>
                  <label>(15)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>X</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>=</mo>
                    <mo data-mjx-texclass="NONE">⁡</mo>
                    <mi>sin</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>∗</mo>
                      <mo>∗</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <mn>2</mn>
                      <mi>π</mi>
                      <mfrac>
                        <msub>
                          <mi>T</mi>
                          <mi>i</mi>
                        </msub>
                        <mrow>
                          <mn>4</mn>
                          <mn>24</mn>
                          <mo>∗</mo>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(16)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>Y</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>=</mo>
                    <mo data-mjx-texclass="NONE">⁡</mo>
                    <mi>cos</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>∗</mo>
                      <mo>∗</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <mn>2</mn>
                      <mi>π</mi>
                      <mfrac>
                        <msub>
                          <mi>T</mi>
                          <mi>i</mi>
                        </msub>
                        <mrow>
                          <mn>4</mn>
                          <mn>24</mn>
                          <mo>∗</mo>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p> where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>Y</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> represent the sine and cosine parameters of the i-th data, respectively, and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>T</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> represents that the corresponding timestamp of the i-th data is the T-th 15min of the day.</p>
              
                <fig id="fig_8">
                  <label>Figure 8</label>
                  <caption>Partial time series data</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_LLhRJnhAcgz9BnNr.png"/>
                </fig>
              
              <p>Through this operation, the format of each input data is changed to a ternary output of [relative time, sine parameter, cosine parameter]. For input data with different dates and the same time, the values of the sine and cosine parameters are exactly the same. By adding these two parameters, the ability of CNN to extract periodic features can be increased, making the final prediction results of the model more realistic.</p><p>For time series data, smoothing was performed again to eliminate special values.</p><p>During the model training process, the various parameters of the model are continuously adjusted based on the performance of the model after multiple iterations, in order to achieve the best performance. When the actual iteration number is around 40, the model already has high accuracy, and the loss value decreases gradually. <xref ref-type="fig" rid="fig_9">Figure 9</xref> shows the prediction results of the model on the test set when iterating to the 40th generation.</p>
              
                <fig id="fig_9">
                  <label>Figure 9</label>
                  <caption>Model prediction results (Dec. 2022 dataset)</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_ysW_-XBhMzgGoWcN.png"/>
                </fig>
              
              <p>Because the test set date is December, there is a significant difference in actual traffic flow compared to other months due to comprehensive factors such as holidays and weather. However, the prediction results of this model still fit the actual values well, except for a few special values, which have basically matched, and there is no underfitting or overfitting phenomenon. This in-dicates that the model has been trained and can be used for evaluation parameter analysis.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>3. Result</title>
      
        <sec disp-level="level2">
          
            <title>3.1. Analysis of evaluation indicators</title>
          
          <p> <xref ref-type="fig" rid="fig_10">Figure 10</xref> shows the convergence degree of the loss function of the CNN-BiLSTM-AM model trained on different datasets, from left to right in 2022, 2021, and 2020, respectively.</p>
          
            <fig id="fig_10">
              <label>Figure 10</label>
              <caption>CNN-BiLSTM-AM model loss function</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_anCvOmRixULeB79R.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_wuFeSpSYUTCcFD0r.png"/>
            </fig>
          
          <p>It can be seen that for different datasets, the model can fit well, and the loss function con-tinuously decreases with iteration, tends to stabilize after 25 generations, and gradually reduces the learning rate, further refining the model. Finally, the loss function no longer decreases between 35 and 40 generations, and the model training is completed.</p><p> <xref ref-type="fig" rid="fig_11">Figure 11</xref> shows the changes in loss function (loss value) and accuracy (acc) of different models during the training process on the 2022 dataset, where DoLSTM and DoBiLSTM represent double-layer LSTM and BiLSTM, respectively.</p>
          
            <fig id="fig_11">
              <label>Figure 11</label>
              <caption>Performance of each model on the 2022 dataset: (a) Changes in ACC values during each model iteration process; (b) Changes in loss values during each model iteration process; (c) Changes in loss values during iteration of models other than CNN</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_ErU_-Z4ZWRZwNElp.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_1ERYixsfYjUvSwuf.png"/>
            </fig>
          
          <p>From subgraph (a) of <xref ref-type="fig" rid="fig_11">Figure 11</xref>, it can be seen that the accuracy of each model increases rapidly with the iteration process and gradually flattens out, with the CNN BiLSTM-AM model having the highest accuracy.</p><p>From subgraph (b) of <xref ref-type="fig" rid="fig_11">Figure 11</xref>, it can be seen that, except for the CNN model with a relatively high initial loss value, the initial loss values of other models are generally consistent. However, as the iteration process progresses, the loss values of each model rapidly decrease.</p><p>From subgraph (c) of <xref ref-type="fig" rid="fig_11">Figure 11</xref>, it can be seen that models with double-layer BiLSTM or dou-ble-layer LSTM have lower loss values, which indirectly indicates the overfitting defect of these models.</p><p>Due to the limitations of the dataset itself, it is difficult for acc to accurately express the accuracy of the model. In reality, traffic flow prediction models can only predict data that is infinitely close to the true value through training optimization. Therefore, in order to better demonstrate the accuracy of each model, this article defines the accuracy of the model as: if the predicted traffic flow from the test set does not fluctuate more than 80-120\% of the actual traffic flow, it is considered that the model has successfully predicted, and based on this, the accuracy of each model can be obtained (as shown in <xref ref-type="table" rid="table_1">Table 1</xref>).</p><p>According to <xref ref-type="table" rid="table_1">Table 1</xref>, the CNN-BiLSTM-AM model has the highest accuracy, and for models with an added AM mechanism, the double-layer LSTM significantly reduces the accuracy of the model, and the accuracy of a single model is also lower than that of a combination model.</p><p> <xref ref-type="table" rid="table_2">Table 2</xref>, <xref ref-type="table" rid="table_3">Table 3</xref> and <xref ref-type="table" rid="table_4">Table 4</xref> show the evaluation parameters of the CNN-BiLSTM-AM model and other com-binations or single models trained on the 2022, 2021, and 2020 datasets, respectively.</p><p>MAE, MSE, and RMSE in the table represent the evaluation indicators of the training set; Val\_MAE, Val\_MSE, and Val\_RMSE represent the evaluation metrics of the validation set. Other models were used as control groups, and the architecture was modified based on the model presented in this paper. Taking the CNN bilayer BiLSTM-AM model as an example, an additional BiLSTM layer and Dropout layer were added between the BiLSTM and AM layers on the basis of the model presented in this paper. The number of neurons in the additional BiLSTM layer was 128, and the Dropout layer ratio was set to 50\%. The hyperparameters of the other layers were also consistent with the model presented in this paper.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>Accuracy of various models (from high to low)</caption>
              <abstract/>
              <table><tbody><tr><th colspan="1" rowspan="1"><p style="text-align: center">Model</p></th><th colspan="1" rowspan="1"><p style="text-align: center">Accuracy</p></th></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-BiLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">72.31%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-LSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">71.98%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-LSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">70.75%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">BiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">69.69%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">69.22%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">DoBiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">67.67%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">DoLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">67.50%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">LSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">67.10%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoBiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">66.03%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-BiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">64.82%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN</p></td><td colspan="1" rowspan="1"><p style="text-align: center">60.16%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoBiLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">43.81%</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">31.75%</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>Various model evaluation parameters (2022 dataset)</caption>
              <abstract/>
              <table><tbody><tr><th colspan="1" rowspan="1"><p style="text-align: center">Model</p></th><th colspan="1" rowspan="1"><p style="text-align: center">MAE</p></th><th colspan="1" rowspan="1"><p style="text-align: center">MSE</p></th><th colspan="1" rowspan="1"><p style="text-align: center">RMSE</p></th><th colspan="1" rowspan="1"><p style="text-align: center">Val_MAE</p></th><th colspan="1" rowspan="1"><p style="text-align: center">Val_MSE</p></th><th colspan="1" rowspan="1"><p style="text-align: center">Val_RMSE</p></th></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-BiLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0741</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0104</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1020</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0860</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0182</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1349</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoBiLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0723</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0100</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1000</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1455</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0453</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.2128</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoLSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0738</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0102</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1010</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1858</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0609</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.2468</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-LSTM-AM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0748</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0105</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1025</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0872</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0192</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1386</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoBiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0752</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0106</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1030</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0872</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0195</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1396</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-BiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0756</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0107</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1034</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0883</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0193</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1389</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-DoLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0748</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0105</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1025</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0866</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0192</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1386</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN-LSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0753</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0106</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1030</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0872</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0187</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1367</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">CNN</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0765</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0111</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1054</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0868</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0188</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1371</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">DoBiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0761</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0109</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1044</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0940</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0233</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1526</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">BiLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0742</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0104</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1020</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0886</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0204</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1428</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">DoLSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0762</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0109</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1044</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0943</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0233</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1526</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">LSTM</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0754</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0107</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1034</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0946</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.0229</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.1513</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>From the table, it can be seen that for the three datasets, the CNN-BiLSTM-AM model per-forms relatively stable with small changes in evaluation parameters, indicating strong applicability of the model.</p><p>Taking the 2022 dataset as an example, <xref ref-type="table" rid="table_2">Table 2</xref> shows that adding double-layer BiLSTM or double-layer LSTM to the composite model can increase the fitting degree of the data to a certain extent. For example, the MSE of the CNN double-layer BiLSTM-AM model is slightly lower than that of the CNN BiLSTM-AM model, but at the same time, for the Val of the CNN double-layer BiLSTM-AM model, the MSE is much higher than that of the CNN-BiLSTM-AM model, indi-cating that the double-layer BiLSTM or double-layer LSTM structure leads to overfitting of the model and is not suitable for actual traffic flow prediction models.</p><p>Replacing the LSTM layer with the BiLSTM layer and adding an AM layer to the model both reduce the evaluation metrics of the training and validation sets, indicating that BiLSTM out-performs LSTM in processing time series data and combining with CNN, AM, and other models. Additionally, the addition of the AM layer enhances the predictive performance of the model.</p><p>Compared with the combined model, the single-model CNN, LSTM, and BiLSTM all perform poorly. CNN only focuses on the extraction of data features, ignoring the time series of data, which makes the evaluation indicators of its training set and verification set high. Although LSTM and BiLSTM value the temporal nature of data, they lack the ability to extract features. This results in both performing well on the training set and experiencing severe overfitting and mediocre performance on the validation set, making it difficult to achieve predictive results. In contrast, BiLSTM has a slightly lower overfitting degree than LSTM, and single-layer LSTM and BiLSTM have a slightly lower overfitting degree than double-layer LSTM and BiLSTM.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>Various model evaluation parameters (2021 dataset)</caption>
              <abstract/>
              <table><tbody><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Model</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">RMSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_RMSE</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0762</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0109</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1044</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0860</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0180</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1342</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0736</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0102</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1010</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.1682</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0546</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.2337</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0742</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0103</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1015</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.1925</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0645</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.2540</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0752</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0106</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1030</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0876</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0183</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1353</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0763</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0109</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1044</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0877</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0193</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1389</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0757</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0875</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0190</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1378</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0759</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0874</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0194</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1393</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0765</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0109</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1044</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0881</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0182</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1349</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0815</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0121</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1100</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0879</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0192</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1386</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0757</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0108</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1039</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0940</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0232</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1523</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0741</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0104</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1020</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0892</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0207</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1439</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0772</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0112</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1058</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0945</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0234</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1530</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0756</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0939</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0226</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1503</span></p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>Various model evaluation parameters (2020 dataset)</caption>
              <abstract/>
              <table><tbody><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Model</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">RMSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_RMSE</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0746</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0105</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1025</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0854</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0181</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1345</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0732</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0102</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1010</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.1523</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0474</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.2177</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0736</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0103</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1015</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.1672</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0528</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.2298</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0751</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0105</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1025</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0910</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0185</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1360</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0752</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0866</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0189</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1375</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0750</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0105</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1025</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0877</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0192</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1386</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0776</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0111</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1054</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0882</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0193</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1389</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0757</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0882</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0187</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1367</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0769</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0112</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1058</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0876</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0194</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1393</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0750</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0107</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1034</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0945</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0232</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1523</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0747</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0106</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1030</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0926</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0222</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1490</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0762</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0109</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1044</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0944</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0234</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1530</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0758</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0108</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1039</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0932</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.0225</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.1500</span></p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Both the training and validation sets show that the proposed model can achieve lower MAE and MSE values, indicating good training performance, high prediction accuracy, and strong applicability. Moreover, compared with a single model, the CNN-BiLSTM-AM model can take into account both the bidirectional time series and feature extraction, and can also focus on more important features in the time series, which is impossible for any single model.</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>3.2. Analysis of evaluation indicators</title>
          
          <p>Robustness, where robustness is a transliteration of Robust, meaning robust and robust. It is also the ability of the system to survive in abnormal and dangerous situations. In a neural network model, robustness can be understood as the model's tolerance to data changes. Huber provides three requirements for robustness from the perspective of robust statistics.</p><p>1) The model has high accuracy or effectiveness.</p><p>2) For small deviations in model assumptions, it only has a minor impact on the performance of the algorithm.</p><p>3) For large deviations in model assumptions that do not have a catastrophic impact on al-gorithm performance.</p><p>For 1), this article has been demonstrated through evaluation indicators in 3.1, so this section will focus on analyzing 2) and 3) to evaluate the robustness of the model (using the 2022 dataset as an example).</p>
          
            <sec disp-level="level3">
              
                <title>3.2.1 Small deviation experiment</title>
              
              <p>To measure the impact of small deviations on the model, this article adds simple noise to all time series data in the 2022 dataset, that is, adding a random integer with an interval of -5 to 5 to each data point, and ensuring that each data point is still greater than 0 after addition. Take the data with the added noise as input, train the model, and analyze the changes in the evaluation indicators of each model compared to the original evaluation indicators. Take two decimal places as a percentage, with positive values representing the increase compared to the original value and negative values representing the decrease compared to the original value.</p>
              
                <table-wrap id="table_5">
                  <label>Table 5</label>
                  <caption>Changes in evaluation indicators of various models with small deviations (2022 dataset)</caption>
                  <abstract/>
                  <table><tbody><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Model</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">RMSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_RMSE</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.54%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.96%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-9.80%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.23%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">4.40%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">20.98%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">2.07%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">3.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">17.32%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">15.12%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">18.10%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">42.54%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.54%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.98%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">9.90%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.65%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.97%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">14.04%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.80%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.95%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">9.75%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.38%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.54%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-7.35%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.20%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.89%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">13.75%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.57%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-2.56%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-16.00%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.59%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-2.80%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-16.73%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.59%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.52%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-7.21%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">4.68%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">6.67%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">25.83%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">3.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.56%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">12.49%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.13%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.23%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.60%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-12.65%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">3.92%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">6.31%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">25.12%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">5.18%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">9.04%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">30.07%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.13%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.43%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.43%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-6.56%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.21%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1.92%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">13.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">3.16%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">7.35%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">27.11%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.39%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.92%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">9.59%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.74%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.43%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-6.56%</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.53%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.93%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">9.64%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.74%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.31%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-11.45%</span></p></td></tr></tbody></table>
                </table-wrap>
              
              <p>As shown in <xref ref-type="table" rid="table_5">Table 5</xref>, the CNN-BiLSTM-AM model has a small variation amplitude when facing small deviations in input data, and can still ensure the accuracy of the model.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.2.2 Large deviation experiment</title>
              
              <p>To measure the impact of large deviations on the model, this article adds simple noise to all time series data in the 2022 dataset, which means adding a random integer with an interval of -100 to 100 to each data point. It is not guaranteed that each data point will still be greater than 0 after addition. Take the data with the added noise as input, train the model, and analyze the changes in the evaluation indicators of each model compared to the original evaluation indicators. Take two decimal places as a percentage, with positive values representing the increase compared to the original value and negative values representing the decrease compared to the original value.</p>
              
                <table-wrap id="table_6">
                  <label>Table 6</label>
                  <caption>Changes in evaluation indicators of various models with large deviations (2022 dataset)</caption>
                  <abstract/>
                  <table><tbody><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Model</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">RMSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MAE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_MSE</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Val_RMSE</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.74%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">13.46%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">36.69%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">9.30%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0.00%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">14.11%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">17.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">41.23%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">19.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">23.18%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">48.15%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.25%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">13.73%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">37.05%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-7.75%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-13.63%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-36.92%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM-AM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">13.37%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">17.14%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">41.40%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.93%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.61%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-12.69%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.90%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">16.04%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">40.05%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">8.94%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-2.56%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-16.00%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">10.58%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.15%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">34.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">7.25%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.04%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-10.20%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">14.84%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">20.00%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">44.72%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">10.05%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">0.52%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">7.21%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN-LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.95%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">15.09%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">38.85%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">8.14%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-4.28%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-20.69%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">CNN</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.81%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">14.41%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">37.96%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">8.64%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-1.60%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-12.65%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoBiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.30%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.84%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">35.83%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">6.91%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-3.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-19.65%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">BiLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">13.46%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">36.69%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">9.14%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-0.49%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-7.00%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">DoLSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.47%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">15.60%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">39.50%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">5.94%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-5.15%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-22.69%</span></p></td></tr><tr><td colspan="1" rowspan="1" colwidth="237"><p style="text-align: center"><span style="font-family: Times New Roman, serif">LSTM</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11.27%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12.15%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">34.86%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">6.45%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">-3.93%</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">-19.82%</span></p></td></tr></tbody></table>
                </table-wrap>
              
              <p>According to <xref ref-type="table" rid="table_6">Table 6</xref>, it can be seen that the CNN-BiLSTM-AM model has a relatively small change in amplitude when facing large deviations in input data, and can still ensure the normal operation of the model.</p><p>In summary, the CNN-BiLSTM-AM model has high accuracy and can ensure its accuracy is not greatly affected when there are small errors in the input data. It can still operate normally when there are large deviations in the input data. Therefore, its robustness is good compared to other models, making it a mature and robust model.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>4. Conclusion</title>
      <p>In view of the characteristics of traffic flow series, this paper proposes a combined model of CNN, BiLSTM, and AM, which combines the advantages of CNN, BiLSTM, and AM. The ex-ample verification shows that the model performs well in three sets of data sets. Compared with other single models and similar combined models, the evaluation index of the model is more excellent, and the robustness is good. It is a robust and mature model. Replacing the LSTM layer with the BiLSTM layer and adding the AM layer both improve the prediction accuracy and ap-plicability of this model. Compared with other models, this model can better process traffic flow data.</p><p>However, this model still has many shortcomings. Due to the limitations of the dataset, this model only considers time as a feature. However, in reality, weather, holidays, other road condi-tions, emergencies, and even the daily flight situation of Heathrow Airport near the detector may affect the traffic flow of that road segment at a single time. These factors could be quantified and analyzed as input features for extraction, followed by weighted reprocessing using AM. For example, quantifying weather factors using one-hot encoding as one of the inputs to the model.</p><p>At the same time, the dataset can also be expanded by obtaining data from other detectors on the expressway and the location of the detector map, in order to simulate the traffic flow situation of the entire section of the expressway. By analyzing and predicting the traffic flow situation of each section of the expressway in real time, the applicability of the model can be further enhanced, and the practical application ability of the model can be further enhanced. Increase the spatial dependency of the model. The improved model can become an important basis for traffic man-agement departments to manage highways and also participate in road construction.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      <p></p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare that they have no conflicts of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>136</volume>
          <page-range>105327</page-range>
          <issue/>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Zhen Jie</given-names>
              <surname>Zheng</surname>
            </name>
            <name>
              <given-names>Zheng Li</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>Li Yun</given-names>
              <surname>Zhu</surname>
            </name>
            <name>
              <given-names>Hai</given-names>
              <surname>Jiang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.aap.2019.105327</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Determinants of the congestion caused by a traffic accident in urban road networks</article-title>
          <source>Accid. Anal. Prev.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>193–213</page-range>
          <issue>3</issue>
          <year>2009</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Y.</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>Y. C.</given-names>
              <surname>Liu</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/18128600902823216</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Traffic forecasting using least squares support vector machines</article-title>
          <source>Transportmetrica</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="conference-proceedings">
          <volume>2713</volume>
          <page-range/>
          <issue>1</issue>
          <year>2023</year>
          <publisher-name>AIP Publishing</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>K. A.</given-names>
              <surname>Momin</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Barua</surname>
            </name>
            <name>
              <given-names>M. S.</given-names>
              <surname>Jamil</surname>
            </name>
            <name>
              <given-names>O. F.</given-names>
              <surname>Hamim</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1063/5.0129721</pub-id>
          <article-title>Short duration traffic flow prediction using Kalman Filtering</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>151-177</page-range>
          <issue>12</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Wen Wei</given-names>
              <surname>Yue</surname>
            </name>
            <name>
              <given-names>Chang Le</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>Guo Qiang</given-names>
              <surname>Mao</surname>
            </name>
            <name>
              <given-names>Nan</given-names>
              <surname>Cheng</surname>
            </name>
            <name>
              <given-names>Di</given-names>
              <surname>Zhou</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.23919/JCC.2021.12.010</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Evolution of road traffic congestion control: A survey from perspective of sensing, communication, and computation</article-title>
          <source>China Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>2681</page-range>
          <issue>4</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Wei Qing</given-names>
              <surname>Zhuang</surname>
            </name>
            <name>
              <given-names>Yong Bo</given-names>
              <surname>Cao</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app13042681</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Short-term traffic flow prediction based on a K-Nearest Neighbor and bidirectional Long Short-Term Memory model</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>1-9</page-range>
          <issue/>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S Vasantha</given-names>
              <surname>Kumar</surname>
            </name>
            <name>
              <given-names>Lelitha</given-names>
              <surname>Vanajakshi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s12544-015-0170-8</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Short-term traffic flow prediction using seasonal ARIMA model with limited input data</article-title>
          <source>Eur. Transp. Res. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>94051–94062</page-range>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H. L.</given-names>
              <surname>Zheng</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>Y. F.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>Z. Q.</given-names>
              <surname>Yan</surname>
            </name>
            <name>
              <given-names>T. H.</given-names>
              <surname>Li</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2022.3204036</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>GCN-GAN: Integrating graph convolutional network and generative adversarial network for traffic flow prediction</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="conference-proceedings">
          <volume>1972</volume>
          <page-range>012107</page-range>
          <issue>1</issue>
          <year>2021</year>
          <publisher-name>IOP Publishing</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>Z. Z.</given-names>
              <surname>Wu</surname>
            </name>
            <name>
              <given-names>M. X.</given-names>
              <surname>Huang</surname>
            </name>
            <name>
              <given-names>A. P.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>Z. X.</given-names>
              <surname>Lan</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi"/>
          <article-title>Traffic prediction based on GCN-LSTM model</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range>365–371</page-range>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>K.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>S. X.</given-names>
              <surname>Yuan</surname>
            </name>
            <name>
              <given-names>Z. Z.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>J. X.</given-names>
              <surname>Wang</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/ICITE56321.2022.10101481</pub-id>
          <article-title>Research on urban road mean speed prediction method based on LSTM-CNN model</article-title>
          <source>2022 IEEE 7th International Conference on Intelligent Transportation Engineering (ICITE), Beijing, China</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range>1-5</page-range>
          <issue/>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M. M.</given-names>
              <surname>Cao</surname>
            </name>
            <name>
              <given-names>V. O. K.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>V. W. S.</given-names>
              <surname>Chan</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/VTC2020-Spring48590.2020.9129440</pub-id>
          <article-title>A CNN-LSTM model for traffic speed prediction</article-title>
          <source>2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring), Antwerp, Belgium</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>1087-1111</page-range>
          <issue>04</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Xiang Dong</given-names>
              <surname>Ran</surname>
            </name>
            <name>
              <given-names>Zhi Guang</given-names>
              <surname>Shan</surname>
            </name>
            <name>
              <given-names>Yong</given-names>
              <surname>Shi</surname>
            </name>
            <name>
              <given-names>Chuang</given-names>
              <surname>Lin</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1142/S0219622019500202</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Short-term travel time prediction: A spatiotemporal deep learning approach</article-title>
          <source>Int. J. Inf. Technol. Decis. Mak.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>151</volume>
          <page-range>107398</page-range>
          <issue/>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Serkan</given-names>
              <surname>Kiranyaz</surname>
            </name>
            <name>
              <given-names>Onur</given-names>
              <surname>Avci</surname>
            </name>
            <name>
              <given-names>Osama</given-names>
              <surname>Abdeljaber</surname>
            </name>
            <name>
              <given-names>Turker</given-names>
              <surname>Ince</surname>
            </name>
            <name>
              <given-names>Moncef</given-names>
              <surname>Gabbouj</surname>
            </name>
            <name>
              <given-names>Daniel J</given-names>
              <surname>Inman</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.ymssp.2020.107398</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>1D convolutional neural networks and applications: A survey</article-title>
          <source>Mech. Syst. Signal Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>2677</volume>
          <page-range>1331-1340</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Asiye</given-names>
              <surname>Baghbani</surname>
            </name>
            <name>
              <given-names>Nizar</given-names>
              <surname>Bouguila</surname>
            </name>
            <name>
              <given-names>Zachary</given-names>
              <surname>Patterson</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1177/03611981221112673</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Short-term passenger flow prediction using a bus network graph convolutional long short-term memory neural network model</article-title>
          <source>Transp. Res. Rec.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>57</volume>
          <page-range>114-119</page-range>
          <issue>6</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Yu Xiu</given-names>
              <surname>Hua</surname>
            </name>
            <name>
              <given-names>Zhi Feng</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>Rong Peng</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>Xian Fu</given-names>
              <surname>Chen</surname>
            </name>
            <name>
              <given-names>Zhi Ming</given-names>
              <surname>Liu</surname>
            </name>
            <name>
              <given-names>Hong Gang</given-names>
              <surname>Zhang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/MCOM.2019.1800155</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Deep learning with long short-term memory for time series prediction</article-title>
          <source>IEEE Commun. Mag.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>112</volume>
          <page-range>62-77</page-range>
          <issue/>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Toon</given-names>
              <surname>Bogaerts</surname>
            </name>
            <name>
              <given-names>Antonio D</given-names>
              <surname>Masegosa</surname>
            </name>
            <name>
              <given-names>Juan S</given-names>
              <surname>Angarita-Zapata</surname>
            </name>
            <name>
              <given-names>Enrique</given-names>
              <surname>Onieva</surname>
            </name>
            <name>
              <given-names>Peter</given-names>
              <surname>Hellinckx</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.trc.2020.01.010</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>A graph CNN-LSTM neural network for short and long-term traffic forecasting based on trajectory data</article-title>
          <source>Transp. Res. Part C Emerg. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>76</volume>
          <page-range/>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Yang</surname>
            </name>
            <name>
              <given-names>H. L.</given-names>
              <surname>Yu</surname>
            </name>
            <name>
              <given-names>Z.</given-names>
              <surname>Zheng</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1049/IET-WSS.2019.0106</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Kalman Filter-based CNN-BiLSTM-ATT model for traffic flow prediction</article-title>
          <source>Comput. Mater. Contin.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range>3285–3292</page-range>
          <issue/>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Siami-Namini</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Tavakoli</surname>
            </name>
            <name>
              <given-names>A. S.</given-names>
              <surname>Namin</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/BigData47090.2019.9005997</pub-id>
          <article-title>The performance of LSTM and BiLSTM in forecasting time series</article-title>
          <source>2019 IEEE International Conference on Big Data, Los Angeles, CA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume/>
          <page-range/>
          <issue/>
          <year>2014</year>
          <person-group person-group-type="author">
            <name>
              <given-names>D.</given-names>
              <surname>Bahdanau</surname>
            </name>
            <name>
              <given-names>K.</given-names>
              <surname>Cho</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Bengio</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1409.0473</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Neural machine translation by jointly learning to align and translate</article-title>
          <source>arXiv preprint arXiv:1409.0473</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range>2048–2057</page-range>
          <issue/>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <given-names>K.</given-names>
              <surname>Xu</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Ba</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Kiros</surname>
            </name>
            <name>
              <given-names>K.</given-names>
              <surname>Cho</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Courville</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Salakhudinov</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Zemel</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Bengio</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1049/IET-WSS.2019.0106</pub-id>
          <article-title>Show, attend and tell: Neural image caption generation with visual attention</article-title>
          <source>Proceedings of the 32nd International Conference on Machine Learning</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>2340-2350</page-range>
          <issue>9</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Jin Jun</given-names>
              <surname>Tang</surname>
            </name>
            <name>
              <given-names>Fang</given-names>
              <surname>Liu</surname>
            </name>
            <name>
              <given-names>Ya Jie</given-names>
              <surname>Zou</surname>
            </name>
            <name>
              <given-names>Wei Bin</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>Yin Hai</given-names>
              <surname>Wang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TITS.2016.2643005</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>An improved fuzzy neural network for traffic speed prediction considering periodic characteristic</article-title>
          <source>IEEE Trans. Intell. Transp. Syst.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>