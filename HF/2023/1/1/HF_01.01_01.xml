<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">HF</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Healthcraft Frontiers</journal-title>
        <abbrev-journal-title abbrev-type="issn">Healthcraft. Front.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">HF</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">3005-799X</issn>
      <issn publication-format="print">3005-7981</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-o0qrcVyd0nS_xUoYcZ5W8h8u8T5UlDSP</article-id>
      <article-id pub-id-type="doi">10.56578/hf010101</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Enhancing Fall Risk Assessment in the Elderly: A Study Utilizing Transfer Learning in an Improved EfficientNet Network with the Gramian Angular Field Technique</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1,2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-2203-8001</contrib-id>
          <name>
            <surname>Li</surname>
            <given-names>Congcong</given-names>
          </name>
          <email>jdlcc@hebau.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-4865-3882</contrib-id>
          <name>
            <surname>Cai</surname>
            <given-names>Yueting</given-names>
          </name>
          <email>20217060832@pgs.hebau.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2808-4432</contrib-id>
          <name>
            <surname>Habeeb</surname>
            <given-names>Laith Jaafer</given-names>
          </name>
          <email>Laith.J.Habeeb@uotechnology.edu.iq</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_4">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-6696-277X</contrib-id>
          <name>
            <surname>Rahman</surname>
            <given-names>Atta-Ur</given-names>
          </name>
          <email>aaurrahman@iau.edu.sa</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_5">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6619-3402</contrib-id>
          <name>
            <surname>Ritzkal</surname>
            <given-names/>
          </name>
          <email>ritzkal@ft.uika-bogor.ac.id</email>
        </contrib>
        <aff id="aff_1">School of Information Science and Technology, Hebei Agricultural University, 071001 Baoding, China</aff>
        <aff id="aff_2">Hebei Key Laboratory of Agricultural Big Data, Hebei Agricultural University, 071001 Baoding, China</aff>
        <aff id="aff_3">Training and Workshop Center, University of Technology-Iraq, 10001 Baghdad, Iraq</aff>
        <aff id="aff_4">College of Computer Science and Information Technology, Imam Abdulrahman Bin Faisal University, 31441 Dammam, Saudi Arabia</aff>
        <aff id="aff_5">Informatics Department, Science &amp; Engineering Faculty, Universitas Ibn Khaldun Bogor, 16162 Bogor, Indonesia</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>30</day>
        <month>11</month>
        <year>2023</year>
      </pub-date>
      <volume>1</volume>
      <issue>1</issue>
      <fpage>1</fpage>
      <lpage>14</lpage>
      <page-range>1-14</page-range>
      <history>
        <date date-type="received">
          <day>11</day>
          <month>09</month>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <day>22</day>
          <month>11</month>
          <year>2023</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Â©2023 by the author(s)</copyright-statement>
        <copyright-year>2023</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p><p style="text-align: justify">Recent years have seen a significant increase in the incidence of falls among the elderly, leading to accidental injuries and fatalities. This trend underscores the critical need for accurate fall risk assessment, a major concern for public health and safety. In addressing this challenge, a novel approach has been developed, leveraging a pressure sensor placed on the foot's sole to gather gait data from elderly individuals. This method provides a precise analysis of gait stability on a daily basis. The research introduced here utilizes the gramian angular summation field (GASF) technique for converting this data into two-dimensional images, which are then processed using an enhanced EfficientNet model. The innovation lies in the integration of a convolutional block attention module (CBAM) into this model, resulting in a CBAM-EfficientNet algorithm. This approach includes freezing the first four stages of the EfficientNet model, focusing training on the deeper layers that incorporate CBAM. This strategy is aimed at augmenting the network's ability to extract critical features from foot pressure data, consequently improving the accuracy of fall risk classification. Experimental evaluation of this optimized model demonstrates a classification accuracy of 98.5% and a sensitivity of 99.0%, indicating its practical efficacy and strong generalization capacity. These findings reveal that the methodology significantly enhances the classification of plantar pressure data, offering valuable support in medical diagnosis and has substantial practical implications.</p></p></abstract>
      <kwd-group>
        <kwd>EfficientNet</kwd>
        <kwd>Convolutional block attention module</kwd>
        <kwd>Gram angular field algorithm</kwd>
        <kwd>Wearable devices</kwd>
        <kwd>Fall risk</kwd>
        <kwd>Transfer learning</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="5"/>
        <fig-count count="12"/>
        <table-count count="6"/>
        <ref-count count="23"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p style="text-align: justify">Global population aging presents a significant challenge, with China experiencing particularly rapid and profound demographic shifts. As per international standards, societies with over 7%-14% of the population aged 65 and above are considered aging. Recent statistics place China's aging population in the upper echelons globally, with over 190 million individuals aged 65 and above in 2022, surpassing the 14% threshold and marking China's entry into an advanced aging society. This demographic shift has heightened societal focus on the health issues of the elderly, particularly the risk of falls (<xref ref-type="bibr" rid="ref_6">Liang et al., 2019</xref>). Accurate fall risk assessment is paramount for enhancing the health and safety of the elderly. Existing research in this domain underscores the need for a comprehensive fall prevention assessment system and effective fall prevention information management strategies to mitigate fall incidences. Clinical assessments traditionally rely on fall risk scales and tests (<xref ref-type="bibr" rid="ref_7">Liang et al., 2015</xref>; <xref ref-type="bibr" rid="ref_15">Shumway-Cook et al., 2000</xref>). However, these methods necessitate medical professionals' involvement and are impractical for daily life monitoring.</p><p style="text-align: justify">Wearable sensors, especially plantar pressure sensors, offer an innovative solution, unencumbered by environmental constraints and boasting substantial concealment, making them ideal for continuous motion monitoring of the elderly. Notable contributions in this field include the system leveraging plantar pressure sensors of <xref ref-type="bibr" rid="ref_22">Yu et al. (2020)</xref> for inversion detection, and the wearable plantar pressure measurement and analysis system (WPPFMA) of <xref ref-type="bibr" rid="ref_23">Zhao et al. (2020)</xref>, and <xref ref-type="bibr" rid="ref_11">Peng et al. (2021)</xref> use of plantar pressure signals in gait health analysis. Such studies highlight the significant potential of plantar pressure data in gait analysis, though its application in fall risk assessment remains underexplored. <xref ref-type="bibr" rid="ref_9">Montanini et al. (2017)</xref> proposed an approach using three pressure sensors on the sole, setting a threshold at one-third of the maximum pressure value during activity. The sensors' analog signals are translated into binary data, effectively delineating the gait cycle phase. <xref ref-type="bibr" rid="ref_4">Gao &amp;amp; Zhao (2021)</xref> analyzed plantar pressure data from 48 subjects to study gait line symmetry and temporal consistency, achieving an 87.5% accuracy on their test dataset.</p><p style="text-align: justify">In the realm of fall risk assessment using plantar pressure data, <xref ref-type="bibr" rid="ref_6">Liang et al. (2019)</xref> demonstrated the potential of raw plantar force data, applying the convolutional long short-term memory (ConvLSTM) model with a notable classification accuracy of 94%. Similarly, <xref ref-type="bibr" rid="ref_14">Shalin et al. (2021)</xref> explored gait freezing identification through features extracted from plantar pressure data, utilizing long short-term memory (LSTM) networks. Their model exhibited an average sensitivity of 82.1% and specificity of 89.5%. Further advancing the field, <xref ref-type="bibr" rid="ref_3">Chan et al. (2023)</xref> developed an intelligent shoe system integrating pressure and inertial sensors. They crafted a hybrid model combining convolutional neural network (CNN) and recurrent neural network (RNN) techniques, achieving a remarkable F1-score of 99.8%. These studies collectively highlight plantar pressure sensors' concealment and comfort, affirming their suitability for everyday fall risk monitoring.</p><p style="text-align: justify">Despite these advancements, challenges persist with the substantial data size generated by plantar pressure sensors, imposing significant demands on data transmission and processing. Direct use of raw sensor data as input signals for fall risk detection models often leads to high computational costs and complex model architectures, hindering mobile deployment. Moreover, the nascent stage of research in this domain means that robust feature extraction from plantar pressure signals and the enhancement of model accuracy in fall risk detection are ongoing concerns.</p><p style="text-align: justify">Addressing these issues requires the development of robust fall risk detection methods based on plantar pressure signals that also prioritize data compactness. This necessitates specific data processing and feature extraction techniques tailored for plantar pressure sensor data. In response, a model has been developed utilizing deep learning techniques. This model introduces a CBAM-EfficientNet technique, based on the EfficientNet model and augmented with the CBAM. It processes plantar pressure data transformed into the GASF format. The inclusion of the CBAM module notably enhances the network's feature extraction capabilities from plantar pressure data. Practical transfer learning is then employed to expedite network training and improve classification performance. Experimental evaluations have demonstrated the model's effectiveness in reliably extracting characteristics from plantar pressure signals.</p>
    </sec>
    <sec sec-type="">
      <title>2. Materials and methods</title>
      
        <sec>
          
            <title>2.1. Data collection and data label</title>
          
          <p>For this study, plantar pressure sensors were placed in the shoes of 24 elderly individuals residing in or near nursing homes to capture human plantar pressure signals. These individuals, all aged 65 or above, were selected excluding those with significant mobility impairments or conditions impacting gait. The aim was to assess fall risk through a comprehensive walking test, focusing on gait patterns and potential indicators of fall risk during various walking tasks.</p><p>The experimental setup was straightforward, requiring no special arrangements. The commencement and conclusion of each walking test were signaled by the recorder. Participants were instructed to walk at a comfortable, regular pace on flat ground, following a straight path or executing turns. Each subject repeated the walking experiment 3-4 times. The human foot was divided into five distinct areas for data analysis: the first toe (T1), the second to fifth toes (T2-5), metatarsals (M1-5), midfoot (MF), and heel (HM, HL) as delineated in <xref ref-type="fig" rid="fig_1">Figure 1</xref> (<xref ref-type="bibr" rid="ref_17">Taylor et al., 2004</xref>). However, during data collection, a significant number of missing values were observed in the T2-5 region, leading to the decision to exclude this data and focus only on the remaining foot areas.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Plantar partition</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_e90mUeQnn-oJ5iod.jpeg"/>
            </fig>
          
          <p>In the data labeling phase, a supervised learning approach was employed (<xref ref-type="fig" rid="fig_2">Figure 2</xref>). The Timed Up and Go Test (TUGT) (<xref ref-type="bibr" rid="ref_12">Podsiadlo &amp;amp; Richardson, 1991</xref>) was initially used to categorize participants. Following the classification criteria set by <xref ref-type="bibr" rid="ref_10">Pardoel et al. (2021)</xref>, 15 individuals were identified as high-risk, 5 as low-risk, and 4 were placed in a 'grey zone' where TUGT alone did not yield a clear classification. Subsequently, those in the grey zone underwent further assessment using the Tinetti Balance and Gait Scale (<xref ref-type="bibr" rid="ref_1">Beck, 1999</xref>; <xref ref-type="bibr" rid="ref_13">RaÃ®che et al., 2000</xref>; <xref ref-type="bibr" rid="ref_18">Tinetti, 1986</xref>). The culmination of these assessments resulted in a final labeling of the data, with 17 volunteers classified as low risk and 7 as high risk for falling.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Data labeling flow chart</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_UjpmcC6hQ1t0X0Ax.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>2.2. Processing of  plantar pressure data</title>
          
          <p style="text-align: justify">In the processing of plantar pressure data, the inherent one-dimensional nature of sensor signals poses a challenge for deep learning methods, which are more adept at handling multi-dimensional data. To address this, <xref ref-type="bibr" rid="ref_20">Wang &amp;amp; Oates (2015)</xref> introduced a novel approach of converting one-dimensional time series into two-dimensional images via the Gramian Angular Field (GAF) algorithm. This method effectively preserves the time-dependence and relevance of the original data.</p><p style="text-align: justify">The plantar pressure sequence data were divided utilizing the sliding window method (<xref ref-type="bibr" rid="ref_5">Li et al., 2020</xref>; <xref ref-type="bibr" rid="ref_8">Liu et al., 2022</xref>), with each window set to a duration of 1 second and an overlap rate of 50%. This approach was chosen to ensure the intact preservation of gait characteristics in the plantar pressure data. Subsequently, the data format was transformed by the GAF algorithm, which utilizes a polar coordinate system, derived from the Kerr matrix, instead of a Cartesian system. The GAF algorithm's implementation involved three critical steps (<xref ref-type="bibr" rid="ref_16">Tan &amp;amp; Le, 2019</xref>):</p><p style="text-align: justify">Normalization: The time series<italic> X = </italic>{<italic>x</italic><sub>1</sub><italic>, x</italic><sub>2</sub><italic>,â¦x<sub>N</sub></italic>}, containing <italic>N</italic> real-valued observations, underwent normalization to ensure that <italic>X</italic> ranged between [-1, 1].</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mlb97tx5vb">
                <mml:msubsup>
                  <mml:mi>x</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>â</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>max</mml:mo>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mi>X</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>min</mml:mo>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mi>X</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>max</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>â</mml:mo>
                    <mml:mo>min</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mi>X</mml:mi>
                    <mml:mi>X</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p style="text-align: justify">Polar coordinate conversion: The normalized one-dimensional time series maintained its absolute temporal relationship using polar coordinates, where values were encoded as angle cosines and timestamps as radii.</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="ms3jni5xr4">
                <mml:mrow>
                  <mml:mo>{</mml:mo>
                  <mml:mo fence="true" stretchy="true" symmetric="true"/>
                  <mml:mtable columnspacing="1em" rowspacing="4pt">
                    <mml:mtr>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>Ï</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mo>â¡</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>â</mml:mo>
                        <mml:mo>â¤</mml:mo>
                        <mml:mo>â¤</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>â</mml:mo>
                        <mml:mi>arccos</mml:mi>
                        <mml:mi>X</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>1</mml:mn>
                        <mml:mn>1</mml:mn>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>r</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msub>
                          <mml:mi>t</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>â</mml:mo>
                        <mml:mfrac>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mi>N</mml:mi>
                        </mml:mfrac>
                        <mml:mi>N</mml:mi>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p style="text-align: justify">where <italic>x<sub>i</sub></italic> is each observation in the time series <italic>X</italic>, <italic>t<sub>i</sub></italic> is the corresponding timestamp, <italic>N</italic> represents the total length of the timestamp. When these normalized values are mapped into a polar coordinate system, the cosine value of each data point, previously normalized to the range [-1, 1], is interpreted within the angular boundaries of [0, Ï].</p><p style="text-align: justify">GASF: The temporal correlation between different time intervals was angularly identified, following the transformation of the rescaled time series into a polar coordinate system. The GAF is defined by calculating the sum of trigonometric functions between each sample point in this new coordinate system.</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mbujcvvibm">
                <mml:mi>G</mml:mi>
                <mml:mi>A</mml:mi>
                <mml:mi>S</mml:mi>
                <mml:mi>F</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:mo>{</mml:mo>
                  <mml:mo fence="true" stretchy="true" symmetric="true"/>
                  <mml:mtable columnalign="center center center center" columnspacing="1em" rowspacing="4pt">
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mo>â¦</mml:mo>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:mi>cos</mml:mi>
                        <mml:mo>â¡</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>Ï</mml:mi>
                            <mml:mi>N</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p><xref ref-type="fig" rid="fig_3">Figure 3</xref> illustrates the complete process of converting the rescaled time series into a coded mapping in polar coordinates. The initial step involved normalizing the time series using Eqs. (1) and (2), followed by a conversion to a polar coordinate system. The final images were obtained using the GAF method, as detailed in Eq. (3). The result of this process was the generation of 2085 high-risk samples and 826 low-risk samples, classified based on the processed plantar pressure data.</p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>GASF</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_l_oV5T7N1mAnEyyU.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>2.3. Fall risk assessment modeling algorithm</title>
          
          
            <sec>
              
                <title>2.3.1 Efficientnet</title>
              
              <p>CNNs have been recognized for their capacity to autonomously extract features from images through convolutional kernel manipulation. The enhancement of a networkâs depth, width, and image resolution typically facilitates the acquisition of multiscale features. However, increasing network depth can lead to complexities like vanishing gradients, while augmenting network width and image resolution significantly elevates computational and memory demands. EfficientNet (<xref ref-type="bibr" rid="ref_21">Woo et al., 2018</xref>), an innovative architecture, was developed to balance these aspects by uniformly scaling the networkâs depth, width, and resolution with fixed scaling factors. With variants ranging from B0 to B9, EfficientNet allows for model parameter adjustments to suit diverse tasks and computational resources. For the task of fall risk classification using plantar pressure data, the EfficientNetB0 architecture was selected. This architecture primarily comprises Mobile Inverted Convolution (MBConv) modules, utilizing 3Ã3 and 5Ã5 convolutional kernels. Each MBConv module includes two 1Ã1 convolutional layers (Conv), a depthwise separable convolutional layer (DWConv), and a Squeeze-and-Excitation (SE) module, as illustrated in <xref ref-type="fig" rid="fig_4">Figure 4</xref>. The structure of EfficientNet is detailed in <xref ref-type="table" rid="table_1">Table 1</xref>, showcasing its ability to effectively extract and utilize features from plantar pressure data for fall risk classification.</p>
              
                <table-wrap id="table_1">
                  <label>Table 1</label>
                  <caption>
                    <title>Efficientnet network architecture</title>
                  </caption>
                  <table><tbody><tr><td colspan="1" rowspan="1"><p>Stage I</p></td><td colspan="1" rowspan="1"><p>Operator F</p></td><td colspan="1" rowspan="1"><p>Resolution H*W</p></td><td colspan="1" rowspan="1"><p>Channels C</p></td><td colspan="1" rowspan="1"><p>Layers L</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>Conv3*3</p></td><td colspan="1" rowspan="1"><p>224*224</p></td><td colspan="1" rowspan="1"><p>32</p></td><td colspan="1" rowspan="1"><p>1</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>MBConv1, k3*3</p></td><td colspan="1" rowspan="1"><p>112*112</p></td><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>1</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>MBConv6, k3*3</p></td><td colspan="1" rowspan="1"><p>112*112</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>2</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>MBConv6, k5*5</p></td><td colspan="1" rowspan="1"><p>56*56</p></td><td colspan="1" rowspan="1"><p>40</p></td><td colspan="1" rowspan="1"><p>2</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>MBConv6, k3*3</p></td><td colspan="1" rowspan="1"><p>28*28</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>3</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>MBConv6, k5*5</p></td><td colspan="1" rowspan="1"><p>14*14</p></td><td colspan="1" rowspan="1"><p>112</p></td><td colspan="1" rowspan="1"><p>3</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>MBConv6, k5*5</p></td><td colspan="1" rowspan="1"><p>14*14</p></td><td colspan="1" rowspan="1"><p>192</p></td><td colspan="1" rowspan="1"><p>4</p></td></tr><tr><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>MBConv6, k3*3</p></td><td colspan="1" rowspan="1"><p>7*7</p></td><td colspan="1" rowspan="1"><p>320</p></td><td colspan="1" rowspan="1"><p>1</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>Conv1*1 &amp;amp; Pooling &amp;amp; FC</p></td><td colspan="1" rowspan="1"><p>7*7</p></td><td colspan="1" rowspan="1"><p>1280</p></td><td colspan="1" rowspan="1"><p>1</p></td></tr></tbody></table>
                </table-wrap>
              
              
                <fig id="fig_4">
                  <label>Figure 4</label>
                  <caption>
                    <title>The MBConv module</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_iRSc9Dn536AAqFPg.png"/>
                </fig>
              
            </sec>
          
          
            <sec>
              
                <title>2.3.2 Transfer learning</title>
              
              <p>Transfer learning refers to the transfer of parameters from a trained model (pre-trained model) to a new model to facilitate training (<xref ref-type="bibr" rid="ref_2">Canayaz, 2021</xref>; <xref ref-type="bibr" rid="ref_19">Wang et al., 2022</xref>). It is predicated on the premise that many data sets or tasks share correlations, allowing for the transfer of previously learned model parameters (akin to transferring knowledge) to a new model. This accelerates and optimizes the modelâs learning process, eliminating the need to learn from scratch, as is common with most networks. The transferred parameters serve as a robust feature set, reducing the reliance on new data sets and shortening training durations. In this study, the weights from the EfficientNet model, trained on a large public dataset, were utilized as pre-trained model weights for the binary classification task of fall risk. The optimal parameters of the new model were obtained through retraining, demonstrating the efficiency and effectiveness of transfer learning in this context.</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.3 Cbam</title>
              
              <p style="text-align: justify">CBAM, as proposed by <xref ref-type="bibr" rid="ref_21">Woo et al. (2018)</xref>, is an enhancement mechanism for CNNs, involving spatial and channel-wise attention processes. The module, depicted in <xref ref-type="fig" rid="fig_5">Figure 5</xref>, comprises both a spatial attention module and a channel attention module, offering a plug-and-play feature that allows for integration at any point within the network without altering the input feature characteristics.</p>
              
                <fig id="fig_5">
                  <label>Figure 5</label>
                  <caption>
                    <title>CBAM</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_7zpV5vop4F287Ghr.png"/>
                </fig>
              
              <p>The channel attention module, illustrated in <xref ref-type="fig" rid="fig_6">Figure 6</xref>, operates on the principle of discerning inter-channel relationships. It processes the input channel features F through both Maximum Pooling (MaxPool) and Average Pooling (AvgPool) to derive <italic>MaxPool</italic>(<italic>F</italic>) (<italic>MaxPool </italic>(<italic>F</italic>)<italic>âR<sup>1Ã1Ãc</sup></italic>) and <italic>AvgPool</italic>(<italic>F</italic>) (<italic>AvgPool </italic>(<italic>F</italic>)<italic>âR<sup>1Ã1Ãc</sup></italic>) features. These are subsequently passed through a multi-layer perceptron (MLP), which performs dimensionality reduction followed by enhancement. The output of the MLP, after undergoing a sigmoid activation function, yields the channel attention feature <italic>Mc</italic>(<italic>F</italic>), as formulated in Eq. (4), where W<sub>0</sub> and W<sub>1</sub> represent the respective weights.</p>
              
                <fig id="fig_6">
                  <label>Figure 6</label>
                  <caption>
                    <title>Channel attention module</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img__CtEVI67IFY1zUgK.png"/>
                </fig>
              
              
                <disp-formula>
                  <label>(4)</label>
                  <mml:math id="mnfmm735w3">
                    <mml:mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
                      <mml:mtr>
                        <mml:mtd/>
                        <mml:mtd>
                          <mml:msub>
                            <mml:mi>M</mml:mi>
                            <mml:mi>C</mml:mi>
                          </mml:msub>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>=</mml:mo>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mi>F</mml:mi>
                          <mml:mi>Sigmoid</mml:mi>
                          <mml:mi>MLP</mml:mi>
                          <mml:mi>MaxPool</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>AvgPool</mml:mi>
                          <mml:mi>F</mml:mi>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd/>
                        <mml:mtd>
                          <mml:mi/>
                          <mml:mi>Sigmoid</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>+</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msub>
                              <mml:mi>W</mml:mi>
                              <mml:mn>1</mml:mn>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>W</mml:mi>
                              <mml:mn>1</mml:mn>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:mo stretchy="false">)</mml:mo>
                              <mml:mo stretchy="false">)</mml:mo>
                              <mml:mo>)</mml:mo>
                              <mml:msub>
                                <mml:mi>W</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mi>MaxPool</mml:mi>
                              <mml:mi>F</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mo>(</mml:mo>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:mo stretchy="false">)</mml:mo>
                              <mml:mo stretchy="false">)</mml:mo>
                              <mml:mo>)</mml:mo>
                              <mml:msub>
                                <mml:mi>W</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mi>AvgPool</mml:mi>
                              <mml:mi>F</mml:mi>
                            </mml:mrow>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </disp-formula>
              
              <p style="text-align: justify">In parallel, the spatial attention module, shown in <xref ref-type="fig" rid="fig_7">Figure 7</xref>, focuses on the relationships between spatial attributes to generate spatial attention maps. The input features F' undergo spatially-oriented MaxPool and AvgPool operations, resulting in <italic>MaxPool</italic>(<italic>F'</italic>) (<italic>MaxPool </italic>(<italic>F'</italic>)<italic>âR<sup>1Ã1Ãc</sup></italic>) and <italic>AvgPool</italic>(<italic>F'</italic>) (<italic>AvgPool</italic>(<italic>F'</italic>)<italic> â R<sup>1Ã1Ãc</sup></italic>) features. These features are first concatenated channel-wise, followed by a convolution operation with a 7Ã7 kernel. A subsequent sigmoid activation operation produces the spatial attention feature <italic>Ms</italic>(<italic>F</italic>), as outlined in the computational process.</p>
              
                <fig id="fig_7">
                  <label>Figure 7</label>
                  <caption>
                    <title>Spatial attention module</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_OwofBLJwRuoABhpZ.png"/>
                </fig>
              
              
                <disp-formula>
                  <label>(5)</label>
                  <mml:math id="m7ai7nvnzg">
                    <mml:msub>
                      <mml:mi>M</mml:mi>
                      <mml:mi>S</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>Ï</mml:mi>
                    <mml:mi>Ï</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mi>f</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mn>7</mml:mn>
                          <mml:mn>7</mml:mn>
                          <mml:mo>Ã</mml:mo>
                        </mml:mrow>
                      </mml:msup>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mrow>
                          <mml:mo>[</mml:mo>
                          <mml:mo>;</mml:mo>
                          <mml:mo>]</mml:mo>
                          <mml:mi>AvgPool</mml:mi>
                          <mml:mi>MaxPool</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msup>
                              <mml:mi>F</mml:mi>
                              <mml:mrow>
                                <mml:mi>â²</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msup>
                              <mml:mi>F</mml:mi>
                              <mml:mrow>
                                <mml:mi>â²</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mi>f</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mn>7</mml:mn>
                          <mml:mn>7</mml:mn>
                          <mml:mo>Ã</mml:mo>
                        </mml:mrow>
                      </mml:msup>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mrow>
                          <mml:mo>[</mml:mo>
                          <mml:mo>;</mml:mo>
                          <mml:mo>]</mml:mo>
                          <mml:msubsup>
                            <mml:mi>F</mml:mi>
                            <mml:mi>S</mml:mi>
                            <mml:mrow>
                              <mml:mtext>avgÂ </mml:mtext>
                            </mml:mrow>
                          </mml:msubsup>
                          <mml:msubsup>
                            <mml:mi>F</mml:mi>
                            <mml:mi>S</mml:mi>
                            <mml:mrow>
                              <mml:mo>max</mml:mo>
                            </mml:mrow>
                          </mml:msubsup>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              <p style="text-align: justify">where, Ï represents the sigmoid function, <inline-formula>
  <mml:math id="maa2opy4zp">
    <mml:msubsup>
      <mml:mi>F</mml:mi>
      <mml:mi>S</mml:mi>
      <mml:mrow>
        <mml:mtext>avgÂ </mml:mtext>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mk5dghot2p">
    <mml:msubsup>
      <mml:mi>F</mml:mi>
      <mml:mi>S</mml:mi>
      <mml:mrow>
        <mml:mo>max</mml:mo>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> denote the mean and maximum pooling features, respectively.</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.4 Cbam-efficientnet framework</title>
              
              <p>The integration of CBAM into the EfficientNet framework represents a pivotal enhancement in the processing of plantar pressure data. CBAM, combining the channel attention module and the spatial attention module, facilitates the extraction of global feature information, thereby augmenting the network's classification accuracy. While shallow networks are proficient in extracting low-level features with high generalization capabilities, they entail higher computational costs. Deep networks, conversely, are adept at extracting more specific, finer details pertinent to particular datasets. By embedding the CBAM module within MBConv of the deep network, an emphasis on salient features of plantar pressure data is achieved. This strategic placement, post DWConv convolution, allows the network to broaden its scope in learning diverse features.</p><p><xref ref-type="fig" rid="fig_8">Figure 8</xref> illustrates the structure of the MBConv module integrated with the CBAM module. Comparative experimental analyses were conducted to ascertain the optimal network layers for the application of the attention mechanism, culminating in the integration of the CBAM module into Stages 5, 6, 7, and 8 of the network architecture, as detailed in <xref ref-type="table" rid="table_1">Table 1</xref>.</p>
              
                <fig id="fig_8">
                  <label>Figure 8</label>
                  <caption>
                    <title>The MBConv module integrated into CBAM module</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_P5yU11KImuTBuHSl.png"/>
                </fig>
              
              <p>The CBAM-EfficientNet model, as proposed in this study, encompasses both transfer learning and the CBAM mechanism within the EfficientNet architecture. The initial weights of the EfficientNet network, pretrained on the ImageNet dataset, were subsequently applied to the foot pressure sensor dataset (<xref ref-type="fig" rid="fig_9">Figure 9</xref>). The model adopts a strategy wherein the shallow layers of the network are frozen, allowing only the deeper layers to undergo weight parameter updates. This approach is predicated on the understanding that while shallow layers in convolutional networks excel in extracting low-level features with strong generalization capabilities, deeper layers are more focused on dataset-specific, finer details. Consequently, in this transfer learning classification task, only the weight parameters of the deep layers are permitted adjustment, while those of the shallow layers remain static. This methodology significantly enhances the classification performance on the two-dimensional representation of foot pressure data, effectively addressing fall risk assessment challenges. The first four stages of the network were frozen, and the subsequent feature extraction layers, inclusive of those with CBAM integration, underwent training to update weight parameters, culminating in the refined classification of fall risk assessment.</p>
              
                <fig id="fig_9">
                  <label>Figure 9</label>
                  <caption>
                    <title>CBAM- Efficientnet model</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_MDTOjOeHcRC6PqT3.png"/>
                </fig>
              
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Experiments and analyses</title>
      
        <sec>
          
            <title>3.1. Experimental setting</title>
          
          <p>The experiment was designed to evaluate human fall risk using plantar pressure data and to verify the accuracy of this approach. Initially, EfficientNet network models with and without transfer learning were trained and compared. Subsequently, the attention mechanism, specifically the CBAM module, was integrated into the MBConv module at various stages (8; 7, 8; 6, 7, 8; and 5, 6, 7, 8) of the EfficientNet network. The impact of these different configurations was then assessed through training. The final phase involved comparing the optimal model with traditional classical networks and existing methods.</p><p>The deep learning framework PyTorch 2.5.0 was utilized for model construction, supported by hardware comprising an Intel Core i9-7900 processor and NVIDIA Geforce GTX3090 graphics card. For classification purposes, the 'high' category was treated as a positive example, and the 'low' category as negative. Optimal model parameter settings, as validated through experimental testing, are presented in <xref ref-type="table" rid="table_2">Table 2</xref>.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Model parameter setting</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Setting Item</p></td><td colspan="1" rowspan="1"><p>Parameter Value</p></td></tr><tr><td colspan="1" rowspan="1"><p>Learning Rate</p></td><td colspan="1" rowspan="1"><p>0.1</p></td></tr><tr><td colspan="1" rowspan="1"><p>Batch Size</p></td><td colspan="1" rowspan="1"><p>32</p></td></tr><tr><td colspan="1" rowspan="1"><p>Epoch</p></td><td colspan="1" rowspan="1"><p>200</p></td></tr><tr><td colspan="1" rowspan="1"><p>Dropout</p></td><td colspan="1" rowspan="1"><p>0.2</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Evaluation metrics such as accuracy, precision, sensitivity, and F1-score were employed to assess model performance.</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="ma0gwly8fu">
                <mml:mtext>Â AccuracyÂ </mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="m1ftppfhza">
                <mml:mtext>Precision</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="mx4zk5k02v">
                <mml:mtext>Sensitivity</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(9)</label>
              <mml:math id="m1byw3lh66">
                <mml:mtext>F1- score</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mo>â</mml:mo>
                    <mml:mo>â</mml:mo>
                    <mml:mi>P</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>S</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>v</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                    <mml:mi>y</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>S</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>v</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
        </sec>
      
      
        <sec>
          
            <title>3.2. Comparison of transfer learning model results</title>
          
          <p><xref ref-type="fig" rid="fig_10">Figure 10</xref> illustrates the model accuracy and loss value curves for configurations with and without transfer learning. At equivalent epochs, the model employing transfer learning exhibited higher accuracy, lower loss values, and faster convergence. Without transfer learning, accuracy peaked at approximately 93.8%, with a final loss value of 0.221. Post-transfer learning implementation, accuracy increased to 96.2%, and the loss value decreased to 0.143. <xref ref-type="table" rid="table_3">Table 3</xref> presents a comparison of the performance metrics, with transfer learning demonstrating superior results, thereby enhancing the classification performance of the fall risk assessment model and increasing classification efficiency. </p>
          
            <fig id="fig_10">
              <label>Figure 10</label>
              <caption>
                <title>(a) Comparison of accuracy; (b) Comparison of loss value</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_l7BK3ZinytmqZe6Y.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_zggK6nB_Nj2jY33q.png"/>
            </fig>
          
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Performance comparison of baseline models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Module</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>EfficientNet</p></td><td colspan="1" rowspan="1"><p>96.9%</p></td><td colspan="1" rowspan="1"><p>96.8%</p></td><td colspan="1" rowspan="1"><p>96.8%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Pre-EfficientNet</p></td><td colspan="1" rowspan="1"><p>98.0%</p></td><td colspan="1" rowspan="1"><p>97.2%</p></td><td colspan="1" rowspan="1"><p>97.6%</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>3.3. Impact of attention mechanism placement on model performance</title>
          
          <p>Investigations were conducted on networks with pre-training and varying placements of the CBAM module. It was observed that models augmented with the CBAM module exhibited enhanced performance in terms of accuracy compared to the initial Pre-EfficientNet model without the module. The inclusion of the CBAM module resulted in an increase in accuracy by 0.3-2%, precision by 0.6-1.2%, and F1-score by 0.6-1.5%. These results underscore the efficacy of transfer learning in expediting network training and improving classification accuracy, particularly in scenarios with limited data.</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Classification results of different improved models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Module</p></td><td colspan="1" rowspan="1"><p>Accuracy</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>Pre-EfficientNetB0</p></td><td colspan="1" rowspan="1"><p>96.2%</p></td><td colspan="1" rowspan="1"><p>98.0%</p></td><td colspan="1" rowspan="1"><p>97.2%</p></td><td colspan="1" rowspan="1"><p>97.6%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stage 8</p></td><td colspan="1" rowspan="1"><p>96.5%</p></td><td colspan="1" rowspan="1"><p>98.6%</p></td><td colspan="1" rowspan="1"><p>97.8%</p></td><td colspan="1" rowspan="1"><p>98.2%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stage 7 and 8</p></td><td colspan="1" rowspan="1"><p>96.7%</p></td><td colspan="1" rowspan="1"><p>98.7%</p></td><td colspan="1" rowspan="1"><p>98.0%</p></td><td colspan="1" rowspan="1"><p>98.3%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stage 6, 7 and 8</p></td><td colspan="1" rowspan="1"><p>97.2%</p></td><td colspan="1" rowspan="1"><p>99.1%</p></td><td colspan="1" rowspan="1"><p>98.4%</p></td><td colspan="1" rowspan="1"><p>98.7%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stage 5, 6, 7 and 8</p></td><td colspan="1" rowspan="1"><p>98.5%</p></td><td colspan="1" rowspan="1"><p>99.2%</p></td><td colspan="1" rowspan="1"><p>99.0%</p></td><td colspan="1" rowspan="1"><p>99.1%</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_4">Table 4</xref> presents the classification results of the various improved models, revealing that the network achieves optimal average evaluation metrics when the CBAM module is added at stages 5, 6, 7, and 8. The average accuracy in this configuration was recorded at 98.2%, marking a significant enhancement in the modelâs classification capabilities. This improvement can be attributed to the CBAM attention mechanism's focus on crucial features in plantar pressure data from both spatial and channel dimensions. <xref ref-type="fig" rid="fig_11">Figure 11</xref> compares the accuracy and loss value variation curves of the optimal model (CBAM added at stages 5, 6, 7, 8) with the base model (Pre-EfficientNet). The optimal model demonstrated higher accuracy and lower loss values, stabilizing at an epoch of approximately 110, thereby confirming the added value of CBAM in learning pivotal features to improve classification accuracy.</p>
          
            <fig id="fig_11">
              <label>Figure 11</label>
              <caption>
                <title>(a) Comparison of model accuracy with or without CBAM; (b) Comparison of model loss values with and without CBAM</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_pMqL2b_ht7sK4FtV.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_5iOt4n7a3VHKKoL6.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>3.4. Evaluation of model effectiveness</title>
          
          <p>Comparative experiments were conducted with classical networks such as ShuffleNet, ResNet50, and ResNet101. <xref ref-type="fig" rid="fig_12">Figure 12</xref> showcases the variation in accuracy among these models. The CBAM-EfficientNet approach achieved higher accuracy and faster convergence compared to other classical networks, attributed to the efficiencies brought by transfer learning and the inherent advantages of the EfficientNet network architecture (uniform tuning of network width, depth, and accuracy) complemented by the CBAM mechanism for extracting significant features from plantar pressure data. <xref ref-type="table" rid="table_5">Table 5</xref> displays the evaluation metrics for the classical network models and the proposed method in this study. The CBAM-EfficientNet method attained the highest accuracy at 98.5%, exhibiting superior performance in precision, sensitivity, and F1-score. Additionally, this model is characterized by a reduced number of parameters, thereby necessitating fewer resources.</p>
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>Classification results of different models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Module</p></td><td colspan="1" rowspan="1"><p>Accuracy</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>CBAM-EfficientNet</p></td><td colspan="1" rowspan="1"><p>98.5%</p></td><td colspan="1" rowspan="1"><p>99.2%</p></td><td colspan="1" rowspan="1"><p>99.0%</p></td><td colspan="1" rowspan="1"><p>99.1%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Shufflenet</p></td><td colspan="1" rowspan="1"><p>91.1%</p></td><td colspan="1" rowspan="1"><p>96.1%</p></td><td colspan="1" rowspan="1"><p>95.0%</p></td><td colspan="1" rowspan="1"><p>95.3%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Resnet50</p></td><td colspan="1" rowspan="1"><p>94.3%</p></td><td colspan="1" rowspan="1"><p>98.3%</p></td><td colspan="1" rowspan="1"><p>96.0%</p></td><td colspan="1" rowspan="1"><p>97.0%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Resnet101</p></td><td colspan="1" rowspan="1"><p>93.9%</p></td><td colspan="1" rowspan="1"><p>98.2%</p></td><td colspan="1" rowspan="1"><p>95.5%</p></td><td colspan="1" rowspan="1"><p>96.7%</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <fig id="fig_12">
              <label>Figure 12</label>
              <caption>
                <title>(a) Comparison of accuracy with classical network models; (b) Comparison of loss values with classical network models</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_tsT3ZDwZaw9khM5H.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_OV2KzVe4PwD8xf0P.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>3.5. Comparison with contemporary research findings</title>
          
          <p style="text-align: justify">A comparative analysis was conducted to evaluate various methods used in current research for assessing fall risk through plantar pressure sensors, as summarized in <xref ref-type="table" rid="table_6">Table 6</xref>. <xref ref-type="bibr" rid="ref_6">Liang et al. (2019)</xref> applied the ConvLSTM method to extract spatiotemporal features from raw plantar pressure data, demonstrating its effectiveness in predicting fall risk among the elderly and establishing a correlation between heel force and fall risk. <xref ref-type="bibr" rid="ref_14">Shalin et al. (2021)</xref> focused on the efficacy of gait freeze detection and prediction using plantar pressure sensors, validating the suitability of LSTM networks for this type of data. <xref ref-type="bibr" rid="ref_3">Chan et al. (2023)</xref> explored fall detection using a hybrid CNN and RNN model, proving the model's applicability to both plantar pressure and inertial sensor data.</p><p style="text-align: justify">The comparative experiments, conducted on the dataset assembled in this study, indicate that the proposed CBAM-EfficientNet model outperforms existing methods in accuracy, precision, sensitivity, and F1-score, while also being more resource-efficient. Specifically, when compared to ConvLSTM, improvements of 6.2% in accuracy, 2.6% in precision, 3.4% in sensitivity, and 2.9% in F1-score were observed. Relative to LSTM, enhancements in accuracy, precision, sensitivity, and F1-score were 6.7%, 2.8%, 3.8%, and 3.4%, respectively. Compared with the hybrid CNN and RNN model, the CBAM-EfficientNet model showed an increase of 4.2% in accuracy, 1.6% in precision, 2.4% in sensitivity, and 0.9% in F1-score. The lightweight nature of the proposed network further substantiates the CBAM-EfficientNet model's superior performance in accurately classifying fall risk.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Comparison of contemporary research findings</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Module</p></td><td colspan="1" rowspan="1"><p>Accuracy</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>CBAM-EfficientNet</p></td><td colspan="1" rowspan="1"><p>98.5%</p></td><td colspan="1" rowspan="1"><p>99.2%</p></td><td colspan="1" rowspan="1"><p>99.0%</p></td><td colspan="1" rowspan="1"><p>99.1%</p></td></tr><tr><td colspan="1" rowspan="1"><p>convLSTM (<xref ref-type="bibr" rid="ref_6">Liang et al., 2019</xref>)</p></td><td colspan="1" rowspan="1"><p>92.3%</p></td><td colspan="1" rowspan="1"><p>96.6%</p></td><td colspan="1" rowspan="1"><p>95.6%</p></td><td colspan="1" rowspan="1"><p>96.0%</p></td></tr><tr><td colspan="1" rowspan="1"><p>LSTM (<xref ref-type="bibr" rid="ref_22">Yu et al., 2020</xref>)</p></td><td colspan="1" rowspan="1"><p>91.8%</p></td><td colspan="1" rowspan="1"><p>96.4%</p></td><td colspan="1" rowspan="1"><p>95.2%</p></td><td colspan="1" rowspan="1"><p>95.7%</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN+RNN (<xref ref-type="bibr" rid="ref_3">Chan et al., 2023</xref>)</p></td><td colspan="1" rowspan="1"><p>94.3%</p></td><td colspan="1" rowspan="1"><p>97.6%</p></td><td colspan="1" rowspan="1"><p>96.6%</p></td><td colspan="1" rowspan="1"><p>98.0%</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Conclusion</title>
      <p>In pursuit of robust fall risk detection methods suitable for daily life applications, this research undertook an extensive examination of existing fall assessment methodologies. The selection of a particular data processing technique was necessitated by the voluminous nature of plantar pressure data. A novel neural network model for fall risk assessment was proposed, incorporating an attention mechanism, and was built upon a gait dataset gathered using plantar pressure sensor devices. Utilizing the EfficientNet model as a base, transfer learning was applied, and the CBAM module was integrated, enhancing the accuracy of risk classification. Initial network weights, trained on a large dataset, were employed to expedite network training and improve learning efficiency. The incorporation of the CBAM module at higher stages of the model augmented the network's capacity to discern critical features in plantar pressure data, thus boosting classification accuracy. The optimized model achieved a classification accuracy of 98.5%, a precision of 99.2%, and a sensitivity of 99.0%. These outcomes affirm the efficacy of the proposed method in enhancing the classification of plantar pressure data, which holds significant practical implications in assisting medical professionals in fall risk diagnosis.</p><p>The study leveraged the GASF algorithm to transform foot pressure sensor data into two-dimensional images, achieving data simplification and robustness. The integration of transfer learning markedly improved the efficiency of fall risk assessment classification. The experimental results validated the ability of GASF images to maintain accuracy in fall risk assessment while reducing data scale, making the model more suitable for practical deployment in fall risk monitoring scenarios.</p><p>Despite its contributions, this study has limitations. The complexity of the human body's motor system cannot be fully captured by plantar pressure sensors alone. Future work could involve the integration of additional sensors or diverse sensor types, ensuring practical applicability in daily life, to acquire more comprehensive limb movement data. This would enable more nuanced analysis and processing of complex movement behaviors. Additionally, the current model predicts fall risk as high or low but lacks the granularity to determine specific risk severity or fall probability. Future endeavors could focus on more precise data labeling to address this limitation.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Beck</surname>
              <given-names>J. C.</given-names>
            </name>
          </person-group>
          <source>Geriatrics Review Syllabus: A Core Curriculum in Geriatric Medicine</source>
          <publisher-name>Kendall/Hunt Publishing Company, Dubuque, IA, US</publisher-name>
          <year>1999</year>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>151</volume>
          <page-range>111310</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Canayaz</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.chaos.2021.111310.</pub-id>
          <article-title>C+EffxNet: A novel hybrid approach for COVID-19 diagnosis on CT images based on CBAM and EfficientNet</article-title>
          <source>Chaos, Solitons Fractals</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>495</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chan</surname>
              <given-names>H. L.</given-names>
            </name>
            <name>
              <surname>Ouyang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>R. S.</given-names>
            </name>
            <name>
              <surname>Lai</surname>
              <given-names>Y. H.</given-names>
            </name>
            <name>
              <surname>Kuo</surname>
              <given-names>C. C.</given-names>
            </name>
            <name>
              <surname>Liao</surname>
              <given-names>G. S.</given-names>
            </name>
            <name>
              <surname>Hsu</surname>
              <given-names>W. Y.</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>Y. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s23010495.</pub-id>
          <article-title>Deep neural network for the detections of fall and physical activities using foot pressures and inertial sensing</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>2021</volume>
          <page-range>1-13</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gao</surname>
              <given-names>W. D</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Z. W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2021/8776059.</pub-id>
          <article-title>Gait phase recognition using fuzzy logic regulation with multisensor data fusion</article-title>
          <source>J. Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1919</page-range>
          <issue>11</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>B. C.</given-names>
            </name>
            <name>
              <surname>Yao</surname>
              <given-names>Z. M.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>J. G.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>S. N.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>X. J.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>Y. N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/electronics9111919.</pub-id>
          <article-title>Improved deep learning technique to detect freezing of gait in Parkinsonâs disease based on wearable sensors</article-title>
          <source>Electronics</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>36-41</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liang</surname>
              <given-names>S. Y.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Y. M.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>G. L.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>G. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CBS46900.2019.9114487.</pub-id>
          <article-title>Elderly fall risk prediction with plantar center of force using convlstm algorithm</article-title>
          <source>, </source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>29393-29407</page-range>
          <issue>11</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liang</surname>
              <given-names>S. Y.</given-names>
            </name>
            <name>
              <surname>Ning</surname>
              <given-names>Y. K.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>H. Q.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Mei</surname>
              <given-names>Z. Y.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>Y. N.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>G. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">https://doi.org/10.3390/s151129393.</pub-id>
          <article-title>Feature selection and predictors of falls with foot force sensors using KNN-Based algorithms</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>1195-1212</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liu</surname>
              <given-names>X. G.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Lou</surname>
              <given-names>C. G.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>H. R.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>X. L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/mbe.2022055.</pub-id>
          <article-title>A lightweight double-channel depthwise separable convolutional neural network for multimodal fusion gait recognition</article-title>
          <source>Math. Biosci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>1233-1242</page-range>
          <issue>3</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Montanini</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Del Campo</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Perla</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Spinsante</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gambi</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/jsen.2017.2778742.</pub-id>
          <article-title>A footwear-based methodology for fall detection</article-title>
          <source>IEEE Sens. J.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>2246</page-range>
          <issue>6</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pardoel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Shalin</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Nantel</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lemaire</surname>
              <given-names>Edward D.</given-names>
            </name>
            <name>
              <surname>Kofman</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s21062246.</pub-id>
          <article-title>Early detection of freezing of gait during walking using inertial measurement unit and plantar pressure distribution data</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>29</volume>
          <page-range>953-964</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Peng</surname>
              <given-names>X. H.</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>Y. K.</given-names>
            </name>
            <name>
              <surname>Ji</surname>
              <given-names>S. J.</given-names>
            </name>
            <name>
              <surname>Amos</surname>
              <given-names>J. T.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>W. N.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ai</surname>
              <given-names>S. L.</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>X. Z.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>Y. Y.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Yao</surname>
              <given-names>D. Z.</given-names>
            </name>
            <name>
              <surname>Valdes-Sosa</surname>
              <given-names>P. A.</given-names>
            </name>
            <name>
              <surname>Ren</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/tnsre.2021.3082936.</pub-id>
          <article-title>Gait analysis by causal decomposition</article-title>
          <source>IEEE Trans. Neural. Syst. Rehabil. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>39</volume>
          <page-range>142-148</page-range>
          <issue>2</issue>
          <year>1991</year>
          <person-group person-group-type="author">
            <name>
              <surname>Podsiadlo</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Richardson</surname>
              <given-names>S. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/j.1532-5415.1991.tb01616.x.</pub-id>
          <article-title>The Timed âUp &amp; Goâ: A test of basic functional mobility for frail elderly persons</article-title>
          <source>J. Am. Geriatrics Soc.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>356</volume>
          <page-range>1001-1002</page-range>
          <issue>9234</issue>
          <year>2000</year>
          <person-group person-group-type="author">
            <name>
              <surname>RaÃ®che</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>HÃ©bert</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Prince</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Corriveau</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/s0140-6736(00)02695-7.</pub-id>
          <article-title>Screening older adults at risk of falling with the Tinetti balance scale</article-title>
          <source>The Lancet</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>1-15</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shalin</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Pardoel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lemaire</surname>
              <given-names>Edward D.</given-names>
            </name>
            <name>
              <surname>Nantel</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kofman</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1186/s12984-021-00958-5.</pub-id>
          <article-title>Prediction and detection of freezing of gait in Parkinsonâs disease from plantar pressure data using long short-term memory neural-networks</article-title>
          <source>J. Neuroengineering Rehabil.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>80</volume>
          <page-range>896-903</page-range>
          <issue>9</issue>
          <year>2000</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shumway-Cook</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Brauer</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Woollacott</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/ptj/80.9.896.</pub-id>
          <article-title>Predicting the probability for falls in community-dwelling older adults using the Timed Up &amp; Go Test</article-title>
          <source>Phys. Therapy</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>11946</volume>
          <page-range>arXiv: 1905.11946</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tan</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>Q. V.</given-names>
            </name>
          </person-group>
          <article-title>EfficientNet: Rethinking model scaling for convolutional neural networks</article-title>
          <source>arXiv preprint</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <issue>3</issue>
          <year>2004</year>
          <person-group person-group-type="author">
            <name>
              <surname>Taylor</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Menz</surname>
              <given-names>H. B.</given-names>
            </name>
            <name>
              <surname>Keenan</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.gaitpost.2003.02.001.</pub-id>
          <article-title>Effects of experimentally induced plantar insensitivity on forces and pressures under the foot during normal walking</article-title>
          <source>Gait Posture</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>119-126</page-range>
          <issue>2</issue>
          <year>1986</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tinetti</surname>
              <given-names>M. E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/j.1532-5415.1986.tb05480.x.</pub-id>
          <article-title>Performance-oriented assessment of mobility problems in elderly patients</article-title>
          <source>J. Am. Geriatrics Soc.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>49-54</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>H.  X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Z. G.</given-names>
            </name>
            <name>
              <surname>Cui</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Cui</surname>
              <given-names>R. Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ccai55564.2022.9807755.</pub-id>
          <article-title>Chinese-Korean Weibo sentiment classification based on pre-trained language model and transfer learning</article-title>
          <source>, http://dx.doi.org/10.1109/CCAI55564.2022.9807755</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>00327</volume>
          <page-range>arXiv:1506.00327</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Z. G.</given-names>
            </name>
            <name>
              <surname>Oates</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1506.00327.</pub-id>
          <article-title>Imaging time-series to improve classification and imputation</article-title>
          <source>arXiv preprint</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>3-19</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Woo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Park</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>J. Y.</given-names>
            </name>
            <name>
              <surname>Kweon</surname>
              <given-names>I. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1807.06521.</pub-id>
          <article-title>Cbam: Convolutional block attention module</article-title>
          <source>, https://doi.org/10.48550/arXiv.1807.06521</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>1646</volume>
          <page-range>012041</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yu</surname>
              <given-names>J. C.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>W. D.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>W. N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1742-6596/1646/1/012041.</pub-id>
          <article-title>Foot pronation detection based on plantar pressure measurement</article-title>
          <source>J. Phys. Conf. Ser.</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>e0237090</page-range>
          <issue>8</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Fei</surname>
              <given-names>C. W.</given-names>
            </name>
            <name>
              <surname>Zia</surname>
              <given-names>A. W.</given-names>
            </name>
            <name>
              <surname>Jing</surname>
              <given-names>L. X.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0237090.</pub-id>
          <article-title>Flexible sensor matrix film-based wearable plantar pressure force measurement and analysis system</article-title>
          <source>PLoS One</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>