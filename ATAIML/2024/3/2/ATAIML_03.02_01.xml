<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="review-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-w_hGrMCTWohsSdeuIETrDpzVU_opJHLm</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml030201</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Advances in Breast Cancer Segmentation: A Comprehensive Review</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-0416-8601</contrib-id>
          <name>
            <surname>Abo-El-Rejal</surname>
            <given-names>Ayah</given-names>
          </name>
          <email>ayah.hesham@bue.edu.eg</email>
          <xref ref-type="aff" rid="aff_1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-9136-7745</contrib-id>
          <name>
            <surname>Ayman</surname>
            <given-names>Shehab Eldeen</given-names>
          </name>
          <email>shehab.ayman@bue.edu.eg</email>
          <xref ref-type="aff" rid="aff_1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0009-6210-970X</contrib-id>
          <name>
            <surname>Aymen</surname>
            <given-names>Farah</given-names>
          </name>
          <email>farah.aymen@bue.edu.eg</email>
          <xref ref-type="aff" rid="aff_1">1</xref>
        </contrib>
        <aff id="aff_1">Faculty of Informatics and Computer Science, The British University in Egypt, 11837 Cairo, Egypt</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>20</day>
        <month>03</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>2</issue>
      <fpage>70</fpage>
      <lpage>83</lpage>
      <page-range>70-83</page-range>
      <history>
        <date date-type="received">
          <day>07</day>
          <month>01</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>11</day>
          <month>03</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The diagnosis and treatment of breast cancer (BC) are significantly subject to medical imaging techniques, with segmentation being crucial in delineating pathological regions for precise diagnosis and treatment planning. This comprehensive analysis explores a variety of segmentation methodologies, encompassing classical, machine learning, deep learning (DL), and manual segmentation, as applied in the medical imaging field for BC detection. Classical segmentation techniques, which include edge-driven and threshold-driven segmentation, are highlighted for their utilization of filters and region-based methods to achieve precise delineation. Emphasis is placed on the establishment of clear guidelines for the selection and comparison of these classical approaches. Segmentation through machine learning is discussed, encompassing both unsupervised and supervised techniques that leverage annotated images and pathology reports for model training, with a focus on their efficacy in BC segmentation tasks. DL methods, especially models such as U-Net and convolutional neural networks (CNNs), are underscored for their remarkable efficiency in segmenting BC images, with U-Net models noted for their minimal requirement for annotated images and achieving accuracy levels up to 99.7%. Manual segmentation, though reliable, is identified as time-consuming and susceptible to errors. Various metrics, such as Dice, F-score, Intersection over Union (IOU), and Area Under the Curve (AUC), are used for assessing and comparing the segmentation techniques. The analysis acknowledges the challenges posed by limited dataset availability, data range inadequacy, and confidentiality concerns, which hinder the broader integration of segmentation methods into clinical practice. Solutions to overcome these challenges are proposed, including the promotion of partnerships to develop and distribute extensive datasets for BC segmentation. This approach would necessitate the pooling of resources from multiple organizations and the adoption of anonymization techniques to safeguard data privacy. Through this lens, the analysis aims to provide a thorough analysis of the practical implications of segmentation methods in BC diagnosis and management, paving the way for future advancements in the field.</p></abstract>
      <kwd-group>
        <kwd>Breast cancer</kwd>
        <kwd>Segmentation</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Diagnosis</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="3"/>
        <fig-count count="4"/>
        <table-count count="1"/>
        <ref-count count="57"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Breast imaging presents a unique landscape characterized by both opportunities and challenges for the development and integration of artificial intelligence (AI). BC screening initiatives globally heavily rely on mammography to mitigate the morbidity and mortality associated with BC. Nevertheless, AI holds vast potential for diverse applications within breast imaging, including decision support, risk assessment, quantification of breast density, workflow optimization, triage, quality evaluation, assessment of responses to image enhancement and NAC.</p><p>Various modalities have been employed in BC screening, detection, and diagnosis, including mammography, positron emission tomography (PET), BUS CT, magnetic resonance imaging (MRI) [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>], and DBT. Notably, mammography is frequently employed due to its proven efficacy in early-stage tumor detection [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>]. In the breast, precise segmentation of the region of interest (ROI) realizes accurate tumor detection. ROI segmentation represents a pivotal component of computer-assisted diagnosis (CAD), with segmentation quality closely tied to the efficacy of employed filters for artifact removal from mammographic images.</p><p>The challenge of limited radiologist resources amidst a deluge of daily mammogram images can lead to diagnostic inaccuracies with potentially significant implications for patients. False-positive diagnoses can result in unnecessary financial burdens and, in severe cases, delayed cancer detection in advanced stages, which can be life-threatening. Conversely, false-negative diagnoses can trigger unwarranted expenses and distress stemming from invasive biopsy procedures and treatments for non-existent cancer.</p><p>Despite notable advancements in medical image segmentation, the practical utility of segmentation methodologies still cannot meet clinical demands. Collaborative endeavors between medical professionals and machine learning experts should be intensified to bridge this gap and cater to clinical requirements. This synergy empowers machine learning experts to devise DL models tailored to clinical needs, ultimately alleviating the workload on medical practitioners.</p><p>This study aims to comprehensively review and analyze the diverse segmentation methodologies employed in medical imaging, particularly focusing on BC detection and diagnosis. Through a detailed examination of classical, machine learning, DL, and manual segmentation techniques, this study aims to elucidate the strengths, limitations, and potential use of those methods in BC imaging. By synthesizing insights from current research findings, challenges, and implications, this study helps comprehensively understand the role of segmentation in facilitating the accurate identification of breast tumors, guiding treatment planning, and enhancing overall patient care. Ultimately, the aim is to contribute to the advancement of segmentation methodologies and their integration into clinical practice for improved BC detection and management.</p><p>This study provides a comprehensive review of a survey on advanced image segmentation methods for various breast screening techniques. What makes this survey unique is that it provides a combination of both technical screening techniques and a medical background on the subject. This study aims to provide readers with either a medical or technical background with an overview of the subject.</p>
    </sec>
    <sec sec-type="">
      <title>2. Background</title>
      <p>Early detection of BC is a paramount concern on a global scale, as it substantially enhances patient survival rates. Mammography stands as a pivotal tool for early-stage BC detection. Effective tumor identification within breast images hinges on robust segmentation techniques. Segmentation plays a pivotal role in image analysis, encompassing detection, classification, feature extraction, and treatment planning, enabling the quantification of breast tissue volume.</p><p>In previous eras, the timely identification of BC predominantly depended on manual assessment and mammography imaging. Manual examination entailed the involvement of healthcare professionals and patients, who engaged in tactile examinations to detect anomalies such as lumps or alterations in breast tissue. BC ranks as the most prevalent cancer among women in the United States, excluding skin cancers, constituting nearly one-third of all new female cancer cases annually. In 2023, it is anticipated that nearly 300,000 cases of invasive BC and over 50,000 cases of ductal carcinoma in situ will be diagnosed, with over 43,000 BC-related deaths expected in the United States alone [<xref ref-type="bibr" rid="ref_6">6</xref>]. The World Health Organization (WHO) emphasizes that BC ranks as the most commonly diagnosed condition globally, leading to around 626,700 female deaths annually from cancer-related causes [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>]. BC progression typically follows three stages: normal, benign, and malignant, with symptoms often appearing as masses, microcalcifications, or architectural distortions visible in mammographic images. <xref ref-type="fig" rid="fig_1">Figure 1</xref> illustrates the incidence and mortality rates for the top ten most prevalent cancers among women in 2020, with BC occupying the highest percentages at 24.48% and 15.52% in the two pie charts, respectively.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Cancer distribution types among women in 2020 [<xref ref-type="bibr" rid="ref_8">8</xref>]</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_Lc83VECM1Ogat9Lh.png"/>
        </fig>
      
      
        <sec>
          
            <title>2.1. Cancer risk assessment</title>
          
          <p>Contemporary risk assessment models are designed to estimate the collective risk of BC occurrence among individuals who share similar risk-related characteristics rather than providing individualized assessments. These models incorporate a multitude of factors into their calculations, including but not limited to age, age of menarche, obstetric history, familial BC history spanning both first-degree and multi-generational relatives, genetic information, number of prior biopsies, racial and ethnic background, and body mass index, among other pertinent variables. The output of these models typically quantifies the likelihood of developing BC over specific time intervals, such as 5 years, 10 years, or over one's lifetime. These risk assessments serve a crucial role in the identification of women who may derive benefits from supplemental high-risk BC screening, chemo-preventive interventions, or lifestyle modifications.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Cancer detection</title>
          
          <p>BC screening initiatives are predominantly anchored in the utilization of screening mammography to curtail the morbidity and mortality associated with BC. Beyond its primary role in cancer detection, the domain of breast imaging offers a spectrum of prospective applications for AI. These encompass both interpretive and non-interpretive domains, encompassing decision support, risk assessment, quantification of breast density, workflow optimization, triage facilitation, quality evaluation, assessment of responses to NAC, and image enhancement. These multifaceted AI applications augment the comprehensive landscape of breast imaging [<xref ref-type="bibr" rid="ref_9">9</xref>], contributing to advancements in patient care and diagnostic efficacy.</p><p>External assessments aiming to gauge the performance of AI algorithms in breast imaging have yielded variable outcomes. Notably, a well-performing AI model displayed diminished performance levels when applied at an external site in its native configuration [<xref ref-type="bibr" rid="ref_10">10</xref>]. A concerning issue further arises from the observation that AI algorithms, once developed and made available, may not exhibit consistent performance across diverse patient subpopulations or demographic groups. It is noteworthy that the development and evaluation of AI tools for BC detection in imaging has predominantly concentrated on mammography.</p><p>A previous external validation endeavor scrutinizing a high-performing AI algorithm, using an independent and diverse population, disclosed markedly reduced performance levels in specific patient cohorts, in stark contrast to previously reported performances. These concerns underscore the potential unintended consequences stemming from the insufficient inclusion of diverse patient groups in testing and validation datasets [<xref ref-type="bibr" rid="ref_11">11</xref>].</p><p>Comparative assessments between AI-based screening and radiologist-led screening have unveiled non-inferior sensitivity and superior specificity, accompanied by a significant 25.1% reduction in false-positive findings [<xref ref-type="bibr" rid="ref_12">12</xref>]. Remarkably, these findings were achieved concomitantly with a substantial 62.6% reduction in workload. Furthermore, a retrospective simulation study showcased that AI-based triage of mammograms into “no-radiologist assessment” and “enhanced assessment” categories had the potential to reduce workloads by over 50% while preemptively identifying a substantial portion of cancers that might otherwise be diagnosed at later stages [<xref ref-type="bibr" rid="ref_13">13</xref>]. Another investigation focused on an AI system employed for lesion detection in Digital Breast Tomosynthesis (DBT) and disclosed that the algorithm, when integrated into mammogram interpretation, led to a nearly 50% reduction in reading times. Notably, this efficiency enhancement was achieved without compromising diagnostic accuracy, as indicated by a statistically significant average improvement of 0.057 in the AUC [<xref ref-type="bibr" rid="ref_14">14</xref>].</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Bc screening techniques</title>
      <p>In order to not only detect but also classify BC in its early stages, several imaging modalities are being made good use of. BC diagnosis and detection rely on the analysis of medical images. Below are some of the most widely used techniques.</p>
      
        <sec>
          
            <title>3.1. Mammogram</title>
          
          <p>Mammography stands as the prevailing and foremost imaging modality employed in the diagnosis of BC. The American Cancer Society (ACS) deems mammograms as a standard protocol for the early detection of BC [<xref ref-type="bibr" rid="ref_15">15</xref>]. In this method, X-ray imaging is harnessed to generate detailed images of both breast structures. For each breast, a pair of mammographic views is acquired: the cranio-caudal perspective (top-down view) and the mediolateral oblique perspective (a side view captured from a specific angle). These views are obtained by carefully compressing the breast in a nearly vertical orientation. Mammography is still the most reliable and affordable method of BC screening. It is especially efficient for recognizing microcalcifications, a prevalent early indicator of BC. However, they face difficulties because of their limited sensitivity to dense breast tissue. It is possible to have false positives and negatives; to do so, more images are required for confirmation. </p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Ultrasound</title>
          
          <p>Ultrasound serves as a prevalent modality in medical diagnosis and is frequently employed as a complementary screening technique alongside mammography. It utilizes the sound waves by producing real-time images that provide a dynamic view of the breast tissue. The combined use of both modalities enhances sensitivity and specificity in BC detection. This approach holds promise as it is potentially effective, noninvasive, safe, cost-effective, and widely accessible for BC detection. Notably, it exhibits greater sensitivity than mammography in identifying anomalies within dense breast tissue, rendering it particularly valuable for women under the age of 35 [<xref ref-type="bibr" rid="ref_16">16</xref>]. It is radiation-free, which makes it well suited not only for dense breast tissue but also for characterizing lesions that are detected on mammography. </p><p>The process of ultrasonography entails the transmission of high-frequency sound waves through the breast, with the returning signals transformed into visual images displayed on a monitor. A transducer is utilized to define tissue boundaries and interpret the reflected signals, allowing for real-time visualization of internal organ shapes and movements. Despite its numerous advantages in BC diagnosis, ultrasound is seldom used as a standalone primary modality due to its reliance on operator skill and limited resolution quality. Since a portable transducer is employed for scanning, image quality predominantly hinges on the clinician's proficiency in performing the scan. Consequently, the accuracy of BC diagnosis, especially in assessing lesion size and shape, is significantly influenced by the clinician's transducer placement and the pressure applied to the breast. Ultrasound imaging has found application in various methods, such as Generative Adversarial Networks (GANs), Stacked Denoising Autoencoders (SDAEs), Spatially-Uniform Approximation Surfaces (SUAS), DL Reconstruction (DLR), Non-Uniform Rational B-Spline (NURBS), Image Reconstruction Diagnostics (IRDx), Residual Networks with Global Average Pooling (ResNet-GAP), Hybrid Multimodal Breast-Density Learning with Generative Adversarial Hybrid Architecture (HMB-DLGAHA), Automated Breast Ultrasound Systems (ABUS), and so on. It is radiation-free and is especially beneficial in identifying lesions observed on mammography. It is also well-suited for dense breast tissue. and useful for directing biopsies.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Breast mri (bmri)</title>
          
          <p>BMRI is a technology harnessing the formidable magnetic strength of 1.5 Tesla along with radio waves to produce highly detailed breast images [<xref ref-type="bibr" rid="ref_17">17</xref>]. To produce detailed images, it uses radio waves and strong magnetic fields. The visibility of lesions is improved by contrast-enhanced MRI. In recent times, MRI has been integrated into BC diagnosis as an initial screening tool for women who have been newly diagnosed with the condition. It proves invaluable in uncovering cancerous cells that traditional imaging methods may overlook. Additionally, BMRI finds significant application in screening individuals at high risk for BC, assessing disease staging, evaluating genetic mutations, aiding in surgical planning, and monitoring patients post-neoadjuvant chemotherapy (NAC) [<xref ref-type="bibr" rid="ref_18">18</xref>]. The technique offers support for multi-planar scanning and 3D reconstruction methods, as seen in <xref ref-type="fig" rid="fig_2">Figure 2</xref>, enabling precise depiction of the size, structure, and location of breast lesions [<xref ref-type="bibr" rid="ref_18">18</xref>]. Various approaches, such as Enhanced Screening for BC (ESBC), Abbreviated MRI (Ab-MRI), Multiparametric MRI (mpMRI), the European Society of Breast Imaging (EUSOBI) protocols, Diffusion-Weighted Imaging (DWI), T1-Weighted MRI (T1-W MRI), and Dynamic Contrast-Enhanced MRI (DCE-MRI), have been employed combined with BMRI.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>3D BMRI volume [<xref ref-type="bibr" rid="ref_18">18</xref>]</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_WL-8-k_wSrSG0U8t.png"/>
            </fig>
          
          <p>Nonetheless, BMRI does come with certain limitations. It is time-intensive and expensive, and its Positive Predictive Value (PPV) is compromised by a relatively high rate of false-positive findings, potentially leading to unnecessary breast biopsies. Moreover, its capability to detect microcalcifications is limited. Pregnant individuals are advised against undergoing this examination due to the use of powerful magnets and contrast agents [<xref ref-type="bibr" rid="ref_19">19</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Computed tomography (ct)</title>
          
          <p>CT offers exceptional three-dimensional visualization of anatomical structures, allowing for precise assessment of soft tissue lesions, including their location and size [<xref ref-type="bibr" rid="ref_20">20</xref>]. While not commonly employed as an early BC detection tool, CT plays a crucial role in staging BC cases that have already been diagnosed, aiding healthcare professionals in treatment planning.</p><p>CT scans typically exhibit low contrast, necessitating the intravenous administration of contrast agents such as iodine-based compounds, barium sulfate, gadolinium, or air mixtures. These agents enhance visibility and facilitate distinguishing malignant lesions from benign ones [<xref ref-type="bibr" rid="ref_21">21</xref>]. It is worth noting that patients undergoing multiple CT scans for screening purposes may potentially be exposed to higher levels of radiation, as CT scans generally entail greater radiation exposure than digital mammograms (DMs). Consequently, CT scans may be recommended for individuals who are contraindicated for MRI. Furthermore, CT exhibits a lower threshold for detecting microcalcifications compared to mammography. In the preoperative evaluation of BC, CT has the potential to serve as an alternative to 3D MRI. Various strategies have been proposed to leverage this technique in the context of BC assessment [<xref ref-type="bibr" rid="ref_22">22</xref>]. However, its routine usage in BC screening is constrained by its limited sensitivity for tiny breast lesions, possible radiation risks, and costs. <xref ref-type="fig" rid="fig_3">Figure 3</xref> presents a visual representation of two distinct DCE-MRI slices. On the left-hand side, a solid tumor is clearly displayed, and this reveals a concentrated mass of abnormal tissue present within the breast. On the other hand, a non-mass tumor can be seen on the right side of <xref ref-type="fig" rid="fig_3">Figure 3</xref>. In this case, the cancerous growth appears to be more diffused. </p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Two DCE-MRI slices of patients with BC: solid tumor (left) and non-mass tumor (right) [<xref ref-type="bibr" rid="ref_23">23</xref>]</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_QccHrRN6eOSxXlDj.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Modalities for diagnosis and treatment</title>
      <p>BC diagnosis primarily relies on two fundamental imaging techniques: radiography and histology. The field of radiology is dedicated to the acquisition of internal body structure images to diagnose and treat patients by assessing the presence or absence of diseases, injuries, and abnormalities. Radiographic imaging methods employed in BC diagnosis encompass Digital Mammography (DM), Breast Ultrasound (BUS), MRI, CT, and PET scans.</p><p>Histopathology, on the other hand, involves the meticulous examination of cancer cells and tissues at an ultrahigh magnification level under a microscope. A small segment of breast tissue is extracted for this analysis, serving as a confirmatory diagnostic test for BC. Various biopsy types are available, contingent upon the patient's condition at the time of the procedure. Each of the imaging modalities plays an integral role within the BC diagnostic toolkit. Once a tumor has been accurately identified, and its characteristics delineated through imaging techniques, the subsequent step involves selecting the most suitable treatment approach. Effective BC treatments encompass surgical interventions, radiation therapy, and chemotherapy. These treatment modalities aim to eradicate cancer cells from their original sites [<xref ref-type="bibr" rid="ref_24">24</xref>].</p><p>In a research endeavor, an AI algorithm was developed employing a dataset comprising BMRI images, encompassing both contrast-enhanced and non-contrast acquisitions. Subsequently, this AI model was subjected to inputs exclusively comprising non-contrast images extracted from BMRI studies. Remarkably, the AI model demonstrated the capability to generate simulated contrast-enhanced BMRI images, showcasing its potential for image enhancement and synthesis [<xref ref-type="bibr" rid="ref_25">25</xref>].</p><p>A notable illustration of AI-driven methodology involves a process wherein suspicious regions of interest identified within DBT data are amalgamated or consolidated to create maximum suspicion projections. These synthesized images serve to accentuate and highlight the suspicious findings, rendering them more discernible. Subsequently, these novel synthesized images are employed as input data for an AI-driven cancer detection model, effectively mitigating the demands associated with image and data preparation and streamlining the process of BC detection [<xref ref-type="bibr" rid="ref_26">26</xref>].</p>
    </sec>
    <sec sec-type="">
      <title>5. Segmentation in bc</title>
      <p>In the realm of image processing, segmentation refers to the process of partitioning an image into distinct regions with the primary objective of isolating the ROI within mammographic images, specifically targeting the identification of masses [<xref ref-type="bibr" rid="ref_27">27</xref>], [<xref ref-type="bibr" rid="ref_28">28</xref>]. It is noteworthy that the accuracy of this detection can be influenced by the presence of pectoral muscles, necessitating the prior removal of artifacts and pectoral muscles to facilitate accurate segmentation. Additionally, when segmentation is directly applied to raw images characterized by noise and inadequate contrast, the potential for over-segmentation and erroneous identification of breast tumors becomes a concern. Therefore, it becomes imperative to employ filtering techniques to eliminate noise and address local irregularities within noisy images, thereby enhancing their overall quality [<xref ref-type="bibr" rid="ref_29">29</xref>], [<xref ref-type="bibr" rid="ref_30">30</xref>]. The fundamental objective of segmentation lies in the extraction of ROIs harboring potential masses, involving the partitioning of breast images into discrete, non-overlapping regions [<xref ref-type="bibr" rid="ref_31">31</xref>]. Nonetheless, it is crucial to acknowledge that segmentation methodologies may encounter various influencing factors that can impede the identification of abnormalities within images, including pixel resolution, integration scale, and preprocessing steps.</p><p>The automation of image analysis and segmentation processes implies a minimal degree or complete absence of human intervention. Computer-aided diagnosis (CAD) is widely embraced within the medical domain to support radiologists in detecting and characterizing breast masses [<xref ref-type="bibr" rid="ref_26">26</xref>], [<xref ref-type="bibr" rid="ref_32">32</xref>], [<xref ref-type="bibr" rid="ref_33">33</xref>]. After CAD is incorporated into clinical practice, it serves to diminish the occurrence of misclassifications, consequently enhancing diagnostic accuracy and optimizing time management [<xref ref-type="bibr" rid="ref_25">25</xref>]. The pivotal roles of image segmentation within the ambit of image analysis encompass the processes of detection, feature extraction, and classification. Breast images are used as follows:</p><p>• Detection: Segmentation aids radiologists in the facile identification of BC, given the dissimilar morphologies of benign and malignant tumors.</p><p>• Feature extraction: Segmentation serves as a pivotal preprocessing step, enhancing image suitability for specific applications by facilitating subsequent feature extraction.</p><p>• Classification: Contour-based segmentation assumes a pivotal role in CAD systems, particularly in mass classification. Segmented images can be categorized as normal, benign, or malignant.</p><p>• Treatment: Segmentation directly influences BC treatment dosage determination, as tumor size is a critical output. Segmentation of breast and lymph node volumes is integral to defining irradiation volumes in the context of BC treatment.</p>
      
        <sec>
          
            <title>5.1. Segmentation methods</title>
          
          <p>Various segmentation methodologies are presently employed in segmentation, encompassing classical, machine learning, and DL segmentation techniques. The primary objective of segmentation lies in facilitating medical professionals in quantifying tissue volumes, identifying pathological regions, conducting diagnoses and anatomical studies, and devising treatment strategies [<xref ref-type="bibr" rid="ref_34">34</xref>]. The process of segmentation facilitates the partitioning of image regions [<xref ref-type="bibr" rid="ref_35">35</xref>], thereby simplifying the task of medical experts in distinguishing between normal and abnormal characteristics within a given medical image.</p>
          
            <sec>
              
                <title>5.1.1 Classical segmentation</title>
              
              <p>Among various filtering techniques, the median filter stands out as the predominant choice in image processing, exhibiting greater prevalence in usage compared to alternative filter types. Furthermore, in the domain of image segmentation, the region-growing method has demonstrated superior performance when juxtaposed with alternative segmentation methodologies. Notably, an exceptional level of accuracy, reaching 99.0%, has been attained with the utilization of a specified threshold limit [<xref ref-type="bibr" rid="ref_36">36</xref>]. Remarkably, the highest degree of accuracy achieved in threshold-based segmentation reached 100.0%, and this pinnacle performance was accomplished through the employment of the morphological filter [<xref ref-type="bibr" rid="ref_37">37</xref>]. Moreover, in the context of edge-based segmentation, the Gabor filter emerged as the filter of choice, attaining the highest sensitivity level at 100.0% [<xref ref-type="bibr" rid="ref_38">38</xref>]. Some of the most commonly used segmentation techniques are as follows:</p><p>• Edge-driven segmentation: Techniques such as Canny edge detection, active contour models, Sobel operators, minimization-based approaches, and contour-based methods fall under this category.</p><p>• Threshold-driven segmentation: This category encompasses various methods, including Otsu thresholding, morphological thresholding, adaptive thresholding, manual thresholding, Kittler's optimal thresholding, as well as global and local thresholding techniques.</p><p>• Region-centric segmentation: Methods like watershed segmentation, rough set theory-based approaches, partial region growth, and marker-controlled segmentation are representative of this segmentation paradigm.</p>
            </sec>
          
          
            <sec>
              
                <title>5.1.2 Machine learning segmentation</title>
              
              <p>In medical image analysis using machine learning, the prerequisite typically entails the utilization of images annotated by qualified medical professionals, complemented by conclusive pathology reports delineating the benign or malignant nature of the depicted conditions. Notably, unsupervised machine learning techniques are prevalently favored over their supervised counterparts within this context. Nevertheless, it is worth highlighting that the best performance attained in supervised machine learning reached an impressive detection rate of 99.82% [<xref ref-type="bibr" rid="ref_39">39</xref>]. Machine learning techniques are as follows: unsupervised and supervised machine learning.</p><p>Within the realm of unsupervised machine learning, the repertoire comprises hierarchical k-clustering, k-means clustering, fuzzy C-clustering, and techniques concerning vector machines and naïve Bayes models.</p><p>In the realm of breast tumor segmentation on mammograms, a method employing hierarchical k-means was introduced by Ramadijanti et al. [<xref ref-type="bibr" rid="ref_40">40</xref>]. This approach incorporates automatic breast tumor detection through valley tracing, thereby determining the optimal quantity of clusters within mammographic images. Experimental outcomes revealed a 61.1% error detection rate, with an associated accuracy rate of 38.8%. Gu et al. [<xref ref-type="bibr" rid="ref_39">39</xref>] introduced a methodology for segmenting breast masses in mammogram images, based on a mathematical model designed to pinpoint the mass's location. The pixel values were subjected to classification via fuzzy c-means clustering, categorizing them into three distinct classes: background, initial mass, and boundary. The evaluation was conducted on 100 mammogram images sourced from the MIAS database, with noise removal achieved through median filtering. The experimental findings demonstrated a notable mass detection rate of 98.82%. An amalgamation of a novel enhancement technique and fuzzy c-means clustering for BC detection was proposed [<xref ref-type="bibr" rid="ref_41">41</xref>], which involves CAD and incorporates modifications to the local range modification (LRM), resulting in the modified LRM (MLRM) technique for noise reduction and enhancement. Mammogram images obtained from the MIAS database were employed in this endeavor. The integration of MLRM and FCMC yielded a commendable accuracy rate of 98.1%.</p><p>The prominent methods of supervised machine learning encompass support vector machines (SVMs), extreme learning machines, and k-means and fuzzy c-means methodologies.</p><p>A structured SVM for BC detection, utilizing mammography images sourced from the DDSM-BCRP and INbreast databases, was introduced in a scientific context [<xref ref-type="bibr" rid="ref_42">42</xref>]. This method exhibited superior performance compared to contemporary approaches, achieving a remarkable computational efficiency of 0.8 seconds and a Dice index of 87.0%. <xref ref-type="fig" rid="fig_4">Figure 4</xref> shows the DDSM dataset sample.</p>
              
                <fig id="fig_4">
                  <label>Figure 4</label>
                  <caption>
                    <title>DDSM dataset sample [<xref ref-type="bibr" rid="ref_40">40</xref>]</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_9OBew-kwmqPb3pPM.png"/>
                </fig>
              
              <p>Oliver et al. [<xref ref-type="bibr" rid="ref_43">43</xref>] presented an automatic breast density analysis technique validated through comparison with manual expert annotations and automatic estimations. A dataset comprising 130 mammogram images obtained from the Spanish screening program specifications (SSPS), including mediolateral and craniocaudal angles, was utilized. Noise mitigation was accomplished using a median filter. The study showed a strong 0.96 connection between the left and right breast mammography density percentages. Additionally, a comparison of both mammogram views exhibited a correlation coefficient of 0.95, facilitated by the implementation of a SVM classifier. Wirtti and Salles [<xref ref-type="bibr" rid="ref_44">44</xref>] proposed a method for mammogram density assessment employing a multiscale wavelet transform. Using wavelet processing, density data were used to train a multilayer perceptron network (MLP). After being trained, this network was applied to mass detection in 19 mammography pictures, producing an 8.7% false-positive rate and a 68.2% true-positive rate (sensitivity).</p>
            </sec>
          
          
            <sec>
              
                <title>5.1.3 Dl segmentation</title>
              
              <p>In medical image segmentation, the U-Net model has garnered significant attention due to its efficacy, particularly in scenarios with limited annotated data, a common constraint in medical imaging tasks. This model has proven especially effective, achieving a remarkable Dice coefficient of 98.87%, surpassing other competing models. Shen et al. [<xref ref-type="bibr" rid="ref_45">45</xref>] presented the Residual-Aided and Mixed-Supervision-Guided Classification U-Net model (ResCUNet), designed specifically for the joint segmentation and classification of mammography images. Utilizing the INbreast dataset and employing convolutional filters for noise reduction, the proposed MS-ResCUNet model exhibited an impressive accuracy rate of 94.16%, surpassing the performance of SegNet, U-Net, and BreastNet. Saffari et al. [<xref ref-type="bibr" rid="ref_46">46</xref>] proposed the Full-Resolution Convolutional Network (FrCN), a novel segmentation model specifically designed for mammogram image segmentation. In addition, the identified and segmented breast lesions were classified as benign or malignant using three traditional DL models: InceptionResNet-V2, ResNet-50, and a normal feedforward CNN. The FrCN-based breast lesion segmentation method, which used mammography images from the INbreast database, produced noteworthy results, such as an overall accuracy of 92.97%, a Dice coefficient of 92.69%, a Matthews Correlation Coefficient (MCC) of 85.93%, and a Jaccard similarity coefficient of 86.37%.</p><p>Hu et al. [<xref ref-type="bibr" rid="ref_47">47</xref>] presented a fully automated method for segmenting breast density utilizing Conditional Generative Adversarial Networks (cGAN), paired with DL for classification. The cGAN network was utilized to segment dense tissues in mammogram images, with an evaluation performed on the INbreast dataset and noise reduction achieved through median filtering. The findings demonstrated a segmentation accuracy of 98.0%, highlighting the efficacy of the cGAN-based strategy. Hu et al. [<xref ref-type="bibr" rid="ref_47">47</xref>] presented a novel method that utilizes deep transfer learning along with four-dimensional data to enhance the contrast of MRI images. This approach involves employing a CNN for Maximum Intensity Projection (MIP) of image features. The authors utilized established architectures, including Densenet169, Resnet50, and Resnet101. Dewangan et al. [<xref ref-type="bibr" rid="ref_48">48</xref>] introduced the BPBRW model, which incorporates a Hybrid Krill Herd African Buffalo Optimization (HKHABO) mechanism to enhance MRI images.</p><p>Dewangan et al. [<xref ref-type="bibr" rid="ref_48">48</xref>] introduced a modified convolutional layer within a CNN framework, inspired by the U-Net model. Their approach was evaluated using two distinct datasets: DDSM-400 and CBIS DDSM. The results indicated a diagnostic performance of 89.8% and an AUC of 86.20% when utilizing ground-truth segmentation maps. Additionally, the method attained a maximum accuracy of 88.0% and 86.0% for U-Net-based segmentation on the DDSM-400 and CBISDDSM datasets, respectively. Tsochatzidis et al. [<xref ref-type="bibr" rid="ref_49">49</xref>] presented a DL model tailored for segmenting and classifying mammography images. They were adapted to the U-Net model, which effectively delineated the breast area within mammogram images. The model underwent thorough evaluation across three diverse mammographic datasets: MIAS, DDSM, and CBIS DDSM. The results demonstrated exceptional performance metrics, with an impressive 98.87% accuracy, 98.88% AUC, 98.98% sensitivity, 98.79% precision, and 97.99% F1-score observed when tested on DDSM datasets.</p><p>A DL system incorporating residual architecture was presented, which integrates mass segmentation using a residual attention U-Net model (RU-Net) and classification using the ResNet classifier [<xref ref-type="bibr" rid="ref_50">50</xref>]. Their approach was evaluated on three datasets: DDSM, BCDR-01, and INbreast, with noise reduction implemented through the cLare filter. The proposed model demonstrated outstanding performance metrics, achieving an average test pixel accuracy of 98.0%, a mean Dice coefficient index (DI) of 98.0%, and an average IOU of 94.0%. Hossain [<xref ref-type="bibr" rid="ref_51">51</xref>] presented a method for segmenting microcalcifications using a modified U-Net segmentation network applied to mammogram images. The model was trained on images sourced from the DDSM database, with noise reduction achieved through the Laplacian filter. This approach yielded promising results, including an F-measure of 98.50%, a Dice score of 97.80%, a Jaccard index of 97.40%, and an average accuracy rate of 98.20%. Sun et al. [<xref ref-type="bibr" rid="ref_52">52</xref>] developed a novel attention-guided dense-upsampling network called AUNet for segmenting breast masses in full mammograms. AUNet employs an asymmetrical encoder-decoder architecture and integrates an efficient upsampling block known as the attention-guided dense upsampling block (AUblock). A comprehensive evaluation was carried out on the publicly available datasets of CBIS-DDSM and INbreast. The method demonstrated significant performance, with an average Dice similarity coefficient of 81.80% for CBIS-DDSM and 79.10% for the INbreast datasets.</p>
            </sec>
          
          
            <sec>
              
                <title>5.1.4 Manual segmentation</title>
              
              <p>In clinical practice, the identification of breast tumors within the ROI is typically accomplished through manual examination by medical professionals. Subsequently, abnormal regions are discerned by juxtaposing these manually identified areas with the remaining anatomical components [<xref ref-type="bibr" rid="ref_53">53</xref>]. Manually scrutinizing numerous images from various imaging modalities poses significant inefficiencies and challenges, potentially leading to misdiagnoses and an increased false-positive rate. Consequently, there is a pressing need for an automated approach to address these issues. In the realm of early BC detection, medical image analysis facilitated by CAD systems has emerged as the most efficient methodology. However, it's important to note that CAD systems tend to identify a higher number of false features compared to genuine anomalies, necessitating the clinician's involvement in result interpretation. This characteristic of CAD systems extends the reading time. In addition, it imposes limitations on the volume of cases that can be effectively analyzed by radiologists.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Challenges and implications</title>
      <p>Recent advancements in AI, specifically DL methodologies, hold the promise of substantially expediting the image analysis procedure, thereby aiding radiologists in achieving earlier BC diagnoses. Empirical investigations have demonstrated that DL-based CAD systems can yield commendable results within the domain of medical image analysis. Nonetheless, several challenges hinder the incorporation of these approaches into clinical practice.</p><p>Despite the achievements garnered by DL models, certain challenges and limitations exist, which necessitate resolution in the context of BC detection, classification, and segmentation. Some of the challenges and implications that face the adoption of automated medical imaging-based diagnosis in the field of BC are as follows:</p><p>Several challenges and constraints are associated with the utilization of DL models for BC detection, classification, and segmentation:</p><p>• Limited availability of comprehensive datasets: DL algorithms for medical imaging heavily rely on large, high-quality training datasets. However, creating such datasets is challenging because of the labor-intensive and error-prone nature of medical image annotation. Mammogram datasets have been more readily available than datasets for other modalities like MRI and PET/CT. Although some solutions achieved high accuracy and had a short runtime, such as the Deep lab v3+ model, the sample size of the data set was insufficient [<xref ref-type="bibr" rid="ref_54">54</xref>].</p><p>• Inadequate range of data: DL models require extensive training data to achieve desirable results. Limited datasets hinder the effectiveness of DL algorithms. Strategies to address this issue include pooling data from multiple healthcare centers, with strict adherence to patient confidentiality guidelines.</p><p>• Reliance on private datasets: Many studies utilize confidential private datasets, making it difficult to compare model efficiency across different studies [<xref ref-type="bibr" rid="ref_55">55</xref>]. Although the private dataset allowed for the development of a string segmentation model, it is specific to a single institution. This resulted in problems such as compatibility with other methods and generalizability. In addition to its dependency on a private dataset, the model's performance could not be assessed across a wide variety of patient populations, nor could its effectiveness be compared to models trained on other datasets. It was difficult to assess the model's generalizability to broader populations, an alternative imaging technique, or other clinical contexts because there was no benchmarking against publicly available datasets.</p><p>• Limitations of data augmentation: Some studies use data augmentation to expand their datasets artificially. However, this method has limitations, as it does not provide significant additional information compared to new independent images.</p><p>• Lack of completely labeled datasets: DL-based CAD systems often struggle with insufficient completely labeled data. Supervised DL approaches require extensive, accurately labeled data, which is challenging and time-consuming to acquire. Unsupervised techniques have been explored but tend to yield less reliable results.</p><p>• Class imbalance: The issue of class imbalance can skew results in favor of the majority class, necessitating the development of more diverse and representative datasets.</p><p>• Confidentiality concerns: Protecting sensitive medical information is crucial. Collaborative and autonomous training of CNNs without patient data disclosure is an emerging area of research. Integrating non-imaging data, such as cancer history and genetic information, with imaging data is an ongoing challenge.</p><p>• Label noise: BC can affect different regions of the same breast differently, leading to varying stages of cancer in a single image. This multi-classification scenario can pose challenges for DL models.</p><p>• Lack of transparency: DL algorithms are often considered “black boxes,” making decision-making processes less transparent. To enhance trust and reliability in DL tools, interpretable methodologies and explanations of DL algorithms are required to be adopted.</p><p>• Potential use of omics data: Exploring omics data (proteomics, transcriptomics, genomics, etc.) as an alternative to imaging data may lead to improved classification accuracy. However, processing omics data is costlier than working with images, and comprehensive omics datasets are less readily available.</p><p>It is crucial to address these challenges, thereby advancing the capabilities and reliability of DL-based approaches for BC diagnosis and management.</p><p>The promise of better performance is finally beginning to emerge as a result of recent developments in machine learning and AI. At present, over 20 breast imaging applications using AI have been approved by the Food and Drug Administration (FDA); nevertheless, overall acceptance and use remain low and highly diverse [<xref ref-type="bibr" rid="ref_56">56</xref>]. Because of its special characteristics, breast imaging presents both opportunities and difficulties for the development and application of AI. On a global scale, screening mammography is the main tool used in BC screening programmes, as mentioned earlier, to lower the disease's morbidity and death rate. In fact, several of the most innovative research initiatives and AI applications already in use are centered around mammography cancer detection. However, there are several other possible uses for AI in breast imaging, such as workflow and the triage phase, evaluation of performance, quantification of breast density, risk assessment, and decision assistance.</p><p>A significant number of mammograms are conducted each year as a result of population-based screening initiatives; in the United States alone, about 40 million mammograms are performed annually. Optimising screening mammography performance is crucial for BC screening programmes due to the high number of mammograms involved and the significance of screening mammography performance. The FDA in the US strictly regulates this through the Mammography Quality Standards Act (MQSA), with a current focus on the Enhancing Quality Using the Inspection Programme (EQUIP) procedure, which was started in 2017. These procedures have made screening mammography conducted in the US more consistent and of high quality. Nevertheless, there is opportunity for improvement in the screening mammography performance indicators despite these efforts. An example of this requirement can be found in the 86.9% sensitivity and 88.9% specificity for screening mammography found in an assessment of performance conducted by the BC Surveillance Consortium. Of the radiologists analysed, nearly half had abnormal interpretation rates (false positives), which emphasises areas for improvement.</p><p>The FDA approved CAD in 1998 for mammography. In addition, by 2002, the Centre for Medicare and Medicaid Services had funded it, leading to 74% of mammograms in 2008. In the field of breast imaging and AI applications, a lot of work and enthusiasm have been devoted to the identification of cancer, particularly in screening mammography, as shown in <xref ref-type="table" rid="table_1">Table 1</xref>. AI applications in breast imaging face challenges like unreliable performance, high costs, and IT needs. Confidence among radiologists, patients, and providers is low. Recent studies show a decline in AI algorithm performance when tested with updated systems, raising concerns about the generalizability of AI algorithms. The adoption of AI in breast imaging faces challenges due to performance monitoring, a lack of reimbursement, and radiologists' ignorance about interactions between AI and themselves. Concerns include biases and the potential impairment of clinical judgement due to overreliance on AI tools.</p><p>High-level declarations on AI’s ethical, legal, and social implications (ELSI) have been released by governmental, international, professional, and private sector organizations recently. These statements show excitement about AI’s potential benefits as well as concerns about potential risks and downsides. High-quality data is required by AI systems for training and validation, which requires ownership, consent, and data privacy. Major tech firms and BC start-ups exacerbate these challenges. Certain governments have released healthcare data to developers. For instance, without obtaining the patients' individual consent, the Italian government gave IBM Watson access to the anonymized health records of all 61 million Italians, including genetic data [<xref ref-type="bibr" rid="ref_57">57</xref>]. The government also offered IBM Watson exclusive use rights. These disclosures give rise to serious questions about what public or commercial values ought to be exchanged for granting private companies access to these extremely rich data collections. The healthcare industry's strict medicolegal and ethical standards may lead to the ban of non-explainable AI. Access to high-quality data is crucial for AI development, but it poses risks of data breaches and harm. Public support for AI use depends on privacy, control, governance, and the public good.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>Summary of FDA-approved AI applications for BC detection</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">Product Name</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Vendor</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Country of Origin</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Modality</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">cmAssist®</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">CureMetrix</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">United States</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">ProFound AI®</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">iCAD, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">United States</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography and tomosynthesis</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">Lunit INSIGHT MMG</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Lunit</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">South Korea</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">MammoScreen® 2.0</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Therapixel</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">France</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography and tomosynthesis</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">Genius AI™ Detection</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Hologic®, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">United States</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography and tomosynthesis</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">Transpara®</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">ScreenPoint Medical B.V.</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Netherlands</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography and tomosynthesis</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span style="color: windowtext">Saige-Dx™</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">DeepHealth, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">United States</span></p></td><td colspan="1" rowspan="1"><p><span style="color: windowtext">Mammography</span></p></td></tr></tbody></table>
        </table-wrap>
      
    </sec>
    <sec sec-type="">
      <title>7. Conclusion</title>
      <p>In conclusion, the comprehensive analysis of segmentation methodologies presented in this paper underscores their crucial role in BC detection and diagnosis within medical imaging. Classical techniques such as region-growing and threshold-based segmentation offer robust performance, while machine learning approaches, both supervised and unsupervised, demonstrate promising results in automated tumor identification. DL methods, particularly U-Net models, exhibit remarkable efficacy, especially in scenarios with limited annotated data, presenting opportunities for enhanced accuracy in segmentation tasks. Despite the advancements, challenges such as the limited availability of comprehensive datasets, class imbalance, and confidentiality concerns persist, highlighting the need for continued research and innovation. It is paramount to address these challenges, thereby harnessing the full potential of segmentation techniques in improving early detection, treatment planning, and patient outcomes in BC care. Overall, this review underscores the importance of segmentation methodologies in facilitating precise and efficient analysis of medical images, ultimately contributing to advancements in BC diagnosis and management.</p><p>The review distinguishes itself by providing ideas for overcoming obstacles, prospective solutions, and forward-looking insights into future directions, in addition to summarizing the existing situation. The evaluation acts as a roadmap for academics and practitioners, pointing them in the direction of areas that need more investigation and providing insightful information to advance techniques for BC segmentation. It can demonstrate its distinctiveness and highlight how it has advanced the knowledge of BC segmentation in both clinical and research settings.</p><p>Further studies can concentrate on merging data from several imaging modalities, like mammography, ultrasound, MRI, and perhaps molecular imaging. A more thorough and precise assessment of BC can be obtained by multimodal techniques. The creation of AI models that can be understood and interpreted becomes essential for therapeutic usage. Subsequent investigations could focus on improving the DL models' transparency so that physicians can comprehend and have confidence in the decision-making procedures. AI systems may develop to offer more individualized risk assessments based on personal patient data, such as genetics, lifestyle choices, and other pertinent health information. This may help create screening and treatment regimens that are more individualized. </p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>175</volume>
          <page-range>1828-1837</page-range>
          <issue>11</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lehman</surname>
              <given-names>Constance D.</given-names>
            </name>
            <name>
              <surname>Wellman</surname>
              <given-names>Robert D.</given-names>
            </name>
            <name>
              <surname>Buist</surname>
              <given-names>Diana S. M.</given-names>
            </name>
            <name>
              <surname>Kerlikowske</surname>
              <given-names>Karla</given-names>
            </name>
            <name>
              <surname>Tosteson</surname>
              <given-names>Anna N. A.</given-names>
            </name>
            <name>
              <surname>Miglioretti</surname>
              <given-names>Diana L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1001/jamainternmed.2015.5231</pub-id>
          <article-title>Diagnostic accuracy of digital screening mammography with and without computer-aided detection</article-title>
          <source>JAMA Intern. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>103</volume>
          <page-range>1152-1161</page-range>
          <issue>15</issue>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Fenton</surname>
              <given-names>Joshua J.</given-names>
            </name>
            <name>
              <surname>Abraham</surname>
              <given-names>Linn</given-names>
            </name>
            <name>
              <surname>Taplin</surname>
              <given-names>Stephen H.</given-names>
            </name>
            <name>
              <surname>Geller</surname>
              <given-names>Berta M.</given-names>
            </name>
            <name>
              <surname>Carney</surname>
              <given-names>Patricia A.</given-names>
            </name>
            <name>
              <surname>D'Orsi</surname>
              <given-names>Carl</given-names>
            </name>
            <name>
              <surname>Elmore</surname>
              <given-names>Joann G.</given-names>
            </name>
            <name>
              <surname>Barlow</surname>
              <given-names>William E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/jnci/djr206</pub-id>
          <article-title>Effectiveness of computer-aided detection in community mammography practice</article-title>
          <source>J. Natl. Cancer Inst.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>44-48</page-range>
          <issue>1</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Keen</surname>
              <given-names>John D.</given-names>
            </name>
            <name>
              <surname>Keen</surname>
              <given-names>Joanna M.</given-names>
            </name>
            <name>
              <surname>Keen</surname>
              <given-names>James E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.jacr.2017.08.033</pub-id>
          <article-title>Utilization of computer-aided detection for digital screening mammography in the United States, 2008 to 2016</article-title>
          <source>J. Am. Coll. Radiol.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="webpage">
          <article-title>Mammography quality standards act and program</article-title>
          <year>2023</year>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>31-37</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Samantha  Zuckerman</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Brian  Sprague</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Donald  Weaver</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Sally  Herschorn</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Emily  Conant</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.jacr.2019.07.020</pub-id>
          <article-title>Survey results regarding uptake and impact of synthetic digital mammography with tomosynthesis in the screening setting</article-title>
          <source>J. Am. Coll. Radiol.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="webpage">
          <article-title>Breast cancer statistics-How common is breast cancer</article-title>
          <source>, https://www.cancer.org/cancer/types/breast-cancer/about/how-common-is-breast-cancer.html</source>
          <year>2023</year>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="webpage">
          <article-title>MQSA national statistics</article-title>
          <source>, https://www.fda.go v/radiation-emitting-products/mqsa-insights/mqsa-national-statistics</source>
          <year>2023</year>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>30</volume>
          <page-range>5023-5052</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Abhisheka</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Biswas</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Purkayastha</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11831-023-09968-z</pub-id>
          <article-title>A comprehensive review on breast cancer detection, classification and segmentation using deep learning</article-title>
          <source>Arch. Comput. Methods Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>2041</page-range>
          <issue>12</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Taylor</surname>
              <given-names>C. R.</given-names>
            </name>
            <name>
              <surname>Monga</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Johnson</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Hawley</surname>
              <given-names>J. R.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/diagnostics13122041</pub-id>
          <article-title>Artificial intelligence applications in breast imaging: Current status and future directions</article-title>
          <source>Diagnostics</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Condon</surname>
              <given-names>J.J.J.</given-names>
            </name>
            <name>
              <surname>Oakden-Rayner</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Hall</surname>
              <given-names>K.A.</given-names>
            </name>
            <name>
              <surname>Reintals</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Carneiro</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Palmer</surname>
              <given-names>L.J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1101/2021.05.28.21257892</pub-id>
          <article-title>Replication of an open-access deep learning system for screening mammography: Reduced performance mitigated by retraining on local data</article-title>
          <source>medRxiv 2021.05.28.21257892</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>e2242343</page-range>
          <issue>11</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hsu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Hippe</surname>
              <given-names>D. S.</given-names>
            </name>
            <name>
              <surname>Nakhaei</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>P. C.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Siu</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ahsen</surname>
              <given-names>M. E.</given-names>
            </name>
            <name>
              <surname>Lotter</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Sorensen</surname>
              <given-names>A. G.</given-names>
            </name>
            <name>
              <surname>Naeim</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Buist</surname>
              <given-names>D. S. M.</given-names>
            </name>
            <name>
              <surname>Schaffter</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Guinney</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Elmore</surname>
              <given-names>J. G.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>C. I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1001/jamanetworkopen.2022.42343</pub-id>
          <article-title>External validation of an ensemble model for automated mammography interpretation by artificial intelligence</article-title>
          <source>JAMA Netw. Open</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>304</volume>
          <page-range>41-49</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lauritzen</surname>
              <given-names>A. D.</given-names>
            </name>
            <name>
              <surname>Rodríguez-Ruiz</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>von Euler-Chelpin</surname>
              <given-names>M. C.</given-names>
            </name>
            <name>
              <surname>Lynge</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Vejborg</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Nielsen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Karssemeijer</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Lillholm</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1148/radiol.210948</pub-id>
          <article-title>An artificial intelligence–based mammography screening protocol for breast cancer: Outcome and radiologist workload</article-title>
          <source>Radiology</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>e468-e474</page-range>
          <issue>9</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dembrower</surname>
              <given-names>Karin</given-names>
            </name>
            <name>
              <surname>Wåhlin</surname>
              <given-names>Erik</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Yue</given-names>
            </name>
            <name>
              <surname>Salim</surname>
              <given-names>Mattie</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>Kevin</given-names>
            </name>
            <name>
              <surname>Lindholm</surname>
              <given-names>Peter</given-names>
            </name>
            <name>
              <surname>Eklund</surname>
              <given-names>Martin</given-names>
            </name>
            <name>
              <surname>Strand</surname>
              <given-names>Fredrik</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/S2589-7500(20)30185-0</pub-id>
          <article-title>Effect of artificial intelligence-based triaging of breast cancer screening mammograms on cancer detection and radiologist workload: A retrospective simulation study</article-title>
          <source>Lancet Digit. Health</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>e180096</page-range>
          <issue>4</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Conant</surname>
              <given-names>E. F.</given-names>
            </name>
            <name>
              <surname>Alicia  Toledano</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Periaswamy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sergei  Fotin</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Go</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Justin  Boatsman</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Jeffrey  Hoffmeister</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1148/ryai.2019180096</pub-id>
          <article-title>Improving accuracy and efficiency with concurrent use of artificial intelligence for digital breast tomosynthesis</article-title>
          <source>Radiol. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>1-26</page-range>
          <issue>2s</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Dhillon</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Hossain</surname>
              <given-names>M. S.</given-names>
            </name>
            <name>
              <surname>Muhammad</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3415155</pub-id>
          <article-title>eDiaPredict: An ensemblebased framework for diabetes prediction</article-title>
          <source>ACM Trans. Multimed. Comput. Commun. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>472</volume>
          <page-range>152-165</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Qi</surname>
              <given-names>Xiao Feng</given-names>
            </name>
            <name>
              <surname>Yi</surname>
              <given-names>Fa Sheng</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Lei</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Yao</given-names>
            </name>
            <name>
              <surname>Pi</surname>
              <given-names>Yong</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Yuan Yuan</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>Ji Xiang</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Jian Yong</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>Quan</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Ji Lan</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Yi</given-names>
            </name>
            <name>
              <surname>Lv</surname>
              <given-names>Qing</given-names>
            </name>
            <name>
              <surname>Yi</surname>
              <given-names>Zhang</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neucom.2021.11.047</pub-id>
          <article-title>Computer-aided diagnosis of breast cancer in ultrasonography images by deep learning</article-title>
          <source>Neurocomputing</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>221</volume>
          <page-range>525-528</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Thompson</surname>
              <given-names>J. L.</given-names>
            </name>
            <name>
              <surname>Wright</surname>
              <given-names>G. P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.amjsurg.2020.12.018</pub-id>
          <article-title>The role of breast MRI in newly diagnosed breast cancer: An evidence-based review</article-title>
          <source>Am. J. Surg.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>103</volume>
          <page-range>101781</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Piantadosi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Sansone</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Fusco</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sansone</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.artmed.2019.101781</pub-id>
          <article-title>Multi-planar 3D breast segmentation in MRI via deep convolutional neural networks</article-title>
          <source>Artif. Intell. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>112</volume>
          <page-range>121-122</page-range>
          <issue>2</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saccarelli</surname>
              <given-names>C. R.</given-names>
            </name>
            <name>
              <surname>Bitencourt</surname>
              <given-names>A. G. V.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>E. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/jnci/djz130</pub-id>
          <article-title>Breast cancer screening in high-risk women: Is MRI alone enough?</article-title>
          <source>J. Natl. Cancer Inst.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1699</page-range>
          <issue>11</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Desperito</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Capaccione</surname>
              <given-names>K. M.</given-names>
            </name>
            <name>
              <surname>Collins</surname>
              <given-names>B. T.</given-names>
            </name>
            <name>
              <surname>Jamabawalikar</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Peng</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Patrizio</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Salvatore</surname>
              <given-names>M. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/life12111699</pub-id>
          <article-title>Chest CT for breast cancer diagnosis</article-title>
          <source>Life (Basel)</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>109</volume>
          <page-range>267-272</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nicolas</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Khalifa</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Laporte</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Bouhroum</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kirova</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.ijrobp.2020.08.051</pub-id>
          <article-title>Safety margins for the delineation of the left anterior descending artery in patients treated for breast cancer</article-title>
          <source>Int. J. Radiat. Oncol. Biol. Phys.</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>26-31</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Koh</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yoon</surname>
              <given-names>Y. Y.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Han</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.clbc.2021.04.015</pub-id>
          <article-title>Deep learning for the detection of breast cancers on chest computed tomography</article-title>
          <source>Clin. Breast Cancer</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Benjelloun</surname>
            </name>
            <name>
              <given-names>M. E.</given-names>
              <surname>Adoui</surname>
            </name>
            <name>
              <given-names>M. A.</given-names>
              <surname>Larhmam</surname>
            </name>
            <name>
              <given-names>S. A.</given-names>
              <surname>Mahmoudi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CloudTech.2018.8713352</pub-id>
          <article-title>Automated breast tumor segmentation in DCE-MRI using deep learning</article-title>
          <source>2018 4th International Conference on Cloud Computing Technologies and Applications (Cloudtech), Brussels, Belgium</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>182</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Thawani</surname>
              <given-names>Ruchi</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>Lina</given-names>
            </name>
            <name>
              <surname>Mohinani</surname>
              <given-names>Ajay</given-names>
            </name>
            <name>
              <surname>Tudorica</surname>
              <given-names>Alina</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Xin</given-names>
            </name>
            <name>
              <surname>Mitri</surname>
              <given-names>Zahi</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Wei</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1186/s12880-022-00908-0</pub-id>
          <article-title>Quantitative DCE-MRI prediction of breast cancer recurrence following neoadjuvant chemotherapy: A preliminary study</article-title>
          <source>BMC Med Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="conf-paper">
          <page-range>119-124</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Tahir F.</given-names>
              <surname>Majeed</surname>
            </name>
            <name>
              <given-names>Naseer</given-names>
              <surname>Al-Jawad</surname>
            </name>
            <name>
              <given-names>Harin</given-names>
              <surname>Sellahewa</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CEEC.2013.6659457</pub-id>
          <article-title>Breast border extraction and pectoral muscle removal in MLO mammogram images</article-title>
          <source>2013 5th Computer Science and Electronic Engineering Conference (CEEC), Colchester, UK</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>219</volume>
          <page-range>192-202</page-range>
          <issue>1</issue>
          <year>2001</year>
          <person-group person-group-type="author">
            <name>
              <surname>Birdwell</surname>
              <given-names>Robyn L.</given-names>
            </name>
            <name>
              <surname>Ikeda</surname>
              <given-names>Debra M.</given-names>
            </name>
            <name>
              <surname>O'Shaughnessy</surname>
              <given-names>Kevin F.</given-names>
            </name>
            <name>
              <surname>Sickles</surname>
              <given-names>Edward A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1148/radiology.219.1.r01ap16192</pub-id>
          <article-title>Mammographic characteristics of 115 missed cancers later detected with screening mammography and the potential utility of computer-aided detection</article-title>
          <source>Radiology</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>e982437</page-range>
          <issue>4</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Roussel</surname>
              <given-names>Norbert</given-names>
            </name>
            <name>
              <surname>Sprenger</surname>
              <given-names>Julie</given-names>
            </name>
            <name>
              <surname>Tappan</surname>
              <given-names>Scott J.</given-names>
            </name>
            <name>
              <surname>Glaser</surname>
              <given-names>John R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.4161/21624054.2014.982437</pub-id>
          <article-title>Robust tracking and quantification of C. elegans body shape and locomotion through coiling,entanglement, and omega bends</article-title>
          <source>Worm</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <volume>16</volume>
          <page-range>703-710</page-range>
          <issue>6</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jebamony</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Jacob</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2174/1573405615666190801121506</pub-id>
          <article-title>Classification of benign and malignant breast masses on mammograms for large datasets using core vector machines</article-title>
          <source>Curr. Med. Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="conf-paper">
          <page-range>557–565</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>Abdellatif</surname>
            </name>
            <name>
              <given-names>T. E.</given-names>
              <surname>Taha</surname>
            </name>
            <name>
              <given-names>O. F.</given-names>
              <surname>Zahran</surname>
            </name>
            <name>
              <given-names>W.</given-names>
              <surname>Al-Nauimy</surname>
            </name>
            <name>
              <given-names>F. E.</given-names>
              <surname>Abd El-Samie</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/NRSC.2013.6587963</pub-id>
          <article-title>K9. automatic segmentation of digital mammograms to detect masses</article-title>
          <source>2013 30th National Radio Science Conference (NRSC), Cairo, Egypt</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>262995</page-range>
          <issue>1</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chaubey</surname>
              <given-names>A.  K.</given-names>
            </name>
          </person-group>
          <article-title>Breast segmentation in mammograms using manual thresholding</article-title>
          <source>World J. Res. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>e14464</page-range>
          <issue>7</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gardezi</surname>
              <given-names>S. J. S.</given-names>
            </name>
            <name>
              <surname>Elazab</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lei</surname>
              <given-names>B. Y.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>T. F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2196/14464</pub-id>
          <article-title>Breast cancer detection and diagnosis using mammographic data: Systematic review</article-title>
          <source>J. Med. Internet Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="conf-paper">
          <page-range>22-25</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S. H.</given-names>
              <surname>Gu</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Ji</surname>
            </name>
            <name>
              <given-names>Y. J.</given-names>
              <surname>Chen</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>J. U.</given-names>
              <surname>Kim</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/CIA.2015.13</pub-id>
          <article-title>Study on breast mass segmentation in mammograms</article-title>
          <source>Information and Application 2015 3rd International Conference on Computer, Yeosu, Korea (South)</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <issue>1</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ribli</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Horvath</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Unger</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Pollner</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Csabai</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s41598-018-22437-z</pub-id>
          <article-title>Detecting and classifying lesions in mammograms with deep learning</article-title>
          <source>Sci. Rep.</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>315-337</page-range>
          <year>2000</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pham</surname>
              <given-names>Dzung L</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>Chenyang</given-names>
            </name>
            <name>
              <surname>Prince</surname>
              <given-names>Jerry L</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1146/annurev.bioeng.2.1.315</pub-id>
          <article-title>Current methods in medical image segmentation</article-title>
          <source>Annu. Rev. Biomed. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="journal">
          <volume>2021</volume>
          <page-range>e9962109</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Michael</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>H. J.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Kulwa</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2021/9962109</pub-id>
          <article-title>Breast cancer segmentation methods: Current status and future potentials</article-title>
          <source>BioMed. Res. Int.</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>90</page-range>
          <issue>1</issue>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dehghani</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Dezfooli</surname>
              <given-names>M A</given-names>
            </name>
          </person-group>
          <article-title>A method for improve preprocessing images mammography</article-title>
          <source>Int. J. Inf. Educ. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>1-11</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Loizidou</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Skouroumouni</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Nikolaou</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Pitris</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/JTEHM.2022.3219891</pub-id>
          <article-title>Automatic breast mass segmentation and classification using subtraction of temporally sequential digital mammograms</article-title>
          <source>IEEE J. Transl. Eng. Health. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="conf-paper">
          <page-range>557-562</page-range>
          <year>2009</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S. S.</given-names>
              <surname>Mohamed</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Behiels</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Dewaele</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TIC-STH.20095444438</pub-id>
          <article-title>Mass candidate detection and segmentation in digitized mammograms</article-title>
          <source>2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH), Toronto, ON, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="journal">
          <volume>30</volume>
          <page-range>1111-1122</page-range>
          <issue>7</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gu</surname>
              <given-names>Sheng Hua</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Yi</given-names>
            </name>
            <name>
              <surname>Sheng</surname>
              <given-names>Fang Qing</given-names>
            </name>
            <name>
              <surname>Zhan</surname>
              <given-names>Tian Ming</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Yun Jie</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s00138-019-01020-0</pub-id>
          <article-title>A novel method for breast mass segmentation: From superpixel to subpixel segmentation</article-title>
          <source>Mach. Vis. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_40">
        <label>40.</label>
        <element-citation publication-type="conf-paper">
          <page-range>170-175</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <given-names>N.</given-names>
              <surname>Ramadĳanti</surname>
            </name>
            <name>
              <given-names>A. R.</given-names>
              <surname>Barakbah</surname>
            </name>
            <name>
              <given-names>F. A.</given-names>
              <surname>Husna</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/KCIC.2018.8628467</pub-id>
          <article-title>Automatic breast tumor segmentation using hierarchical K-means on mammogram</article-title>
          <source>2018 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC), Bali, Indonesia</source>
        </element-citation>
      </ref>
      <ref id="ref_41">
        <label>41.</label>
        <element-citation publication-type="journal">
          <volume>24</volume>
          <issue>2</issue>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Senthilkumar</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Umamaheswari</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Combination of novel enhancement technique and fuzzy C means clustering technique in breast cancer detection</article-title>
          <source>Biomed. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_42">
        <label>42.</label>
        <element-citation publication-type="journal">
          <year>2014</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dhungel</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Carneiro</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>A. P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1410.7454</pub-id>
          <article-title>Deep structured learning for mass segmentation from mammograms</article-title>
          <source>arXiv preprint arXiv:1410.7454,</source>
        </element-citation>
      </ref>
      <ref id="ref_43">
        <label>43.</label>
        <element-citation publication-type="journal">
          <volume>28</volume>
          <page-range>604-612</page-range>
          <issue>5</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Oliver</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Tortajada</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lladó</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Freixenet</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ganau</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tortajada</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Vilagran</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sentís</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Martí</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10278-015-9777-5</pub-id>
          <article-title>Breast density analysis using an automatic density segmentation algorithm</article-title>
          <source>J. Digit. Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_44">
        <label>44.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-7</page-range>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <given-names>T. T.</given-names>
              <surname>Wirtti</surname>
            </name>
            <name>
              <given-names>E. O. T.</given-names>
              <surname>Salles</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/BRC.2011.5740680</pub-id>
          <article-title>Segmentation of masses in digital mammograms</article-title>
          <source>ISSNIP Biosignals and Biorobotics Conference, Vitoria, Brazil</source>
        </element-citation>
      </ref>
      <ref id="ref_45">
        <label>45.</label>
        <element-citation publication-type="journal">
          <volume>27</volume>
          <page-range>196-200</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>T. Y.</given-names>
            </name>
            <name>
              <surname>Gou</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>J. G.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>F. Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/LSP.2019.2963151</pub-id>
          <article-title>Simultaneous segmentation and classification of mass region from mammograms using a mixed-supervision guided deep model</article-title>
          <source>IEEE Signal Process. Lett.</source>
        </element-citation>
      </ref>
      <ref id="ref_46">
        <label>46.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>988</page-range>
          <issue>11</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saffari</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Rashwan</surname>
              <given-names>H. A.</given-names>
            </name>
            <name>
              <surname>Abdel-Nasser</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>V. K.</given-names>
            </name>
            <name>
              <surname>Arenas</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Mangina</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Herrera</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Puig</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/diagnostics10110988</pub-id>
          <article-title>Fully automated breast density segmentation and classification using deep learning</article-title>
          <source>Diagnostics (Basel)</source>
        </element-citation>
      </ref>
      <ref id="ref_47">
        <label>47.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>e200159</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hu</surname>
              <given-names>Q. Y.</given-names>
            </name>
            <name>
              <surname>Whitney</surname>
              <given-names>H. M.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Ji</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>P. F.</given-names>
            </name>
            <name>
              <surname>Giger</surname>
              <given-names>M. L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1148/ryai.2021200159</pub-id>
          <article-title>Improved classification of benign and malignant breast lesions using deep feature maximum intensity projection MRI in breast cancer diagnosis using dynamic contrast-enhanced MRI</article-title>
          <source>Radiol. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_48">
        <label>48.</label>
        <element-citation publication-type="journal">
          <volume>81</volume>
          <page-range>13935-13960</page-range>
          <issue>10</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dewangan</surname>
              <given-names>K K</given-names>
            </name>
            <name>
              <surname>Dewangan</surname>
              <given-names>D K</given-names>
            </name>
            <name>
              <surname>Sahu</surname>
              <given-names>S P</given-names>
            </name>
            <name>
              <surname>Janghel</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11042-022-12385-2</pub-id>
          <article-title>Breast cancer diagnosis in an early stage using novel deep learning with hybrid optimization technique</article-title>
          <source>Multimed. Tools Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_49">
        <label>49.</label>
        <element-citation publication-type="journal">
          <volume>200</volume>
          <page-range>105913</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tsochatzidis</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Koutla</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Costaridou</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Pratikakis</surname>
              <given-names>I</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.cmpb.2020.105913</pub-id>
          <article-title>Integrating segmentation information into CNN for breast cancer diagnosis of mammographic masses</article-title>
          <source>Comput. Methods Programs Biomed.</source>
        </element-citation>
      </ref>
      <ref id="ref_50">
        <label>50.</label>
        <element-citation publication-type="conf-paper">
          <page-range>475-484</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>D.</given-names>
              <surname>Abdelhafiz</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Nabavi</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Ammar</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Yang</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Bi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3307339.3342157</pub-id>
          <article-title>Residual deep learning system for mass segmentation and classification in mammography</article-title>
          <source>Proceedings of the 10th ACMInternational Conference on Bioinformatics, Computational Biology and Health Informatics, Niagara Falls, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_51">
        <label>51.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>86-94</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hossain</surname>
              <given-names>M. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.jksuci.2019.10.014</pub-id>
          <article-title>Microcalcification segmentation using modified U-net segmentation network from mammogram images</article-title>
          <source>J. King Saud Univ. Comput. Inf. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_52">
        <label>52.</label>
        <element-citation publication-type="journal">
          <volume>65</volume>
          <page-range>055005</page-range>
          <issue>5</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sun</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Cheng</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Bo Qiang</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Zai Yi</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Mei Yun</given-names>
            </name>
            <name>
              <surname>Zheng</surname>
              <given-names>Hai Rong</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>David Dagan</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Shan Shan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1361-6560/ab5745</pub-id>
          <article-title>AUNet: Attention-guided dense-upsampling networks for breast mass segmentation in whole mammograms</article-title>
          <source>Phys. Med. Biol.</source>
        </element-citation>
      </ref>
      <ref id="ref_53">
        <label>53.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1814–1817</page-range>
          <year>2004</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J. E.</given-names>
              <surname>Ball</surname>
            </name>
            <name>
              <given-names>T. W.</given-names>
              <surname>Butler</surname>
            </name>
            <name>
              <given-names>L. M.</given-names>
              <surname>Bruce</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/IEMBS.2004.1403541</pub-id>
          <article-title>Towards automated segmentation and classification of masses in mammograms</article-title>
          <source>The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, San Francisco, CA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_54">
        <label>54.</label>
        <element-citation publication-type="journal">
          <volume>30</volume>
          <page-range>173-190</page-range>
          <issue>S1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhou</surname>
              <given-names>K. C.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>D. Z.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3233/THC-228017</pub-id>
          <article-title>Deep learning-based breast region extraction of mammographic images combining pre-processing methods and semantic segmentation supported by Deeplab v3+</article-title>
          <source>Technol. Health Care</source>
        </element-citation>
      </ref>
      <ref id="ref_55">
        <label>55.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>V. K.</given-names>
            </name>
            <name>
              <surname>Rashwan</surname>
              <given-names>H. A.</given-names>
            </name>
            <name>
              <surname>Romani</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Akram</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Pandey</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Sarker</surname>
              <given-names>M. M. K.</given-names>
            </name>
            <name>
              <surname>Saleh</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Arenas</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Arquez</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Puig</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Torrents-Barrena</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1809.01687</pub-id>
          <article-title>Breast tumor segmentation and shape classification in mammograms using generative adversarial and convolutional neural network</article-title>
          <source>arXiv preprint arXiv:1809.01687</source>
        </element-citation>
      </ref>
      <ref id="ref_56">
        <label>56.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>2041</page-range>
          <issue>12</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Taylor</surname>
              <given-names>C. R.</given-names>
            </name>
            <name>
              <surname>Monga</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Johnson</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Hawley</surname>
              <given-names>J. R.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/diagnostics13122041</pub-id>
          <article-title>Artificial intelligence applications in breast imaging: Current status and future directions</article-title>
          <source>Diagnostics</source>
        </element-citation>
      </ref>
      <ref id="ref_57">
        <label>57.</label>
        <element-citation publication-type="journal">
          <volume>49</volume>
          <page-range>25-32</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Carter</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Rogers</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Win</surname>
              <given-names>K. T.</given-names>
            </name>
            <name>
              <surname>Frazer</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Richards</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Houssami</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.breast.2019.10.001</pub-id>
          <article-title>The ethical, legal and social implications of using artificial intelligence systems in breast cancer care</article-title>
          <source>The Breast</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>