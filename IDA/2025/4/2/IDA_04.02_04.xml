<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IDA</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Information Dynamics and Applications</journal-title>
        <abbrev-journal-title abbrev-type="issn">Inf. Dyn. Appl.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IDA</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1494</issn>
      <issn publication-format="print">2958-1486</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-WXfLDnytNvKRGpAwWyHOFA4cGBxeP2he</article-id>
      <article-id pub-id-type="doi">10.56578/ida040204</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Novel Performance-Based Hyperparameter Optimization with the Use of Bounding Box Tuner (BBT)</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0005-2671-8832</contrib-id>
          <name>
            <surname>Mutlu</surname>
            <given-names>Abdulvahap</given-names>
          </name>
          <email>241144107@firat.edu.tr</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-9677-5684</contrib-id>
          <name>
            <surname>DoğAn</surname>
            <given-names>şEngüL</given-names>
          </name>
          <email>sdogan@firat.edu.tr</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5126-6445</contrib-id>
          <name>
            <surname>Tuncer</surname>
            <given-names>TüRker</given-names>
          </name>
          <email>turkertuncer@firat.edu.tr</email>
        </contrib>
        <aff id="aff_1">Department of Digital Forensics Engineering, Technology Faculty, Firat Universityy, 23119 Elazig, Turkey</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>29</day>
        <month>06</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>2</issue>
      <fpage>95</fpage>
      <lpage>114</lpage>
      <page-range>95-114</page-range>
      <history>
        <date date-type="received">
          <day>31</day>
          <month>05</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>24</day>
          <month>06</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Hyperparameter search was found not making good use of compute resources as surrogate-based optimizers consume extensive memory and demand long set-up time. Meanwhile, projects running with fixed budgets require lean tuning tools. The current study presents Bounding Box Tuner (BBT) and conducts tests of its capability to attain maximum validation accuracy while reducing tuning time and memory use. The project team compared BBT with Random Search, Gaussian Processes for Bayesian Optimization, Tree-Structured Parzen Estimator (TPE), Evolutionary Search and Local Search to decide on the optimum option. Modified National Institute of Standards and Technology (MNIST) classification with a multilayer perceptron (0.11 M weights) and Tiny Vision Transformer (TinyViT) (9.5 M weights) were adopted. Each optimizer was assigned to run 50 trials. During the trial, early pruning stopped a run if validation loss rose for four epochs. All tests applied one NVIDIA GTX 1650 Ti GPU; the key metrics for measurement included best validation accuracy, total search time, and time per trial. As regards the perceptron task, BBT reached 97.88% validation accuracy in 1994 s whereas TPE obtained 97.98% in 2976 s. Concerning TinyViT, BBT achieved 94.92% in 2364 s, and GP-Bayesian gained 94.66% in 2191 s. It was discovered that BBT kept accuracy within 0.1 percentage points of the best competitor and reduced tuning time by one-third. The algorithm renders the surrogate model unnecessary, enforces constraints by design and exposes solely three user parameters. Supported by the evidence of these benefits, BBT was considered to be a practical option for rapid and resource-aware hyperparameter optimization in deep-learning pipelines.</p></abstract>
      <kwd-group>
        <kwd>Bounding Box Tuner</kwd>
        <kwd>Hyperparameter optimization</kwd>
        <kwd>Performance-based tuning</kwd>
        <kwd>Hyperparameter optimization methods</kwd>
        <kwd>Axis-aligned sampling</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Machine learning</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="3"/>
        <fig-count count="5"/>
        <table-count count="3"/>
        <ref-count count="76"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Hyperparameter optimization (HPO) constitutes the basis of modern machine learning workflows. Even apparently modest neural networks expose an intertwined set of learning rates, architectural depths, regularization coefficients and batch sizes whose combined values determine training stability, convergence speed and most importantly, generalization. Over the past decade, practitioners have migrated from exhaustive grid search to more sophisticated strategies such as random sampling, Bayesian Optimization with Gaussian Processes or Tree-Structured Parzen Estimators, successive-halving schemes (e.g., Hyperband and Asynchronous Successive Halving Algorithm (ASHA)), as well as population-based evolutionary algorithms [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>]. These methods demonstrate their capability in reducing the sessions of full-length training required to locate near-optimal configurations, yet each carries trade-offs that affect their performance in time- or resource- constrained environments [<xref ref-type="bibr" rid="ref_7">7</xref>].</p><p>Bayesian optimization achieves data-efficient exploration through surrogate modelling but incurs expensive model retraining cost for iteration, scales unsatisfactorily as the dimensionality or noise of the search space elevates, and frequently ignores meaningful inter-parameter interactions by relying on separable kernels or univariate acquisition updates.</p><p>Successive-halving families exploit early stopping to cull weak configurations; however, they treat the admissible hyperparameter domain as static, hence devoting budget to regions that soon prove unpromising.</p><p>Evolutionary and population-based training embrace non-convex landscapes by mutating and recombining entire parameter vectors. Nevertheless, they generally require hundreds of objective evaluations before convergence; unguarded mutation could also result in excessive budget expenditure on implausible regions [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>] .</p><p>As a consequence, researchers and engineers deploying deep models in edge devices, research prototypes or limited-credit cloud platforms still grapple with long tuning cycles and escalating costs, particularly when they cannot leverage large, distributed clusters or proprietary Automated Machine Learning (AutoML) systems [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>].</p>
      
        <sec>
          
            <title>1.1. Literature review</title>
          
          
            <sec>
              
                <title>1.1.1 Random and grid search</title>
              
              <p>Exhaustive grid search was one of the earliest strategies for hyperparameter tuning, systematically evaluating points on a predefined grid in the hyperparameter space. Despite being straightforward, grid search suffers from the curse of dimensionality: the number of combinations grows exponentially along with the number of hyperparameters, hence curtailing the feasibility to cover a fine-grained grid when more than a few hyperparameters are involved.</p><p>Random search offers a straightforward and effective alternative by sampling hyperparameter configurations uniformly at random from the search space. Contrary to expectations, random search has been demonstrated to outperform grid search in high-dimensional settings because, with the same number of trials, it explores a broader range of values for each discrete hyperparameter rather than redundantly evaluating many combinations along a rigid and systematic grid. Random search is completely <italic>exploration</italic>-oriented; despite its comprehensive exploration of the hyperparameter landscape, it does not incorporate any learning from past trials to guide future searches. Yet, the search itself could serve as a robust baseline in numerous studies due to its simplicity and ability to scale with arbitrary dimensions and search spaces. In practice, random search is frequently used in combination with early stopping heuristics or as a component within more advanced algorithms (e.g., as the initial exploration phase). </p>
            </sec>
          
          
            <sec>
              
                <title>1.1.2 Bayesian optimization</title>
              
              <p>Bayesian optimization is a model-based approach to hyperparameter tuning that has gained prominence for its efficiency in searching expensive, black-box functions [<xref ref-type="bibr" rid="ref_12">12</xref>]. The essential idea is to establish a probabilistic surrogate model of the objective function (e.g., validation error as a function of hyperparameters) based on the results of previous trials, and then apply this model to plan for the setting of the next hyperparameter. Typically, Bayesian HPO methods apply a Gaussian Process (GP) or a Tree-Structured Parzen Estimator (TPE) or other regression model to the observed performance data [<xref ref-type="bibr" rid="ref_13">13</xref>]. This surrogate provides a predictive distribution for the performance of any candidate hyperparameter configuration, which is then used by an acquisition function to balance exploration and exploitation when proposing the next query point.</p><p>Bayesian optimization has been successfully utilized to tuning machine learning algorithms, usually achieving better results with far fewer evaluations than random or grid search, especially when the hyperparameter search space ranges from low- to moderate-dimensional and the cost of training/evaluating one configuration is substantial. The approach explicitly manages the exploration-exploitation trade-off: early iterations will explore broadly since uncertainty in the surrogate is high everywhere. As data accumulate, the model homes in on promising regions, i.e., exploiting the surrogate’s knowledge to fine-tune the best observed peaks [<xref ref-type="bibr" rid="ref_14">14</xref>]. Theoretically speaking, under certain smoothness assumptions and appropriate acquisition functions, Bayesian optimization is found to converge towards the global optimum, with bounds on regret (difference occurs between the found solution and the true optimum) that decay as more evaluations have been performed [<xref ref-type="bibr" rid="ref_15">15</xref>].</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.3 Evolutionary and population-based algorithms</title>
              
              <p>Evolutionary algorithms approach HPO by mimicking principles of natural evolution, searching for good configurations through a process of mutation, recombination, and selection applied to a population of candidate solutions. In the context of HPO, an individual in the population encodes a set of hyperparameters as a “chromosome” string. A genetic algorithm (GA) will randomly initialize a population of such individuals in hyperparameter settings, evaluate their fitness (e.g., the negative validation error of a model trained with those hyperparameters), and then iteratively produce new generations by selecting fitter individuals to breed/crossover and randomly mutating some of their hyperparameter values. Over successive generations, the population tends to accumulate better hyperparameter configurations, as high-performing regions of the search space are exploited and combined, while mutation introduces new exploratory variations. Other evolutionary and bio-inspired algorithms like Particle Swarm Optimization (PSO) and Differential Evolution (DE) have been applied to hyperparameter search; these maintain a set of candidate solutions that move through the search space influenced by their own and their neighbors’ past successes (PSO) or by differential mutations of population members (DE), gradually converging toward optima [<xref ref-type="bibr" rid="ref_16">16</xref>], [<xref ref-type="bibr" rid="ref_17">17</xref>]. Evolutionary approaches are particularly flexible as exemplified by their handling of discrete and continuous hyperparameters, complex mixed-type spaces, and multiple objectives naturally [<xref ref-type="bibr" rid="ref_18">18</xref>]. They typically do not rely on smoothness or differentiability of the objective, but on the capability to evaluate hyperparameter configurations. This renders them more robust at the cost of frequently requiring a considerable number of evaluations to reach convergence, especially if the population size and the number of generations are large. In practice, evolutionary algorithms have been utilized effectively for tuning deep networks and in neural architecture search, where the search space is significantly large and highly non-convex; they have discovered novel architectures or hyperparameter schedules that human experts might not consider beforehand [<xref ref-type="bibr" rid="ref_19">19</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>].</p><p>A notable family of evolutionary HPO methods in deep learning is population-based training (PBT) [<xref ref-type="bibr" rid="ref_8">8</xref>]. PBT is a specific strategy that blends evolutionary ideas with online training of models: instead of evaluating each hyperparameter configuration from scratch, PBT maintains a population of neural network training processes running in parallel, each with its own hyperparameters. At periodic intervals (epochs or batches), the algorithm selects the best-performing models and exploits them by replacing the worst-performing models with copies of the best (including their learned weights), then explores by mutating the hyperparameters of those copied models (e.g., slightly perturbing the learning rate or dropout rate). This way, PBT effectively tunes hyperparameters on the fly as part of the training process, continually adapting hyperparameters based on intermediate results. Over time, less effective hyperparameter settings are pruned out, and all training resources are shifted toward variants of the better settings.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.4 Local search and greedy strategies</title>
              
              <p>Local Search and greedy strategies focus on iteratively improving a single hyperparameter configuration by making local changes, rather than maintaining a global population or probabilistic model of the entire space. These methods start from an initial guess (which could be randomly chosen or informed by prior knowledge) and then proceed to greedily adjust hyperparameters in order to reduce the objective (e.g., validation loss), one small step at a time. A simple example is coordinate descent, an optimization algorithm that reduces a function by optimizing along coordinate directions iteratively, on hyperparameters. In other words, one can fix all but one hyperparameter and then do a one-dimensional search (or just experiment with a few increments/decrements) to locate a better value for that hyperparameter, then proceed to another hyperparameter, cycling through them iteratively. This technique treats each hyperparameter separately and ignores interactions in the short term, but can be effective if the hyperparameters are roughly independent or if a good solution can be found by sequentially tuning each to optimality. Another approach is iterative refinement or hill climbing, where at each step, the algorithm tries small random perturbations of the current best hyperparameter set (e.g., slightly increasing or decreasing a continuous hyperparameter, or toggling a categorical option) and moves to the new configuration if it improves performance [<xref ref-type="bibr" rid="ref_21">21</xref>]. After numerous iterations, hill climbing will pursue a path of incremental improvements until it reaches a point where no local tweak yields a satisfactory consequence (a local optimum). Greedy Local Searches are typically fast and simple to implement; they may operate effectively when the hyperparameter space is smooth and unimodal around the optimum so that a local optimum is likely the global optimum. Nevertheless, in deep learning, hyperparameter landscapes are often rugged and multimodal, namely a purely local method could become entangle in a suboptimal region because it fails to take into account more radical changes that would adversely affect performance at first but later lead to a better configuration [<xref ref-type="bibr" rid="ref_22">22</xref>], [<xref ref-type="bibr" rid="ref_23">23</xref>]. Despite their limitations, Local Search strategies could play a role in HPO [<xref ref-type="bibr" rid="ref_24">24</xref>].</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.5 Multi-fidelity and hybrid approaches</title>
              
              <p>A significant development in hyperparameter optimization, especially pertinent to deep learning, is the class of multi-fidelity methods [<xref ref-type="bibr" rid="ref_25">25</xref>], [<xref ref-type="bibr" rid="ref_26">26</xref>]. These methods recognize that one can get partial information about the quality of a hyperparameter configuration by running a truncated or smaller version of the training job, thereby saving time and resources compared to running full training for every trial all the time. Evaluating a neural network after only a few epochs (or on a subset of the data, or with a smaller model size) provides a noisy estimate of its final performance, but this estimate is valuable to decide if further training should be conducted [<xref ref-type="bibr" rid="ref_25">25</xref>]. Multi-fidelity HPO algorithms implement this concept to allocate varying amounts of resources to different trials, pruning the unpromising ones early and providing full training selectively to the most promising configurations [<xref ref-type="bibr" rid="ref_27">27</xref>].</p><p>A basic algorithm in this category is the Successive Halving Algorithm (SHA) [<xref ref-type="bibr" rid="ref_4">4</xref>]. SHA begins by training a vast number of candidate hyperparameter configurations for a short-term budget, for instance, a few epochs each. After this initial stage, only the top-performing fraction of configurations, say the top 50%, are selected to continue the next step when the remaining ones are discarded. The “survivors” are then trained for a long-term budget with more epochs, and the selection process repeats to retain the top fraction, i.e., the best performers. This halving process continues several rounds until the final round, when a small number of, possibly one, configuration(s) are trained for the maximum budget. SHA is designed to spend most of its computation on the more promising hyperparameters, while quickly eliminating substandard performers to gather resources. The “racing” mechanism of SHA ensures a form of exploitation with focuses on winners after the initial exploration, effectively after a certain number of short trials. Theoretical analysis demonstrates that SHA could promptly locate the existence of an authentically optimal hyperparameter configuration, within a logarithmic factor, and its performance is comparable to an idealized oracle with the foresight to allocate resources [<xref ref-type="bibr" rid="ref_28">28</xref>]. Nevertheless, the drawback of SHA was its dependence on the choice of initial budget and the downsampling rate, namely the fraction of data to be kept in each round, so as to guarantee its effectiveness. If the initial budget is either meagre or enormous relative to the problem to be resolved, SHA might prematurely discard good configuration or waste resources, respectively.</p><p>Hyperband is an extension of successive halving that addresses the problem of determining the appropriate budget <italic>a priori</italic>. Hyperband essentially runs multiple trials of SHA with different settings in parallel or interleaved: all possible budget-per-trial settings are taken into account with a maximum amount of resources while some fractions of the overall effort are allocated to each setting. Practically, hyperband operates by defining several “brackets”, where each bracket is a SHA with a designated configuration (different initial number of configurations versus budget per configuration trade-off). Low-budget brackets could explore a certain number of configurations superficially whereas high-budget brackets possess more resources to focus on the examination of a few configurations deeply. By mixing both low-budget and high-budget brackets, Hyperband could become more robust to opt for the optimal budget requirements, thus Hyperband as a whole is comparable to the ideal SHA within a factor logarithmic in the ratio to be considered between the maximum and minimum budgets. Hyperband has been shown with empirical evidence to substantially speed up hyperparameter search for deep networks, when compared to random search. The process of boosting the performance of hyperparameter search could be done by early termination of substandard models and adoption of only a fraction of computation to find models with satisfactory performance which is comparable to random search. Obviously, hyperband is data-driven and adaptive, requiring no prior guess about how long to train each model, which is a major advantage in practice.</p><p>Plain Hyperband and SHA are limited in their applications as both treat the selection of configurations to continue as a blunt process based on only the current performance, without using any predictive modeling of the hyperparameter space. To rectify the problem, hybrid methods such as the Bayesian Optimization + HyperBand (BOHB) is employed as a proposed solution [<xref ref-type="bibr" rid="ref_29">29</xref>]. BOHB augments the Hyperband procedure with a Bayesian optimization perspective as it employs a Tree Parzen Estimator (TPE) model to guide the sampling of new hyperparameter configurations, instead of choosing them uniformly at random. The multi-fidelity racing of Hyperband is used by BOHB to evaluate a certain number of configurations, but preferentially sample configurations that past observations indicate are promising, according to the TPE model that is updated with the concomitant results. This hybrid gains the advantages of both worlds in one go: the agility of Hyperband to quickly discard bad options, and the guiding hand of Bayesian model-based search to bias the exploration towards better regions of the space. To compare tasks like tuning convolutional neural networks and reinforcement learning hyperparameters, BOHB has demonstrated more robust performance than either Hyperband or Bayesian optimization alone, especially under tight budget when pure random exploration or pure model-based exploitation can falter.</p><p>Another modern approach in this vein is the use of evolutionary algorithms with aggressive early stopping. For example, Differential Evolution HyperBand (DEHB) combines an evolutionary search strategy, i.e., differential evolution, with the multi-fidelity evaluation of Hyperband. A DE evolution is executed over hyperparameter populations while subjecting individuals to successive halving-style culling based on partial results [<xref ref-type="bibr" rid="ref_30">30</xref>]. Adopting a similar approach, one can integrate Asynchronous Successive Halving (ASHA) as a scheduler with various search algorithms; ASHA is a version of successive halving that functions without synchronizing after completing each rung and it permits trials to commence and end asynchronously, hence creating ideal distributed settings with numerous parallel workers [<xref ref-type="bibr" rid="ref_5">5</xref>]. ASHA achieves practically the same result as Hyperband but with greater efficiency in real systems because workers are never left idle to wait for others to finish a rung. These hybrid and multi-fidelity methods reflect a trend in HPO towards adaptive resource allocation rather than treating each hyperparameter trial as an all-or-nothing proposition. They possess the selective momentum to dynamically allocate more resources to promising trials and curtail the resources spent on underperforming ones.</p><p>In terms of theoretical background, multi-fidelity methods like SHA/Hyperband could work in relation to the concept of exploration versus exploitation in multi-armed bandits [<xref ref-type="bibr" rid="ref_28">28</xref>], [<xref ref-type="bibr" rid="ref_31">31</xref>]. Each hyperparameter configuration in these methods is like an arm; pulling an arm with a certain budget yields a noisy reward (partial training result). Algorithms like Hyperband implement a principled strategy to allocate pulls (training epochs) to each arm in proportions that balance discovering the best arm versus concentrating on arms that have seemingly good appearance. Convergence guarantees for these methods assume some forms of correlation between low-budget and high-budget performance, an implicit assumption that a substandard configuration after a small budget is unlikely to turn outstanding with more budget which usually holds in practice, despite the possibility of exceptions. Empirical studies on benchmarks for image classification, etc. show that multi-fidelity optimizers could reach near-optimal hyperparameter settings orders-of-magnitude faster in wall-clock time than conventional methods, particularly when training time is the bottleneck [<xref ref-type="bibr" rid="ref_32">32</xref>] These methods have soon been adopted in both academic research and production AutoML systems because they provide straightforward solution to address the heavy computational cost of deep learning HPO by pruning uneconomical trials early.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.6 Differentiable hyperparameter optimization</title>
              
              <p>The emerging research in hyperparameter optimization seeks to turn the hyperparameter tuning process differentiable, thereby enabling the use of gradient-based optimization methods to adjust hyperparameters [<xref ref-type="bibr" rid="ref_33">33</xref>]. Traditional HPO treats the training of a model with a given hyperparameter set as an atomic operation that yields a final validation loss or accuracy, with no notion of gradient in relation to hyperparameters, since the hyperparameters are not part of the end-to-end computation graph. Differentiable hyperparameter optimization methods formulate HPO as a bilevel optimization problem, in which the weights of the model are the inner-level variables and the hyperparameters are the upper-level variables to be optimized by differentiating during the training process [<xref ref-type="bibr" rid="ref_34">34</xref>].</p><p>One approach to differentiable HPO is to approximate the training procedure in a differentiable manner. For instance, one can train the model for a few steps and then use implicit differentiation or finite differences of the resulting validation loss to estimate gradients with respect to hyperparameters like learning rate or regularization strength [<xref ref-type="bibr" rid="ref_35">35</xref>], [<xref ref-type="bibr" rid="ref_36">36</xref>]. According to some pioneering works, certain hyperparameters including weight decay, or a learning rate schedule parameterized by a few variables could compute the gradient of the validation loss with respect to those hyperparameters. During the process, a truncated training loop is unrolled or closed-form solutions in simpler models could be used and then the hyperparameters are updated via gradient descent [<xref ref-type="bibr" rid="ref_37">37</xref>], [<xref ref-type="bibr" rid="ref_38">38</xref>]. Another approach involves relaxing discrete hyperparameters into continuous variables using a softmax or continuous relaxation technique. For example, methods inspired by differentiable neural architecture search, such as DARTS, create a weighted mixture of hyperparameter settings like a soft selection between alternative layer configurations or data augmentations. These methods apply gradient descent to adjust those weights, effectively identifying the optimal choices of hyperparameter [<xref ref-type="bibr" rid="ref_39">39</xref>]. Once training is complete, the continuous relaxation is projected back to a discrete choice by picking the argmax weight as the hyperparameter choice [<xref ref-type="bibr" rid="ref_39">39</xref>], [<xref ref-type="bibr" rid="ref_40">40</xref>].</p><p>A recent innovation in this domain is to perform HPO within a single training run [<xref ref-type="bibr" rid="ref_35">35</xref>]. Instead of the traditional loop of “set hyperparameters, fully trained model, observed results”, differentiable HPO can adjust hyperparameters continuously in one training cycle. As a concrete example, an approach dubbed Differentiable Hyperparameter Optimization (DHPO) has been proposed where hyperparameters of each layer (like kernel sizes, and numbers of filters, etc.) are encoded as learnable parameters alongside the weights of networks, and an outer loss on a validation set guides their updates [<xref ref-type="bibr" rid="ref_35">35</xref>], [<xref ref-type="bibr" rid="ref_37">37</xref>], [<xref ref-type="bibr" rid="ref_38">38</xref>]. Such methods have reported achieving similar or better accuracy than exhaustive HPO at a fraction of the cost. They tune several hyperparameters in one run that would normally require training dozens of separate models via random or Bayesian search, hence yielding an order-of-magnitude speedup.</p><p>While promising, differentiable HPO comes with practical challenges, the bilevel optimization is unstable or memory-intensive as it keeps track of changes in hyperparameters that would have affected the outcomes of training. Techniques like truncating the unrolled training (to a smaller number of steps) or using approximations (like using older model states to approximate the hyperparameter gradient) are considered necessary. There is also a risk of hyperparameters overfitting the validation set if not regularized, because they are directly optimized to minimize validation error within the same run when that validation data is found. Theoretical analysis of these methods typically uses bilevel optimization theory; under certain convexity assumptions, the theory could guarantee convergence to stationary points of the validation loss with respect to hyperparameters. In non-convex settings as in the case of deep networks, one could not ensure global optimality and the methods might converge to a local optimum of the hyperparameters, though still performing well in practice.</p><p>In summary, differentiable hyperparameter optimization represents a cutting-edge trend aiming to further automate and speed up model tuning by merging the boundary between training and tuning. It complements the other methods under discussion so far; Bayesian and evolutionary methods operate at the level of discrete trials and treat the model as a black box; differentiable HPO opens the black box to peek at the influence of hyperparameters on training dynamics. This area is still undergoing active development, yet not commonly used in large-scale practices, it offers a glimpse of future AutoML systems where models could self-tune many of their own hyperparameters through gradient-driven adaptation.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.7 Early stopping based on validation performance</title>
              
              <p>One of the most common regularization and time-saving strategies in deep learning is early stopping. If further training is observed to degrade validation performance or yield no meaningful improvement, the training of a model will be suspended before the nominal number of training iterations (epochs) is completed [<xref ref-type="bibr" rid="ref_41">41</xref>], [<xref ref-type="bibr" rid="ref_42">42</xref>]. Typical early stopping implementation sets aside a validation dataset and monitors a relevant metric (e.g., validation loss or accuracy) after running each epoch or every few epochs. If the validation metric has not improved for a certain number of consecutive checks (say a patience parameter), training is stopped based on the assumption that the model overfits or it is noted that even when the training continues, there will not be additional benefits beyond random fluctuations. The model parameters from the epoch with the best validation score are then taken to be the final choice. This straightforward procedure effectively guards against overfitting as it inherently balances insufficient training (underfitting) and excessive training (overfitting on the training data) by using the validation set to guide the finding of an approximate sweet spot for stopping.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.8 Successive halving and hyperband for early stopping</title>
              
              <p>While the conventional early stopping is applied to a single training run so as to prevent the occurrence of overfitting, similar principles could be employed in hyperparameter search at a higher level when running numerous trainings. Previous sections in this study have covered the notion that algorithms like Successive Halving and Hyperband implement systematic early stopping of multiple trials. In these contexts, early stopping is not primarily about avoiding overfitting but about efficient allocation of computational resources among competing hyperparameter candidates. The design of Successive Halving (SHA) helps save running a large fraction of trials after a few epochs and permits a selective subset to continue. This method is useful in performing automated early stopping for trials that appear least promising. Any single model might have stopped in advance before it overfits and its performance is worse than others.</p><p>The efficacy of SHA/Hyperband as early stopping strategies relies on the assumption of correlation in which a hyperparameter configuration that yields poor validation accuracy after, say 1 epoch, is likely to be subpar after 50 epochs [<xref ref-type="bibr" rid="ref_25">25</xref>]. This assumption could be upheld most of the time as some configurations might learn slowly and eventually outperform others if there is sufficient time allocation. The bracket strategy of Hyperband functions partially as a hedge against such cases by allotting certain configurations more initial budget in some brackets. If a configuration is truly a “late bloomer”, one of the brackets with a larger initial budget might catch its potential whereas the most aggressive bracket might stop it too early. Thus, Hyperband is robust since it depends not just on a single stopping schedule.</p><p>These multi-trial early stopping methods directly impact the practical HPO. When tuning a deep neural network on an image classification task instead of training each candidate for a fixed 100 epochs, one could use Hyperband to train, namely 50 candidates for 10 epochs, then continue only the top 10 of those to 30 epochs, and afterwards, continue the top 3 to the full 100 epochs. The final result, i.e., the best of those 3 fully trained models, will be nearly as good as the best out of training all 50 for 100 epochs, but the total computation used is only a fraction of training 50×100 epochs (roughly, it trained 50 for 10 + 10 for 20 more + 3 for 70 more, which is about 50×10 + 10×20 + 3×70 = 500 + 200 + 210 = 910 epoch-equivalents, versus 5000 epoch-equivalents if all were trained fully). In this hypothetical theory, Hyperband used <inline-formula>
  <mml:math id="mc5uua0nq5">
    <mml:mo>∼</mml:mo>
  </mml:math>
</inline-formula>18% of the computation of exhaustive search, hence an enormous saving. In exchange, one accepts a small risk: it might miss a configuration that would have eventually been the best because it looked mediocre in the first 10 epochs and got terminated. Empirical evidence and benchmarks suggest that this trade-off is worthwhile in most of the cases. The opportunity of missing the global optimum is low if the performance after a small fraction of training is at least somewhat predictive of final performance, as is the case in many tasks.</p><p>In summary, SHA and Hyperband generalize the idea of early stopping from “stop training when there is no improvement” (single run to avoid overfitting) to “stop training this configuration if it is unlikely to be the best” (multiple runs to allocate effort properly). Both uses of early stopping are complementary: one can and should use validation-based stopping within each training run to avoid overfitting and use SHA/Hyperband logic across runs to budget evaluation time. Modern HPO frameworks do both. For instance, they might run many trials with a scheduler like ASHA, and within each trial, the training code uses an early stopping callback for its own training convergence; whichever criterion triggers first will stop that trial (either outperformed by peers or plateaued on validation). This layering of early stopping ensures maximal efficiency in searching hyperparameters for deep learning.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.9 Pruning models during training (structured and unstructured)</title>
              
              <p>Pruning in deep learning refers to techniques that remove parameters or structures from a neural network that are deemed unnecessary for making predictions, thus yielding a smaller (and often faster or more efficient) model with minimal loss in accuracy [<xref ref-type="bibr" rid="ref_43">43</xref>], [<xref ref-type="bibr" rid="ref_44">44</xref>]. Pruning is generally implemented subsequent to or during the training process to achieve model compression or to diminish computational requirements.</p><p>Two broad categories of pruning are in practice and they involve unstructured pruning and structured pruning. Unstructured pruning removes individual weights from the weight matrices of the network (i.e., setting certain weight values to zero and eliminating their influence effectively). This leads to a sparse network: the original architecture/number of layers and neurons remains constant but many connections have zero weight and can be omitted from computation [<xref ref-type="bibr" rid="ref_45">45</xref>]. A common criterion for unstructured pruning is magnitude; in other words, after training a model, one could remove all weights whose absolute values are below a certain threshold or simply remove the smallest X% of weights globally or per layer, on the intuition that those contribute least to the output [<xref ref-type="bibr" rid="ref_46">46</xref>].</p><p>Structured pruning removes higher-level structures; for example, entire neurons in a fully-connected layer, entire channels or filters in a convolutional layer, or whole attention heads in a transformer model [<xref ref-type="bibr" rid="ref_47">47</xref>], [<xref ref-type="bibr" rid="ref_48">48</xref>], [<xref ref-type="bibr" rid="ref_49">49</xref>]. The architecture of the network in structured pruning is changed effectively; therefore, if we remove 2 out of 64 filters in a convolutional layer, the input channels of subsequent layers are reduced. Structured pruning is advantageous in yielding a smaller dense network, which could directly translate to faster inference and less memory usage without the support of special hardware. The criteria for structured pruning include metrics like the <inline-formula>
  <mml:math id="mg9c4qjbz9">
    <mml:msub>
      <mml:mi>l</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> or <inline-formula>
  <mml:math id="mrswqmsdzm">
    <mml:msub>
      <mml:mi>l</mml:mi>
      <mml:mn>2</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> norm of filter weights (filters removed with the smallest norm, assuming they have least contribution), or more sophisticated importance such as the amount of the loss increased when a designated neuron is ablated [<xref ref-type="bibr" rid="ref_50">50</xref>], [<xref ref-type="bibr" rid="ref_51">51</xref>]. Structured pruning is generally used with caution because removing a whole unit could exert more significant impact on network function rather than removing a single weight. It is therefore common to retrain or fine-tune the network after pruning to enable the remaining units to compensate for the lost ones. When done iteratively to prune a little and retrain, even structured pruning could remove a significant fraction of units (e.g., 30-50% of filters) with only minor accuracy dropped in many vision models [<xref ref-type="bibr" rid="ref_48">48</xref>], [<xref ref-type="bibr" rid="ref_52">52</xref>].</p><p>When pruning is applied during training rather than as a post-processing step, it involves a schedule to start training the model with full capacity. Connections are pruned away at certain points or gradually. One method might be adopted to begin pruning after a few epochs; once the network has acquired some useful weights, every epoch removes the lowest-magnitude at 2% of the remaining weights until a target sparsity level is achieved by the end of the training. This approach, sometimes called gradual pruning, gives the network time to adjust to the decreasing capacity [<xref ref-type="bibr" rid="ref_46">46</xref>], [<xref ref-type="bibr" rid="ref_53">53</xref>]. It has been observed that if pruning is too aggressive too early, the training could deteriorate because the model might lose too many degrees of freedom before solidifying the essential patterns. Gradual pruning could integrate naturally with the training loop and could save training time in later epochs since the model becomes sparser and cheaper to evaluate, although initially one pays the cost of training the full model for some duration. Some recent strategies even do pruning from initialization or very early training: in the Lottery Ticket Hypothesis, there exists a subnetwork (“winning ticket”) within a randomly initialized dense network, so full accuracy could be reached if trained in isolation [<xref ref-type="bibr" rid="ref_54">54</xref>]. In this light, algorithms have been proposed to prune networks at initialization or after just a few epochs, to identify these winning subnetworks and then train only them to go forward, and to effectively train a much smaller network as soon as possible. This yields huge training speedups because the majority of weights are never even updated [<xref ref-type="bibr" rid="ref_55">55</xref>], [<xref ref-type="bibr" rid="ref_56">56</xref>]. However, it is challenging to reliably find such subnetworks without testing many combinations, and this remains an area for further research [<xref ref-type="bibr" rid="ref_57">57</xref>], [<xref ref-type="bibr" rid="ref_58">58</xref>].</p><p>In the context of hyperparameter optimization, model pruning could be viewed as another dimension of optimization. One might consider the sparsity level or prune percentage as a hyperparameter to tune (trading off model size versus accuracy) [<xref ref-type="bibr" rid="ref_59">59</xref>]. HPO methods have been applied to pruning to find the optimal layer-wise pruning ratios that yield the best accuracy-speed tradeoff. Furthermore, incorporating pruning into HPO could accelerate the evaluation of hyperparameters; therefore, if one hyperparameter setting consistently leads to a large amount of redundant weights, pruning during training could reduce computation and thus indirectly speed up the HPO process. Some HPO frameworks include built-in “pruners”; in that context, pruner means an algorithm which could stop underperforming trials as in Hyperband rather than pruning network weights. Yet the philosophy is analogous as it cuts off the unneeded computations [<xref ref-type="bibr" rid="ref_27">27</xref>]. Both forms of pruning aim to focus resources on the most important aspect.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.10 Adaptive resource allocation for tuning</title>
              
              <p>Adaptive resource allocation refers to strategies that dynamically determine the distribution of computational budget across various training runs or parts of training, based on ongoing results. Several instances of this concept have been encountered since the logic of Hyperband to allocate more epochs to promising trials, or the focus of PBT on promising members of a population are prime examples. Researchers have, beside those instances, explored various techniques to fine-tune resource allocation in hyperparameter searches and training processes.</p><p>One effective yet simple heuristic is the median stopping rule attempted in some industry AutoML platforms [<xref ref-type="bibr" rid="ref_60">60</xref>], [<xref ref-type="bibr" rid="ref_61">61</xref>]. In each trial of this approach, there are certain checkpoints like after each epoch or after a fixed wall-clock time; one could compute the median of the performance metric (e.g., validation accuracy) across all completed trials at the checkpoints. If the trial in question is performing worse than this median, it is stopped early. The intuition is that if a configuration is lagging behind the typical progress of other configurations, it is unlikely to become the best by the end, so resources are better spent elsewhere. This rule is adaptive and non-parametric, adjusting to the distribution of performance in the current experiment. It is less aggressive than Hyperband as this method stops roughly the bottom half rather than a predetermined fraction, but could be combined with other methods.</p><p>Another sophisticated approach is learning curve extrapolation, which is to train all trials for a minimal amount, e.g., a few epochs, and fit a model to the trajectory of performance of each trial over time. Techniques like Bayesian modeling of learning curves or parametric models (e.g., assuming performance follows a power-law or exponential saturation curve) allow one to predict the final performance of a model, given its partial learning curve [<xref ref-type="bibr" rid="ref_62">62</xref>]. Using these predictions, decision could be made promptly to stop those trials that are predicted to have a low final accuracy, even at the current epoch, they might not be the worst. Such approaches could sometimes identify “slow starters” that will eventually perform better to avoid the pitfall of naive early stopping. However, predicting learning curves reliably is challenging owing to the variety of curve shapes neural nets, i.e., some might plateau; others might jump after a certain epoch due to learning rate schedules. Current research has shown that given apt calibrated models and sufficient prior data, learning curve prediction could further boost the efficiency of HPO on top of methods like Hyperband via catering the stopping criterion to the behavior of each specific trial rather than using a one-size-fits-all schedule.</p><p>Adaptive resource allocation extends to methods like fidelity scheduling, where one might dynamically decide not just the duration of training, but aspects like resolution of input data or model size to be used for intermediate evaluations [<xref ref-type="bibr" rid="ref_26">26</xref>]. An HPO process might first try configurations on a smaller version of the dataset or a smaller network, and progressively increase the difficulty with full data or larger model for configurations that perform equally well in the smaller setting. This is akin to multi-fidelity, where fidelity could mean dataset size or model complexity but not just training epochs. The allocation of resources in this manner might quickly eliminate hyperparameters that just excel in small-scale tests and focus on those that could also function equally satisfactorily on larger scales.</p><p>Some recent work, on the algorithmic front, has applied reinforcement learning to the problem of resource allocation in HPO. A reinforcement learning agent observes the state of ongoing trials including their performances and remaining budgets to derive a policy to select the trial to extend or to allocate a new batch of resources, with the reward of attaining a high final model accuracy under a fixed total resource expense. This is a complex scenario but conceptually could outperform static policies by effectively allocating resources based on previous experience gained from a series of problems encountered. The agent might learn that certain patterns in early validation improvements are strong indicators of eventual success or failure, and so allocate budget accordingly.</p>
            </sec>
          
          
            <sec>
              
                <title>1.1.11 Bounding box tuner (bbt) in context</title>
              
              <p>The Bounding Box Tuner (BBT) is an innovation in hyperparameter optimization that builds upon the above approaches by introducing a dynamic space refinement mechanism [<xref ref-type="bibr" rid="ref_63">63</xref>], [<xref ref-type="bibr" rid="ref_64">64</xref>]. At its core, BBT adapts the search space itself during the optimization process, effectively tightening the bounds, i.e., the “bounding box” in hyperparameter space around regions with promising hyperparameters. This approach contrasts with most traditional HPO methods, which keep the hyperparameter search domain static throughout the search. As evidence accumulates, the search space shrinks, BBT could successfully focus computational effort on the most relevant areas and exclude regions that are unlikely to contain good solutions[<xref ref-type="bibr" rid="ref_65">65</xref>], [<xref ref-type="bibr" rid="ref_66">66</xref>].</p><p>The proposed Bounding Box Tuner might practically operate as follows: it commences with user-specified broad ranges for each hyperparameter (e.g., learning rate in [1e-5, 1e-1], number of layers in <inline-formula>
  <mml:math id="mkzbziop97">
    <mml:mo>[</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mn>2</mml:mn>
    <mml:mn>10</mml:mn>
    <mml:mstyle scriptlevel="0">
      <mml:mspace width="0.167em"/>
    </mml:mstyle>
  </mml:math>
</inline-formula>, etc.). It then samples and evaluates a number of configurations by using random sampling or another strategy initially. Based on the results, BBT identifies a subset of the space where high-performing configurations are concentrated. The most optimal outcomes achieved to date might be achieved when learning rate is between 1e-3 and 5e-3 and the number of layers is between 4 and 6. It then updates the search bounds to that sub-region, possibly with some margins to allow exploration around it. Subsequent hyperparameter proposals are restricted to this smaller hyper-rectangle region. As the search progresses and more data points are gathered, the bounding box could be further adjusted, either contracted or slightly shifted, to continuously home in on the area yielding the best results. This iterative bounding process continues until the algorithm converges or a maximum number of trials is reached and the outcome is a progressively narrowing search that zooms into the likely optimum.</p><p>BBT complements existing HPO methods rather than replacing them as it is considered an outer loop around any base optimizer. Bayesian optimization or evolutionary search as the internal method could suggest new points after each iteration or a set of iterations and apply the bounding heuristic to adjust the domain fed into that internal optimizer [<xref ref-type="bibr" rid="ref_64">64</xref>]. Through this approach, BBT provides a form of memory or meta-learning that standard optimizers lack as it obviously remembers the region of interests. Bayesian optimization implicitly performs similar function as its surrogate by becoming very flat/uncertain in unvisited regions and sharper around visited good regions; however, it will still occasionally sample the far corners of the original space if the acquisition function visualizes the potential. BBT would outright eliminate those corners from consideration after the optimum is ascertained to lie elsewhere, thereby potentially saving the exploratory evaluations. BBT is exploitative to a certain extent since this technique assumes that once a region with good hyperparameters is found, the global optimum will be nearby, yet this conjecture is to be confirmed. The implementation of BBT might allow some mechanisms to occasionally test beyond the current bounds so as to avoid local optimum traps, akin to a cooling schedule in simulated annealing, so the search is sometimes allowed to escape the current region.</p><p>The idea of narrowing search bounds has antecedents in iterative deepening and zooming algorithms in global optimization. The DIRECT algorithm (DIviding RECTangles) systematically partitions the search space into increasingly smaller hyper-rectangles focusing on regions with low function values. Bounding Box Tuner brings a similar spirit to hyperparameter tuning but in a more heuristic-driven way, is tailored to machine learning. The operation works under the assumption that users begin with rather wide hyperparameter ranges, but not all of that space is indeed reasonable. By identifying and zooming to an identified region, BBT effectively performs a form of automated range tuning, which is manually prepared by practitioners. Subsequent to a preliminary search, one might realize that “all the best models had learning rate <inline-formula>
  <mml:math id="mm1c6szd6i">
    <mml:mo>∼</mml:mo>
  </mml:math>
</inline-formula>0.001, so let's search more closely around that value”. BBT formalizes and automates this intuition to reveal more intriguing findings.</p><p>In the context of pruning and early stopping, the philosophy of BBT is analogous. Since unnecessary model parameters are pruned or unpromising trials are stopped to save resources, BBT prunes away swathes of hyperparameter space that appear unpromising. BBT might use early-stopped results from many configurations to identify the focused region. It could run a Hyperband-like procedure on the full space to get an initial mapping of performance, then define a bounding box around the top performers and continue the search with Bayesian optimization in that reduced space for more fine-grained exploration. Such a two-phase approach, global exploration preceding local exploitation, is not novel, but BBT provides a systematic way to carry out the transition by modifying bounds.</p><p>The introduction of BBT extends the hyperparameter optimization toolkit by emphasizing adaptive search space shaping and is particularly useful in high-dimensional problems or cases with mixed continuous and categorical parameters, where certain combinations of categories and ranges of values are recognized to be irrelevant or suboptimal. By cutting those out, BBT could reduce the dimensionality or effective volume of the search, turning subsequent optimization simpler and potentially improving the convergence speed. BBT is viewed as imposing a kind of prior or trust region that becomes tighter over time, which may assist surrogate-model-based optimizers like GPs in avoiding the distraction by too-large domains where their models are uninformative.</p><p>The drawback of BBT is its inherent incompetence to guarantee the finding of the global optimum; if the initial bounding decision is too aggressive, it might exclude the authentic best early on. Therefore, an important aspect of this innovation is the way for it to decide the timing and degree of bounding. Statistical tests or heuristic thresholds could be used to only shrink bounds when there is high confidence that the best lies within a certain interval for each hyperparameter. For example, if all top N performers have a learning rate in a narrow range, with none coming close outside that range. BBT should therefore be configured to retain some exploration, like allowing an occasional point outside the box, until late in the search.</p><p>To sum up, BBT fits into the landscape of HPO and training optimization as a higher-level strategy that can work alongside Bayesian, random, evolutionary, and multi-fidelity methods. It complements these methods by addressing a different facet, i.e., the adaptation of the search space. The attempt to overcome one of the practical challenges in HPO requires the initial guess of a reasonable search range, and it can potentially accelerate the finding of the optimum by discarding irrelevant regions earlier. This approach extends existing work by pushing more adaptivity into the HPO process, and early reports indicate that it can lead to quicker convergence in tuning tasks without sacrificing the solution quality. As with any new methods, further benchmarking (e.g., comparing BBT-augmented search versus standard search on image classification or NLP tuning tasks) will clarify its strengths and limitations. BBT is well-aligned with the prevailing trend of improving the efficiency and hands-free operation of hyperparameter optimization, hence reducing the need for manual intervention in trimming search spaces, much as algorithms like Hyperband in reducing the need for manual early stopping for trials.</p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>1.2. Research gaps</title>
          
          <p><p>Few algorithms progressively tighten the search domain using only observed validation rewards, eliminating the need for fitted surrogate models while refocusing exploration.</p><p>Current mainstream methods either mutate dimensions independently (e.g., univariate TPE splits) or assume axis-aligned Gaussian priors, failing to exploit the empirical observation that the best-performing configurations often cluster within a convex hull defined by a small subset of elite trials.</p><p>Techniques that aggressively narrow the domain could converge prematurely, whereas methods that preserve global sampling throughout the search squander evaluations after the optimization has explicitly localized promising basins. A principled, budget-aware decay schedule for exploration probability remains underexplored.</p><p>Although pruning becomes the standard to save compute, a certain number of adaptive search algorithms do not explicitly incorporate rung-level statistics, including the median and percentile, into their decision logic, hence curtailing additional savings.</p></p>
        </sec>
      
      
        <sec>
          
            <title>1.3. Motivation</title>
          
          <p>Hyperparameter optimization drains time and energy from deep-learning projects because the dominant methods either progress too slowly or waste compute on the poor regions of the search space. Bayesian and TPE-style optimizers spend a large fraction of their wall-clock budget updating surrogate models whose cost increases in accordance with every additional dimension [<xref ref-type="bibr" rid="ref_67">67</xref>]. Random, evolutionary, or simple Local Searches avoid that overhead, yet they repeatedly sample configurations that break architectural constraints, overflow GPU memory, or situate far away from any promising area [<xref ref-type="bibr" rid="ref_68">68</xref>]. Clever early-stopping schedules reduce training time only, yet nothing could be achieved to obliterate the bad configurations to be proposed for saving purpose.</p><p>BBT is designed for situations where practitioners have only a handful of hours or GPUs to identify a competitive set of hyperparameters and where the model architecture imposes hard relationships among them. The algorithm depends on a straightforward but powerful idea: after each evaluation, it withholds the two best configurations, draws a tight hyper-rectangle that encloses both, and chooses the next trial from inside that box most frequently while occasionally exploring the global space. Every interior point inherits the feasibility of its anchors, divisibility or memory constraints are respected automatically, and the search immediately avoids vast and unproductive regions. The box shrinks whenever new top performers appear, so BBT continuously refines its focus without fitting any surrogate and without any handcrafted scheduling heuristics.</p><p>This localization strategy, when applied, delivers nearly all the accuracy of surrogate based approaches and finishes in significantly less wall-clock time, the algorithm matched Optuna-TPE on a simple MLP while consuming approximately two thirds of the time budget; it is discovered to outperform all baselines on a constraint heavy Tiny Vision Transformer (TinyViT) within the same trial limit. These results exhibit that BBT turns the question “how many configurations can we afford to try?” into “how quickly can we zoom into the right neighborhood?”, hence offering teams a pragmatic way to obtain near-optimal hyperparameters before their compute allocation or iteration window expires.</p>
        </sec>
      
      
        <sec>
          
            <title>1.4. Innovation and contributions</title>
          
          <p><p>Top-2 Bounding-Box Contraction. After an initial quasi-random seeding phase, BBT identifies the two highest-scoring configurations and defines an axis-aligned bounding box whose limits are their dimension-wise minima and maxima. All exploitative samples are drawn uniformly from this convex hull, thereby preserving cross-parameter interactions without expensive kernel learning.</p><p>Probabilistic Global Exploration with Budget-Aware Decay. A time-dependent exploration probability <inline-formula>
  <mml:math id="mf3rd3uix8">
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> (35% in the first half of the budget, 10% thereafter) injects uniformly random configurations from the original hyperparameter space. This schedule ensures continual diversity in advance and efficient exploitation later, delivering consistent accuracy gains with lower variance than fixed-rate or purely greedy strategies.</p><p>Pruning-Aware Objective Evaluation. BBT delegates training to a user-defined evaluation function that returns zero reward upon rung-based pruning (e.g., median-of-rung). This simple convention lets BBT inherit the cost savings of Hyperband-style early stopping without modifying the algorithm's core logic.</p><p>Empirical Evidence of Efficiency. Both a two-layer MLP and a TiNX-YiT on MNIST, BBT attains validation accuracies matching or exceeding Optuna-TPE, scikit-optimize GP, evolutionary search, and local random-neighbor search while reducing wall-clock tuning time by 15–50%. These gains crucially persist despite strict five-epoch evaluation windows, underscoring BBT's suitability for rapid-prototyping scenarios.</p></p><p>These contributions altogether address the pressing needs for efficient and compute-conscious HPO and lay the foundation for future extensions that could couple bounding-box contraction with curvature-aware surrogate modelling or trust-region Bayesian optimization.</p>
        </sec>
      
    </sec>
    <sec sec-type="methods">
      <title>2. Methods</title>
      
        <sec>
          
            <title>2.1. Bounding box tuner (bbt)</title>
          
          <p>BBT is a derivative-free optimizer that contracts its sampling region around the two best performing configurations observed to date [<xref ref-type="bibr" rid="ref_69">69</xref>], [<xref ref-type="bibr" rid="ref_70">70</xref>]. The algorithm proceeds as shown in <xref ref-type="table" rid="table_1">Table 1</xref>. An initial quasi-random seed of <inline-formula>
  <mml:math id="mqjrnj5mj2">
    <mml:msub>
      <mml:mi>n</mml:mi>
      <mml:mn>0</mml:mn>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:mn>10</mml:mn>
  </mml:math>
</inline-formula> trials populates a leaderboard sorted by validation accuracy. The two leaders, <inline-formula>
  <mml:math id="mab3a5pmvn">
    <mml:msubsup>
      <mml:mi>θ</mml:mi>
      <mml:mn>1</mml:mn>
      <mml:mo>∗</mml:mo>
    </mml:msubsup>
  </mml:math>
</inline-formula>  and <inline-formula>
  <mml:math id="mlgoc4lkqk">
    <mml:msubsup>
      <mml:mi>θ</mml:mi>
      <mml:mn>2</mml:mn>
      <mml:mo>∗</mml:mo>
    </mml:msubsup>
  </mml:math>
</inline-formula>, define an axis-aligned hyper-rectangle (the “bounding box”) whose edges are the component-wise minima and maxima of these anchors. Subsequent proposals are drawn either uniformly inside this box (focused search) or uniformly from the global space <inline-formula>
  <mml:math id="mko7dvm06w">
    <mml:mi>Ω</mml:mi>
  </mml:math>
</inline-formula> (exploration) with a probability that decays linearly from 0.35 to 0.10 over the course of the trial budget. Each candidate is evaluated under identical early pruning rules; if 30 consecutive proposals fail to improve the performance, the search halts early at each epoch. Early stopping will be applied with the median validation accuracy of the completed runs to be computed; trials falling below this median will be terminated. Trials that are pruned will receive a score of 0.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Algorithm of Bounding Box Tuner</title>
              </caption>
              <table><tbody><tr><th colspan="1" rowspan="1"><p>Input</p></th><th colspan="1" rowspan="1"><p>Search space <mml:math id="my20e38gpz">
  <mml:mi>Ω</mml:mi>
</mml:math> of $d<mml:math id="maxgbcu3a6">
  <mml:mi>h</mml:mi>
  <mml:mi>y</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mo>;</mml:mo>
</mml:math>T \cdot<mml:math id="moh5x8j47c">
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mo>;</mml:mo>
</mml:math>n_0=10<mml:math id="mtfxerlnvj">
  <mml:mo>;</mml:mo>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
</mml:math>p_0=0.35 \rightarrow p_1=0.10<mml:math id="mfy3869sz9">
  <mml:mo>;</mml:mo>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
</mml:math>\boldsymbol{\tau}=\mathbf{3 0}<mml:math id="mm3ilodk08">
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>I</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>z</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>f</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>\left\{\theta^1, \ldots, \theta^{\mathrm{n_0}} \right\} \sim \mathrm{U}(\Omega)<mml:math id="mjqxjnx1qn">
  <mml:mo>;</mml:mo>
  <mml:mo>;</mml:mo>
  <mml:mi>e</mml:mi>
  <mml:mi>v</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>y</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>e</mml:mi>
</mml:math>s<mml:math id="mvr4abfha3">
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>A</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>L</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>2</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>\theta^*{ }_1, \theta^*{ }_2<mml:math id="m8540ijrkv">
  <mml:mi>b</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>f</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>B</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>B</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>F</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>v</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>y</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>3</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>j<mml:math id="mxkyumj3t8">
  <mml:mo>:</mml:mo>
  <mml:mi>l</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>{ }_{\mathrm{j}}=\min \left(\theta^*{ }_{1 \mathrm{j}}, \theta^*{ }_{2 \mathrm{j}}\right)<mml:math id="mqjhucxhgs">
  <mml:mo>;</mml:mo>
  <mml:mi>u</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>{ }_{\mathrm{j}}=\max \left(\theta^*{ }_{1 \mathrm{j}}, \theta^*{ }_{2 \mathrm{j}}\right)<mml:math id="msg5gjtg87">
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>D</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>4</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>\theta\tilde{} \sim \mathrm{U}(\Omega)<mml:math id="m8mcaw79zd">
  <mml:mi>w</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>y</mml:mi>
</mml:math>p=\operatorname{linear}\left(p_0 \rightarrow p_1\right)<mml:math id="my3amrym1w">
  <mml:mo>;</mml:mo>
  <mml:mi>e</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>e</mml:mi>
</mml:math>\theta\tilde{} \sim \mathrm{U}(\mathrm{box})<mml:math id="m2dm24bfz8">
  <mml:mo>.</mml:mo>
  <mml:mi>R</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>l</mml:mi>
</mml:math>\theta<mml:math id="mz4n257y2e">
  <mml:mi>s</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>f</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>E</mml:mi>
  <mml:mi>v</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>T</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>5</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>\theta\tilde{}<mml:math id="m7bpw23yzf">
  <mml:mi>w</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mo>;</mml:mo>
</mml:math>s(\theta\tilde{})<mml:math id="mg20ugohey">
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>U</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>I</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>6</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>(\theta\tilde{}, s)<mml:math id="mndcfzs3bp">
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>b</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>I</mml:mi>
  <mml:mi>f</mml:mi>
  <mml:mo>.</mml:mo>
</mml:math>s(\theta\tilde{})<mml:math id="m6w09aq4qf">
  <mml:mi>i</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>v</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
</mml:math>\theta^*{ }_1<mml:math id="msixx6kob5">
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>\theta^*{ }_2<mml:math id="miuw9uxpqp">
  <mml:mo>,</mml:mo>
  <mml:mo>(</mml:mo>
  <mml:mo>)</mml:mo>
  <mml:mi>r</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
</mml:math>\kappa<mml:math id="m4usc6e2rz">
  <mml:mo>;</mml:mo>
  <mml:mi>o</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>h</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>e</mml:mi>
</mml:math>\kappa \leftarrow \kappa+1<mml:math id="m06gkkmcpk">
  <mml:mo>.</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>−</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>"</mml:mo>
  </mml:mrow>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>T</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>m</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>w</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>S</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>f</mml:mi>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>7</mml:mn>
  <mml:mn>1</mml:mn>
  <mml:mn>1</mml:mn>
</mml:math>k \ge \tau<mml:math id="mz3v270ffb">
  <mml:mi>o</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>i</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>s</mml:mi>
</mml:math>= T$; else return to Step 3.</p></td></tr><tr><td colspan="1" rowspan="1"><p>Output</p></td><td colspan="1" rowspan="1"><p>Best configuration.</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Step 1: Draw initial trials <inline-formula>
  <mml:math id="mt4nqaqtdu">
    <mml:mo>→</mml:mo>
  </mml:math>
</inline-formula> Sample <inline-formula>
  <mml:math id="m7avs2ff5l">
    <mml:msub>
      <mml:mi>n</mml:mi>
      <mml:mn>0</mml:mn>
    </mml:msub>
    <mml:mo>=</mml:mo>
    <mml:mn>10</mml:mn>
  </mml:math>
</inline-formula> configurations uniformly from the full hyper-parameter space <inline-formula>
  <mml:math id="mj0rk1crv4">
    <mml:mi>Ω</mml:mi>
  </mml:math>
</inline-formula> (quasi-random). Evaluate &amp;amp; record <inline-formula>
  <mml:math id="mtbj9s8cu6">
    <mml:mo>→</mml:mo>
  </mml:math>
</inline-formula> Train each configuration for up to the prescribed epoch budget while applying pruning rules (e.g., median-of-rung). Create leaderboard <inline-formula>
  <mml:math id="mx78qo0kbx">
    <mml:mo>→</mml:mo>
  </mml:math>
</inline-formula> Store every pair (<inline-formula>
  <mml:math id="m2e626upya">
    <mml:mi>θ</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>) where $s<inline-formula>
  <mml:math id="msc5p8h9xa">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mo>−</mml:mo>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>s<inline-formula>
  <mml:math id="mz5yhwwrfm">
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mn>2</mml:mn>
  </mml:math>
</inline-formula>\left(\theta^*{ }_1, \theta^*{ }_2\right)<inline-formula>
  <mml:math id="myc467zee7">
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>"</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mn>3</mml:mn>
  </mml:math>
</inline-formula>j \in\{1, \ldots, d\}$ :</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mkepvom5qr">
                <mml:msub>
                  <mml:mtext> lower </mml:mtext>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mtext> upper </mml:mtext>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>min</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>max</mml:mo>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>θ</mml:mi>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>∗</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>θ</mml:mi>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                      <mml:mo>∗</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>θ</mml:mi>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>∗</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>θ</mml:mi>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                      <mml:mo>∗</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="mgxqrykt43">
                <mml:mi>p</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:msub>
                  <mml:mi>p</mml:mi>
                  <mml:mn>0</mml:mn>
                </mml:msub>
                <mml:msub>
                  <mml:mi>p</mml:mi>
                  <mml:mn>0</mml:mn>
                </mml:msub>
                <mml:msub>
                  <mml:mi>p</mml:mi>
                  <mml:mn>1</mml:mn>
                </mml:msub>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>t</mml:mi>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>n</mml:mi>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>n</mml:mi>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>p</mml:mi>
                    <mml:mn>0</mml:mn>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>p</mml:mi>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                </mml:mrow>
                <mml:mn>0.35</mml:mn>
                <mml:mn>0.10</mml:mn>
              </mml:math>
            </disp-formula>
          
          <p>where, $t<inline-formula>
  <mml:math id="moxa427sr5">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>T<inline-formula>
  <mml:math id="mqk8u29oh0">
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>B</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>;</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>p_t \rightarrow<inline-formula>
  <mml:math id="mxfxnef738">
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
  </mml:math>
</inline-formula>\Omega<inline-formula>
  <mml:math id="m8oscp1io8">
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>;</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>\rightarrow<inline-formula>
  <mml:math id="m19ai697up">
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>G</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>E</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mn>5</mml:mn>
    <mml:mn>0</mml:mn>
    <mml:mn>6</mml:mn>
  </mml:math>
</inline-formula>s=0<inline-formula>
  <mml:math id="m8sicuzhmc">
    <mml:mo>;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>U</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mn>7</mml:mn>
  </mml:math>
</inline-formula>\theta_{\text {new }}, s_{\text {new }}<inline-formula>
  <mml:math id="mf75nnytoi">
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>f</mml:mi>
  </mml:math>
</inline-formula>s_{\text {new }}<inline-formula>
  <mml:math id="m6dslsp8ra">
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>\theta^*{ }_1, \theta^*{ }_2<inline-formula>
  <mml:math id="m00lobxa7t">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>\kappa<inline-formula>
  <mml:math id="muym2nep6m">
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
  </mml:math>
</inline-formula>\rightarrow \kappa \leftarrow 0<inline-formula>
  <mml:math id="m8pgg5ya41">
    <mml:mo>,</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>\rightarrow \kappa \leftarrow \kappa+1<inline-formula>
  <mml:math id="m6uv6ex34z">
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mn>8</mml:mn>
  </mml:math>
</inline-formula>\tau<inline-formula>
  <mml:math id="mbhi1aqrra">
    <mml:mo>(</mml:mo>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
  </mml:math>
</inline-formula>\tau<inline-formula>
  <mml:math id="m5fnd1i2ct">
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mo>)</mml:mo>
    <mml:mo>;</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>t=T<inline-formula>
  <mml:math id="mlogp0em2n">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>O</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>O</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mn>3</mml:mn>
    <mml:mn>9</mml:mn>
  </mml:math>
</inline-formula>\theta_{\text {best }}<inline-formula>
  <mml:math id="mi2vi8zmxo">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>s_{\text {best }}$.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Core features of bbt</title>
          
          <p><p>The sampling region contracts automatically around the empirical optima, concentrating effort where payoff is the highest while still allowing global search.</p><p>As every new proposal is drawn between two feasible anchors, architectural divisibility constraints (e.g., embedding dimension divisible by the number of heads) are always satisfied [<xref ref-type="bibr" rid="ref_71">71</xref>].</p><p>BBT inherits rung-based or median-of-rung pruning rules, discarding low-quality trials early and allocating compute to promising ones.</p><p>A time decaying exploration probability prevents entrapment in the local optima, ensuring adequate coverage of <inline-formula>
  <mml:math id="mdfynoc624">
    <mml:mi>Ω</mml:mi>
  </mml:math>
</inline-formula> throughout the budget.</p></p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Dataset</title>
          
          <p>The MNIST handwritten-digit corpus (60000 training, 10000 test images) is used in the experiments. Pixel intensities were normalized to zero mean and unit variance. Five thousand training images were randomly withheld for validation; no data augmentation was applied.</p>
        </sec>
      
      
        <sec>
          
            <title>2.4. Models and search spaces</title>
          
          <p>Two architectures were optimized:</p><p>Multi-layer perceptron (MLP).</p><p>Search dimensions:</p><p><p style="text-align: justify">learning rate <inline-formula>
  <mml:math id="mehvgkxyb2">
    <mml:mi>L</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mo>∈</mml:mo>
    <mml:mrow>
      <mml:mo>[</mml:mo>
      <mml:mo>×</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>×</mml:mo>
      <mml:mo>]</mml:mo>
      <mml:mn>1</mml:mn>
      <mml:mn>1</mml:mn>
      <mml:msup>
        <mml:mn>10</mml:mn>
        <mml:mrow>
          <mml:mo>−</mml:mo>
          <mml:mn>4</mml:mn>
        </mml:mrow>
      </mml:msup>
      <mml:msup>
        <mml:mn>10</mml:mn>
        <mml:mrow>
          <mml:mo>−</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:mrow>
      </mml:msup>
    </mml:mrow>
  </mml:math>
</inline-formula>, log-uniform,</p><p style="text-align: justify">batch size <inline-formula>
  <mml:math id="ma0rafhfvo">
    <mml:mi>B</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mo>∈</mml:mo>
    <mml:mrow>
      <mml:mo>{</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>…</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>}</mml:mo>
      <mml:msup>
        <mml:mn>2</mml:mn>
        <mml:mn>4</mml:mn>
      </mml:msup>
      <mml:msup>
        <mml:mn>2</mml:mn>
        <mml:mn>5</mml:mn>
      </mml:msup>
      <mml:msup>
        <mml:mn>2</mml:mn>
        <mml:mn>7</mml:mn>
      </mml:msup>
    </mml:mrow>
  </mml:math>
</inline-formula>,</p><p style="text-align: justify">hidden layers <inline-formula>
  <mml:math id="mp2bo2f28c">
    <mml:mi>L</mml:mi>
    <mml:mo>∈</mml:mo>
    <mml:mo>[</mml:mo>
  </mml:math>
</inline-formula>1, 3]</p><p style="text-align: justify">units per layer <inline-formula>
  <mml:math id="mmg2svggpr">
    <mml:mi>U</mml:mi>
    <mml:mo>∈</mml:mo>
  </mml:math>
</inline-formula>[$32<inline-formula>
  <mml:math id="m41ct3xb3t">
    <mml:mo>,</mml:mo>
    <mml:mo>]</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mn>256</mml:mn>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>V</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>D</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
  </mml:math>
</inline-formula>L R \in\left[1 \times 10^{-5}, 5 \times 10^{-3}\right]<inline-formula>
  <mml:math id="mm8a70pa8u">
    <mml:mo>,</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
  </mml:math>
</inline-formula>B S \in\left\{2^4, 2^5, \ldots, 2^7\right\}<inline-formula>
  <mml:math id="mq7e7fivau">
    <mml:mo>,</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
  </mml:math>
</inline-formula>D \in[$1$,$6],</p><p>embedding dimension <inline-formula>
  <mml:math id="mm7r8rsv1c">
    <mml:mi>E</mml:mi>
    <mml:mo>∈</mml:mo>
    <mml:mo>[</mml:mo>
  </mml:math>
</inline-formula>32, 256],</p><p>attention heads <inline-formula>
  <mml:math id="mpriywleqq">
    <mml:mi>H</mml:mi>
    <mml:mo>∈</mml:mo>
    <mml:mo>[</mml:mo>
  </mml:math>
</inline-formula>1, 8] with <inline-formula>
  <mml:math id="mj26kqxiad">
    <mml:mo lspace="thickmathspace" rspace="thickmathspace">mod</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo lspace="thickmathspace" rspace="thickmathspace">mod</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>E</mml:mi>
    <mml:mi>H</mml:mi>
  </mml:math>
</inline-formula>=0.</p></p><p>Both models were trained with Adam and categorical cross-entropy.</p>
        </sec>
      
      
        <sec>
          
            <title>2.5. Trial budget and early stopping</title>
          
          <p>Each configuration was trained for at most five epochs.</p><p><p>MLP: Trials with validation accuracy <inline-formula>
  <mml:math id="mh2ii3yv9j">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mn>0.30</mml:mn>
  </mml:math>
</inline-formula> after epoch 1 or <inline-formula>
  <mml:math id="m95jrnszt0">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mn>0.60</mml:mn>
  </mml:math>
</inline-formula> after epoch 3 were pruned.</p><p>TinyViT: At each epoch, the median validation accuracy of the completed runs was computed; trials falling below this median were terminated. Trials that were pruned received a score of 0.</p></p>
        </sec>
      
      
        <sec>
          
            <title>2.6. Benchmarking</title>
          
          <p>BBT was compared with five baselines under identical budgets of 50 scored trials per model: random search, Gaussian-Process Bayesian Optimization, Tree Structured Parzen Estimator, an <inline-formula>
  <mml:math id="mx3vorq0kc">
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>μ</mml:mi>
    <mml:mi>λ</mml:mi>
  </mml:math>
</inline-formula> evolutionary algorithm (population=10, mutation probability=0.3) and random neighbor Local Search. Primary performance was the highest validation accuracy achieved within the budget. Secondary metrics were the cumulative search time and the number of completed epochs. All searches ran on a laptop equipped with an NVIDIA GeForce GTX 1650 Ti GPU and an Intel Core i7-10750H CPU. Wall-clock time included data loading, forward and backward passes, and optimizer overheads.</p>
        </sec>
      
    </sec>
    <sec sec-type="results">
      <title>3. Results</title>
      <p><xref ref-type="table" rid="table_2">Table 2</xref> (MLP) and <xref ref-type="table" rid="table_3">Table 3</xref> report the headline numbers produced by a single 50-trial sweep of each optimizer on the two architectures studied.</p>
      
        <table-wrap id="table_2">
          <label>Table 2</label>
          <caption>
            <title>Comparison on MLP</title>
          </caption>
          <table><tbody><tr><th colspan="1" rowspan="1"><p>Optimizer</p></th><th colspan="1" rowspan="1"><p>Best Val-Acc</p></th><th colspan="1" rowspan="1"><p>Time (s)</p></th><th colspan="1" rowspan="1"><p>Trials</p></th></tr><tr><td colspan="1" rowspan="1"><p>Optuna (TPE) [<xref ref-type="bibr" rid="ref_72">72</xref>]</p></td><td colspan="1" rowspan="1"><p>0.9798</p></td><td colspan="1" rowspan="1"><p>2976</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>GP-Bayesian</p></td><td colspan="1" rowspan="1"><p>0.9798</p></td><td colspan="1" rowspan="1"><p>3271</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Evolutionary</p></td><td colspan="1" rowspan="1"><p>0.9770</p></td><td colspan="1" rowspan="1"><p>3243</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Random Search</p></td><td colspan="1" rowspan="1"><p>0.9768</p></td><td colspan="1" rowspan="1"><p>3102</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Local Search</p></td><td colspan="1" rowspan="1"><p>0.9608</p></td><td colspan="1" rowspan="1"><p>898</p></td><td colspan="1" rowspan="1"><p>16</p></td></tr><tr><td colspan="1" rowspan="1"><p>Bounding Box Tuner</p></td><td colspan="1" rowspan="1"><p>0.9788</p></td><td colspan="1" rowspan="1"><p>1994</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <table-wrap id="table_3">
          <label>Table 3</label>
          <caption>
            <title>Comparison on TinyViT</title>
          </caption>
          <table><tbody><tr><th colspan="1" rowspan="1"><p>Optimizer</p></th><th colspan="1" rowspan="1"><p>Best Val-Acc</p></th><th colspan="1" rowspan="1"><p>Time (s)</p></th><th colspan="1" rowspan="1"><p>Trials</p></th></tr><tr><td colspan="1" rowspan="1"><p>Optuna (TPE)</p></td><td colspan="1" rowspan="1"><p>0.9466</p></td><td colspan="1" rowspan="1"><p>2572</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>GP-Bayesian</p></td><td colspan="1" rowspan="1"><p>0.9436</p></td><td colspan="1" rowspan="1"><p>2191</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Evolutionary</p></td><td colspan="1" rowspan="1"><p>0.9476</p></td><td colspan="1" rowspan="1"><p>5173</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Random Search</p></td><td colspan="1" rowspan="1"><p>0.9482</p></td><td colspan="1" rowspan="1"><p>3031</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr><tr><td colspan="1" rowspan="1"><p>Local Search</p></td><td colspan="1" rowspan="1"><p>0.9162</p></td><td colspan="1" rowspan="1"><p>1329</p></td><td colspan="1" rowspan="1"><p>22</p></td></tr><tr><td colspan="1" rowspan="1"><p>Bounding Box Tuner</p></td><td colspan="1" rowspan="1"><p>0.9492</p></td><td colspan="1" rowspan="1"><p>2364</p></td><td colspan="1" rowspan="1"><p>50</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <sec>
          
            <title>3.1. Multi-layer perceptron (mlp)</title>
          
          <p>Accuracy landscape. All surrogate-based methods (Bayesian, TPE) and the performance-based method, BBT, converged within 0.20 percentage points of one another by the end of the 50-trial budget. The final score of BBT, 0.9788, was only 0.10 points lower than the joint leaders (TPE and Bayesian) and 0.20 points higher than uniform Random Search. Evolutionary search sat midway between Random Search and BBT.</p><p>Wall-clock efficiency. BBT reached its peak score after 1994 s-- 982 s faster than TPE and 1277 s faster than GP-Bayesian--despite executing exactly the same number of scored trials. The algorithm therefore delivered 99.9% of the best observed accuracy at <inline-formula>
  <mml:math id="mi6xl61knd">
    <mml:mo>∼</mml:mo>
  </mml:math>
</inline-formula>34% lower cost than the nearest high-accuracy baseline. Local Search was the only faster method (898 s) but plateaued at 0.9608 after just 16 improving moves; the remaining 34 budgeted trials were left unused because the adaptive neighbor procedure could no longer locate an ascent direction.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Tiny vision transformer (tinyvit)</title>
          
          <p>Absolute leader. In the larger, constraint-rich ViT space, BBT recorded the highest validation accuracy overall (0.9492). Random search and Evolutionary search fell 0.10-0.16 points behind, while TPE and GP-Bayesian lagged by 0.26 and 0.56 points, respectively.</p><p>Speed profile. Although GP-Bayesian completed the fastest (2191 s), its accuracy was the lowest of all surrogate-based approaches. BBT provided the best balance, finishing in 2364 s (second fastest) but producing the top score. Evolutionary search was the slowest.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Cross-model comparison</title>
          
          <p>Consistency. BBT delivered top three accuracies in both search spaces and never dropped more than 0.10 points behind the leader. In contrast, each baseline optimizer had at least one setting where it lost more than 0.25 points to the best score. When performance is considered, BBT is cost-effective and yields better performance than other benchmarked optimization methods.</p><p>Trial utilization. BBT used the full allocation of 50 scored trials, leveraging its early stop patience counter only if no improvements occurred for 30 consecutive evaluations; this threshold was not reached in either run. Local search exhausted its local neighborhood before hitting the budget in both cases; therefore, a natural example of an optimizer that trades search reach for speed is provided.</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Practical ramifications</title>
          
          <p><p>Deploying BBT in place of TPE or GP-Bayesian would reduce tuning time for lightweight CNN backbones such as MLP by $&gt;$1000, s while preserving sub-0.1-% accuracy differences.</p><p>For transformer-style models with tighter architectural constraints, BBT is both the most accurate and the most time-efficient among methods that exceed 0.94 validation accuracy, rending it the obvious first choice when quick iteration cycles are paramount.</p><p>Random search remains a viable baseline when the wall-clock time is not critical, but it requires <inline-formula>
  <mml:math id="mm8snqjahj">
    <mml:mo>∼</mml:mo>
  </mml:math>
</inline-formula>30% more time than BBT to reach nearly the same score on Tiny-ViT and still underperforms when BBT is on MLP.</p><p>Evolutionary search might appeal in highly multi-modal or discrete spaces, yet its two-fold time overhead relative to BBT is not compensated by the advantages of accuracy in either benchmark.</p></p><p>Overall speaking, these results demonstrate that a simple axis-aligned bounding-box strategy could rival and outperform sophisticated surrogate-based hyperparameter optimizers, especially in face of stringent compute budgets and substantial architectural feasibility constraints.</p>
        </sec>
      
    </sec>
    <sec sec-type="discussion">
      <title>4. Discussion</title>
      <p>The present study introduces a lightweight, performance-based hyperparameter optimizer, Bounding Box Tuner (BBT) and demonstrates its competitive performance on two markedly different neural architectures. Detailed comparisons could be seen in <xref ref-type="fig" rid="fig_1">Figure 1</xref>, <xref ref-type="fig" rid="fig_2">Figure 2</xref> and <xref ref-type="fig" rid="fig_3">Figure 3</xref>. Despite merely utilizing axis-aligned sampling and simple early pruning hooks, BBT achieved top-three validation accuracy under strict search budgets while reducing wall-clock time by hundreds to thousands of seconds relative to comparably accurate baselines. These findings highlight three notable properties of the algorithm; in other words, adaptive locality, constraint preservation, and favorable cost-benefit scaling.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Algorithm of BBT</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_VaCjadDCANacrf4P.png"/>
        </fig>
      
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Algorithm of BBT</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_bHHnk5JT_J7ftOP6.png"/>
        </fig>
      
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Validation accuracy comparison</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_z27StbW0ONELPX-K.png"/>
        </fig>
      
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>Total tuning time (s)</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_oywU7TzYAqinqBMv.png"/>
        </fig>
      
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Time per trial (s)</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_ogZIiZjmxRxY9uxE.png"/>
        </fig>
      
      <p>Adaptive locality without surrogate overhead. Modern Bayesian and density-estimation strategies allocate substantial runtime to fitting probabilistic models over the search space. BBT attains similar or better (As shown in <xref ref-type="fig" rid="fig_3">Figure 3-5</xref>) end-point accuracies by exploiting a far simpler signal, i.e., the geometric span of the two best configurations. Subsequent to merely ten random seed trials, the bounding box contracts around high-payoff regions and continues to refine as new top candidates emerge. This strategy reduces both the computational overhead of surrogate maintenance and the sample complexity required to learn a useful global model, especially in low-epoch regimes where observations are noisy.</p><p>Constraint awareness. Surrogate-based optimizers such as GP-Bayesian and TPE sometimes emit transformer settings in which the embedding dimension E is not divisible by the number of attention heads H. In the implementation, these infeasible proposals are retained but assigned a validation score of 0, effectively wasting a trial. BBT avoids the issue entirely as every new candidate is sampled between two anchor configurations that already satisfy E mod H = 0, so feasibility is guaranteed with no additional rejection logic. This intrinsic constraint handling is valuable in hardware-bound searches that mix continuous and discrete parameters, e.g., channel counts, attention heads, or quantization widths where enforcing validity often dominates the implementation complexity.</p><p>Graceful cost scaling. BBT requires no extra meta-parameters beyond a decaying exploration rate, a patience counter, and initial sample seeds (10 in this research), and its early-stop mechanism never fires within the 50-trial budget, so larger budgets would only amortize its modest overhead further. On the MLP task, as shown in <xref ref-type="fig" rid="fig_3">Figure 3</xref>, BBT achieved the lowest wall-clock time per scored trial (<inline-formula>
  <mml:math id="mcq3toid8i">
    <mml:mo>≈</mml:mo>
    <mml:mn>39</mml:mn>
    <mml:mstyle scriptlevel="0">
      <mml:mspace width="0.167em"/>
    </mml:mstyle>
    <mml:mrow>
      <mml:mi>s</mml:mi>
    </mml:mrow>
  </mml:math>
</inline-formula>) among all methods, including both surrogate-based baselines. On the TinyViT task, GP-Bayesian was slightly faster per trial (<inline-formula>
  <mml:math id="mj5qwhdu6p">
    <mml:mo>≈</mml:mo>
    <mml:mn>44</mml:mn>
    <mml:mstyle scriptlevel="0">
      <mml:mspace width="0.167em"/>
    </mml:mstyle>
    <mml:mrow>
      <mml:mi>s</mml:mi>
    </mml:mrow>
  </mml:math>
</inline-formula>), yet delivered the lowest accuracy of the surrogate group. BBT maintained a competitive per-trial cost (<inline-formula>
  <mml:math id="mzodffwtkr">
    <mml:mo>≈</mml:mo>
    <mml:mn>47</mml:mn>
    <mml:mstyle scriptlevel="0">
      <mml:mspace width="0.167em"/>
    </mml:mstyle>
    <mml:mrow>
      <mml:mi>s</mml:mi>
    </mml:mrow>
  </mml:math>
</inline-formula>) while achieving the highest overall accuracy. Local Search remained the raw speed champion; however, in per trial timing, he is not a good option. Moreover, Local Search furnished considerably lower peak accuracy, suitably placing it for coarse prototype sweeps or extreme low-budget scenarios.</p>
      
        <sec>
          
            <title>4.1. Limitations</title>
          
          <p>The evaluation in the current study used a single data set (MNIST) and relatively small models, limiting immediate extrapolation to large-scale vision or language workloads. In higher-dimensional spaces, the axis-aligned box might enclose substantial low-density volume, diluting the efficiency gains observed. The reliance of BBT on the top-two leaderboard positions could stall if the search landscape contains multiple disconnected basins of comparable score; periodic re-seeding or a dynamic k-best hull helps alleviate this problem. Finally, all comparisons were based on one sweep per optimizer; although the relative ordering was clear-cut, more replicates would provide tighter confidence in marginal score differences. The proposed BBT supports parallelization; however, only one GPU is available and hinders the testing of parallelization effect [<xref ref-type="bibr" rid="ref_73">73</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Practical implications</title>
          
          <p>For practitioners who have to iterate quickly under hard time budgets, BBT offers an attractive “drop-in” replacement for heavier optimizers, delivering near-state-of-the-art accuracy with minimal configuration and no surrogate tuning. Its compute savings translate directly into cost reductions on cloud platforms and shorten the feedback loop for model developers. Since the feasibility is guaranteed by construction, BBT aptly fits in the production pipelines where invalid configurations trigger expensive but failed jobs [<xref ref-type="bibr" rid="ref_74">74</xref>], [<xref ref-type="bibr" rid="ref_75">75</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Future work</title>
          
          <p>Future work includes parallelization and the effects of parallelization as there was not enough GPU to test this feature. Furthermore, the proposed BBT on more datasets and different situations could be tested, say for a simple neural network or ViT-Large, and larger hyperparameter spaces etc. This will provide a better insight of BBT against the current HPO methods. Moreover, two extensions appear particularly promising. First, a diagonal-plus-low-rank transformation of the bounding box could capture local anisotropy without sacrificing analytic simplicity, potentially boosting efficiency in the correlated subspaces. Second, integrating a lightweight performance predictor trained exclusively on in-box samples might enable hybrid exploitation-exploration schedules that retain the speed of BBT while sharpening final accuracy at the same time. Beyond the single-objective tuning, the geometric core of the algorithm naturally generalizes to multi-objective settings by defining separate bounding hulls in the objective space or by sampling along the Pareto frontier. Investigating these avenues on larger data sets and multi-node hardware will determine the full scope of the applicability of BBT. </p><p>BBT advances the hyperparameter optimization toolbox by reconciling three often competing goals: robust accuracy, strict feasibility, and low wall-clock cost. Its simplicity invites rapid adoption and further methodological refinement, thus positioning bounding box sampling as a practical bridge between naive random search and compute-intensive surrogate modelling.</p>
        </sec>
      
    </sec>
    <sec sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>Bounding Box Tuner (BBT) demonstrates that competitive hyper-parameter optimization does not require sophisticated surrogate modelling or extensive meta-parameter tuning. Based on a simple, dynamically shrinking axis-aligned hyper-rectangle and a decaying exploration schedule, BBT consistently achieved top-tier validation accuracy on both a compact CNN (MLP) and a constraint-rich TinyViT while shortening wall clock search time by 30 to 60% relative to the most accurate baselines. These gains arise from three primary mechanisms:</p><p><p>Rapid localization. Ten initial random probes suffice to locate a high-payoff region, after which the bounding box focuses sampling without the overhead of fitting or updating a global predictive model.</p><p>Implicit constraint enforcement. Sampling strictly within the span of two feasible anchors eliminates, by construction, invalid configurations, demonstrating a property that becomes increasingly valuable in search spaces and mixing discrete architectural choices with continuous training parameters.</p><p>Compute-savvy pruning. BBT integrates median-of-run early stopping at no extra costs, diverting resources away from unpromising trials and accelerating convergence.</p></p><p>Minimal parameterization of the method involves the exploration rate, patience counter and initial seeds only. It could simplify deployment in the production pipelines where ease of integration often outweighs the improvement of marginal accuracy. In addition, the favorable time accuracy profile of BBT translates directly into lower energy consumption and monetary cost on cloud platforms, an increasingly relevant factor for sustainable machine-learning practice [<xref ref-type="bibr" rid="ref_76">76</xref>].</p><p>This evaluation also highlights boundaries of the current design. Axis-aligned contraction might lose efficiency in very high-dimensional or highly anisotropic spaces; multiple near-optimal basins could trap the algorithm if the top-two solutions share a single region. Addressing these issues through adaptive box rotation, a k-best hull, or periodic re-seeding represents the next step to be followed naturally. Extending BBT to multi-objective settings and validating it on the larger-scale data sets and hardware configurations will further clarify its generalization.</p><p>Ultimately, BBT was found to be a practical middle ground between random search and heavyweight surrogate based optimizers; its simplicity to be implemented is conducive to ideal resource allocation. The running of the proposed BBT is reasonably inexpensive, intrinsically constraint-aware, and empirically competitive. All these favorable attributes recommend Bounding Box sampling to be a robust default choice for rapid and resource-constrained hyperparameter tuning in the contemporary workflows for our progressive development in deep learning.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare that they have no conflicts of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>281-305</page-range>
          <issue>1</issue>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bergstra</surname>
              <given-names>James</given-names>
            </name>
            <name>
              <surname>Bengio</surname>
              <given-names>Yoshua</given-names>
            </name>
          </person-group>
          <article-title>Random search for hyper-parameter optimization</article-title>
          <source>J. Mach. Learn. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>25</volume>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Snoek</surname>
              <given-names>Jasper</given-names>
            </name>
            <name>
              <surname>Larochelle</surname>
              <given-names>Hugo</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>Ryan P</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1206.2944</pub-id>
          <article-title>Practical Bayesian optimization of machine learning algorithms</article-title>
          <source>Adv. Neural Inf. Process. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="conf-paper">
          <volume>24</volume>
          <page-range>1-9</page-range>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bergstra</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bardenet</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bengio</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Kégl</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Algorithms for hyper-parameter optimization</article-title>
          <source>Advances in Neural Information Processing Systems, Cadiz, Spain</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="conf-paper">
          <page-range>240–248</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jamieson</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Talwalkar</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Non-stochastic best arm identification and hyperparameter optimization</article-title>
          <source>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, Cadiz, Spain</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>230-246</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>Lisha</given-names>
            </name>
            <name>
              <surname>Jamieson</surname>
              <given-names>Kevin</given-names>
            </name>
            <name>
              <surname>Rostamizadeh</surname>
              <given-names>Afshin</given-names>
            </name>
            <name>
              <surname>Gonina</surname>
              <given-names>Ekaterina</given-names>
            </name>
            <name>
              <surname>Ben-Tzur</surname>
              <given-names>Moritz</given-names>
            </name>
            <name>
              <surname>Hardt</surname>
              <given-names>Moritz</given-names>
            </name>
            <name>
              <surname>Recht</surname>
              <given-names>Benjamin</given-names>
            </name>
            <name>
              <surname>Talwalkar</surname>
              <given-names>Ameet</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1810.05934</pub-id>
          <article-title>A system for massively parallel hyperparameter tuning</article-title>
          <source>Proc. Mach. Learn. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>33</volume>
          <page-range>4780-4789</page-range>
          <issue>01</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Real</surname>
              <given-names>Esteban</given-names>
            </name>
            <name>
              <surname>Aggarwal</surname>
              <given-names>Alok</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Yanping</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>Quoc V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1609/aaai.v33i01.33014780</pub-id>
          <article-title>Regularized Evolution for Image Classifier Architecture Search</article-title>
          <source>Proc. AAAI Conf. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>104</volume>
          <page-range>148-175</page-range>
          <issue>1</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shahriari</surname>
              <given-names>Bobak</given-names>
            </name>
            <name>
              <surname>Swersky</surname>
              <given-names>Kevin</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Ziyu</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>Ryan P</given-names>
            </name>
            <name>
              <surname>De Freitas</surname>
              <given-names>Nando</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/JPROC.2015.2494218</pub-id>
          <article-title>Taking the human out of the loop: A review of Bayesian optimization</article-title>
          <source>Proc. IEEE</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jaderberg</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dalibard</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Osindero</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Czarnecki</surname>
              <given-names>W. M.</given-names>
            </name>
            <name>
              <surname>Donahue</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Razavi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Vinyals</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Green</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Dunning</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Simonyan</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kavukcuoglu</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1711.09846</pub-id>
          <article-title>Population based training of neural networks</article-title>
          <source>arXiv preprint arXiv:1711.09846</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="conf-paper">
          <page-range>507-523</page-range>
          <person-group person-group-type="author">
            <name>
              <surname>Hutter</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Hoos</surname>
              <given-names>H. H.</given-names>
            </name>
            <name>
              <surname>Leyton-Brown</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-3-642-25566-340</pub-id>
          <article-title>Sequential model-based optimization for general algorithm configuration</article-title>
          <source>International Conference on Learning and Intelligent Optimization, Berlin, Germany</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zela</surname>
              <given-names>Aaron</given-names>
            </name>
            <name>
              <surname>Klein</surname>
              <given-names>Aaron</given-names>
            </name>
            <name>
              <surname>Falkner</surname>
              <given-names>Stefan</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>Frank</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1807.06906</pub-id>
          <article-title>Towards automated deep learning: Efficient joint neural architecture and hyperparameter search</article-title>
          <source>arXiv preprint arXiv:1807.06906</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>212</volume>
          <page-range>106622</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>Xin</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Kaiyong</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>Xiaowen</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.knosys.2020.106622</pub-id>
          <article-title>AutoML: A survey of the state-of-the-art</article-title>
          <source>Knowl.-Based Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>455-492</page-range>
          <issue>4</issue>
          <year>1998</year>
          <person-group person-group-type="author">
            <name>
              <surname>D. R. Jones</surname>
              <given-names>M. Schonlau</given-names>
            </name>
            <name>
              <surname>Welch</surname>
              <given-names>W. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1023/A:1008306431147</pub-id>
          <article-title>Efficient global optimization of expensive black-box functions,</article-title>
          <source>J. Glob. Optim.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Williams</surname>
              <given-names>C. K.</given-names>
            </name>
            <name>
              <surname>Rasmussen</surname>
              <given-names>C. E.</given-names>
            </name>
          </person-group>
          <source>Gaussian Processes for Machine Learning</source>
          <publisher-name>Cambridge, MA: MIT Press</publisher-name>
          <year>2006</year>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <year>2009</year>
          <person-group person-group-type="author">
            <name>
              <surname>Srinivas</surname>
              <given-names>Niranjan</given-names>
            </name>
            <name>
              <surname>Krause</surname>
              <given-names>Andreas</given-names>
            </name>
            <name>
              <surname>Kakade</surname>
              <given-names>Sham M</given-names>
            </name>
            <name>
              <surname>Seeger</surname>
              <given-names>Matthias</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TIT.2011.2182033</pub-id>
          <article-title>Gaussian process optimization in the bandit setting: No regret and experimental design</article-title>
          <source>arXiv preprint arXiv:0912.3995</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <issue>10</issue>
          <year>2011</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bull</surname>
              <given-names>Adam D</given-names>
            </name>
          </person-group>
          <article-title>Convergence rates of efficient global optimization algorithms</article-title>
          <source>J. Mach. Learn. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="conf-paper">
          <volume>4</volume>
          <page-range>1942-1948</page-range>
          <year>1995</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kennedy</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Eberhart</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICNN.1995.488968</pub-id>
          <article-title>Particle swarm optimization</article-title>
          <source>Proceedings of ICNN’95 - International Conference on Neural Networks, Perth, Australia</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>341-359</page-range>
          <issue>4</issue>
          <year>1997</year>
          <person-group person-group-type="author">
            <name>
              <surname>Storn</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1023/A:1008202821328</pub-id>
          <article-title>Differential evolution- A simple and efficient heuristic for global optimization over continuous spaces</article-title>
          <source>J. Glob. Optim.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Miikkulainen</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Meyerson</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Rawal</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fink</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Francon</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Shahrzad</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Navruzyan</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Duffy</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Hodjat</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Evolving deep neural networks</article-title>
          <source>Artificial Intelligence in the Age of Neural Networks and Brain Computing</source>
          <publisher-name>Academic Press</publisher-name>
          <year>2024</year>
          <page-range>269-287</page-range>
          <pub-id pub-id-type="doi">10.1016/B978-0-323-96104-2.00002-6</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>S. R.</given-names>
            </name>
            <name>
              <surname>Rose</surname>
              <given-names>D. C.</given-names>
            </name>
            <name>
              <surname>Karnowski</surname>
              <given-names>T. P.</given-names>
            </name>
            <name>
              <surname>Lim</surname>
              <given-names>S. H.</given-names>
            </name>
            <name>
              <surname>Patton</surname>
              <given-names>R. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/2834892.2834896</pub-id>
          <article-title>Optimizing deep learning hyper-parameters through an evolutionary algorithm</article-title>
          <source>Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments (MLHPC'15), Austin, TX, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conference-proceedings">
          <volume>70</volume>
          <page-range>2902-2911</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Real</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Moore</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Selle</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Saxena</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Suematsu</surname>
              <given-names>Y. L.</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Kurakin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Large-scale evolution of image classifiers</article-title>
          <source>, https://proceedings.mlr.press/v70/real17a.html</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Russell</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Norvig</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <source>Artificial Intelligence: A Modern Approach</source>
          <publisher-name>Upper Saddle River: Prentice Hall</publisher-name>
          <year>1995</year>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>188-217</page-range>
          <issue>1</issue>
          <year>2006</year>
          <person-group person-group-type="author">
            <name>
              <surname>Audet</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Dennis Jr</surname>
              <given-names>J. E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1137/040603371</pub-id>
          <article-title>Mesh adaptive direct search algorithms for constrained optimization</article-title>
          <source>SIAM J. Optim.</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bengio</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Practical recommendations for gradient-based training of deep architectures</article-title>
          <source>Neural Networks: Tricks of the Trade: Second Edition</source>
          <publisher-name>Berlin, Heidelberg: Springer Berlin Heidelberg</publisher-name>
          <year>2012</year>
          <page-range>437-478</page-range>
          <pub-id pub-id-type="doi">10.1007/978-3-642-35289-8_26</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="conf-paper">
          <volume>28</volume>
          <issue>1</issue>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>D. J. D. Yamins J. Bergstra</surname>
              <given-names>D. J. D. J.</given-names>
            </name>
            <name>
              <surname>Cox</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures</article-title>
          <source>International Conference on Machine Learning, Atlanta, Georgia, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="conf-paper">
          <volume>15</volume>
          <page-range>3460-3468</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>J. T. Springenberg T. Domhan</surname>
              <given-names>J. T. T.</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves</article-title>
          <source>Proceedings of the 24th International Joint Conference on Artificial Intelligence, Buenos Aires, Argentina</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="conf-paper">
          <volume>70</volume>
          <page-range>1799-1808</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kandasamy</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Póczos</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Multi-fidelity bayesian optimisation with continuous approximations</article-title>
          <source>Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>1-52</page-range>
          <issue>185</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Jamieson</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>DeSalvo</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Rostamizadeh</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Talwalkar</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title>
          <source>J. Mach. Learn. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1238-1246</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Karnin</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Koren</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Somekh</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Almost optimal exploration in multi-armed bandits</article-title>
          <source>Proceedings of the 30th International Conference on Machine Learning, Atlanta, GA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1437-1446</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Falkner</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Klein</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Bohb: Robust and efficient hyperparameter optimization at scale,</article-title>
          <source>Proceedings of the 35th International Conference on Machine Learning, Stockholm, Sweden</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Awad</surname>
              <given-names>Narges</given-names>
            </name>
            <name>
              <surname>Mallik</surname>
              <given-names>Nikhil</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>Frank</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2105.09821</pub-id>
          <article-title>DEHB: Evolutionary Hyperband for scalable, robust and efficient hyperparameter optimization</article-title>
          <source>arXiv preprint arXiv:2105.09821</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>47</volume>
          <page-range>235-256</page-range>
          <issue>2</issue>
          <year>2002</year>
          <person-group person-group-type="author">
            <name>
              <surname>Auer</surname>
              <given-names>Peter</given-names>
            </name>
            <name>
              <surname>Cesa-Bianchi</surname>
              <given-names>Nicolò</given-names>
            </name>
            <name>
              <surname>Fischer</surname>
              <given-names>Paul</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1023/A:1013689704352</pub-id>
          <article-title>Finite-time analysis of the multiarmed bandit problem</article-title>
          <source>Mach. Learn.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dong</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2001.00326</pub-id>
          <article-title>Nas-bench-201: Extending the scope of reproducible neural architecture search</article-title>
          <source>arXiv preprint arXiv:2001.00326</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="conf-paper">
          <page-range>318-326</page-range>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Domke</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Generic methods for optimization-based modeling</article-title>
          <source>Proceedings of the 15th International Conference on Artificial Intelligence and Statistics, La Palma, Canary Islands, Spain</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1568-1577</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Franceschi</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Frasconi</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Salzo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Grazzi</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Pontil</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Bilevel programming for hyperparameter optimization and meta-learning</article-title>
          <source>Proceedings of the 35th International Conference on Machine Learning, Stockholm, Sweden</source>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1540-1522</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lorraine</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Vicol</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Duvenaud</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Optimizing millions of hyperparameters by implicit differentiation</article-title>
          <source>Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics, Palermo, Sicily, Italy</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="conf-paper">
          <page-range>73-746</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pedregosa</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Hyperparameter optimization with approximate gradient</article-title>
          <source>Proceedings of the 33rd In-ternational Conference on Machine Learning, New York, NY, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="conf-paper">
          <page-range>2113–2122</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Maclaurin</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Duvenaud</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Gradient-based hyperparameter optimization through reversible learning</article-title>
          <source>International Conference on Machine Learning, Lille, France</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="journal">
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Baydin</surname>
              <given-names>Atilim Gunes</given-names>
            </name>
            <name>
              <surname>Cornish</surname>
              <given-names>Robert</given-names>
            </name>
            <name>
              <surname>Rubio</surname>
              <given-names>David Martinez</given-names>
            </name>
            <name>
              <surname>Schmidt</surname>
              <given-names>Mark</given-names>
            </name>
            <name>
              <surname>Wood</surname>
              <given-names>Frank</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1703.04782</pub-id>
          <article-title>Online learning rate adaptation with hypergradient descent</article-title>
          <source>arXiv preprint arXiv:1703.04782</source>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liu</surname>
              <given-names>Hanxiao</given-names>
            </name>
            <name>
              <surname>Simonyan</surname>
              <given-names>Karen</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Yiming</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1806.09055</pub-id>
          <article-title>DARTS: Differentiable architecture search</article-title>
          <source>arXiv preprint arXiv:1806.09055</source>
        </element-citation>
      </ref>
      <ref id="ref_40">
        <label>40.</label>
        <element-citation publication-type="journal">
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jang</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Gu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Poole</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1611.01144</pub-id>
          <article-title>Categorical reparameterization with gumbel-softmax,</article-title>
          <source>arXiv preprint arXiv:1611.01144</source>
        </element-citation>
      </ref>
      <ref id="ref_41">
        <label>41.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Prechelt</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Early stopping—but when?</article-title>
          <source>Neural Networks: Tricks of the Trade</source>
          <publisher-name>Springer Berlin Heidelberg,</publisher-name>
          <year>2022</year>
          <page-range>55-69</page-range>
          <pub-id pub-id-type="doi">10.1007/3-540-49430-8_3</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_42">
        <label>42.</label>
        <element-citation publication-type="conf-paper">
          <page-range>402-408</page-range>
          <year>2000</year>
          <person-group person-group-type="author">
            <name>
              <surname>Caruana</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Lawrence</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Giles</surname>
              <given-names>C. L.</given-names>
            </name>
          </person-group>
          <article-title>Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping</article-title>
          <source>Advances in Neural Information Processing Systems 13, Denver, CO, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_43">
        <label>43.</label>
        <element-citation publication-type="conf-paper">
          <page-range>598-605</page-range>
          <year>1989</year>
          <person-group person-group-type="author">
            <name>
              <surname>LeCun</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Denker</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Solla</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Optimal brain damage</article-title>
          <source>Advances in Neural Information Processing Systems 2, Denver, CO, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_44">
        <label>44.</label>
        <element-citation publication-type="conf-paper">
          <page-range>164-171</page-range>
          <year>1992</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hassibi</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Stork</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Second order derivatives for network pruning: Optimal brain surgeon</article-title>
          <source>Advances in Neural Information Processing Systems 5, Denver, CO, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_45">
        <label>45.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1135–1143</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Han</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pool</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Tran</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dally</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Learning both weights and connections for efficient neural network</article-title>
          <source>Advances in Neural Information Processing Systems 28, Montreal, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_46">
        <label>46.</label>
        <element-citation publication-type="journal">
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1710.01878</pub-id>
          <article-title>To prune, or not to prune: Exploring the efficacy of pruning for model compression</article-title>
          <source>arXiv Preprint arXiv:1710.01878</source>
        </element-citation>
      </ref>
      <ref id="ref_47">
        <label>47.</label>
        <element-citation publication-type="journal">
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Kadav</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Durdanovic</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Samet</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Graf</surname>
              <given-names>H. P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1608.08710</pub-id>
          <article-title>Pruning filters for efficient convnets</article-title>
          <source>arXiv Preprint arXiv:1608.08710</source>
        </element-citation>
      </ref>
      <ref id="ref_48">
        <label>48.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1389–1397</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">https://doi.org/10 .1109/ICCV.2017.155</pub-id>
          <article-title>Channel pruning for accelerating very deep neural networks</article-title>
          <source>Proceedings of the IEEE International Conference on Computer Vision, Venice, Italy</source>
        </element-citation>
      </ref>
      <ref id="ref_49">
        <label>49.</label>
        <element-citation publication-type="conf-paper">
          <volume>32</volume>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Michel</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Levy</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Neubig</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Are sixteen heads really better than one?</article-title>
          <source>Advances in Neural Information Processing Systems, Vancouver, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_50">
        <label>50.</label>
        <element-citation publication-type="journal">
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Molchanov</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Tyree</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Karras</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Aila</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Kautz</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1611.06440</pub-id>
          <article-title>Pruning convolutional neural networks for resource efficient inference</article-title>
          <source>arXiv Preprint arXiv:1611.06440</source>
        </element-citation>
      </ref>
      <ref id="ref_51">
        <label>51.</label>
        <element-citation publication-type="conf-paper">
          <page-range>5058-5066</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Luo</surname>
              <given-names>J. H.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1707.06342</pub-id>
          <article-title>Thinet: A filter level pruning method for deep neural network compression</article-title>
          <source>Proceedings of the IEEE International Conference on Computer Vision, Venice, Italy</source>
        </element-citation>
      </ref>
      <ref id="ref_52">
        <label>52.</label>
        <element-citation publication-type="journal">
          <page-range>304-320</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Huang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-3-030-01270-0_19</pub-id>
          <article-title>Data-driven sparse structure selection for deep neural networks</article-title>
          <source>Computer Vision – ECCV 2018: 15th European Conference</source>
        </element-citation>
      </ref>
      <ref id="ref_53">
        <label>53.</label>
        <element-citation publication-type="journal">
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Narang</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Elsen</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Diamos</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Sengupta</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1704.05119</pub-id>
          <article-title>Exploring sparsity in recurrent neural networks</article-title>
          <source>arXiv Preprint arXiv:1704.05119</source>
        </element-citation>
      </ref>
      <ref id="ref_54">
        <label>54.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Frankle</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Carbin</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1803.03635</pub-id>
          <article-title>The lottery ticket hypothesis: Finding sparse, trainable neural networks</article-title>
          <source>arXiv Preprint arXiv:1803.03635</source>
        </element-citation>
      </ref>
      <ref id="ref_55">
        <label>55.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ajanthan</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Philip  Torr</surname>
              <given-names>H. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1810.02340</pub-id>
          <article-title>Snip: Single-shot network pruning based on connection sensitivity</article-title>
          <source>arXiv Preprint arXiv:1810.02340</source>
        </element-citation>
      </ref>
      <ref id="ref_56">
        <label>56.</label>
        <element-citation publication-type="journal">
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Frankle</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dziugaite</surname>
              <given-names>G. K.</given-names>
            </name>
            <name>
              <surname>Daniel  Roy</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Carbin</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1903.01611</pub-id>
          <article-title>Stabilizing the lottery ticket hypothesis</article-title>
          <source>arXiv Preprint arXiv:1903.01611</source>
        </element-citation>
      </ref>
      <ref id="ref_57">
        <label>57.</label>
        <element-citation publication-type="journal">
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dettmers</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Zettlemoyer</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1907.04840</pub-id>
          <article-title>Sparse networks from scratch: Faster training without losing performance</article-title>
          <source>arXiv Preprint arXiv:1907.04840</source>
        </element-citation>
      </ref>
      <ref id="ref_58">
        <label>58.</label>
        <element-citation publication-type="conf-paper">
          <volume>119</volume>
          <page-range>2943–2952</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Evci</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Gale</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Menick</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Castro</surname>
              <given-names>P. S.</given-names>
            </name>
            <name>
              <surname>Elsen</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Rigging the lottery: Making all tickets winners</article-title>
          <source>Proceedings of the 37th International Conference on Machine Learning, Vienna, Austria</source>
        </element-citation>
      </ref>
      <ref id="ref_59">
        <label>59.</label>
        <element-citation publication-type="journal">
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gale</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Elsen</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Hooker</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1902.09574</pub-id>
          <article-title>The state of sparsity in deep neural networks</article-title>
          <source>arXiv Preprint arXiv:1902.09574</source>
        </element-citation>
      </ref>
      <ref id="ref_60">
        <label>60.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1487–1495</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Golovin</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Solnik</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Moitra</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kochanski</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Karro</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Sculley</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3097983.3098043</pub-id>
          <article-title>Google vizier: A service for black-box optimization</article-title>
          <source>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_61">
        <label>61.</label>
        <element-citation publication-type="conf-paper">
          <page-range>561–577</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Moritz</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Nishihara</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tumanov</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Liaw</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Liang et al.</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Ray: A distributed framework for emerging ai applications</article-title>
          <source>13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18), Carlsbad, CA</source>
        </element-citation>
      </ref>
      <ref id="ref_62">
        <label>62.</label>
        <element-citation publication-type="journal">
          <year>2014</year>
          <person-group person-group-type="author">
            <name>
              <surname>Swersky</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Snoek</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>R. P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.1406.3896</pub-id>
          <article-title>Freeze-thaw bayesian optimization</article-title>
          <source>arXiv Preprint, vol. arXiv:1406.3896</source>
        </element-citation>
      </ref>
      <ref id="ref_63">
        <label>63.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>497-509</page-range>
          <issue>4</issue>
          <year>2007</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rommel  Regis</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Christine  Shoemaker</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1287/ijoc.1060.0182</pub-id>
          <article-title>A stochastic radial basis function method for the global optimization of expensive functions</article-title>
          <source>INFORMS J. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_64">
        <label>64.</label>
        <element-citation publication-type="journal">
          <volume>32</volume>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eriksson</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Pearce</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gardner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ryan  Turner</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Poloczek</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Scalable global optimization via local bayesian optimization</article-title>
          <source>Adv. Neural Inf. Process. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_65">
        <label>65.</label>
        <element-citation publication-type="journal">
          <volume>79</volume>
          <page-range>157-181</page-range>
          <issue>1</issue>
          <year>1993</year>
          <person-group person-group-type="author">
            <name>
              <surname>Donald  Jones</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Cary  Perttunen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bruce  Stuckman</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/BF00941892</pub-id>
          <article-title>Lipschitzian optimization without the lipschitz constant</article-title>
          <source>J. Optim. Theory Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_66">
        <label>66.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>495-519</page-range>
          <issue>2</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Letham</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Karrer</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Ottoni</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Bakshy</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1214/18-BA1110</pub-id>
          <article-title>Constrained bayesian optimization with noisy experiments</article-title>
          <source>Bayesian Anal.</source>
        </element-citation>
      </ref>
      <ref id="ref_67">
        <label>67.</label>
        <element-citation publication-type="journal">
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>De Freitas</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian optimization in high dimensions via random embeddings</article-title>
          <source>arXiv Preprint arXiv:1309.4741</source>
        </element-citation>
      </ref>
      <ref id="ref_68">
        <label>68.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>1-21</page-range>
          <issue>55</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Elsken</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Metzen</surname>
              <given-names>J. H.</given-names>
            </name>
            <name>
              <surname>Hutter</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Neural architecture search: A survey</article-title>
          <source>J. Mach. Learn. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_69">
        <label>69.</label>
        <element-citation publication-type="journal">
          <volume>45</volume>
          <page-range>385-482</page-range>
          <issue>3</issue>
          <year>2003</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kolda</surname>
              <given-names>T. G.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>R. M.</given-names>
            </name>
            <name>
              <surname>Torczon</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">0.1137/S003614450242889</pub-id>
          <article-title>Optimization by direct search: New perspectives on some classical and modern methods</article-title>
          <source>SIAM Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_70">
        <label>70.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Conn</surname>
              <given-names>A. R.</given-names>
            </name>
            <name>
              <surname>Scheinberg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Vicente</surname>
              <given-names>L. N.</given-names>
            </name>
          </person-group>
          <source>Introduction to Derivative-Free Optimization</source>
          <publisher-name>SIAM</publisher-name>
          <year>2009</year>
        </element-citation>
      </ref>
      <ref id="ref_71">
        <label>71.</label>
        <element-citation publication-type="journal">
          <volume>30</volume>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Vaswani</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shazeer</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Parmar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Uszkoreit</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Gomez</surname>
              <given-names>A. N.</given-names>
            </name>
            <name>
              <surname>Kaiser</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Polosukhin</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Attention is all you need</article-title>
          <source>Adv. Neural Inf. Process. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_72">
        <label>72.</label>
        <element-citation publication-type="conf-paper">
          <page-range>2623–2631</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Akiba</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Sano</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Yanase</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Ohta</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Koyama</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3292500.3330701</pub-id>
          <article-title>Optuna: A next-generation hyperparameter optimiza-tion framework</article-title>
          <source>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, Anchorage, AK, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_73">
        <label>73.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>747-769</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bouthillier</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Delaunay</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Bronzi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Trofimov</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nichyporuk</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Szeto</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Mohamed</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Pal</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Vincent</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Accounting for variance in machine learning benchmarks</article-title>
          <source>Proc. Mach. Learn. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_74">
        <label>74.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>1-43</page-range>
          <issue>248</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Henderson</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Romoff</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Brunskill</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Jurafsky</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Pineau</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Towards the systematic reporting of the energy and carbon footprints of machine learning</article-title>
          <source>J. Mach. Learn. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_75">
        <label>75.</label>
        <element-citation publication-type="journal">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Patterson</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Gonzalez</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Lluı́s  Munguia</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Rothchild</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>So</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Texier</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dean</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2104.10350</pub-id>
          <article-title>Carbon emissions and large neural network training</article-title>
          <source>arXiv Preprint arXiv:2104.10350</source>
        </element-citation>
      </ref>
      <ref id="ref_76">
        <label>76.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range>13693-13696</page-range>
          <issue>9</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Strubell</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ganesh</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McCallum</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1609/aaai.v34i09.7123</pub-id>
          <article-title>Energy and policy considerations for modern deep learning research</article-title>
          <source>Proc. AAAI Conf. Artif. Intell.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>