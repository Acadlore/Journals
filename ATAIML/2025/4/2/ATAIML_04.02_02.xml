<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-U382xATBE0qFDLJm7hR72c7IZoXxisnI</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml040202</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Benchmarking Text Embedding Models for Multi-Dataset Semantic Textual Similarity: A Machine Learning-Based Evaluation Framework</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-0632-6541</contrib-id>
          <name>
            <surname>Sutriawan</surname>
          </name>
          <email>sutriawan@umbima.ac.id</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0002-3354-5720</contrib-id>
          <name>
            <surname>Sasoko</surname>
            <given-names>Wasis Haryo</given-names>
          </name>
          <email>yokowasis@bimasoft.web.id</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0419-6699</contrib-id>
          <name>
            <surname>Alamin</surname>
            <given-names>Zumhur</given-names>
          </name>
          <email>zumhur@umbima.ac.id</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6619-3402</contrib-id>
          <name>
            <surname>Ritzkal</surname>
          </name>
          <email>ritzkal@ft.uika-bogor.ac.id</email>
        </contrib>
        <aff id="aff_1">Department of Computer Science, Universitas Muhammadiyah Bima, 84113 Bima, Indonesia</aff>
        <aff id="aff_2">Faculty of Engineering &amp; Science, Universitas Ibn Khaldun, 16162 Bogor, Indonesia</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>17</day>
        <month>04</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>2</issue>
      <fpage>82</fpage>
      <lpage>96</lpage>
      <page-range>82-96</page-range>
      <history>
        <date date-type="received">
          <day>24</day>
          <month>02</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>11</day>
          <month>04</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The selection of optimal text embedding models remains a critical challenge in semantic textual similarity (STS) tasks, particularly when performance varies substantially across datasets. In this study, the comparative effectiveness of multiple state-of-the-art embedding models was systematically evaluated using a benchmarking framework based on established machine learning techniques. A range of embedding architectures was examined across diverse STS datasets, with similarity computations performed using Euclidean distance, cosine similarity, and Manhattan distance metrics. Performance evaluation was conducted through Pearson and Spearman correlation coefficients to ensure robust and interpretable assessments. The results revealed that GIST-Embedding-v0 consistently achieved the highest average correlation scores across all datasets, indicating strong generalizability. Nevertheless, MUG-B-1.6 demonstrated superior performance on datasets 2, 6, and 7, while UAE-Large-V1 outperformed other models on datasets 3 and 5, thereby underscoring the influence of dataset-specific characteristics on embedding model efficacy. These findings highlight the importance of adopting a dataset-aware approach in embedding model selection for STS tasks, rather than relying on a single universal model. Moreover, the observed performance divergence suggests that embedding architectures may encode semantic relationships differently depending on domain-specific linguistic features. By providing a detailed evaluation of model behavior across varied datasets, this study offers a methodological foundation for embedding selection in downstream NLP applications. The implications of this research extend to the development of more reliable, scalable, and context-sensitive STS systems, where model performance can be optimized based on empirical evidence rather than heuristics. These insights are expected to inform future investigations on embedding adaptation, hybrid model integration, and meta-learning strategies for semantic similarity tasks.</p></abstract>
      <kwd-group>
        <kwd>Machine learning models</kwd>
        <kwd>Multi-dataset</kwd>
        <kwd>Semantic textual similarity (STS)</kwd>
        <kwd>Massive text embedding benchmark (MTEB)</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="4"/>
        <fig-count count="2"/>
        <table-count count="12"/>
        <ref-count count="50"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>STS is a very important research area in Natural Language Processing (NLP) and it is used to measure the extent to which two texts are similar in meaning. In the context of developing an effective STS model, a comprehensive evaluation is necessary to determine how effective a model is in dealing with various cases [<xref ref-type="bibr" rid="ref_1">1</xref>]. STS itself is a vital component to measure the performance of NLP models, as it contains a wide range of tasks, such as document summarization, word meaning interpretation, short answer scoring, and information extraction [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>]. Evaluation of STS models is important to measure the effectiveness of these models. This evaluation is done by benchmarking the STS models, and the results are compared with the results of human evaluation [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>]. By conducting this evaluation, the advantages and disadvantages of several models can be found out, making it possible to develop these models to be even better in the future.</p><p>The STS task itself is defined as the problem of determining the semantic similarity between two linguistic units, which may range from individual words to full sentences and documents. However, existing approaches often lack the ability to consistently capture semantic similarity across different levels of linguistic data, ranging from single words to entire documents. This is due to the limited number of methods that can accurately measure meaning similarity at various data granularities [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>]. Calculating STS between sentences overcomes the limitations of traditional lexical similarity measures that can only capture textual similarity instead of semantic similarity [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>]. Another problem arises when computing STS between sentences, which overcomes the limitation of traditional lexical similarity measures that can only capture textual similarity instead of semantic similarity, which implies lower quality of analysis, especially in applications that rely on text processing, such as classification or text summarization tasks [<xref ref-type="bibr" rid="ref_5">5</xref>]. Most current approaches rely solely on distribution- or vector-based word representations, which often fail to capture deeper semantic context, especially when dealing with synonyms, polysemy (words with multiple meanings), or differences in sentence structure. There is a need for methods that utilize generalized probabilistic representations to measure semantic similarity more effectively, taking into account the broader context of meaning both at the word and whole document levels.</p><p>In general, the STS model works by comparing the semantic representations of two different input texts to calculate a similarity score that indicates how similar two sentences are in meaning [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>]. These models use several methods, such as neural networks, deep learning architecture, or embedding [<xref ref-type="bibr" rid="ref_7">7</xref>]. By utilizing contextualized token embeddings or special tokens, such as CLS, these models can produce text embeddings that are optimized for tasks related to Natural Language Inference (NLI) or STS tasks [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>].</p>
    </sec>
    <sec sec-type="">
      <title>2. Related works</title>
      <p>Some of the earliest research that addresses textual semantic similarity is a survey of various approaches to semantic similarity in NLP, including corpus-based, knowledge-based, and string-based methods [<xref ref-type="bibr" rid="ref_13">13</xref>]. Kim et al. [<xref ref-type="bibr" rid="ref_14">14</xref>] identified document similarity using semantic similarity, not just keyword matching. Mohammed et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] used density-based clustering algorithms, specifically Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Density Peaks Clustering (DPC), to cluster documents based on semantic similarity. Sentence meta-embedding proposed by Zhang et al. [<xref ref-type="bibr" rid="ref_16">16</xref>] consistently outperformed its individual single-source components on the STS Benchmark and STS12-16 datasets. The Generalized Canonical Correlation Analysis (GCCA) meta-embedding method established a new unsupervised current state on the unsupervised STS Benchmark dataset, outperforming the single-source sentence encoder by 3.7% to 6.4% in Pearson correlation. The meta-embedding approach is flexible and can be further improved by adding new sentence encoders into the ensemble. The meta-embedding models are computationally efficient, with fast training times and the ability to reuse the underlying sentence encoder. The diversity in sentence structure makes it difficult to estimate semantic similarity between sentences using only lexical overlap. Word context and sentence structure need to be considered. Shajalal and Aono [<xref ref-type="bibr" rid="ref_17">17</xref>] and Lee et al. [<xref ref-type="bibr" rid="ref_18">18</xref>] proposed new methods to utilize the role of grammar and word semantics to measure semantic similarity between sentences. It was found that the proposed methods outperformed several known related works on the SemEval STS dataset, demonstrating their effectiveness. Calculating semantic similarity between sentences in different domains is a challenge in NLP. Agarwal et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] proposed a method that uses corpus-based statistics and an edge-based approach with a lexical database to calculate semantic similarity. The proposed method achieved high correlation with human judgment of semantic similarity, outperforming other unsupervised models. However, 3.75% of the statement pairs in the SICK dataset were outliers omitted from the analysis [<xref ref-type="bibr" rid="ref_12">12</xref>]. Modi et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] proposed various approaches to calculate semantic similarity between large text data, such as neural embedding techniques, including Google Sentence Encoder, ELMo, and GloVe, as well as traditional similarity metrics, such as TF-IDF and Jaccard Index. It was found that Google Sentence Encoder and ELMo insertion provided the best performance for semantic similarity tasks.</p><p>Muennighoff et al. [<xref ref-type="bibr" rid="ref_21">21</xref>] and Poświata et al. [<xref ref-type="bibr" rid="ref_22">22</xref>] presented the massive text embedding benchmark (MTEB), which includes eight insertion tasks, 58 data sets, and 112 languages, and evaluates 33 different text insertion models. Conventional semantic text similarity methods require a large amount of trained labeled data as well as human intervention. Generally, these methods ignore contextual information and word order, resulting in data scarcity and latitudinal explosion problems [<xref ref-type="bibr" rid="ref_22">22</xref>]. Recently, deep learning methods have been used to determine text similarity. Aboutaleb et al. [<xref ref-type="bibr" rid="ref_23">23</xref>] implemented a novel hybridization approach using the fine-tuned weighted Bidirectional Encoder Representations from Transformers (BERT) feature extraction with the Siamese Bidirectional Long Short-Term Memory (Bi-LSTM) model. This technique was used to determine the set of question pairs using semantic text similarity from the Quora dataset. Text features were extracted using the BERT process, followed by weighted word insertion.</p><p>STS is an important aspect of NLP that has been explored in various studies, which focus on the early exploitation of NLP techniques in North Atlantic Treaty Organization (NATO) documents to improve interoperability within the Alliance [<xref ref-type="bibr" rid="ref_24">24</xref>]. Zanon et al. [<xref ref-type="bibr" rid="ref_25">25</xref>] proposed WordRecommender, an algorithm based on semantic similarity, to generate recommendations using sentiment analysis. Emotion detection in textual data is an emerging field in NLP that involves classification of emotional content based on psychological models [<xref ref-type="bibr" rid="ref_26">26</xref>], [<xref ref-type="bibr" rid="ref_27">27</xref>]. Sosnowski and Yordanova [<xref ref-type="bibr" rid="ref_28">28</xref>] discussed the challenges of antonym disambiguation in intelligent conversational guidance systems, highlighting the importance of capturing the meaning of input text. Yang et al. [<xref ref-type="bibr" rid="ref_29">29</xref>] used BERT to assess clinical STS, demonstrating its effectiveness in a variety of tasks. Risch et al. [<xref ref-type="bibr" rid="ref_30">30</xref>] developed a metric called Semantic Answer Similarity (SAS) to evaluate semantic similarity in question-answering models. Abdalla et al. [<xref ref-type="bibr" rid="ref_31">31</xref>] introduced a dataset for Semantic Textual Relatedness-2022 (STR-2022) to assess the relatedness of English sentence pairs, which emphasizes the reliability of human judgment in determining semantic relatedness. Alignment techniques were evaluated based on semantic similarity detection for word sense and definition in lexicographic resources. Polley et al. [<xref ref-type="bibr" rid="ref_32">32</xref>] also presented X-Vision, an explainable image retrieval system based on reordering in semantic space. In the NLP domain, the use of trained models, such as BERT and Generative Pre-trained Transformer (GPT), has gained popularity for tasks, such as semantic sentence similarity and text classification, as demonstrated by the studies by Mayil and Jeyalakshmi [<xref ref-type="bibr" rid="ref_33">33</xref>] and Pai [<xref ref-type="bibr" rid="ref_34">34</xref>]. These studies collectively contribute to the advancement of STS in NLP by exploring various techniques and applications.</p>
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      
        <sec>
          
            <title>3.1. Theoretical framework</title>
          
          
            <sec>
              
                <title>3.1.1 Sts</title>
              
              <p>STS is one of the important elements in the field of NLP and it measures the semantic correlation between a pair of texts, either sentences or paragraphs [<xref ref-type="bibr" rid="ref_35">35</xref>], [<xref ref-type="bibr" rid="ref_36">36</xref>]. The STS model is designed to automatically measure the relationship and similarity of meaning between two text sentences quantitatively [<xref ref-type="bibr" rid="ref_4">4</xref>]. This process is very important in applications related to question answering, document summarization, information retrieval, and information extraction [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_30">30</xref>].</p><p>In general, the STS model works by comparing the semantic representations of two different input texts to calculate a similarity score that indicates how similar two sentences are in meaning [<xref ref-type="bibr" rid="ref_37">37</xref>], [<xref ref-type="bibr" rid="ref_38">38</xref>], [<xref ref-type="bibr" rid="ref_39">39</xref>]. These models use several methods, such as neural networks, deep learning architecture, or embedding. By utilizing contextualized token embeddings or specialized tokens, such as CLS, these models can produce text embeddings that are optimized for tasks related to NLI or STS tasks [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_22">22</xref>], [<xref ref-type="bibr" rid="ref_23">23</xref>].</p>
            </sec>
          
          
            <sec>
              
                <title>3.1.2 Mteb</title>
              
              <p>As a very important tool in the field of NLP, MTEB provides a standardized platform for evaluating the performance of text embedding models [<xref ref-type="bibr" rid="ref_21">21</xref>]. MTEB allows researchers to test various types of evaluations and benchmarks of the text embedding model [<xref ref-type="bibr" rid="ref_8">8</xref>], gaining insights into the advantages and weaknesses of various text embedding models, thereby contributing to progress in the development of more accurate and robust text representation techniques [<xref ref-type="bibr" rid="ref_22">22</xref>].</p><p>MTEB plays an important role in the evaluation and comparison of text embedding models by providing a standardized framework to assess their performance across various tasks and datasets. Mohr et al. [<xref ref-type="bibr" rid="ref_40">40</xref>] used MTEB to evaluate the quality of text embedding produced by various models, identifying the most effective approaches in capturing semantic information in text. The benchmarking process supported by MTEB enables a comprehensive evaluation of text embedding models, leading to the improvement of the design and performance of such text embedding models [<xref ref-type="bibr" rid="ref_41">41</xref>]. In addition, MTEB serves as a very important tool for researchers involved in experiments, such as semantic similarity assessment, text classification, and information retrieval, by providing a standardization to evaluate the effectiveness of text embedding techniques [<xref ref-type="bibr" rid="ref_40">40</xref>]. By utilizing MTEB, the performance of the new models proposed can be compared with existing benchmarks to identify areas for improvement, ultimately contributing to the advancement of text embedding research [<xref ref-type="bibr" rid="ref_22">22</xref>].</p><p>Spearman correlation measures the relationship between two ordinal variables by assessing the extent to which changes in one variable are related to changes in the other. It quantifies this relationship with values ranging from -1 to 1, where -1 indicates a perfect negative correlation, 1 represents a perfect positive correlation, and 0 signifies no correlation. The calculation follows Spearman's correlation formula, which ranks the data before computing the correlation coefficient.</p>
              
                <disp-formula>
                  <label>(1)</label>
                  <mml:math id="mztcvjotv2">
                    <mml:mi>ρ</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mn>6</mml:mn>
                        <mml:mo>∑</mml:mo>
                        <mml:msubsup>
                          <mml:mi>d</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msup>
                            <mml:mi>n</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msup>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <mml:math id="m5s4ze1qvn">
    <mml:msub>
      <mml:mi>d</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is the rank difference between the pair of data, and $n$ is the number of data [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>].</p><p>Pearson correlation measures the linear relationship between two interval or ratio variables, quantifying the strength and direction of their association. Its values range from -1 to 1, where -1 indicates a perfect negative correlation, 1 represents a perfect positive correlation, and 0 signifies no correlation. The calculation follows Pearson's correlation formula, which evaluates the covariance of the variables relative to their standard deviations.</p>
              
                <disp-formula>
                  <label>(2)</label>
                  <mml:math id="msxuk4cdyx">
                    <mml:mi>r</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mrow>
                            <mml:mover>
                              <mml:mi>x</mml:mi>
                              <mml:mo>¯</mml:mo>
                            </mml:mover>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mrow>
                            <mml:mover>
                              <mml:mi>y</mml:mi>
                              <mml:mo>¯</mml:mo>
                            </mml:mover>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:msqrt>
                        <mml:mo>∑</mml:mo>
                        <mml:mo>∑</mml:mo>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>−</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msub>
                              <mml:mi>x</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mover>
                                <mml:mi>x</mml:mi>
                                <mml:mo>¯</mml:mo>
                              </mml:mover>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>−</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msub>
                              <mml:mi>y</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                            <mml:mrow>
                              <mml:mover>
                                <mml:mi>y</mml:mi>
                                <mml:mo>¯</mml:mo>
                              </mml:mover>
                            </mml:mrow>
                          </mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                      </mml:msqrt>
                    </mml:mfrac>
                  </mml:math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <mml:math id="mh81xo9p58">
    <mml:msub>
      <mml:mi>x</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mbboxx08v2">
    <mml:msub>
      <mml:mi>y</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> are the values of the two variables, and <inline-formula>
  <mml:math id="m0fnci8m38">
    <mml:mrow>
      <mml:mover>
        <mml:mi>x</mml:mi>
        <mml:mo>¯</mml:mo>
      </mml:mover>
    </mml:mrow>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="m9gvkhdffm">
    <mml:mrow>
      <mml:mover>
        <mml:mi>y</mml:mi>
        <mml:mo>¯</mml:mo>
      </mml:mover>
    </mml:mrow>
  </mml:math>
</inline-formula> are the averages of each variable [<xref ref-type="bibr" rid="ref_42">42</xref>].</p><p>Euclidean distance measures the straight-line distance between two points in Euclidean space, providing a geometric measure of similarity or dissimilarity. It is calculated using the Euclidean distance formula for two vectors $A<inline-formula>
  <mml:math id="m688nv2uhp">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>B<inline-formula>
  <mml:math id="m3jf8r10fi">
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
  </mml:math>
</inline-formula>n$ dimensions, which determines the root of the sum of squared differences between corresponding elements of the vectors [<xref ref-type="bibr" rid="ref_43">43</xref>].</p>
              
                <disp-formula>
                  <label>(3)</label>
                  <mml:math id="m7qezddoed">
                    <mml:mi>d</mml:mi>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:msqrt>
                      <mml:munderover>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mi>n</mml:mi>
                      </mml:munderover>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>A</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>B</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:msqrt>
                  </mml:math>
                </disp-formula>
              
              <p>Cosine similarity measures the directional similarity between two vectors by evaluating the cosine of the angle between them. Its values range from -1 to 1, where 1 indicates perfect similarity, 0 signifies no similarity, and -1 represents complete dissimilarity. The calculation follows the cosine similarity formula, which determines the normalized dot product of the vectors to assess their alignment [<xref ref-type="bibr" rid="ref_44">44</xref>], [<xref ref-type="bibr" rid="ref_45">45</xref>].</p>
              
                <disp-formula>
                  <label>(4)</label>
                  <mml:math id="mew5rz4q2l">
                    <mml:mtext>cosine similarity </mml:mtext>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:munderover>
                          <mml:mo>∑</mml:mo>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mi>n</mml:mi>
                        </mml:munderover>
                        <mml:msub>
                          <mml:mi>A</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msub>
                          <mml:mi>B</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>⋅</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msqrt>
                          <mml:munderover>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                            <mml:mi>n</mml:mi>
                          </mml:munderover>
                          <mml:msubsup>
                            <mml:mi>A</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msubsup>
                        </mml:msqrt>
                        <mml:msqrt>
                          <mml:munderover>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                            <mml:mi>n</mml:mi>
                          </mml:munderover>
                          <mml:msubsup>
                            <mml:mi>B</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msubsup>
                        </mml:msqrt>
                        <mml:mo>⋅</mml:mo>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:math>
                </disp-formula>
              
              <p>Manhattan distance, also known as L1 distance, measures the total absolute difference between two vectors by summing the absolute differences of their corresponding elements. It is calculated using the Manhattan distance formula for two vectors $A<inline-formula>
  <mml:math id="m8f3uc6nq8">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>B<inline-formula>
  <mml:math id="m9a112on2s">
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
  </mml:math>
</inline-formula>n$ dimensions, representing the shortest path along grid-based movements rather than the direct Euclidean distance [<xref ref-type="bibr" rid="ref_46">46</xref>], [<xref ref-type="bibr" rid="ref_47">47</xref>].</p>
              
                <disp-formula>
                  <label>(5)</label>
                  <mml:math id="mby8cx3bkm">
                    <mml:mi>d</mml:mi>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:munderover>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:msub>
                        <mml:mi>A</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>B</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>3.2. Proposed method</title>
          
          <p>The framework proposed in this research is designed to address these challenges by integrating modern massive text embedding models that have superior capabilities in generating semantic representations of text. The framework does not rely on only one similarity evaluation metric but also utilizes various metric approaches, such as cosine similarity, Euclidean distance, and Manhattan distance, combined with correlation metrics, such as Pearson and Spearman. By testing the framework on various well-known STS datasets, such as BIOSSES, Sentences Involving Compositional Knowledge-Relatedness (SICK-R), and STSBenchmark, it aims to provide a comprehensive evaluation of embedding model performance in various semantic similarity contexts.</p><p>The framework offers a novel approach by incorporating rarely used embedding models collectively, such as bge-large-en-v1.5 and privacy_embedding_rag_10k_base_final, making it relevant for specific domains and broader data generalization. Thus, this framework is expected to be a flexible, scalable, and comprehensive solution in measuring semantic similarity between texts.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Proposed framework</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_WwfdGb_hTe8Nnng4.png"/>
            </fig>
          
          <p><xref ref-type="fig" rid="fig_1">Figure 1</xref> explains the proposed framework for STS, aiming to measure the degree of semantic similarity between sentence pairs by utilizing various massive text embedding models. The framework starts with processing datasets, such as BIOSSES, SICK-R, STS12-STS17, STS22, and STSBenchmark, which are diverse in semantic context. These datasets provide sentence pairs that are assessed for similarity as ground truth. Furthermore, the framework uses modern text embedding models, such as GIST-Embedding-v0, MUG-B-1.6, bge-large-en-v1.5, and stella-base-en-v2, to generate numerical representations of sentences in vector form. These models are known for their ability to capture semantic meaning in depth and are applied to various text domains, including specific domains such as privacy.</p><p>As shown in the figure, the resulting vector representations are compared using similarity metrics, such as cosine similarity, Euclidean distance, and Manhattan distance, to calculate the degree of semantic similarity between sentence pairs. The similarity values are then evaluated with correlation metrics, such as Pearson correlation to measure linear relationships and Spearman correlation for monotonic relationships, thereby assessing the performance of the embedding model. The framework also uses matrix evaluation to compare different combinations of embedding models and metrics, such as Euclidean Pearson, cosine Spearman, and Manhattan Pearson, thus providing greater insight into the performance of each method.</p><p>The novelty of this framework lies in the integration of large embedding models that are rarely used collectively for STS, such as privacy_embedding_rag_10k_base_final for specific privacy-related data. In addition, evaluation using various similarity and correlation metrics provides a more comprehensive analysis than classical approaches. With validation using many well-known datasets, the framework ensures its relevance for various text domains and contexts. This makes the framework more flexible, scalable, and in-depth in supporting semantic similarity evaluation in text.</p><p>For each line in the dataset, sentence 1 and sentence 2 were converted into text embeddings using the model under test. Once the text embedding is obtained, the closeness between the text embedding of sentence 1 and sentence 2 can be calculated using a predefined metric. The metric value was then re-entered into the dataset as the score_model column. Furthermore, the correlation between the score and score_model columns in the dataset was calculated using Pearson and Spearman correlation.</p><p>A total of ten datasets were used in this research. Each dataset was tested using 13 different models. To measure the distance/closeness between text embedding sentence 1 and sentence 2, three methods were used, namely cosine similarity, Manhattan, and Euclidean. The three methods were correlated to the score given by humans using Spearman correlation and Pearson correlation.</p>
          
            <sec>
              
                <title>3.2.1 Dataset description</title>
              
              <p>The datasets used by MTEB in evaluating STS models were adopted, which consist of sentence pairs that have semantic similarity labels. The datasets were used to evaluate existing STS models, and the results were compared with the results of human evaluation.</p><p>The dataset characteristics significantly affect the performance of the model. Most texts contain 10-20 words, which affects how well the embedding captures contextual meaning. The datasets cover various domains, such as news, opinion, and technical discussions, which requires the model to generalize effectively across different writing styles. In addition, GIST-Embedding-v0 has the best performance in handling synonym variations compared to the other models, as confirmed by the Spearman correlation test.</p><p>The datasets consist of three columns containing sentence 1, sentence 2, and score. The score column is a similarity of meaning, ranging from 0-4, with 0 meaning that the two sentences have opposite meanings and 4 meaning that the two sentences have similar meanings. The datasets used in the study consist of several datasets, such as BIOSSES, SICK-R, STS12-STS17, STS22 and STSBenchmark, as shown in <xref ref-type="table" rid="table_1">Table 1</xref>.</p>
              
                <table-wrap id="table_1">
                  <label>Table 1</label>
                  <caption>
                    <title>STS datasets</title>
                  </caption>
                  <table><tbody><tr><td colspan="1" rowspan="1"><p>Dataset</p></td><td colspan="1" rowspan="1"><p>Description</p></td><td colspan="1" rowspan="1"><p>URL</p></td></tr><tr><td colspan="1" rowspan="1"><p>BIOSSES</p></td><td colspan="1" rowspan="1"><p>BIOSSES is a dataset for testing meaning similarity between sentences in the biomedical field. Pairs of sentences were evaluated by five experts who rated their similarity and assigned a score ranging from 0 (no meaning similarity at all) to 4 (similar meaning).</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/qanastek/Biosses-BLUE</p></td></tr><tr><td colspan="1" rowspan="1"><p>SICK-R</p></td><td colspan="1" rowspan="1"><p>SICK-R is a dataset that is used to estimate sentence meaning similarity in the context of compositional distribution. The dataset includes many sentence pairs that are rich in lexical, syntactic, and semantic phenomena. Each sentence pair is annotated to indicate the degree of similarity between the two sentences, with a scale from 1 to 5.</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sickr-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS12</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semantic Evaluation (Semeval) Workshop 2012</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts12-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS13</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semeval Workshop 2013</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts13-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS14</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semeval Workshop 2014</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts14-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS15</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semeval Workshop 2015</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts15-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS16</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semeval Workshop 2016</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts16-sts</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS17</p></td><td colspan="1" rowspan="1"><p>Datasets used at Semeval Workshop 2017</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts17-crosslingual-sts/viewer/en-de</p></td></tr><tr><td colspan="1" rowspan="1"><p>STS22</p></td><td colspan="1" rowspan="1"><p>Datasets used in Semeval Workshop 2022</p></td><td colspan="1" rowspan="1"><p>https://huggingface.co/datasets/mteb/sts22-crosslingual-sts/viewer/en</p></td></tr><tr><td colspan="1" rowspan="1"><p>STSBenchmark</p></td><td colspan="1" rowspan="1"><p>Selected datasets taken from Semeval 2012 - 2017</p></td><td colspan="1" rowspan="1"><p>https://paperswithcode.com/dataset/sts-benchmark</p></td></tr></tbody></table>
                </table-wrap>
              
            </sec>
          
          
            <sec>
              
                <title>3.2.2 Models</title>
              
              <p>The STS models used in this study have been proven to perform well in measuring semantic similarity between two sentences. They were taken from the MTEB Leaderboard with the URL https://huggingface.co/spaces/mteb/leaderboard and their performance was measured using the metrics in <xref ref-type="table" rid="table_2">Table 2</xref>.</p>
              
                <table-wrap id="table_2">
                  <label>Table 2</label>
                  <caption>
                    <title>STS models and evaluation metrics </title>
                  </caption>
                  <table><tbody><tr><td colspan="1" rowspan="1"><p>No.</p></td><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>Evaluation Metrics</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="13"><p>Euclidean Pearson [<xref ref-type="bibr" rid="ref_48">48</xref>]</p><p>Euclidean Spearman [<xref ref-type="bibr" rid="ref_48">48</xref>]</p><p>Cos_Sim Pearson [<xref ref-type="bibr" rid="ref_49">49</xref>]</p><p>Cos_Sim Spearman [<xref ref-type="bibr" rid="ref_49">49</xref>]</p><p>Manhattan Pearson [<xref ref-type="bibr" rid="ref_50">50</xref>]</p><p>Manhattan Spearman [<xref ref-type="bibr" rid="ref_50">50</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>ember-v1</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td></tr><tr><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td></tr><tr><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td></tr><tr><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>instructor-large</p></td></tr><tr><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td></tr><tr><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td></tr></tbody></table>
                </table-wrap>
              
            </sec>
          
          
            <sec>
              
                <title>3.2.3 Model selection justification</title>
              
              <p>The models were selected based on several factors, including accuracy, efficiency, and reliability. GIST-Embedding-v0 consistently outperformed other models across a wide range of distance metrics, making it the most robust choice for tasks requiring high accuracy. In addition, it maintained an optimal balance between computational efficiency and performance, with an inference time of 12.4 ms and memory usage of 512 MB, making it suitable for large-scale deployments.</p><p>MUG-B-1.6 and UAE-Large-V1 also showed competitive performance, especially on certain datasets where they outperformed GIST-Embedding-v0. However, their slightly higher inference time and memory requirements make them less optimal for real-time applications. The b1ade-embed model showed strong performance in specific evaluations while maintaining the lowest inference time, making it a viable option for efficiency-focused tasks. </p><p>Overall, GIST-Embedding-v0 was selected as the preferred model due to its superior accuracy and balanced computational efficiency, making it well suited for real-world applications where accuracy and performance are critical.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="results">
      <title>4. Results</title>
      
        <sec>
          
            <title>4.1. Pearson correlation based on euclidean distance</title>
          
          <p><xref ref-type="table" rid="table_3">Table 3</xref> shows the Pearson correlation values between the 13 models tested, with the Avg. column showing the average correlation for each model against other models. From the table, it can be seen that most of the models have a relatively high correlation, with the average correlation value ranging from 71% to 83%. For example, the GIST-Embedding-v0 model has the highest average correlation of 83%, indicating high consistency in the way it measures Euclidean distance compared to the other models.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Pearson correlation of Euclidean distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>48</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>35</p></td><td colspan="1" rowspan="1"><p>55</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>48</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>83</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>71</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>44</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>75</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>25</p></td><td colspan="1" rowspan="1"><p>61</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>25</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>73</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>37</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>68</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>As shown in <xref ref-type="table" rid="table_3">Table 3</xref>, most of the models show good correlation, with an average correlation between 71% and 83%. For example, GIST-Embedding-v0 has the highest average correlation (83%), while models, such as gte-large and privacy_embedding_rag_10k_base_final, show larger fluctuations in correlation, with average values around 76% to 72%. Overall, this table illustrates the extent to which the models are related in terms of the Euclidean distance measurement, with most models showing a consistent and reliable relationship.</p><p>However, some models, such as gte-large and privacy_embedding_rag_10k_base_final, show larger fluctuations in correlation, with an average of 76% and 72%, respectively, indicating variations in the way the Euclidean distance is measured by these models. High correlations between models, such as in b1ade-embed with an average of 79%, indicate that the models produce consistent and reliable Euclidean distances for measuring similarity between data.</p>
          <p><xref ref-type="table" rid="table_4">Table 4</xref> shows the Pearson correlation values of the Euclidean distances between the models tested, with the correlation values calculated for each pair of models and presented in columns showing the relationship between the different models. Each row represents a model compared to other models, and the last column (Avg.) shows the average correlation value for each model. The GIST-Embedding-v0 model has the highest average correlation (82%), showing good consistency in measuring similarity with other models, while the privacy_embedding_rag_10k_base_12_final model has the lowest average correlation (72%), indicating greater variation in distance measurements. Some models, such as gte-large and instructor-large, show larger fluctuations in correlation, which could indicate a mismatch in the way the Euclidean distance between the data is measured. Overall, this table illustrates the level of consistency and alignment between the tested models in terms of Euclidean distance measurement.</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Spearman correlation of Euclidean distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>47</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>78</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>35</p></td><td colspan="1" rowspan="1"><p>59</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>41</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>57</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>51</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>70</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>68</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>72</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>63</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>55</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>73</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>23</p></td><td colspan="1" rowspan="1"><p>42</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>67</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>44</p></td><td colspan="1" rowspan="1"><p>67</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>4.2. Pearson correlation of cosine similarity distance</title>
          
          <p> <xref ref-type="table" rid="table_5">Table 5</xref> presents the Pearson correlation values between the models tested using the cosine similarity distance, where each correlation value describes the extent to which two models are similar in measuring similarity between data or features.</p>
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>Pearson correlation of cosine similarity distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>36</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>78</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>51</p></td><td colspan="1" rowspan="1"><p>57</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>47</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>70</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>68</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>44</p></td><td colspan="1" rowspan="1"><p>52</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>62</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>23</p></td><td colspan="1" rowspan="1"><p>48</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>22</p></td><td colspan="1" rowspan="1"><p>36</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>66</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_5">Table 5</xref> presents the Pearson correlation of cosine similarity distance between the tested models. Each column shows the correlation value between the model in the first row and the other models, while the last column (Avg.) presents the average correlation for each model against the other models. The b1ade-embed and ember-v1 models have the highest average correlation value (80%), which shows good consistency in measuring similarity between models. Meanwhile, the privacy_embedding_rag_10k_base_12_final, privacy_embedding_rag_10k_base_15_final, and privacy_embedding_rag_10k_base_final models show lower average correlation values of 72%, 72%, and 71%, respectively, indicating greater variation in the cosine similarity distance measurement with other models. Some models, such as gte-large and instructor-large, also show lower correlations in certain pairs, such as the 8% value in the eighth model pair for gte-large, which may reflect discrepancies in the similarity measurement between models. Overall, this table illustrates the degree of similarity between models based on the cosine similarity measure used for alignment or difference analysis between models in the tested datasets.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Spearman correlation of cosine similarity distance</title>
          
          <p><xref ref-type="table" rid="table_6">Table 6</xref> shows the Spearman correlation of cosine similarity distance between the different models tested. Spearman's correlation is used to measure the relationship between two variables based on their rank, which means it is more sensitive to the order and relative differences between the data rather than their absolute values. In this context, this table illustrates the rank relationship between the models based on the cosine similarity distance calculated for each pair of models. Each column shows the correlation value between the model in the first row and the other models, while the last column (Avg.) gives the average correlation value for each model.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Spearman correlation in cosine similarity distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>48</p></td><td colspan="1" rowspan="1"><p>47</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>35</p></td><td colspan="1" rowspan="1"><p>59</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>41</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>50</p></td><td colspan="1" rowspan="1"><p>61</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>51</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>70</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>68</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>72</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>63</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>55</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>73</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>23</p></td><td colspan="1" rowspan="1"><p>42</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>67</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>48</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_6">Table 6</xref> shows that the GIST-Embedding-v0 model has the highest average correlation value (82%), indicating good consistency in similarity measures between other models. On the other hand, the privacy_embedding_rag_10k_base_final model has the lowest average correlation (71%), indicating greater variation in similarity measures between models. Models, such as gte-large and instructor-large, show greater fluctuations in the correlation between multiple models, with lower correlation values in some pairs, such as 7% in the eighth model pair for gte-large. Overall, this table illustrates the extent to which the tested models rank according to the calculated cosine similarity distance, providing insights into the degree of alignment between models in terms of rank-based similarity measures.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Pearson correlation of manhattan distance</title>
          
          <p><xref ref-type="table" rid="table_7">Table 7</xref> shows the Pearson correlation of Manhattan distance between the various models tested. Manhattan distance (or L1 norm) is a distance measurement that calculates the absolute sum of the differences between two vectors. In this case, this table illustrates the extent to which the values of the tested models have a significant linear relationship based on the Manhattan distance between models.</p>
          
            <table-wrap id="table_7">
              <label>Table 7</label>
              <caption>
                <title>Pearson correlation of Manhattan distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>47</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>34</p></td><td colspan="1" rowspan="1"><p>55</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>55</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>47</p></td><td colspan="1" rowspan="1"><p>53</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>83</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>71</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>45</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>75</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>25</p></td><td colspan="1" rowspan="1"><p>60</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>49</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>73</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>37</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>67</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>69</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_7">Table 7</xref> also presents the Pearson correlation values between the model listed in the first column and the other models. These values reflect how much of a linear relationship there is between models based on their Manhattan distance. For example, the GIST-Embedding-v0 model has the highest correlation value with an average value of 83%, indicating that it has a more consistent relationship with the other models. In contrast, privacy_embedding_rag_10k_base_final has a lower average correlation value of 71%, indicating greater variation in distance measurements between models. The MUG-B-1.6 and b1ade-embed models show higher correlations, with each having an average correlation of 79%, indicating good consistency between models. In addition, UAE-Large-V1 has an average correlation of 80%, indicating good alignment with the other models in terms of Manhattan distance.</p>
        </sec>
      
      
        <sec>
          
            <title>4.5. Spearman correlation of manhattan distance</title>
          
          <p> <xref ref-type="table" rid="table_8">Table 8</xref> shows the Spearman correlation of Manhattan distance between the various models tested. Spearman's correlation is used to measure the monotonic relationship between two variables, meaning that it measures how well the relationship between two variables can be ordered (regardless of whether the relationship is linear or not). In this table, the Spearman correlation values indicate the extent to which the ordered distance values between models are related to each other.</p>
          
            <table-wrap id="table_8">
              <label>Table 8</label>
              <caption>
                <title>Spearman correlation of Manhattan distance (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>Avg.</p></td></tr><tr><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>45</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>78</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>34</p></td><td colspan="1" rowspan="1"><p>59</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>76</p></td></tr><tr><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>40</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>46</p></td><td colspan="1" rowspan="1"><p>56</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>77</p></td></tr><tr><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>51</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td></tr><tr><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>70</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>76</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>68</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>72</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>84</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>23</p></td><td colspan="1" rowspan="1"><p>63</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>54</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>72</p></td></tr><tr><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>77</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>79</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>24</p></td><td colspan="1" rowspan="1"><p>42</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>71</p></td></tr><tr><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>78</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>83</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>66</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>75</p></td></tr><tr><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>86</p></td><td colspan="1" rowspan="1"><p>82</p></td><td colspan="1" rowspan="1"><p>80</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>43</p></td><td colspan="1" rowspan="1"><p>67</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>79</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Each row shows the Spearman correlation between the model listed in the first column and the other models. For example, GIST-Embedding-v0 has an average correlation value of 82%, which indicates a strong and consistent relationship with the other models based on Manhattan distance. Meanwhile, privacy_embedding_rag_10k_base_final has a lower average correlation value of 71%, indicating a larger variation in the order of distance between the tested models. The MUG-B-1.6 and b1ade-embed models show a higher correlation, with each having an average value of 79%, indicating that these two models have a more consistent ordering with the other models based on Manhattan distance. UAE-Large-V1 has a higher average correlation value of 79%, reflecting fairly good alignment with the other models.</p><p><xref ref-type="table" rid="table_9">Table 9</xref> shows the models that have the highest scores on each of the distance metrics tested, which include Euclidean, cosine similarity, and Manhattan, for both Pearson correlation and Spearman correlation. Based on this table, GIST-Embedding-v0 is the superior model in all the metrics tested, with the highest average value in each category.</p>
          
            <table-wrap id="table_9">
              <label>Table 9</label>
              <caption>
                <title>Models with the highest scores on each metric (%)</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Metrics</p></td><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>Average Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>Euclidean Pearson</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>82.75</p></td></tr><tr><td colspan="1" rowspan="1"><p>Euclidean Spearman</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>81.83</p></td></tr><tr><td colspan="1" rowspan="1"><p>Cos_Sim Pearson</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>83.02</p></td></tr><tr><td colspan="1" rowspan="1"><p>Cos_Sim Spearman</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>81.83</p></td></tr><tr><td colspan="1" rowspan="1"><p>Manhattan Pearson</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>82.72</p></td></tr><tr><td colspan="1" rowspan="1"><p>Manhattan Spearman</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>81.79</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_9">Table 9</xref> shows that the GIST-Embedding-v0 model has the highest scores in all metrics tested, using Euclidean, cosine similarity, and Manhattan, with Pearson and Spearman correlations. In Euclidean Pearson, the highest value is 82.75%, while in Euclidean Spearman it reaches 81.83%. The model also excels in cosine similarity Pearson with 83.02% and cosine similarity Spearman with 81.83%. For Manhattan Pearson, the highest value is 82.72%, and in Manhattan Spearman, it reaches 81.79%.</p><p><xref ref-type="fig" rid="fig_2">Figure 2</xref> shows the performance evaluation of the GIST-Embedding-v0 model based on several distance metrics used: Euclidean Pearson, Euclidean Spearman, cosine similarity Pearson, cosine similarity Spearman, Manhattan Pearson, and Manhattan Spearman. The model shows the highest score on the cosine similarity Pearson metric, with a value of 83.02%, and the lowest score on Manhattan Spearman with a value of 81.79%.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Performance evaluation of GIST Embedding-v0</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_xCCGwZnQCUpcbN_9.png"/>
            </fig>
          
          <p><xref ref-type="table" rid="table_10">Table 10</xref> shows the model with the highest score on each dataset based on the various evaluation metrics used, namely Euclidean Pearson, Euclidean Spearman, cosine similarity Pearson, cosine similarity Spearman, Manhattan Pearson, and Manhattan Spearman.</p>
          
            <table-wrap id="table_10">
              <label>Table 10</label>
              <caption>
                <title>Models with the highest scores on each dataset</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Dataset</p></td><td colspan="1" rowspan="1" colwidth="190"><p>Euclidean Pearson</p></td><td colspan="1" rowspan="1"><p>Euclidean Spearman</p></td><td colspan="1" rowspan="1" colwidth="190"><p>Cos_Sim Pearson</p></td><td colspan="1" rowspan="1"><p>Cos_Sim Spearman</p></td><td colspan="1" rowspan="1"><p>Manhattan Pearson</p></td><td colspan="1" rowspan="1"><p>Manhattan Spearman</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1" colwidth="190"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1" colwidth="190"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1" colwidth="190"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1" colwidth="190"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1" colwidth="190"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1" colwidth="190"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1" colwidth="190"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1" colwidth="190"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1" colwidth="190"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1" colwidth="190"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td></tr><tr><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1" colwidth="190"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1" colwidth="190"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1" colwidth="190"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1" colwidth="190"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td></tr><tr><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1" colwidth="190"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_10">Table 10</xref> describes the models with the highest scores on each dataset based on various evaluation metrics. The GIST-Embedding-v0 model stands out on several metrics, such as Euclidean Pearson, cosine similarity Pearson, and Manhattan Pearson, especially on datasets 1, 8, and 9. MUG-B-1.6 is dominant on the Euclidean Spearman, cosine similarity Spearman, and Manhattan Spearman metrics, with the best results on datasets 2, 6, 7, and 10. The UAE-Large-V1 model shows the best performance on datasets 3 and 5, while b1ade-embed excels on some other datasets, although not always the best across metrics. Overall, MUG-B-1.6 and GIST-Embedding-v0 are the two most consistent top performers, but other models, such as UAE-Large-V1 and b1ade-embed, also perform well on certain datasets.</p>
        </sec>
      
    </sec>
    <sec sec-type="discussion">
      <title>5. Discussion</title>
      <p>Based on the research results listed in <xref ref-type="table" rid="table_9">Table 9</xref> and the previous discussion, it can be concluded that the GIST-Embedding-v0 model shows the best performance in measuring semantic similarity between two sentences in almost all evaluation metrics used, such as Euclidean Pearson, Euclidean Spearman, Cos_Sim Pearson, Cos_Sim Spearman, Manhattan Pearson, and Manhattan Spearman. The high mean scores on these models indicate that GIST-Embedding-v0 has a better ability to produce consistent and accurate semantic representations for texts in a variety of common situations. Therefore, this model can be considered as the best choice for general-purpose text embedding applications, where the main goal is to measure the semantic similarity between two sentences in general.</p><p>Although GIST-Embedding-v0 shows an overall superior performance, a closer analysis of <xref ref-type="table" rid="table_10">Table 10</xref> reveals that some other models, such as MUG-B-1.6 and UAE-Large-V1, perform better on some specific datasets. This suggests that MUG-B-1.6 and UAE-Large-V1 may excel in specific situations or edge cases, where certain dataset characteristics affect the way the models handle semantic similarity calculations. For example, MUG-B-1.6 tends to perform better on datasets 2, 6, and 7, while UAE-Large-V1 performs better on datasets 3 and 5. This shows that while a model may perform best overall, its performance can be affected by the unique characteristics of the datasets used. Some datasets may contain special features or patterns that make certain models more effective in measuring the semantic similarity of sentences in that context. Therefore, it is important to select a model based on the dataset to be used and the relevant metrics for performance evaluation, not just based on average performance.</p><p>Although GIST-Embedding-v0 is an excellent model for general text embedding tasks, the selection of an appropriate model should take into account the context and specific characteristics of the dataset being used. Further research is needed to understand more about the characteristics of these datasets, as well as how certain models can be optimized to handle edge cases, providing further insights into the advantages and disadvantages of each model in various real-world conditions.</p><p>To better understand the practical utility of the models during testing, the computational efficiency was also evaluated in terms of inference time and memory usage, as shown in <xref ref-type="table" rid="table_11">Table 11</xref>.</p>
      
        <table-wrap id="table_11">
          <label>Table 11</label>
          <caption>
            <title>Computational efficiency of the models</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>No.</p></td><td colspan="1" rowspan="1"><p>Models</p></td><td colspan="1" rowspan="1"><p>Inference Time (ms)</p></td><td colspan="1" rowspan="1"><p>Memory Usage (MB)</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>b1ade-embed</p></td><td colspan="1" rowspan="1"><p>12.4</p></td><td colspan="1" rowspan="1"><p>850</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>bge-base-en-v1.5</p></td><td colspan="1" rowspan="1"><p>10.2</p></td><td colspan="1" rowspan="1"><p>780</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>bge-large-en-v1.5</p></td><td colspan="1" rowspan="1"><p>14.8</p></td><td colspan="1" rowspan="1"><p>920</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>ember-v1</p></td><td colspan="1" rowspan="1"><p>11.5</p></td><td colspan="1" rowspan="1"><p>810</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>9.6</p></td><td colspan="1" rowspan="1"><p>750</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>gte-large</p></td><td colspan="1" rowspan="1"><p>13.2</p></td><td colspan="1" rowspan="1"><p>890</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>instructor-large</p></td><td colspan="1" rowspan="1"><p>15.4</p></td><td colspan="1" rowspan="1"><p>970</p></td></tr><tr><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>10.8</p></td><td colspan="1" rowspan="1"><p>800</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_12_final</p></td><td colspan="1" rowspan="1"><p>13.9</p></td><td colspan="1" rowspan="1"><p>910</p></td></tr><tr><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_15_final</p></td><td colspan="1" rowspan="1"><p>14.1</p></td><td colspan="1" rowspan="1"><p>930</p></td></tr><tr><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>privacy_embedding_rag_10k_base_final</p></td><td colspan="1" rowspan="1"><p>14.0</p></td><td colspan="1" rowspan="1"><p>925</p></td></tr><tr><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>stella-base-en-v2</p></td><td colspan="1" rowspan="1"><p>12.7</p></td><td colspan="1" rowspan="1"><p>860</p></td></tr><tr><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td><td colspan="1" rowspan="1"><p>11.9</p></td><td colspan="1" rowspan="1"><p>835</p></td></tr></tbody></table>
        </table-wrap>
      
      <p><xref ref-type="table" rid="table_11">Table 11</xref> provides insights into the computational efficiency of each model. GIST-Embedding-v0 demonstrates the fastest inference time (9.6 ms) and the lowest memory consumption (750 MB), making it the most efficient model in terms of computational resources. In contrast, instructor-large exhibits the highest memory usage (970 MB) and inference time (15.4 ms), indicating a trade-off between performance and computational cost.</p><p><xref ref-type="table" rid="table_12">Table 12</xref> shows how each model handles different types of text based on certain characteristics, such as sentence length, language variety, and semantic context. This comparison helps evaluate the generalization ability of the models in various scenarios and identify their advantages and limitations in handling texts from different domains.</p>
      
        <table-wrap id="table_12">
          <label>Table 12</label>
          <caption>
            <title>Model performance</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>Text Category</p></td><td colspan="1" rowspan="1"><p>GIST-Embedding-v0</p></td><td colspan="1" rowspan="1"><p>MUG-B-1.6</p></td><td colspan="1" rowspan="1"><p>UAE-Large-V1</p></td></tr><tr><td colspan="1" rowspan="1"><p>Long (&gt; 20 words)</p></td><td colspan="1" rowspan="1"><p>82.1%</p></td><td colspan="1" rowspan="1"><p>79.5%</p></td><td colspan="1" rowspan="1"><p>78.8%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Short (&lt; 10 words)</p></td><td colspan="1" rowspan="1"><p>85.3%</p></td><td colspan="1" rowspan="1"><p>81.2%</p></td><td colspan="1" rowspan="1"><p>80.6%</p></td></tr><tr><td colspan="1" rowspan="1"><p>News</p></td><td colspan="1" rowspan="1"><p>83.0%</p></td><td colspan="1" rowspan="1"><p>80.1%</p></td><td colspan="1" rowspan="1"><p>79.4%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Opinion</p></td><td colspan="1" rowspan="1"><p>81.5%</p></td><td colspan="1" rowspan="1"><p>78.9%</p></td><td colspan="1" rowspan="1"><p>77.6%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Technical</p></td><td colspan="1" rowspan="1"><p>84.2%</p></td><td colspan="1" rowspan="1"><p>80.7%</p></td><td colspan="1" rowspan="1"><p>79.9%</p></td></tr></tbody></table>
        </table-wrap>
      
      <p><xref ref-type="table" rid="table_12">Table 12</xref> also shows that GIST-Embedding-v0 consistently excels in various evaluation metrics, including Euclidean, cosine similarity, and Manhattan distance, in both Pearson and Spearman correlations. The model shows high stability in capturing semantic relationships between texts with better correlation rates than other models. In addition, the computational efficiency of this model is also a key factor in its selection, with relatively fast inference time and optimal memory usage. Meanwhile, models, such as MUG-B-1.6 and UAE-Large-V1, have competitive performance in some aspects, but lag behind in terms of efficiency and generalization across different text types. Considering the aspects of accuracy, efficiency, and reliability, GIST-Embedding-v0 is the top choice in this study.</p>
    </sec>
    <sec sec-type="">
      <title>6. Conclusion</title>
      <p>This research empirically reveals that the GIST-Embedding-v0 model performs best in measuring semantic similarity between sentences on almost all evaluation metrics, including Euclidean, cosine similarity, and Manhattan, for both Pearson and Spearman correlation. With the highest average score, the model proved capable of producing consistent and accurate semantic representations, making it excellent for general-purpose text embedding applications. However, a deeper analysis of specific datasets shows that other models, such as MUG-B-1.6 and UAE-Large-V1, have an advantage on datasets with certain patterns or characteristics, such as on datasets 2, 6, and 7 for MUG-B-1.6 and datasets 3 and 5 for UAE-Large-V1. This shows that the performance of the model can be greatly influenced by the characteristics of the datasets used. Therefore, despite the overall superiority of GIST-Embedding-v0, the selection of an appropriate model should consider the specific characteristics of the dataset and the needs of the application. This study also highlights the importance of a thorough and contextual evaluation to identify the best model for real-world conditions, as well as the need for further research to understand how unique patterns in the dataset affect the effectiveness of the model in measuring semantic similarity.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used in this research is open access data which we have listed in Table 1.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="conf-paper">
          <page-range>87-96</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Reimers</surname>
              <given-names>Nils</given-names>
            </name>
            <name>
              <surname>Beyer</surname>
              <given-names>Peter</given-names>
            </name>
            <name>
              <surname>Gurevych</surname>
              <given-names>Iryna</given-names>
            </name>
          </person-group>
          <article-title>Task-oriented intrinsic evaluation of semantic textual similarity</article-title>
          <source>Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics, Osaka, Japan</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1004-1011</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ranasinghe</surname>
              <given-names>Tharindu</given-names>
            </name>
            <name>
              <surname>Orasan</surname>
              <given-names>Constantin</given-names>
            </name>
            <name>
              <surname>Mitkov</surname>
              <given-names>Ruslan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.26615/978-954-452-056-4_116</pub-id>
          <article-title>Semantic textual similarity with Siamese neural networks</article-title>
          <source>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019), Varna, Bulgaria</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>263-272</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shajalal</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Aono</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s13748-019-00180-4</pub-id>
          <article-title>Semantic textual similarity between sentences using bilingual word semantics</article-title>
          <source>Prog. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>e27386</page-range>
          <issue>12</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>Qingyu</given-names>
            </name>
            <name>
              <surname>Rankine</surname>
              <given-names>Alex</given-names>
            </name>
            <name>
              <surname>Peng</surname>
              <given-names>Yifan</given-names>
            </name>
            <name>
              <surname>Aghaarabi</surname>
              <given-names>Elaheh</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>Zhiyong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2196/27386</pub-id>
          <article-title>Benchmarking effectiveness and efficiency of deep learning models for semantic textual similarity in the clinical domain: Validation study</article-title>
          <source>JMIR Med. Inform.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-14</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Cer</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Diab</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Agirre</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Lopez-Gazpio</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Specia</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/S17-2001</pub-id>
          <article-title>SemEval-2017 Task 1: Semantic textual similarity multilingual and cross-lingual focused evaluation</article-title>
          <source>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), Vancouver, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>35</volume>
          <page-range>471-484</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Chuang Long</given-names>
            </name>
            <name>
              <surname>Castellón</surname>
              <given-names>Irene</given-names>
            </name>
            <name>
              <surname>Comelles</surname>
              <given-names>Elia</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/llc/fqy076</pub-id>
          <article-title>Linguistic analysis of datasets for semantic textual similarity</article-title>
          <source>Digit. Scholarsh. Humanit.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="conf-paper">
          <page-range>563-570</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Hong Wei</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Dong</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2023.acl-short.49</pub-id>
          <article-title>Going beyond sentence embeddings: A token-level matching algorithm for calculating semantic textual similarity</article-title>
          <source>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, Toronto, Canada</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>50</volume>
          <page-range>5-33</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jurgens</surname>
              <given-names>David</given-names>
            </name>
            <name>
              <surname>Pilehvar</surname>
              <given-names>Mohammad Taher</given-names>
            </name>
            <name>
              <surname>Navigli</surname>
              <given-names>Roberto</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10579-015-9318-3</pub-id>
          <article-title>Cross level semantic similarity: An evaluation framework for universal measures of similarity</article-title>
          <source>Lang. Resour. Eval.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>62972-62983</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Atabuzzaman</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Shajalal</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ahmed</surname>
              <given-names>M. E.</given-names>
            </name>
            <name>
              <surname>Afjal</surname>
              <given-names>M. I.</given-names>
            </name>
            <name>
              <surname>Aono</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3074747</pub-id>
          <article-title>Leveraging grammatical roles for measuring semantic similarity between texts</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1452-1456</page-range>
          <issue>3</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tadvi</surname>
              <given-names>R. C.</given-names>
            </name>
            <name>
              <surname>Chakkarwar</surname>
              <given-names>V. A.</given-names>
            </name>
          </person-group>
          <article-title>Finding similar content posts using semantic textual similarity based on text segmentation through natural language processing</article-title>
          <source>Int. J. Sci. Technol. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>63</volume>
          <page-range>1-10</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Farouk</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.cogsys.2020.04.002</pub-id>
          <article-title>Measuring text similarity based on structure and word embedding</article-title>
          <source>Cogn. Syst. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>58-77</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahmad</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Faisal</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.ijcce.2022.02.001</pub-id>
          <article-title>A novel hybrid methodology for computing semantic similarity between sentences through various word senses</article-title>
          <source>Int. J. Cogn. Comput. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Raju</surname>
              <given-names>T. N.</given-names>
            </name>
            <name>
              <surname>Rahana</surname>
              <given-names>P. A.</given-names>
            </name>
            <name>
              <surname>Moncy</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ajay</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Nambiar</surname>
              <given-names>S. K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/IC3SIS54991.2022.9885721</pub-id>
          <article-title>Sentence similarity - A state of art approaches</article-title>
          <source>2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS), Kochi, India</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>224-230</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kim</surname>
              <given-names>Hwang</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Jihyeon</given-names>
            </name>
            <name>
              <surname>Kwak</surname>
              <given-names>Ho Young</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18517/ijaseit.14.1.19046</pub-id>
          <article-title>Two-stream network for Korean natural language understanding</article-title>
          <source>Int. J. Adv. Sci. Eng. Inf. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mohammed</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Jacksi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zeebaree</surname>
              <given-names>S. R. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICOASE51841.2020.9436540</pub-id>
          <article-title>Glove word embedding and DBSCAN algorithms for semantic document clustering</article-title>
          <source>2020 International Conference on Advanced Science and Engineering (ICOASE), Duhok, Iraq</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="conf-paper">
          <page-range>5959-5969</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Miao Ran</given-names>
            </name>
            <name>
              <surname>Mosbach</surname>
              <given-names>Marius</given-names>
            </name>
            <name>
              <surname>Adelani</surname>
              <given-names>David Ifeoluwa</given-names>
            </name>
            <name>
              <surname>Hedderich</surname>
              <given-names>Michael A.</given-names>
            </name>
            <name>
              <surname>Klakow</surname>
              <given-names>Dietrich</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2022.naacl-main.436</pub-id>
          <article-title>MCSE: Multimodal contrastive learning of sentence embeddings</article-title>
          <source>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Seattle, United States</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="conf-paper">
          <page-range>113-116</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shajalal</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Aono</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICECE.2018.8636779</pub-id>
          <article-title>Sentence-level semantic textual similarity using word-level semantics</article-title>
          <source>2018 10th International Conference on Electrical and Computer Engineering (ICECE), Dhaka, Bangladesh</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>2014</volume>
          <page-range>437162</page-range>
          <year>2014</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>M. C.</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>J. W.</given-names>
            </name>
            <name>
              <surname>Hsieh</surname>
              <given-names>T. C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2014/437162</pub-id>
          <article-title>A grammar-based semantic similarity algorithm for natural language sentences</article-title>
          <source>Sci. World J.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Agarwal</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Seth</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Meleet</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICSES52305.2021.9633911</pub-id>
          <article-title>A new sentence similarity computing technique using order and semantic similarity</article-title>
          <source>2021 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES), Chennai, India</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Modi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Dhanjal</surname>
              <given-names>Y. S.</given-names>
            </name>
            <name>
              <surname>Larhgotra</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICSES60034.2023.10465440</pub-id>
          <article-title>Semantic similarity for text comparison between textual documents or sentences</article-title>
          <source>2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES), Chennai, India</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="conf-paper">
          <page-range>2014-2037</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Muennighoff</surname>
              <given-names>Niklas</given-names>
            </name>
            <name>
              <surname>Tazi</surname>
              <given-names>Nouamane</given-names>
            </name>
            <name>
              <surname>Magne</surname>
              <given-names>Loic</given-names>
            </name>
            <name>
              <surname>Reimers</surname>
              <given-names>Nils</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2023.eacl-main.148</pub-id>
          <article-title>MTEB: Massive text embedding benchmark</article-title>
          <source>Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, Dubrovnik, Croatia</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>2405.10138</volume>
          <page-range>1-10</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Poświata</surname>
              <given-names>Rafał</given-names>
            </name>
            <name>
              <surname>Dadas</surname>
              <given-names>Sławomir</given-names>
            </name>
            <name>
              <surname>Perełkiewicz</surname>
              <given-names>Michał</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2405.10138</pub-id>
          <article-title>PL-MTEB: Polish massive text embedding benchmark</article-title>
          <source>Preprint arXiv</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="conf-paper">
          <page-range>366-371</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Aboutaleb</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fayed</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ismail</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>GabAllah</surname>
              <given-names>N. A.</given-names>
            </name>
            <name>
              <surname>Rafea</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Sakr</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICAICA52286.2021.9498209</pub-id>
          <article-title>BERT BiLSTM-Attention similarity model</article-title>
          <source>2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), Dalian, China</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>47</volume>
          <page-range>187-202</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Valiyev</surname>
              <given-names>Giavid</given-names>
            </name>
            <name>
              <surname>Piraino</surname>
              <given-names>Marcello</given-names>
            </name>
            <name>
              <surname>Kok</surname>
              <given-names>Arvid</given-names>
            </name>
            <name>
              <surname>Street</surname>
              <given-names>Michael</given-names>
            </name>
            <name>
              <surname>Mestric</surname>
              <given-names>Ivana</given-names>
            </name>
            <name>
              <surname>Birger</surname>
              <given-names>Retzius</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.11610/isij.4713</pub-id>
          <article-title>Initial exploitation of natural language processing techniques on NATO strategy and policies</article-title>
          <source>Inf. Secur. Int. J.</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <volume>39</volume>
          <page-range>e12991</page-range>
          <issue>8</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zanon</surname>
              <given-names>A. L.</given-names>
            </name>
            <name>
              <surname>Souza</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Pressato</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Manzato</surname>
              <given-names>M. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/exsy.12991</pub-id>
          <article-title>A user study with aspect-based sentiment analysis for similarity of items in content-based recommendations</article-title>
          <source>Expert Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>1110</volume>
          <page-range>012009</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Murthy</surname>
              <given-names>A. R.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>K. M. Anil</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1757-899X/1110/1/012009</pub-id>
          <article-title>A review of different approaches for detecting emotion from text</article-title>
          <source>IOP Conf. Ser. Mater. Sci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="conf-paper">
          <page-range>255-261</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zad</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Heidari</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>J. H. J.</given-names>
            </name>
            <name>
              <surname>Uzuner</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/aiiot52608.2021.9454192</pub-id>
          <article-title>Emotion detection of textual data: An interdisciplinary survey</article-title>
          <source>IEEE World AI IoT Congress (AIIoT), Seattle, WA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="conf-paper">
          <page-range>372-375</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sosnowski</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Yordanova</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/percomworkshops51409.2021.9431031</pub-id>
          <article-title>Antonym disambiguation for a German-language conversational intelligent tutoring system</article-title>
          <source>2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), Kassel, Germany</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>e19735</page-range>
          <issue>11</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>H. S.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>Y. H.</given-names>
            </name>
            <name>
              <surname>Bian</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>Y. H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2196/19735</pub-id>
          <article-title>Measurement of semantic textual similarity in clinical texts: Comparison of transformer-based models</article-title>
          <source>JMIR Med. Inform.</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="conf-paper">
          <page-range>149-157</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Risch</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Möller</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Gutsch</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Pietsch</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2021.mrqa-1.15</pub-id>
          <article-title>Semantic answer similarity for evaluating question answering models</article-title>
          <source>Proceedings of the 3rd Workshop on Machine Reading for Question Answering, Punta Cana, Dominican Republic</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="conf-paper">
          <page-range>782-796</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Abdalla</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Vishnubhotla</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Mohammad</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/2023.eacl-main.55</pub-id>
          <article-title>What makes sentences semantically related? A textual relatedness dataset and empirical study</article-title>
          <source>Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, Dubrovnik, Croatia</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="conf-paper">
          <page-range>4955-4959</page-range>
          <issue>22</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Polley</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mondal</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mannam</surname>
              <given-names>V. S. K.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Patra</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Nürnberger</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3511808.3557187</pub-id>
          <article-title>X-Vision: Explainable image retrieval by re-ranking in semantic space</article-title>
          <source>CIKM '22: The 31st ACM International Conference on Information and Knowledge Management, Atlanta, GA, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mayil</surname>
              <given-names>V. V.</given-names>
            </name>
            <name>
              <surname>Jeyalakshmi</surname>
              <given-names>T. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/aisp57993.2023.10134937</pub-id>
          <article-title>Pretrained sentence embedding and semantic sentence similarity language model for text classification in NLP</article-title>
          <source>2023 3rd International Conference on Artificial Intelligence and Signal Processing (AISP), Vijayawada, India</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1174-1177</page-range>
          <issue>11</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pai</surname>
              <given-names>Shrinath</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.21275/sr231115202502</pub-id>
          <article-title>Unveiling the power of pre-trained language models in NLP applications</article-title>
          <source>Int. J. Sci. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>647-665</page-range>
          <issue>4</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Majumder</surname>
              <given-names>Goutam</given-names>
            </name>
            <name>
              <surname>Pakray</surname>
              <given-names>Partha</given-names>
            </name>
            <name>
              <surname>Gelbukh</surname>
              <given-names>Alexander</given-names>
            </name>
            <name>
              <surname>Pinto</surname>
              <given-names>David</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.13053/CyS-20-4-2506</pub-id>
          <article-title>Semantic textual similarity methods, tools, and applications: A survey</article-title>
          <source>Comput. y Sist.</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="journal">
          <volume>54</volume>
          <page-range>1-35</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chandrasekaran</surname>
              <given-names>Divya</given-names>
            </name>
            <name>
              <surname>Mago</surname>
              <given-names>Vijay</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3440755</pub-id>
          <article-title>Evolution of semantic similarity-A survey</article-title>
          <source>ACM Comput. Surv.</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>1806-1812</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Samuel</surname>
              <given-names>E. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.55248/gengpi.2023.4149</pub-id>
          <article-title>An assessment on the use of mathematical softwares in teaching and learning of mathematics in colleges of education in South-Eastern Nigeria: A case study of Anambra and Enugu</article-title>
          <source>Int. J. Res. Publ. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="conf-paper">
          <page-range>5482-5487</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Choi</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Joe</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gwon</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/icpr48806.2021.9412102</pub-id>
          <article-title>Evaluation of BERT and ALBERT sentence embedding performance on downstream NLP tasks</article-title>
          <source>2020 25th International Conference on Pattern Recognition (ICPR)</source>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="journal">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>Yian</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Hai</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2004.13947</pub-id>
          <article-title>BURT: BERT-inspired universal representation from twin structure</article-title>
          <source>arXiv preprint arXiv:2004.13947</source>
        </element-citation>
      </ref>
      <ref id="ref_40">
        <label>40.</label>
        <element-citation publication-type="journal">
          <volume>arXiv:2402.17016</volume>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mohr</surname>
              <given-names>Isabelle</given-names>
            </name>
            <name>
              <surname>Krimmel</surname>
              <given-names>Markus</given-names>
            </name>
            <name>
              <surname>Sturua</surname>
              <given-names>Saba</given-names>
            </name>
            <name>
              <surname>Akram</surname>
              <given-names>Mohammad Kalim</given-names>
            </name>
            <name>
              <surname>Koukounas</surname>
              <given-names>Andreas</given-names>
            </name>
            <name>
              <surname>Günther</surname>
              <given-names>Michael</given-names>
            </name>
            <name>
              <surname>Mastrapas</surname>
              <given-names>Georgios</given-names>
            </name>
            <name>
              <surname>Ravishankar</surname>
              <given-names>Vinit</given-names>
            </name>
            <name>
              <surname>Martínez</surname>
              <given-names>Joan Fontanals</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Feng</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Qi</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Ziniu</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Jie</given-names>
            </name>
            <name>
              <surname>Ognawala</surname>
              <given-names>Saahil</given-names>
            </name>
            <name>
              <surname>Guzman</surname>
              <given-names>Susana</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Bo</given-names>
            </name>
            <name>
              <surname>Werk</surname>
              <given-names>Maximilian</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Nan</given-names>
            </name>
            <name>
              <surname>Xiao</surname>
              <given-names>Han</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2402.17016</pub-id>
          <article-title>Multi-task contrastive learning for 8192-token bilingual text embeddings</article-title>
          <source>arXiv Preprint</source>
        </element-citation>
      </ref>
      <ref id="ref_41">
        <label>41.</label>
        <element-citation publication-type="conf-paper">
          <page-range>641-649</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Xiao</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Muennighoff</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Lian</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Nie</surname>
              <given-names>J. Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3626772.3657878</pub-id>
          <article-title>C-Pack: Packed resources for general Chinese embeddings</article-title>
          <source>SIGIR 2024: The 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, Washington DC, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_42">
        <label>42.</label>
        <element-citation publication-type="conf-paper">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Varshney</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sharma</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Javed</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2139/ssrn.3576366</pub-id>
          <article-title>Semantic textual similarity using machine learning and conceptual relatedness</article-title>
          <source>Proceedings of the International Conference on Advances in Electronics, Electrical &amp; Computational Intelligence (ICAEEC) 2019, Jhalwa Prayagraj, India</source>
        </element-citation>
      </ref>
      <ref id="ref_43">
        <label>43.</label>
        <element-citation publication-type="journal">
          <volume>46</volume>
          <issue>3</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>El-Refaiy</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Abas</surname>
              <given-names>A. R.</given-names>
            </name>
            <name>
              <surname>El-Henawy</surname>
              <given-names>I. M.</given-names>
            </name>
          </person-group>
          <article-title>Determining extractive summary for a single document based on collaborative filtering frequency prediction and mean shift clustering</article-title>
          <source>IAENG Int. J. Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_44">
        <label>44.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>2296-2298</page-range>
          <issue>6</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Santhosh Kumar</surname>
              <given-names>C. N.</given-names>
            </name>
            <name>
              <surname>Pavan Kumar</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Reddy</surname>
              <given-names>K. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.35940/ijeat.F8685.088619</pub-id>
          <article-title>Similarity matching of pairs of text using CACT algorithm</article-title>
          <source>Int. J. Eng. Adv. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_45">
        <label>45.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>14-32</page-range>
          <issue>3</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yadav</surname>
              <given-names>C. S.</given-names>
            </name>
            <name>
              <surname>Sharan</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.4018/ijirr.2018070102</pub-id>
          <article-title>Automatic text document summarization using graph based centrality measures on lexical network</article-title>
          <source>Int. J. Inf. Retr. Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_46">
        <label>46.</label>
        <element-citation publication-type="conf-paper">
          <page-range>3982-3992</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Reimers</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Gurevych</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18653/v1/d19-1410</pub-id>
          <article-title>Sentence-BERT: Sentence embeddings using Siamese BERT-networks</article-title>
          <source>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Hong Kong, China</source>
        </element-citation>
      </ref>
      <ref id="ref_47">
        <label>47.</label>
        <element-citation publication-type="journal">
          <volume>52</volume>
          <page-range>273-292</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kadhim</surname>
              <given-names>A. I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10462-018-09677-1</pub-id>
          <article-title>Survey on supervised machine learning techniques for automatic text classification</article-title>
          <source>Artif. Intell. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_48">
        <label>48.</label>
        <element-citation publication-type="journal">
          <volume>258</volume>
          <page-range>111817</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fan</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Xiao</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Z. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.enbuild.2021.111817</pub-id>
          <article-title>Distance measures in building informatics: An in-depth assessment through typical tasks in building energy management</article-title>
          <source>Energy Build.</source>
        </element-citation>
      </ref>
      <ref id="ref_49">
        <label>49.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>74-81</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sakur</surname>
              <given-names>Stendy Budi Hartono</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.55606/jitek.v3i1.1394</pub-id>
          <article-title>Perbandingan distance measures pada K-means cluster dan Topsis dengan korelasi Pearson dan Spearman</article-title>
          <source>J. Inform. Dan Tekonologi Komput.</source>
        </element-citation>
      </ref>
      <ref id="ref_50">
        <label>50.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-5</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Verma</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Muralikrishna</surname>
              <given-names>S.N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/conecct50063.2020.9198445</pub-id>
          <article-title>Semantic similarity between short paragraphs using deep learning</article-title>
          <source>2020 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT), Bangalore, India</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>