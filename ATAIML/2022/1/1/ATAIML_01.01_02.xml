<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="review-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-565kE9inYy-_PkXjbDyCaJxvXJOglpm_</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml010102</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A Survey on Multimedia Ontologies for a Semantic Annotation of Cinematographic Resources for the Web of Data</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1,2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1652-5410</contrib-id>
          <name>
            <surname>Amaria</surname>
            <given-names>Samdalle</given-names>
          </name>
          <email>francis.yongwa-dtissibe@univ-maroua.cm</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2,3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8414-214X</contrib-id>
          <name>
            <surname>Guidedi</surname>
            <given-names>Kaladzavi</given-names>
          </name>
          <email>kaladzavi@univ-maroua.cm</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1,2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1206-1789</contrib-id>
          <name>
            <surname>Lazarre</surname>
            <given-names>Warda</given-names>
          </name>
          <email>oumarou.hayatou@univ-maroua.cm</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_4">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1554-1187</contrib-id>
          <name>
            <surname>Kolyang</surname>
            <given-names/>
          </name>
          <email>kolyang@univ-maroua.cm</email>
        </contrib>
        <aff id="aff_1">Faculty of Science, University of Maroua, P.O. Box 46 Maroua, Cameroon</aff>
        <aff id="aff_2">Laboratoire de Recherche en Informatique, University of Maroua, P.O. Box 46 Maroua, Cameroon</aff>
        <aff id="aff_3">National Advanced School of Engineering of Maroua, University of Maroua, P.O. Box 46 Maroua, Cameroon</aff>
        <aff id="aff_4">Laboratoire de Recherche en Informatique (LaRI), The University of Maroua, P.O. Box: 46 Maroua, Cameroon</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>19</day>
        <month>11</month>
        <year>2022</year>
      </pub-date>
      <volume>1</volume>
      <issue>1</issue>
      <fpage>2</fpage>
      <lpage>10</lpage>
      <page-range>2-10</page-range>
      <history>
        <date date-type="received">
          <day>29</day>
          <month>06</month>
          <year>2022</year>
        </date>
        <date date-type="accepted">
          <day>10</day>
          <month>09</month>
          <year>2022</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2022 by the author(s)</copyright-statement>
        <copyright-year>2022</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The Semantic Web provides approaches and tools that allow for the processing and analysis of online content, including multimedia resources. Multimedia resources like videos, audios, and photos are increasingly common in contemporary Web content. Cinematographic works (also known as film contents) stand out among these resources as one of the most recent attractions on the Internet. An important tool employed recently in the semantic indexation of digital resources and film content is ontological annotation. This paper studies the current multimedia ontologies related to the film contents on the web. The relevant indicators were discussed comparatively, and some open issues were reviewed in details. In this way, the authors managed to integrate the metadata related to online films practically into the web of data.</p></abstract>
      <kwd-group>
        <kwd>Cinematographic works</kwd>
        <kwd>Knowledge engineering</kwd>
        <kwd>Multimedia ontologies</kwd>
        <kwd>Semantic web</kwd>
        <kwd>Web of data</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="4"/>
        <fig-count count="4"/>
        <table-count count="1"/>
        <ref-count count="39"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p style="text-indent: 10.1pt;">Regarding various spheres of interest and values, the Web provides a variety of information sources. The quantity and attractiveness of resources available on the Web have grown over time [<xref ref-type="bibr" rid="ref_1">1</xref>]. The techniques provided by the Semantic Web enable reasoning over these resources. Multimedia resources including videos, audios, films, and images are increasingly common in contemporary Web contents. A prominent indicator of the rise of such resources in daily activities of the current society is the deluge of multimedia resources on the Internet and in some offline platforms. Both experts and amateurs create and consume these multimedia contents.</p><p style="text-indent: 10.1pt;">Cinematographic works are a subcategory of multimedia resources that include all on-screen visual components, such as framing, composition, camera angles, film selection, depth of focus, color, exposure, and filtering. A majority of film creators and viewers use the Internet to learn more about cinematic topics, and nearly 24% of films are web-driven [<xref ref-type="bibr" rid="ref_1">1</xref>]. Access to such pertinent content in a timely manner is therefore a major challenge [<xref ref-type="bibr" rid="ref_2">2</xref>].</p><p style="text-indent: 10.1pt;">For data access and retrieval, semantic indexation of video content has evolved to be a critical issue. Contrary to textual assets, media search relies on methods that either have onerous specifications for feature comparison (such as color or texture), or on associated descriptors, which involve choosing elements of a frame or video and translating them into text or concepts from a predefined vocabulary [<xref ref-type="bibr" rid="ref_3">3</xref>]. However, a sizable number of concepts in a taxonomical framework, concepts, roles, and rules are also required for the content representation of Multimedia Ontologies [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>]. </p><p style="text-indent: 10.1pt;">There are various aspects of sociocultural concepts in the world of cinema. Examples of concepts that can be utilized for indexing such resources include actor names, generics, and places used in films. As in “Jet Lee” (Asian), “Siriki” or “Souke” (African), “Jack Bauer,” “Mr. Bean,” etc., an actor's name has a social identity (country or town). A generic in a film is typically a familiar melody fragment; other generics include the channels on which films are shown, the audiences they are aimed at, etc. The indexation system of the web of data is improved by the modeling of such ideas, e.g., removing a list of films shown at a particular tourist destination or at a popular location. From this perspective, it is necessary to have a shared vocabulary among ontologies addressing cinematographic content and associated semantic structures. The theories of cultural heritage modeling can be applied in this direction.</p><p style="text-indent: 10.1pt;">In this research, the authors examined multimedia ontologies that are currently in use to describe cinematographic works. The remainder of this article is structured as follows: Section 2 introduces the semantic web and multimedia resources; Section 3 examines existing multimedia ontologies in relation to cinematographic works and film production; Section 4 provides a brief discussion on these multimedia ontologies and their shortcomings, with conclusive open perspectives.</p>
    </sec>
    <sec sec-type="">
      <title>2. The semantic web and multimedia resources</title>
      <p>Data access, retrieval, and actual application now depend heavily on semantic indexation of images and videos [<xref ref-type="bibr" rid="ref_6">6</xref>]. This section examines the evolution of the Web and how it has affected knowledge representation in general for multimedia resources and specifically for cinematographic resources [<xref ref-type="bibr" rid="ref_7">7</xref>].</p>
      
        <sec>
          
            <title>2.1. Multimedia metadata</title>
          
          <p>Multimedia data has a very complex formalism as it contains a variety of things, including videos, texts, sounds, photos, 3D models, and more [<xref ref-type="bibr" rid="ref_8">8</xref>]. There are numerous multimedia applications in the fields of distance learning, digital libraries, health (telemedicine, medical image databases), entertainment (databases of on-demand video, interactive TV), business (video conferencing, e-commerce), and cultural heritage. The MPEG-7 format has a wide range of uses, including home entertainment systems, broadcast media choices, digital libraries for multimedia, and multimedia editing. This format makes it possible for users to access enormous multimedia archives and multimedia catalogues in order to find content that can be purchased (<xref ref-type="table" rid="table_1">Table 1</xref>). The MPEG-7 standard is compatible with others that have shown success and acceptance in both the traditional media and new media industries. The semantic web has improved the understanding of knowledge representation. It enables computers to comprehend web material and provide a clear meaning in relation to the desired application [<xref ref-type="bibr" rid="ref_9">9</xref>]. By providing high quality video metadata, the semantic web can be searched for information more effectively.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Cinematographic resources and knowledge engineering</title>
          
          <p>All on-screen visual components are included in cinematographic works. An initial plot, idea, or commission is followed by screenplay, casting, shooting, recording sound during preproduction, editing, and screening the finished product in front of an audience, which may lead to a film release and exhibition. The cinematographic production is both an aesthetic and commercial endeavor. From its conception until its consumption, it follows a production chain. Along with the publishing, music, fashion, design, and other cultural and creative sectors, the cinema business fits more widely into these categories. In terms of operation and financial success, the cultural and creative industries have changed significantly during the previous fifteen years [<xref ref-type="bibr" rid="ref_10">10</xref>]. This is a result of technological development, as well as changes related to dissemination and consumption behaviors, which are also related to technological improvements. Around the world, many technologies and cinematic techniques are used during the making of films in a variety of economic, social, and political circumstances. Tcheuyap [<xref ref-type="bibr" rid="ref_11">11</xref>] presented the two key themes dictating the cultural identity of African Film products, African Films and Films from Africa.</p><p>In general, the film industry is strongly anchored in the process of cultural globalization. The American and French domination in the production and distribution sector is a reality and has an influence on other cultures around the world. A recent study carried by the CNC [<xref ref-type="bibr" rid="ref_12">12</xref>] shows that, there is a considerable qualitative and quantitative increase in film production in almost all the contexts (see <xref ref-type="fig" rid="fig_1">Figure 1</xref>), revealing more of cultural identifies. An information vectors prescriptive analysis of movie production, enlightens more about the fact that 24% of movie viewers are influenced by the content available on the web (see <xref ref-type="fig" rid="fig_2">Figure 2</xref>). We believe that a more specific annotation process (considering infrastructure, language, activities, communities, etc.) may be a key factor of the integration of multimedia content on the web of data.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Evolution of the number of films released [<xref ref-type="bibr" rid="ref_11">11</xref>]</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_bXPthDUQLEbV2OI-.png"/>
            </fig>
          
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Information prescriber vectors [<xref ref-type="bibr" rid="ref_12">12</xref>]</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_2zLYncIk_GbuWAgl.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Overview of multimedia ontologies</title>
      <p style="text-indent: 10.2pt;">Numerous studies on the annotation, indexation, and retrieval of multimedia information on the Web have produced positive findings recently [<xref ref-type="bibr" rid="ref_13">13</xref>]. The majority of current methods rely on the semantic web to allow computers to interpret and comprehend metadata effectively. We are able to find some really intriguing multimedia ontologies that are provided in the following after searching via web repositories and available literature.</p><p style="text-indent: 10.2pt;">NINSUNA Ontology, which Deursen et al. [<xref ref-type="bibr" rid="ref_14">14</xref>] introduced, supports common media formats on the web and acts a metadata-driven system for media modification and delivery (MP4, WebM, Ogg, MPEG-2 TS). It is made up of classes and properties that can be used to retrieve information about media fragments and create a multimedia description apart from the metadata of the original multimedia format. Despite being primarily concerned with format description and redefinition, it offers less insight into the media's substance.</p><p style="text-indent: 10.2pt;">Multimedia ontology manage (MOM), which Bertini et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] modeled as a complete system, enables the creation of multimedia ontologies, supports automatic annotation and the production of extended text (and audio) commentaries of video sequences, and realizes complex queries by reasoning on the ontology [<xref ref-type="bibr" rid="ref_16">16</xref>]. The majority of the time, it is used to automatically caption video scenes and occasionally to create sports commentary.</p><p style="text-indent: 10.2pt;">For effective semantic annotation, Thomas and Syama [<xref ref-type="bibr" rid="ref_17">17</xref>] suggested an ontology-based machine learning system that employs SIFT and HoG characteristics of images from the selected frames and trains them with SVM classifiers.</p><p style="text-indent: 10.2pt;">For the study of China Central Television (CCTV) data, CCTV Ontology was created based on the standard event ontology paradigm for multimedia applications [<xref ref-type="bibr" rid="ref_18">18</xref>]. CCTV Ontology aims to exploit semantics for the identification of potential criminal activity and its perpetrators in a video fragment. It formalizes the fundamental ideas, characteristics, and connections between ideas in the forensic domain [<xref ref-type="bibr" rid="ref_19">19</xref>]. It can be applied to security concerns like searching for information (person, face, and car detection, as well as throwing, kicking, and running actions) in videos of riots and violent conflicts.</p><p style="text-indent: 10.2pt;">An MPEG-7-based multimedia ontology called COMM is comprised of multimedia patterns based on deep ontological foundations, which are built on the fundamental ontology DOLCE and reliable ontology engineering principles [<xref ref-type="bibr" rid="ref_20">20</xref>].</p><p style="text-indent: 10.2pt;">Another Multimedia ontology proposed by Saathoff and Scherp [<xref ref-type="bibr" rid="ref_21">21</xref>] and Gangemi and Presutti [<xref ref-type="bibr" rid="ref_22">22</xref>] is Multimedia Metadata Ontology (M3O). Because of its extensive axiomatization, it is well known as a pattern-oriented ontology design based on the fundamental ontology DOLCE [<xref ref-type="bibr" rid="ref_23">23</xref>]. It identifies five fundamental patterns necessary to convey metadata for multimedia content using Description Logics for formalism. It supports both the annotation with low-level features taken from the multimedia content as well as the representation of high-level semantic annotation with background information. M3O has been included into the Semantic MM4U framework [<xref ref-type="bibr" rid="ref_24">24</xref>] for experimental purposes, and it has assisted in enhancing the Yahoo and Google search engines. It achieved great success in a number of areas, including customized sports news, context-aware travel guides, and the creation and semantic augmentation of individual photo albums.</p><p style="text-indent: 10.2pt;">A full OWL defined ontology framework called Dynamic Pictorially Enriched Ontologies (DPEO) was created by Ballan et al. [<xref ref-type="bibr" rid="ref_25">25</xref>] for the semantic annotation of soccer video clips. To increase the effectiveness of automatic semantic annotation, it employs the Semantic Web Rule Language (SWRL) to reason on both concepts and their instance values.</p><p style="text-indent: 10.2pt;">To construct a wider collection of semantic ideas for reasoning about multimedia information, Naphade et al. [<xref ref-type="bibr" rid="ref_26">26</xref>] presented Large-Scale Concept Ontology for Multimedia. It has over 834 visual concepts and is specifically made to present news footage.</p><p style="text-indent: 10.2pt;">Media resource 1.0, a basic vocabulary ontology created by the W3C Media Annotations Working Group, is presented by Lee et al. [<xref ref-type="bibr" rid="ref_27">27</xref>]. It seeks to provide an interoperable set of reusable information by standardizing the mapping of popular media formats. It supports six different multimedia file types and roughly 18 different multimedia metadata formats, including Dublin Core, MPEG-7, IPTC, and OGG (3GP, FLV, QuickTime, MP4, OGG, WebM).</p><p style="text-indent: 10.2pt;">In order to simplify the process of expressive video annotation, Valkanas et al. [<xref ref-type="bibr" rid="ref_28">28</xref>] created POLYSEMA, a tool that combines semantic web ontologies and MPEG-7 metadata. The gaming industry frequently takes use of this ontology.</p><p style="text-indent: 10.2pt;">The ReDeFer project’s Rhizomik ontology [<xref ref-type="bibr" rid="ref_29">29</xref>] was created using higher-level multimedia characteristics for the music concepts. This ontology resulted from the conversion of the XML Schema from the MPEG-7 standard into an OWL ontology in accordance with the guidelines provided.</p><p style="text-indent: 10.2pt;">Kanzaki is an OWL DL ontology that, by itself, provides the vocabulary used to identify musical works, events, instruments, and performers as well as the semantic relationships between them [<xref ref-type="bibr" rid="ref_30">30</xref>]. The FOAF ontology is specialized in its ideas.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>Classification of some multimedia ontologies</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>No</p></td><td colspan="1" rowspan="1"><p>Ontology</p></td><td colspan="1" rowspan="1"><p>Type of features</p><p>considered</p></td><td colspan="1" rowspan="1"><p>Targeted</p><p>application</p></td><td colspan="1" rowspan="1"><p>Semantic</p><p>level</p></td><td colspan="1" rowspan="1"><p>Interoperability</p></td><td colspan="1" rowspan="1"><p>Indices value [<xref ref-type="bibr" rid="ref_31">31</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>NinSuna Ontology [<xref ref-type="bibr" rid="ref_14">14</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Metadata driven media delivery</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>YES</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>Ontology Based Video Annotation and Retrieval System [<xref ref-type="bibr" rid="ref_17">17</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF</p></td><td colspan="1" rowspan="1"><p>Transportation systems</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>CCTV Ontology [<xref ref-type="bibr" rid="ref_19">19</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>TV and camera monitoring</p></td><td colspan="1" rowspan="1"><p>Geometric</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>MOM Ontology [<xref ref-type="bibr" rid="ref_15">15</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Games and sports tools</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>COMM [<xref ref-type="bibr" rid="ref_2">2</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF &amp;amp;amp; HLF</p></td><td colspan="1" rowspan="1"><p>Audi-visual object retrieval systems</p></td><td colspan="1" rowspan="1"><p>Geo-Spatial</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>1.19</p></td></tr><tr><td colspan="1" rowspan="1"><p>6</p></td><td colspan="1" rowspan="1"><p>M3O [<xref ref-type="bibr" rid="ref_21">21</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF &amp;amp;amp; HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>YES</p></td><td colspan="1" rowspan="1"><p>1.23</p></td></tr><tr><td colspan="1" rowspan="1"><p>7</p></td><td colspan="1" rowspan="1"><p>Dynamic Pictorial Enriched Ontology [<xref ref-type="bibr" rid="ref_25">25</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF</p></td><td colspan="1" rowspan="1"><p>Video soccer systems</p></td><td colspan="1" rowspan="1"><p>Geo-Spatial</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>8</p></td><td colspan="1" rowspan="1"><p>LSCOM [<xref ref-type="bibr" rid="ref_22">22</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF &amp;amp;amp; HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>9</p></td><td colspan="1" rowspan="1"><p>Media Resource Ontology [<xref ref-type="bibr" rid="ref_17">17</xref>]</p></td><td colspan="1" rowspan="1"><p>LLF &amp;amp;amp; HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>YES</p></td><td colspan="1" rowspan="1"><p>1.56</p></td></tr><tr><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>POLISEMA MPEG-7 Video Annotator [<xref ref-type="bibr" rid="ref_28">28</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Annotation tools</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>11</p></td><td colspan="1" rowspan="1"><p>MPEG-7 Rhizomik [<xref ref-type="bibr" rid="ref_29">29</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>YES, XML-OWL</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>Kanzaki Ontology [<xref ref-type="bibr" rid="ref_15">15</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>VidOnto [<xref ref-type="bibr" rid="ref_31">31</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>Large Annotation Ontology [<xref ref-type="bibr" rid="ref_32">32</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Annotation tools</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p>X</p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>Movie Ontology</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>Cinema Ontology [<xref ref-type="bibr" rid="ref_33">33</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Annotation tools</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p> </p></td><td colspan="1" rowspan="1"><p>X</p></td></tr><tr><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>M3 Ontology [<xref ref-type="bibr" rid="ref_34">34</xref>]</p></td><td colspan="1" rowspan="1"><p>HLF</p></td><td colspan="1" rowspan="1"><p>Web search</p></td><td colspan="1" rowspan="1"><p>Content-Based Semantics</p></td><td colspan="1" rowspan="1"><p> </p></td><td colspan="1" rowspan="1"><p>0.95</p></td></tr></tbody></table>
        </table-wrap>
      
      <p style="text-indent: 10.2pt;">Additionally, we came across VidOnto [<xref ref-type="bibr" rid="ref_31">31</xref>], an ontology that can be used to comprehend video content and enhance the quality of structured annotations of ideas and predicates, but it is limited in its ability to convey the semantic knowledge of the video content. It is appropriate for reasoning-based high-level scene interpretation of videos and for querying video descriptions. Although the rationale is quite intriguing, it does not define the socio-culturally relevant reasoning variables and pays little attention to audiovisual events like awards. This ontology does not have a strong representation of concepts connected to the cultural identity of the video clip.</p><p style="text-indent: 10.2pt;">The large annotation ontology that defines film semantic annotation, a lexicon, and ideas was proposed by Li et al. [<xref ref-type="bibr" rid="ref_32">32</xref>] based on a film video benchmark data set. This model is capable of annotating films and video scenes, according to a HowNet experiment.</p><p style="text-indent: 10.2pt;">The Department of Informatics at the University of Zurich developed the Film Ontology in 2009, an OWL-specified ontology that Amancio Bouza started. The ontology attempts to provide controlled vocabulary to semantically characterize film-related ideas. This ontology includes a hierarchy of ideas that are specifically related to the cinematic realm. Looking at this ontology from several angles, it appears to be among the finest for the category of cinematic works. Although context-aware ideas have the potential to enrich the semantic level of the concepts.</p><p style="text-indent: 10.2pt;">Teyeb et al. [<xref ref-type="bibr" rid="ref_33">33</xref>] presented a semantic annotation of French film events and imagery. The results of this experiment, which was run on ten documents that contained images of film works, were highly promising. This ontology's weakness stems from the absence of a clear connection between it and concepts from the outside world.</p><p style="text-indent: 10.2pt;">A well-known project called M3 Multimedia was started by the Spanish research team Buscamedia [<xref ref-type="bibr" rid="ref_34">34</xref>]. It intends to develop a semantic search engine for media resources, specifically for tools for media production and delivery that are audiovisual. A wide range of comprehensive multimedia ideas and languages are included in this ontology.</p><p style="text-indent: 10.2pt;">We are able to create comparative research that identified five criteria for evaluating these multimedia ontologies that are related to cinema thanks to some elements of the NEON approach [<xref ref-type="bibr" rid="ref_35">35</xref>] and Lemos et al.'s analysis on multimedia annotation on the Web of Data. Therefore, we took into account the following factors: the type of features used in the annotation process, such as High-Level Features (HLF) or Low-Level Features (LLF), the target application field, the semantic level, the degree of interoperability with other reputable annotators, and the index value for consistency [<xref ref-type="bibr" rid="ref_30">30</xref>] (see <xref ref-type="table" rid="table_1">Table 1</xref>).</p>
    </sec>
    <sec sec-type="">
      <title>4. Semantic annotation of cinematographic works</title>
      <p style="text-indent: 10.2pt;">There are some really fascinating ontologies in the multimedia field. To disclose the evolutionary trend from 2001 to 2019, Suarez-Figueroa et al. [<xref ref-type="bibr" rid="ref_30">30</xref>] proposed to classify multimedia ontologies into four subclasses: Images and shape, object, visual objects, and music ontologies (<xref ref-type="fig" rid="fig_3">Figure 3</xref>). We observed that the majority of these studies focused more on multimedia ontologies related to musical arts and object annotation and less on cinematographic works.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Evolution trends of multimedia ontologies</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_AWOdns7Y6_4ZPH-U.png"/>
        </fig>
      
      <p>The accessibility of these kinds of materials on the Semantic Web might yet be improved, according to organizations representing the film industry, by many additional concepts that allow for more information to be available about a cinematographic production. As seen, the annotation already demonstrates that the majority of the suggested multimedia's ontologies consider the semantic background while constructing knowledge [<xref ref-type="bibr" rid="ref_36">36</xref>]. Thus, researching the sociocultural aspects of films seems to hold promise for the web of Data. The notions and characteristics unique to cinematographic works started to emerge soon afterwards (<xref ref-type="fig" rid="fig_3">Figure 3</xref>). The absence of widely used vocabularies that have been used for multimedia metadata annotation presents certain difficulties when dealing with multimedia annotation on the Semantic Web; as a result, some features of distinct vocabularies may have the same name but different meanings. The IBM 2002 TREC team considered a semi-automatic method for building multimedia ontologies from multimedia collections in these suggested ontologies [<xref ref-type="bibr" rid="ref_37">37</xref>], which combined tools for content-based retrieval and tools for building ontologies from text. The results of an application to a sizable collection of educational films from the 1940s to the 1960s are intriguing, but the semantic description of films and films is still very poor. The Multimedia Ontologies discussed in Section 3 above do not include many aspects of film production, such as the geospatial location of the film or the various roles played by each person during the production process. A significant study conducted [<xref ref-type="bibr" rid="ref_38">38</xref>] demonstrates how linguistic diversity is increasingly influencing cinematic productions. In the case of Morocco, which has 79% of its films in Arabic, 17% in French, and 4% in English, the UNESCO Statistic branch [<xref ref-type="bibr" rid="ref_39">39</xref>] demonstrates that over 50% of films made have a main language. On the other hand, there is no dominant language in Indian cinema. India has a more diverse film industry thanks to the 16.1% of their films that are produced in Hindi, 15.3% in Telougou, 14.7% in Tampul, 11% in Kannada, and 10% in Bengale. The research on multimedia ontologies does not cover all of these limitations.</p><p>The Semantic Web could provide more functionality for the cinematographic domain when it comes to accessing or retrieving information. The target audience, the language used in the film, the events or awards to which it has already been nominated, the context of the film's production (which varies from continent to continent), the relationship between actor names and socio-cultural origins, and subtitling, for example, can further enrich the semantic annotation of film products (see use-case illustration in <xref ref-type="fig" rid="fig_4">Figure 4</xref>). For instance, names (such as Jet Li, Siriki, and Arnold Schwarzenegger) or locations (such as the Tour Eiffel or landmarks) that may disclose an actor's ancestry are not yet taken into account in ontological annotations on films.</p>
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>A use-case of a film annotation model considering socio-cultural concepts</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_P5JRvWD6Di9kPWky.png"/>
        </fig>
      
    </sec>
    <sec sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>Multimedia annotation has gained importance since it attempts to give the contents of films various semantic and visual aspects. It is very challenging to analyze and retrieve content-based cinematographic works, drawing on the semantics attached to the backbone multimedia ontology, as it needs to consider the semantics of utilized vocabularies a particular category of multimedia resources.</p><p>In this paper, we attempted to examine the semantic properties that current multimedia ontologies took into consideration. A comparative study was carried out with the aim of evaluating the vocabulary taken into account in relation to the annotation of filmmaking or cinematographic works. Films frequently show a degree of cultural identity, which may also be annotated. Since these film products are connected to the actual world, and because previous studies presented films in a content-based perspective, another intriguing objective may be to depict the cultural semantics of film notions. By suggesting vocabulary to expand the Linked Open Vocabularies and hence improve information retrieval of this content on the Web of Data, we could come closer to capturing these socio-cultural truths.</p><p>Building content-based semantics to address socio-cultural knowledge found in film products and proposing vocabulary to address them on the LOV may be of interest. Another intriguing angle is to model film theory in order to illustrate the process of film making.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      <p>Conceptualization, Samdalle. Amaria. and Kaladzavi. Guidedi.; methodology, Samdalle. Amaria.; validation, Kaladzavi. Guidedi. and Kolyang.; formal analysis, Kaladzavi Guidedi; investigation, Samdalle. Amaria.; resources, Warda Lazarre.; writing—original draft preparation, Samdalle Amaria.; writing—review and editing, Kaladzavi Guidedi., Kolyang.; visualization, Kolyang.; supervision, Kolyang. All authors have read and agreed to the published version of the manuscript.</p>
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p style="text-indent: 10.2pt;"><span style="color: black; background-color: white;">The data graphs supporting our research results may be released upon application to CNC – Vertigo, enquête Cinexpert / DEPS, Ministère de la Culture, 2019.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hitzler</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>A review of the semantic web field</article-title>
          <source>Commun. ACM</source>
          <year>2021</year>
          <volume>64</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">https://doi.org/10.1145/3397512</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Arndt</surname>
              <given-names/>
            </name>
            <name>
              <surname>Troncy</surname>
              <given-names/>
            </name>
            <name>
              <surname>Staab</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hardman</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>COMM: A core ontology for multimedia annotation</article-title>
          <source>Handbook on Ontologies, Heidelberg</source>
          <publisher-loc>Berlin</publisher-loc>
          <publisher-name>Springer</publisher-name>
          <year>2009</year>
          <page-range>403-421</page-range>
          <fpage>403</fpage>
          <lpage>421</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.1007/978-3-540-92673-3_18</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Steiff</surname>
              <given-names/>
            </name>
          </person-group>
          <source>The Complete Idiot’s Guide to Independent Filmmaking</source>
          <publisher-name>Alpha Books</publisher-name>
          <year>2005</year>
          <page-range>26-28</page-range>
          <fpage>26</fpage>
          <lpage>28</lpage>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Sikos</surname>
              <given-names/>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Kwaśnicka</surname>
              <given-names/>
            </name>
            <name>
              <surname>Jain</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Ontology-based structured video annotation for content-based video retrieval via spatiotemporal reasoning</article-title>
          <source>Bridging the Semantic Gap in Image and Video Analysis, Intelligent Systems Reference Library</source>
          <publisher-loc>Berlin</publisher-loc>
          <publisher-name>Springer</publisher-name>
          <year>2018</year>
          <volume>145</volume>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/978-3-319-73891-8_6</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>D'Odorico</surname>
              <given-names/>
            </name>
            <name>
              <surname>Bennett</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Automated reasoning on vague concepts using formal ontologies, with an application to event detection on video data</article-title>
          <publisher-name>Whiterose</publisher-name>
          <conf-name>Commonsense 2013, 11th International Symposium on Logical Formalizations of Commonsense Reasoning</conf-name>
          <conf-acronym>ISLFCR 2013</conf-acronym>
          <conf-loc>Aya Napa, Cyprus</conf-loc>
          <conf-date>May 27-29, 2013</conf-date>
          <year>2013</year>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gandon</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>A survey of the first 20 years of research on semantic web and linked data</article-title>
          <source>Ingenierie des Systemes Information</source>
          <year>2018</year>
          <volume>2018</volume>
          <page-range>11-56</page-range>
          <fpage>11</fpage>
          <lpage>56</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.3166/ISI.23.3-4.11-56</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sjekavica</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gledec</surname>
              <given-names/>
            </name>
            <name>
              <surname>Horvat</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Multimedia annotation using semantic web technologies</article-title>
          <source>Recent Advances in Information Science</source>
          <year>2013</year>
          <volume>2013</volume>
          <page-range>228-233</page-range>
          <fpage>228</fpage>
          <lpage>233</lpage>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jaouachi</surname>
              <given-names/>
            </name>
            <name>
              <surname>Khemakhem</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hernandez</surname>
              <given-names/>
            </name>
            <name>
              <surname>Haemmere</surname>
              <given-names/>
            </name>
            <name>
              <surname>Jemaa</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Vers une annotation sémantique des images web fonde sur des patrons RDF</article-title>
          <source>CORIA 2015 Comput. Sci.</source>
          <year>2015</year>
          <volume>2015</volume>
          <pub-id pub-id-type="doi">https://doi.org/10.24348/coria.2015.66</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lemos</surname>
              <given-names/>
            </name>
            <name>
              <surname>Souza</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Knowledge organization systems for the representation of multimedia resources on the Web: A comparative analysis</article-title>
          <source>Knowl. Organ.</source>
          <year>2020</year>
          <volume>47</volume>
          <issue>4</issue>
          <page-range>300-319</page-range>
          <fpage>300</fpage>
          <lpage>319</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.5771/0943-7444-2020-4-300</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="webpage">
          <article-title>Décret relatif au soutien au cinéma et à la création audiovisuelle</article-title>
          <source>Openjustice</source>
          <year>2022</year>
          <uri>https://etaamb.openjustice.be/fr/decret-du-10-novembre-2011_n2011029587</uri>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tcheuyap</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Definitions, Identity and Theoretical Considerations</article-title>
          <source>Crit. Interv.</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <page-range>10-26</page-range>
          <fpage>10</fpage>
          <lpage>26</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1080/19301944.2011.10781397</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="webpage">
          <article-title>Ministère de la Culture et de la Communication</article-title>
          <source>Ministère de la Culture</source>
          <year>2017</year>
          <uri>https://www.culture.gouv.fr/en/Thematiques/Etudes-et-statistiques/Rencontres/Cafe-du-Deps-3-Chiffres-cles-de-la-culture-et-de-la-communication-2017</uri>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="webpage">
          <article-title>Ministère de la Culture et de la Communication</article-title>
          <source>NCDEPS</source>
          <year>2018</year>
          <uri>http://www.cnc-aff.fr/home.aspx</uri>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Deursen</surname>
              <given-names/>
            </name>
            <name>
              <surname>Lancker</surname>
              <given-names/>
            </name>
            <name>
              <surname>Neve</surname>
              <given-names/>
            </name>
            <name>
              <surname>Paridaens</surname>
              <given-names/>
            </name>
            <name>
              <surname>Mannens</surname>
              <given-names/>
            </name>
            <name>
              <surname>Walle</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>NinSuna: A fully integrated platform for format-independent multimedia content adaptation and delivery based on semantic web technologies</article-title>
          <source>Multimed. Tools Appl.</source>
          <year>2010</year>
          <volume>46</volume>
          <issue>3</issue>
          <page-range>371-398</page-range>
          <fpage>371</fpage>
          <lpage>398</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.1007/s11042-009-0354-0</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Bertini</surname>
              <given-names/>
            </name>
            <name>
              <surname>Del Bimbo</surname>
              <given-names/>
            </name>
            <name>
              <surname>Nunziati</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Automatic detection of player's identity in soccer videos using faces and text cues</article-title>
          <publisher-name>Association for Computing Machinery</publisher-name>
          <conf-name>proceedings of the 14th ACM international conference on multimedia Santa Barbara, CA</conf-name>
          <conf-loc>USA</conf-loc>
          <conf-date>October 23-27, 2006</conf-date>
          <year>2006</year>
          <page-range>663-666</page-range>
          <fpage>663</fpage>
          <lpage>666</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1145/1180639.1180778.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Garcia</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gil</surname>
              <given-names/>
            </name>
            <name>
              <surname>Delgado</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>A web ontologies framework for digital rights management</article-title>
          <source>J. Artif. Intell. Law</source>
          <year>2007</year>
          <volume>2007</volume>
          <page-range>137-154</page-range>
          <fpage>137</fpage>
          <lpage>154</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s10506-007-9032-6</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thomas</surname>
              <given-names/>
            </name>
            <name>
              <surname>Syama</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Ontology based video annotation and retrieval system</article-title>
          <source>Int. J. Emerg. Technol. Adv. Eng.</source>
          <year>2014</year>
          <volume>4</volume>
          <issue>7</issue>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Westermann</surname>
              <given-names/>
            </name>
            <name>
              <surname>Jain</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Toward a common event model for multimedia applications</article-title>
          <source>IEEE Multimed.</source>
          <year>2007</year>
          <volume>14</volume>
          <issue>1</issue>
          <page-range>19-29</page-range>
          <fpage>19</fpage>
          <lpage>29</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1109/MMUL.2007.23</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Kahar</surname>
              <given-names/>
            </name>
            <name>
              <surname>Izquierdo</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Ontology-based analysis of CCTV data</article-title>
          <publisher-name>IET</publisher-name>
          <conf-name>7th Latin American Conference on Networked and Electronic Media</conf-name>
          <conf-acronym>LACNEM 2017</conf-acronym>
          <conf-loc>Valparaiso, Chile</conf-loc>
          <conf-date>November 6-7, 2017</conf-date>
          <year>2017</year>
          <pub-id pub-id-type="doi">https://doi.org/10.1049/ic.2017.0037.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oberle</surname>
              <given-names/>
            </name>
            <name>
              <surname>Lamparter</surname>
              <given-names/>
            </name>
            <name>
              <surname>Grimm</surname>
              <given-names/>
            </name>
            <name>
              <surname>Vrandecic</surname>
              <given-names/>
            </name>
            <name>
              <surname>Staab</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gangemi</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Towards ontologies for formalizing modularization and communication in large software systems</article-title>
          <source>J. Appl. Ontol.</source>
          <year>2006</year>
          <volume>1</volume>
          <issue>2</issue>
          <page-range>163-202</page-range>
          <fpage>163</fpage>
          <lpage>202</lpage>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Saathoff</surname>
              <given-names/>
            </name>
            <name>
              <surname>Scherp</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Unlocking the semantics of multimedia presentations in the web with the multimedia metadata ontology</article-title>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>ACM</publisher-name>
          <conf-name>Proceedings of the19th International Conference on World Wide Web</conf-name>
          <conf-acronym>ICWWW 2010</conf-acronym>
          <conf-loc>Raleigh, NC, USA</conf-loc>
          <conf-date>April 26-30, 2010</conf-date>
          <year>2010</year>
          <page-range>831-840</page-range>
          <fpage>831</fpage>
          <lpage>840</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1145/1772690.1772775.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Gangemi</surname>
              <given-names/>
            </name>
            <name>
              <surname>Presutti</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Handbook on ontologies, chapter ontology design patterns</article-title>
          <source>International Handbooks on Information Systems</source>
          <publisher-name>Springer</publisher-name>
          <year>2009</year>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Borgo</surname>
              <given-names/>
            </name>
            <name>
              <surname>Masolo</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Handbook on ontologies, chapter foundational choices in DOLCE</article-title>
          <source>International Handbooks on Information Systems</source>
          <publisher-name>Springer</publisher-name>
          <year>2009</year>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Boll</surname>
              <given-names/>
            </name>
            <name>
              <surname>Sandhaus</surname>
              <given-names/>
            </name>
            <name>
              <surname>Scherp</surname>
              <given-names/>
            </name>
            <name>
              <surname>Westermann</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Semantics, content, and structure of many for the creation of personal photo albums</article-title>
          <publisher-name>Association for Computing Machinery</publisher-name>
          <conf-name>Proceedings of the 15th International Conference on Multimedia 2007</conf-name>
          <conf-acronym>ICM 2007</conf-acronym>
          <conf-loc>Augsburg, Germany</conf-loc>
          <conf-date>September 24-29, 2007</conf-date>
          <year>2007</year>
          <page-range>641-650</page-range>
          <fpage>641</fpage>
          <lpage>650</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.1145/1291233.1291385.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ballan</surname>
              <given-names/>
            </name>
            <name>
              <surname>Bertini</surname>
              <given-names/>
            </name>
            <name>
              <surname>Bimbo</surname>
              <given-names/>
            </name>
            <name>
              <surname>Serra</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Semantic annotation of soccer videos by visual instance clustering and spatial-temporal reasoning in ontologies</article-title>
          <source>Multimed. Tools Appl.</source>
          <year>2010</year>
          <volume>48</volume>
          <issue>2</issue>
          <page-range>313-337</page-range>
          <fpage>313</fpage>
          <lpage>337</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.1007/s11042-009-0342-4</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Naphade</surname>
              <given-names/>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names/>
            </name>
            <name>
              <surname>Tesic</surname>
              <given-names/>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hsu</surname>
              <given-names/>
            </name>
            <name>
              <surname>Kennedy</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hauptmann</surname>
              <given-names/>
            </name>
            <name>
              <surname>Curtis</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Large-scale concept ontology for multimedia</article-title>
          <source>IEEE MultiMedia</source>
          <year>2006</year>
          <volume>13</volume>
          <issue>3</issue>
          <page-range>86-91</page-range>
          <fpage>86</fpage>
          <lpage>91</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1109/MMUL.2006.63</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="newspaper">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names/>
            </name>
            <name>
              <surname>Bailer</surname>
              <given-names/>
            </name>
            <name>
              <surname>Burger</surname>
              <given-names/>
            </name>
            <name>
              <surname>Champin</surname>
              <given-names/>
            </name>
            <name>
              <surname>Evain</surname>
              <given-names/>
            </name>
            <name>
              <surname>Malaise</surname>
              <given-names/>
            </name>
            <name>
              <surname>Michel</surname>
              <given-names/>
            </name>
            <name>
              <surname>Sasaki</surname>
              <given-names/>
            </name>
            <name>
              <surname>Sederberg</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Ontology for Media Resources 1.0, W3C Recommendation 09 February 2012</article-title>
          <source>W3C</source>
          <year>2012</year>
          <uri>http://www.w3.org/TR/mediaont-10/</uri>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Valkanas</surname>
              <given-names/>
            </name>
            <name>
              <surname>Tsetsos</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hadjiefthymiades</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>The POLYSEMA MPEG-7 video annotator</article-title>
          <publisher-name>SAMT</publisher-name>
          <conf-name>Poster and Demo Proceedings of the 2nd International Conference on Semantic and Digital Media Technologies, Genoa</conf-name>
          <conf-loc>Italy</conf-loc>
          <conf-date>December 5-7, 2007</conf-date>
          <year>2007</year>
          <page-range>15-16</page-range>
          <fpage>15</fpage>
          <lpage>16</lpage>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Garcia</surname>
              <given-names/>
            </name>
            <name>
              <surname>Celma</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Semantic integration and retrieval of multimedia metadata</article-title>
          <source>In 5th Knowledge Markup and Semantic Annotation Workshop</source>
          <year>2006</year>
          <volume>185</volume>
          <page-range>69-80</page-range>
          <fpage>69</fpage>
          <lpage>80</lpage>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Suarez-Figueroa</surname>
              <given-names/>
            </name>
            <name>
              <surname>Atemezing</surname>
              <given-names/>
            </name>
            <name>
              <surname>Corcho</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>The landscape of multimedia ontologies in the last decade</article-title>
          <source>Multimed. Tools Appl.</source>
          <year>2013</year>
          <volume>62</volume>
          <issue>2</issue>
          <page-range>377-399</page-range>
          <fpage>377</fpage>
          <lpage>399</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s11042-011-0905-z</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sikos</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>VidOnt: A core reference ontology for reasoning over video scenes</article-title>
          <source>J. Inform. Telecomm.</source>
          <year>2018</year>
          <volume>2</volume>
          <issue>2</issue>
          <page-range>192-204</page-range>
          <fpage>192</fpage>
          <lpage>204</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1080/24751839.2018.1437696</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names/>
            </name>
            <name>
              <surname>Ding</surname>
              <given-names/>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names/>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Building a large annotation ontology for movie video retrieval</article-title>
          <source>Int. J. Digit. Content Technol. Its Appl.</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>5</issue>
          <page-range>74-81</page-range>
          <fpage>74</fpage>
          <lpage>81</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.4156/jdcta.vol4.issue5.8</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Teyeb</surname>
              <given-names/>
            </name>
            <name>
              <surname>Khemakhem</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hernandez</surname>
              <given-names/>
            </name>
            <name>
              <surname>Haemmere</surname>
              <given-names/>
            </name>
            <name>
              <surname>Jemaa</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Vers une annotation sémantique des images web fonde sur des patrons RDF</article-title>
          <source>CORIA 2015 Comput. Sc.</source>
          <year>2018</year>
          <volume>2012</volume>
          <pub-id pub-id-type="doi">https://doi.org/10.24348/coria.2015.66</pub-id>
          <pub-id pub-id-type="publisher-id">26484695</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="thesis">
          <person-group person-group-type="author">
            <name>
              <surname>Atemezing</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Analyzing and ranking multimedia ontologies for their reuse</article-title>
          <source>Master Dissertation</source>
          <year>1999</year>
          <publisher-name>Universidad Politecnica de Madrid, University</publisher-name>
          <publisher-loc>Spain</publisher-loc>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="newspaper">
          <person-group person-group-type="author">
            <name>
              <surname>Pradel</surname>
              <given-names/>
            </name>
            <name>
              <surname>Hernandez</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Une ontologie du Cinéma pour évaluer les applications du Web Semantique</article-title>
          <source>Une ontologie du Cinémam</source>
          <year>2012</year>
          <uri>https://www.irit.fr/OJD/OJD_4.pdf</uri>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Alejandro</surname>
              <given-names/>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>Semi-automatic, data-driven construction of multimedia ontologies</article-title>
          <publisher-name>IEEE</publisher-name>
          <conf-name>2003 International Conference on Multimedia and Expo</conf-name>
          <conf-acronym>ICME 2003</conf-acronym>
          <conf-loc>Baltimore, MD, USA</conf-loc>
          <conf-date>July 6-9, 2003</conf-date>
          <year>2003</year>
          <page-range>1-781</page-range>
          <fpage>1</fpage>
          <lpage>781</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1109/ICME.2003.1221034.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <surname>Suarez-Figueroa</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gomez-Perez</surname>
              <given-names/>
            </name>
            <name>
              <surname>Fernandez-Lopez</surname>
              <given-names/>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Suarez-Figueroa</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gomez-Perez</surname>
              <given-names/>
            </name>
            <name>
              <surname>Motta</surname>
              <given-names/>
            </name>
            <name>
              <surname>Gangemi</surname>
              <given-names/>
            </name>
          </person-group>
          <article-title>The NeOn methodology for ontology engineering</article-title>
          <publisher-loc>Berlin</publisher-loc>
          <publisher-name>Springer</publisher-name>
          <conf-name>Ontology Engineering in a Networked World, Heidelberg, Berlin</conf-name>
          <conf-loc>1 December</conf-loc>
          <conf-date>2012</conf-date>
          <year>2012</year>
          <page-range>9-34</page-range>
          <fpage>9</fpage>
          <lpage>34</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/978-3-642-24794-1_2.</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="webpage">
          <article-title>La Diversité linguistique des films de long métrage</article-title>
          <source>Institut de statistique de UNESCO</source>
          <year>2012</year>
          <uri>https://unesdoc.unesco.org/ark:/48223/pf0000217085_fre</uri>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="webpage">
          <article-title>La Diversité dans les films long métrages</article-title>
          <source>Institut de statistique de UNESCO</source>
          <year>2013</year>
          <uri>https://unesdoc.unesco.org/ark:/48223/pf0000221628_fre</uri>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>