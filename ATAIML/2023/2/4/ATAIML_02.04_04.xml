<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAIML</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on AI and Machine Learning</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Mach. Learn.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAIML</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9570</issn>
      <issn publication-format="print">2957-9562</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-_dmRktp2-Ip91Vtzim-mltZ-qS_su6K5</article-id>
      <article-id pub-id-type="doi">10.56578/ataiml020404</article-id>
      <title-group>
        <article-title>Predictive Modelling of Employee Attrition Using Deep Learning</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Quinteros</surname>
            <given-names>Dino Michael</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8174-8771</contrib-id>
          <email>dquinterosna@ucv.edu.pe</email>
        </contrib>
        <aff id="1">Professional Academic School of Systems Engineering, Cesar Vallejo University, 15314 Lima, Peru</aff>
      </contrib-group>
      <year>2023</year>
      <volume>2</volume>
      <issue>4</issue>
      <fpage>212</fpage>
      <lpage>225</lpage>
      <page-range>212-225</page-range>
      <history>
        <date date-type="received">
          <month>09</month>
          <day>12</day>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <month>11</month>
          <day>09</day>
          <year>2023</year>
        </date>
        <date date-type="pub">
          <month>11</month>
          <day>14</day>
          <year>2023</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2023 by the authors</copyright-statement>
        <copyright-year>2023</copyright-year>
        <license>. Licensee Acadlore Publishing Services Limited, Hong Kong. This article can be downloaded for free, and reused and quoted with a citation of the original published version, under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 license</ext-link>.</license>
      </permissions>
      <abstract><p>This investigation delineates an optimised predictive model for employee attrition within a substantial workforce, identifying pertinent models tailored to the specific context of employee and organisational variables. The selection and refinement of the appropriate predictive model serve as cornerstones for enhancements and updates, which are integral to honing the model's precision in prognosticating potential departures. Through meticulous optimisation, the model demonstrates proficiency in pinpointing the pivotal factors contributing to employee turnover and elucidating the interdependencies among salient variables. A suite of 27 general and eight critical variables were scrutinised. Pertinent correlations were unearthed, notably between monthly income and job satisfaction, home-to-work distance and job satisfaction, as well as age with both job satisfaction and performance metrics. Drawing from prior studies in analogous domains, a three-stage analytical methodology encompassing data exploration, model selection, and implementation was employed. The rigorous training of the optimised model encompassed both attrition factors and variable correlations, culminating in predictive outcomes with a precision of 90% and an accuracy of 87%. Implementing the refined model projected that 113 out of 709 employees, equating to 15.93%, were at a heightened risk of exiting the organisation. This quantitative foresight equips stakeholders with a strategic tool for preemptive interventions to mitigate turnover and sustain organisational vitality.</p></abstract>
      <kwd-group>
        <kwd>Deep learning</kwd>
        <kwd>Employee attrition prediction</kwd>
        <kwd>Predictive modelling</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors">1</count>
        <fig-count>22</fig-count>
        <table-count>5</table-count>
        <ref-count>14</ref-count>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec disp-level="level1" sec-type="intro">
      <title>1. Introduction</title>
      <p>Employee attrition presents a significant challenge within corporate structures, leading to considerable delays, costs, and elongated recruitment processes. The complexities that accompany staff resignations exacerbate risks associated with the attainment of annual corporate objectives. In the quest for an efficacious resolution, an optimised deep learning model has been developed to predict attrition with commendable accuracy and reliability. Comparative analyses demonstrate the model’s superior performance against extant literature.</p><p>Notably, emerging economies in Latin America exhibit a lack of adequate policies and procedures to gauge work environment dynamics and potential attrition, affecting 45% of businesses. Contrarily, in the United States and Europe, although 60% of firms reportedly possess robust protocols to anticipate staff departures, the application of such measures remains suboptimal. Human resources management, while central to organizational function, frequently overlooks the pre-resignation phase, thereby complicating the transition period up to the onboarding of new staff. The challenges are magnified when the roles in question demand specialised skills [<xref ref-type="bibr" rid="ref_1">1</xref>].</p><p>Attrition, defined as the withdrawal from employment for varied reasons, both intrinsic and extrinsic, results in substantial operational and strategic gaps. The rate of attrition emerges as a crucial metric, albeit one often neglected in corporate analyses [<xref ref-type="bibr" rid="ref_2">2</xref>]. The pertinence of human resources to corporate health is undisputed, yet the mechanisms to effectively predict and mitigate employee turnover require further elucidation. Mansor et al. [<xref ref-type="bibr" rid="ref_3">3</xref>] advocate for the identification of employee-aligned characteristics to enhance predictive accuracy regarding attrition. Maximizing profitability through the utilization of technical personnel skilled in specialized tasks is recognized as a critical component for sustaining business operations. Accordingly, the recruitment and retention of such specialized staff are acknowledged as decisive factors in the continuance of commercial enterprises [<xref ref-type="bibr" rid="ref_1">1</xref>].</p><p>The withdrawal of specialised personnel from an organisation not only undermines the achievement of institutional goals but also precipitates a loss of skills, experience, and potential business opportunities, underscoring the significance of retention strategies [<xref ref-type="bibr" rid="ref_4">4</xref>]. Within this context, the efficacy of machine learning models for customer churn prediction is well-documented. Nevertheless, such traditional models falter when tasked with addressing the nuances of employee-related processes, thereby necessitating more tailored approaches [<xref ref-type="bibr" rid="ref_5">5</xref>].</p><p>Customised deep learning architectures are increasingly recognised for their capacity to refine forecasts and bolster decision-making frameworks, thus circumventing inefficiencies and resource depletion. It is imperative to identify the catalysts for employee departure [<xref ref-type="bibr" rid="ref_6">6</xref>]. Deep learning, a cornerstone of data science, utilises an array of techniques to achieve precise outcomes that inform strategic decisions [<xref ref-type="bibr" rid="ref_2">2</xref>]. Machine learning models, as delineated by Alsheref et al. [<xref ref-type="bibr" rid="ref_7">7</xref>], undergo a tripartite development process: initial data exploration, subsequent model selection, and final implementation.</p><p>In other studies, it was identified that the highest dropout rates in higher education students are associated with issues of personal and social cost. For this reason, the authors specify that it is necessary to know the students at risk and understand the main dropout factors [<xref ref-type="bibr" rid="ref_8">8</xref>]. Likewise, the factors that influence dropout are associated with background, family, academic records and socioeconomic status. These input factors could be associated with various data collected [<xref ref-type="bibr" rid="ref_9">9</xref>].</p><p>Tran et al. [<xref ref-type="bibr" rid="ref_10">10</xref>] posit that the identification of pivotal variables, contingent upon company-specific contexts, is crucial for model integration. They further utilised a K-means clustering algorithm, uncovering its significance in predicting employee turnover. It was found that accuracy peaked at 97% for smaller, homogeneous groups, while larger groups yielded 80% accuracy, underscoring the efficacy of grouping specialised employees in crucial operational processes.</p><p>Contrastive analysis of classification models revealed varying levels of predictive accuracy and interpretability [<xref ref-type="bibr" rid="ref_6">6</xref>]. Logistic regression, for instance, achieved an accuracy of 88% and a receiver operating characteristic (ROC) curve of 85%, underscoring the need to elucidate job abandonment factors. Pratt et al. [<xref ref-type="bibr" rid="ref_11">11</xref>] employed an assortment of models, including decision trees, binomial and logistic regression, support vector machines, and random forests, which collectively reached an average accuracy of 85%. Dake and Buabeng-Andoh [<xref ref-type="bibr" rid="ref_12">12</xref>] implemented a classification model aimed at predicting student attrition, considering a suite of 24 variables predominantly related to personal context and environmental factors. The model achieved 72% accuracy and highlighted the imperative for further optimisation to enhance predictive performance. Yahia et al. [<xref ref-type="bibr" rid="ref_4">4</xref>] deployed an attrition prediction model that mapped influential characteristics within a dataset of 450 employees, achieving 84% accuracy.</p><p>This study unveils an optimised deep learning model tailored for attrition prediction, necessitating diversified models replete with pertinent indicators, reflective of the categorical and institutional segments. The analysis method pertaining to the optimised model, alongside the resultant findings and deduced conclusions, are comprehensively delineated.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>2. Methodology</title>
      
        <sec disp-level="level2">
          
            <title>2.1. Method</title>
          
          <p>The methodology employed in this research incorporated an exploratory data analysis, adhering to the tripartite framework delineated by Alsheref et al. [<xref ref-type="bibr" rid="ref_7">7</xref>]. This framework comprises data exploration, model selection, and model implementation. Within the scope of this study, 27 variables were scrutinised to ascertain their impact on the model's predictive capability. It was identified that the most salient variables included: age of the employee, attrition, commute distance from house to workplace (Distance_House), monthly income (Income_M), job satisfaction regarding the employee's monthly salary (Satisfaction_I), job satisfaction with respect to the employee's age (Satisfaction_A), performance evaluations and job satisfaction regarding distance from the employee's home (Satisfaction_DH).</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.2. Data exploration</title>
          
          <p>Data description is a relevant process in data analysis, including collection, determination, cleaning, consistency and verifications. Therefore, consistent, complete and accurate data will provide results more efficiently [<xref ref-type="bibr" rid="ref_13">13</xref>]. The dataset under scrutiny comprised 709 records pertaining to employees within the life insurance sector, encompassing a diverse array of roles and attributes.</p><p><xref ref-type="table" rid="table_1">Table 1</xref> presents the variables under consideration and their respective data types.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>Variables and types</caption>
              <abstract/>
              <table><tbody><tr><td colspan="1" rowspan="1"><p><span>No.</span></p></td><td colspan="1" rowspan="1"><p><span>Variable</span></p></td><td colspan="1" rowspan="1"><p><span style="color: black">Type</span></p></td><td colspan="1" rowspan="1"><p><span>No.</span></p></td><td colspan="1" rowspan="1"><p><span>Variable</span></p></td><td colspan="1" rowspan="1"><p><span style="color: black">Type</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>0</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Age</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>14</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Job_Level</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>1</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Desertion</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>15</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Role</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>2</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Business_Trip</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>16</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Satisfaction_I</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>3</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Daily_Rate</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>17</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Status_P</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>4</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Area</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>18</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Income_M</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>5</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Distance_House</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>19</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Monthly_Rate</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>6</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Education</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>20</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Companies_W</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>7</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Profession</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>21</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Over_18</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>8</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Employee</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>22</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Over_E</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>9</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Employee_N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>23</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Salary_Por</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>10</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Satisfaction_A</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>24</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Performance art</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>11</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Gender</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>object</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>25</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Satisfaction_DH</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>12</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Hourly_Rate</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>26</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>StandardHours</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span>13</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>Job_Part</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span>ext. 64</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span> </span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span> </span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span> </span></p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Exploratory data analysis was conducted to elucidate factors influencing employee attrition and to pinpoint the principal causes of turnover. The selection of variables was informed by a survey instrument whose validity was established through expert appraisal, focusing on relevance and consistency in the instrument's implementation. Various analytical techniques, such as graphical representations, time-series analyses, and correlation matrices, were employed. These methods facilitated the identification of data patterns instrumental in forecasting the ramifications of employee attrition and underscored the significance of factor identification. A notable correlation was observed between the variables of ‘Distance_House’ and ‘Age’, and indices of satisfaction and performance, thus warranting a detailed examination of these relationships due to their potential impact.</p><p><xref ref-type="fig" rid="fig_1">Figure 1</xref> delineates the time series and correlations among ‘Distance_House’ and ‘Age’ with ‘Satisfaction_DH’, ‘Satisfaction_A’, and ‘Performance’.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>Time series and correlations (Distance_House and Age with Satisfaction_DH, Satisfaction_A and Performance)</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_sheVZukBmU-lwnZP.jpeg"/>
            </fig>
          
          <p>Data distributions and line graphs were utilized for a suite of variables, including ‘Age’, ‘Attrition’, ‘Daily_Rate’, ‘Distance_House_Education’, ‘Employee’, ‘Employee_N’, ‘Satisfaction_E’, ‘Hourly_Rate’, ‘Job_Part’, ‘Job_Level’, ‘Job_Satisfaction’, ‘Income_M’, ‘Monthly_Rate’, ‘Companies_W’, ‘Over_18’, ‘Over_E’, ‘Salary_Por’, ‘Performance’, ‘Satisfaction’, and ‘StandardHours’. Predominant levels identified within these variables necessitated correlation to each corresponding factor. The variables exhibited significant attributes that were imperative for discerning specific employee characteristics, thereby enhancing the precision of attrition predictions. Such predictions are informed not solely by the general corporate context but also by the individual contexts of employees. The dataset was thus required to embody a degree of granularity that would allow for substantive relational analyses among the variables.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>Characteristics of the dataset</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img__fAY1TeK-qCCR7SB.jpeg"/>
            </fig>
          
          <p> <xref ref-type="fig" rid="fig_2">Figure 2</xref> illustrates the dataset characteristics.</p><p>For the efficacy of the predictive model, two critical criteria were considered essential: the nature of the dataset and the inter-variable correlations.</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.3. Model selection</title>
          
          <p>The alignment of the study's objectives with the selection of an appropriate deep learning model necessitated a meticulous review of literature and subsequent empirical evaluation. For this purpose, general and specific contextual variables were meticulously considered. From the range of models identified in prior research, three were subjected to rigorous testing against the dataset to determine their congruence with the study’s objectives: logistic regression, random forest, and neural networks.</p>
          
            <sec disp-level="level3">
              
                <title>2.3. 1 Logistic regression model</title>
              
              <p>In instances where recurrent application and effective classification are paramount, logistic regression models have been favoured. These models necessitate a substantial volume of data records, interlinked with relevant variables tailored for specific contexts [<xref ref-type="bibr" rid="ref_14">14</xref>]. The logistic regression model was applied to the dataset, yielding a precision of 85% and an accuracy of 83%.</p><p><xref ref-type="fig" rid="fig_3">Figure 3</xref> displays the correlations between variables.</p>
              
                <fig id="fig_3">
                  <label>Figure 3</label>
                  <caption>Correlations between variables</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_pcoer8UuMdhjKXXF.jpeg"/>
                </fig>
              
              <p> <xref ref-type="fig" rid="fig_4">Figure 4</xref> depicts the outcomes of the logistic regression model.</p>
              
                <fig id="fig_4">
                  <label>Figure 4</label>
                  <caption>Results of the logistic regression model</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_A6gsfJfXDbQKuSfn.png"/>
                </fig>
              
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.3. 2 Random forest model</title>
              
              <p>Random forest models employ an ensemble of decision trees to converge upon a singular objective, acclaimed for their interpretability and alignment with research aims [<xref ref-type="bibr" rid="ref_11">11</xref>]. Deployment of the dataset through a random forest model achieved a precision and accuracy of 83%.</p><p><xref ref-type="fig" rid="fig_5">Figure 5</xref> illustrates the results derived from the random forest model.</p>
              
                <fig id="fig_5">
                  <label>Figure 5</label>
                  <caption>Results of the random forest model</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_TzBio0lVdGrRrZ02.png"/>
                </fig>
              
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.3. 3 Neural network model</title>
              
              <p>Neural networks, an emergent model within the realm of deep learning, have demonstrated prowess in processing extensive variable sets expeditiously. These models are renowned for their innovative techniques in resolving business challenges. The architecture comprises an input layer, which introduces patterns into the network, and several hidden layers where data processing occurs. Connections within these layers, characterized by weights and biases, facilitate the computational processes. Upon receiving input, neurons calculate a weighted sum, inclusive of bias. The resultant value, in conjunction with an activation function, dictates neuron activation, leading to data transmission across the network. The utilisation of a non-linear activation function is chiefly for binary classification models, where the prediction of probabilities is required [<xref ref-type="bibr" rid="ref_11">11</xref>].</p><p>Within the neural network architecture, each neuron is programmed to compute a weighted sum of the received input values, to which a bias term is added. It is then subjected to an activation function, which determines the neuron's activation status based on the calculated sum. Subsequently, the activated neuron propagates the information through the network, eventually reaching the final hidden layer, which connects to the output layer. The employment of a non-linear activation function facilitates the scaling of output data, which is primarily utilized in binary classification models for the prediction of probabilities as outcomes.</p><p> <xref ref-type="fig" rid="fig_6">Figure 6</xref> presents the nonlinear artificial neural network (ANN) model.</p>
              
                <fig id="fig_6">
                  <label>Figure 6</label>
                  <caption>Nonlinear ANN model</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_KUUQOVNv0cI2kZPT.png"/>
                </fig>
              
              <p> <xref ref-type="fig" rid="fig_7">Figure 7</xref> displays results of the neural network model.</p>
              
                <fig id="fig_7">
                  <label>Figure 7</label>
                  <caption>Results of the neural network model</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_g8OnmvCtkVGW7jST.png"/>
                </fig>
              
              <p>When subjected to the neural network model, the dataset revealed a precision of 90% and an accuracy of 87%. Therefore, the neural network model was identified as the most suitable foundation for the development of an optimised predictive model for attrition.</p><p>The selection criteria were twofold: first, the presence of correlated variables within the model; second, the attainment of superior precision and accuracy in predictive capability.</p>
            </sec>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.4. Implementation of the selected model</title>
          
          <p>Within the selected model, 27 variables were identified as possessing specific characteristics pertinent to the employee's role within the internal context of the organization. Initial deployment of this model yielded a precision of 90% and an accuracy of 87%. This model served as the precursor for advancements towards an optimized predictive model. Consequently, variables intrinsic to the employee's environment were incorporated, namely: Business_Trip, Area, Profession, Gender, Role, and Status_P. These variables were imperative for initiating the data cleansing process and subsequent training phases.</p><p>For the data cleansing stage, a methodology was employed whereby variables such as Attrition, Over18, and Overtime were encoded as integers to facilitate visualization. Variables deemed non-essential to the model's predictive capacity, including Employee, StandardHours, Over_18, and Employee_N, were excised from the dataset. Training the model involved utilizing the attrition column as the target variable, influencing the component's capacity to discern patterns. Training commenced with subsets of data: an initial ten events yielded a learning accuracy of 65%, escalating to 80% with 50 events, and surpassing 95% upon the introduction of 100 events.</p><p><xref ref-type="fig" rid="fig_8">Figure 8</xref> illustrates the variables relevant to the model implementation.</p>
          
            <fig id="fig_8">
              <label>Figure 8</label>
              <caption>Relevant variables</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_1uL4dHHb67vDfxHn.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="results">
      <title>3. Results</title>
      
        <sec disp-level="level2">
          
            <title>3.1. Training of the optimised model</title>
          
          <p>Subsequent to the data cleansing process, the variables retained were curated to enhance the model's predictive performance, necessitating the validation of tests and the pertinence of outcomes. The training was executed in three sequential deployments. Initially, an assemblage of ten events was processed, followed by a cohort of 50 events, and culminating in a final set of 100 events. It was observed that an accuracy threshold exceeding 95% was attained in the ultimate deployment. Training with a dataset comprising 100 events was determined to be requisite for the augmentation of the model's accuracy.</p><p><xref ref-type="fig" rid="fig_9">Figure 9</xref> delineates the model's accruing accuracy throughout the training phases.</p>
          
            <fig id="fig_9">
              <label>Figure 9</label>
              <caption>Accuracy of the model during training</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_Qe5gcQRwwQ06Ztm7.jpeg"/>
            </fig>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>3.2. Results of the optimised model</title>
          
          <p>Upon the completion of the training process, the optimized model demonstrated a commendable accuracy of 97.36%.</p><p><xref ref-type="fig" rid="fig_10">Figure 10</xref> illustrates the results obtained from the optimized model.</p><p>Concomitantly, the deployment phase allowed for the prediction of the prospective attrition among the workforce.</p>
          
            <fig id="fig_10">
              <label>Figure 10</label>
              <caption>Results of the optimized model</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_xwYAgNUfScYOGF7f.png"/>
            </fig>
          
          <p><xref ref-type="fig" rid="fig_11">Figure 11</xref> presents the forecasted number of employees predicted to sever their association with the company.</p><p>The ROC curve analysis was conducted to assess the binary classification capability of the model, segregating employees into either a positive (likely to leave) or negative (likely to remain) category. The results indicated a robust model performance, characterized by a substantial area under the ROC curve, i.e. area under the curve (AUC), approaching the optimal value of 1, specifically notated as 0.97, which signifies a high level of precision.</p>
          
            <fig id="fig_11">
              <label>Figure 11</label>
              <caption>Forecasted number of employees to leave the company</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_yJYzIja7EnCxdyKF.png"/>
            </fig>
          
          <p> <xref ref-type="fig" rid="fig_12">Figure 12</xref> depicts the test results of the ROC curve.</p>
          
            <fig id="fig_12">
              <label>Figure 12</label>
              <caption>Results of the optimized model</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_kSdFB8GQoe55fFzK.jpeg"/>
            </fig>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>3.3. Determinants of employee attrition</title>
          
          <p>Analysis of the distance between home and workplace as a variable revealed a correlation with employee attrition; it was observed that an increased distance is associated with a higher attrition rate. Conversely, employees residing in proximity to the workplace were predominantly those who remained within the company. This suggests that proximity may play a deterrent role in the likelihood of employee turnover. The findings point to a necessity for a broader evaluation of contributory factors in this domain.</p><p> <xref ref-type="fig" rid="fig_13">Figure 13</xref> details the analytical code utilized for assessing the impact of commute distance.</p>
          
            <fig id="fig_13">
              <label>Figure 13</label>
              <caption>Code identifying the home-to-work factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_ONs6tYBhl819TYim.png"/>
            </fig>
          
          <p> <xref ref-type="fig" rid="fig_14">Figure 14</xref> provides a visual representation of the correlation between home-to-work distance and job attrition.</p>
          
            <fig id="fig_14">
              <label>Figure 14</label>
              <caption>Impact of the home-to-work factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_2wFdN1kKn4voW9EA.jpeg"/>
            </fig>
          
          <p>Furthermore, the investigation into monthly income as a variable indicated a pattern wherein employees with lower income brackets exhibited a higher tendency to leave the company, while those earning higher wages were more inclined to stay. This underscores the significance of financial compensation in employee retention strategies.</p><p> <xref ref-type="fig" rid="fig_15">Figure 15</xref> illustrates the code employed to determine the influence of monthly income.</p>
          
            <fig id="fig_15">
              <label>Figure 15</label>
              <caption>Code identifying the monthly income factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_nW0h7zTGRztnwhCn.png"/>
            </fig>
          
          <p><xref ref-type="fig" rid="fig_16">Figure 16</xref> displays the relationship between monthly income levels and employee retention outcomes.</p><p>Age was also scrutinized as a relevant variable. The data suggest a lower attrition rate among employees aged between 30 and 40 years, while a higher departure rate was noted among younger employees, specifically those aged 20 to 30 years. This demographic distribution intimates a potential focus area for enhancing retention policies.</p>
          
            <fig id="fig_16">
              <label>Figure 16</label>
              <caption>Code identifying the age factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_DZwYMu3faIr_EFJx.png"/>
            </fig>
          
          <p><xref ref-type="fig" rid="fig_17">Figure 17</xref> depicts the code utilized to elucidate the age factor in employee attrition.</p>
          
            <fig id="fig_17">
              <label>Figure 17</label>
              <caption>Impact of the age factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_18pS9Y4CymiYjzD-.jpeg"/>
            </fig>
          
          <p><xref ref-type="fig" rid="fig_18">Figure 18</xref> shows the distribution of attrition across different age groups.</p>
          
            <fig id="fig_18">
              <label>Figure 18</label>
              <caption>Impact of the monthly income factor</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_caknRBvtmpbo8vkG.jpeg"/>
            </fig>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>3.4. Correlations</title>
          
          <p>Correlational studies were conducted to ascertain the relationships between various employee attributes and job satisfaction, as well as between age and job performance. Employee remuneration emerged as a critical variable, with its influence on job satisfaction being a determining factor in the potential for job attrition. It was found that higher salaries are closely associated with elevated levels of employee satisfaction, thereby reducing the propensity for job desertion.</p>
          <p> <xref ref-type="fig" rid="fig_19">Figure 19</xref> and <xref ref-type="table" rid="table_2">Table 2</xref> delineate the relationship between salary and employee satisfaction.</p>
          
            <fig id="fig_19">
              <label>Figure 19</label>
              <caption>Relationship between monthly income and satisfaction</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_3VYYsxBHtsssjM0T.png"/>
            </fig>
          
          <p><xref ref-type="table" rid="table_2">Table 2</xref> presents the findings from Spearman's rho test regarding the correlation coefficient, delineating the relationship between monthly income and employee satisfaction. A significant correlation has been identified, with p=0.000&lt;<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>α</mi>
  </math>
</inline-formula>=0.01. This establishes a statistically significant relationship between monthly income and satisfaction levels. Specifically, a higher salary is correlated with increased satisfaction, as indicated by a Spearman's rho of 0.492, denoting a moderate positive correlation.</p><p>The commute distance was also scrutinized as a variable of interest. It was observed that greater commute distances are inversely related to employee satisfaction, which could potentially lead to increased job turnover.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>Correlation between monthly income and satisfaction</caption>
              <abstract/>
              <table><tbody><tr><td colspan="3" rowspan="1"><p style="text-align: center"><span style="color: rgb(1, 2, 5); font-family: Times New Roman, serif">Correlations</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Monthly income</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Satisfaction</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">1,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0,492</span><sup><span style="color: black; font-family: Times New Roman, serif">**</span></sup></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">.</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">709</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0,492</span><sup><span style="color: black; font-family: Times New Roman, serif">**</span></sup></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">1,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">0,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">.</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">709</span></p></td></tr><tr><td colspan="3" rowspan="1"><p style="text-align: center"><span style="color: rgb(1, 2, 5); font-family: Times New Roman, serif">**Correlation is significant at the 0.01 level (two-sided).</span></p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="fig" rid="fig_20">Figure 20</xref> provides an analysis of the impact of commute distance on employee satisfaction.</p>
          
            <fig id="fig_20">
              <label>Figure 20</label>
              <caption>Impact of commute distance on satisfaction</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_UEA3auJIJFjHy62s.png"/>
            </fig>
          
          <p> <xref ref-type="table" rid="table_3">Table 3</xref> presents the statistical relationship between commute distance and satisfaction.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>Correlation between commute distance and satisfaction</caption>
              <abstract/>
              <table><tbody><tr><td colspan="3" rowspan="1"><p style="text-align: center">Correlations</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"></p></td><td colspan="1" rowspan="1"><p style="text-align: center">Commute distance</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Satisfaction</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,392</span><sup><span style="color: black">**</span></sup></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,392</span><sup><span style="color: black">**</span></sup></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black; font-family: Times New Roman, serif">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td></tr><tr><td colspan="3" rowspan="1"><p style="text-align: center">**Correlation is significant at the 0.01 level (two-sided).</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The results, as indicated in <xref ref-type="table" rid="table_3">Table 3</xref>, were derived from Spearman's rho test, which elucidated the correlation coefficient between the distance from home to the workplace and employee satisfaction. The test yielded p=0.000&lt;<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>α</mi>
  </math>
</inline-formula>=0.01. This confirms a statistically significant correlation; specifically, a shorter commute is associated with an elevated level of satisfaction among employees. The Spearman's rho of 0.392 signifies a low but positive correlation.</p><p>Analysis of age dynamics was also conducted, which revealed distinct satisfaction levels across age brackets. Employees aged between 18 and 25, as well as those over 45, exhibit higher degrees of satisfaction, potentially attributable to the distinct career stages represented by these age groups. Conversely, those aged between 25 and 45 showed lower satisfaction levels, which may predispose them to higher turnover.</p><p><xref ref-type="fig" rid="fig_21">Figure 21</xref> and <xref ref-type="table" rid="table_4">Table 4</xref> illustrate the correlation between age groups and employee satisfaction.</p><p>As presented in <xref ref-type="table" rid="table_4">Table 4</xref>, the results obtained from Spearman's rho test indicate the correlation coefficient between the variable of age and employee satisfaction. With p=0.006&lt;<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>α</mi>
  </math>
</inline-formula>=0.01, a statistically significant correlation is established. It has been observed that an increase in age is correlated with higher levels of satisfaction within the workplace. Nevertheless, with a rho value of 0.216, this correlation is classified as low positive.</p><p>Regarding age and performance, the data indicated that optimal performance is achieved between the ages of 35 and 55. Meanwhile, younger employees (aged 18-25) and those over 55 exhibit lower performance metrics.</p>
          
            <fig id="fig_21">
              <label>Figure 21</label>
              <caption>Impact of age on satisfaction</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_ATMZugwgaF3RkWY_.png"/>
            </fig>
          
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>Correlation between age and satisfaction</caption>
              <abstract/>
              <table><tbody><tr><td colspan="3" rowspan="1"><p style="text-align: center">Correlations</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"></p></td><td colspan="1" rowspan="1"><p style="text-align: center">Age</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Satisfaction</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,216</span><sup><span style="color: black">**</span></sup></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,006</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">159</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">159</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,216</span><sup><span style="color: black">**</span></sup></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,006</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td></tr><tr><td colspan="3" rowspan="1"><p>**Correlation is significant at the 0.01 level (two-sided).</p></td></tr></tbody></table>
            </table-wrap>
          
          <p> <xref ref-type="fig" rid="fig_22">Figure 22</xref> and <xref ref-type="table" rid="table_5">Table 5</xref> showcase the correlation between age and job performance.</p>
          
            <fig id="fig_22">
              <label>Figure 22</label>
              <caption>Impact of age on satisfaction</caption>
              <abstract/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/10/img_lDgG8s1qD-vi6BP3.png"/>
            </fig>
          
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>Correlation between age and performance</caption>
              <abstract/>
              <table><tbody><tr><td colspan="3" rowspan="1"><p style="text-align: center">Correlations</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"></p></td><td colspan="1" rowspan="1"><p style="text-align: center">Age</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Performance art</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,210</span><sup><span style="color: black">**</span></sup></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Correlation coefficient</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,318</span><sup><span style="color: black">**</span></sup></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">1,000</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">Follow-up (bilateral)</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">0,000</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">.</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">N</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="color: black">709</span></p></td></tr><tr><td colspan="3" rowspan="1"><p style="text-align: center">**Correlation is significant at the 0.01 level (two-sided).</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_5">Table 5</xref> delineates the correlation between employee age and performance, as evidenced by the Spearman's rho test. With p=0.000&lt;<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>α</mi>
  </math>
</inline-formula>=0.01 indicates a highly significant correlation between the two variables. It is inferred from this result that an increase in employee age is associated with an enhancement in performance. However, the correlation coefficient, rho, valued at 0.210, signifies a modestly positive correlation.</p>
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="discussion">
      <title>4. Discussion</title>
      <p>The logistic regression model was examined, with its direct application to specialized company processes yielding precision and accuracy rates exceeding 83% (precision: 85%, accuracy: 83%). However, it was noted that this model does not account for variable correlation across diverse contexts, which limits its capacity for optimization based on the variables presented. The random forest model, designed to generate assertiveness without necessitating contextual variable correlations, consistently demonstrated results with an 83% success rate in both precision and accuracy. This uniformity in performance denotes its robustness. In contrast, the neural network model was capable of integrating and correlating multiple variables within employee-specific contexts as defined by the company. This model showed a superior performance with results surpassing 87% (90% precision and 87% accuracy). Subsequently, the neural network was selected based on two criteria: the inter-correlation of variables and its superior precision and accuracy. It encompassed 27 variables reflecting employee characteristics pertinent to the internal company context.</p><p>An optimized deep learning model was further considered, incorporating techniques such as identification of contextually relevant variables. This model achieved a noteworthy accuracy of 97.36% following training. The optimized model demonstrated enhanced performance relative to models proposed by Guerranti and Dimitri [<xref ref-type="bibr" rid="ref_6">6</xref>], who reported an 88% accuracy, and Pratt et al. [<xref ref-type="bibr" rid="ref_11">11</xref>] who documented an 85% accuracy average. The selection of variables representative of the company's context was instrumental in these improvements. The findings from the optimized model provide insights into predicting labor attrition based on specific and representative variables within the company's context. Future research should focus on identifying new variables that can refine the training process, thus enhancing accuracy and precision, and reducing the time required for model training. Finally, the significant monetary and labor losses incurred by companies, particularly small and medium-sized enterprises, due to employee attrition within the first six to 12 months post-hiring, are noteworthy. The optimized model has proven effective in identifying variables that may lead to attrition, thereby enabling strategies for improved hiring processes and employee retention.</p>
    </sec>
    <sec disp-level="level1" sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>Through the implementation of the optimized model, it was discerned that an estimated 113 (15.93%) of 709 employees are predicted to leave the organization. Predominant variables influencing attrition were identified as salary, distance from home, age, and performance metrics. It is imperative for organizations to address these variables to enhance employee retention strategies. Comparative analyses of logistic regression, random forest, and neural network models revealed constraints in pinpointing variables of significance that align with a company's specific context. Traditional models typically factor in one or two variables, whereas the optimized model incorporates a broader spectrum of seven pertinent variables: Age, Attrition, Distance_House, Income_M, Satisfaction_I, Satisfaction_A, Performance, and Satisfaction_DH, along with four inter-variable correlations. A robust correlation between monthly income and job satisfaction was observed, where a moderate positive correlation (rho=0.492 and p=0.000) was reported, suggesting that higher salaries are commensurate with increased employee satisfaction.</p><p>A correlation between the employee's distance from home to the workplace and their level of satisfaction was identified, with a lower positive correlation (rho=0.392 and p=0.000) indicating that closer proximity correlates with heightened satisfaction. The relationship between employee age and job satisfaction was also significant, albeit displaying a lower positive correlation (rho=0.216 and p=0.006), implying that satisfaction tends to augment with age. Additionally, a significant yet low positive correlation was noted between age and performance (rho=0.210 and p=0.000), indicating that employee performance incrementally improves with age. Future research should prioritize the integration of variables reflecting significant personal attributes, labor market trends, and entrepreneurial initiatives. This approach is anticipated to refine the model's predictive accuracy towards an optimal 100% threshold. Furthermore, a thorough examination of the identified correlations is warranted to elucidate the dynamics influencing variable interrelationships and their implications for continuous improvement strategies.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      <p></p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p><span>The data used to support the research findings are available from the corresponding author upon request.</span></p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author declares no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>86</page-range>
          <issue>4</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>F.</given-names>
              <surname>Fallucchi</surname>
            </name>
            <name>
              <given-names>F. M.</given-names>
              <surname>Coladangelo</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Juliano</surname>
            </name>
            <name>
              <given-names>E. W. De</given-names>
              <surname>Luca</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/computers9040086</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Predicting employee attrition using machine learning techniques</article-title>
          <source>Computers</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>6424</page-range>
          <issue>13</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Ahsan</given-names>
              <surname>Raza</surname>
            </name>
            <name>
              <given-names>Kashif</given-names>
              <surname>Munir</surname>
            </name>
            <name>
              <given-names>Majed</given-names>
              <surname>Almutairi</surname>
            </name>
            <name>
              <given-names>Farhan</given-names>
              <surname>Younas</surname>
            </name>
            <name>
              <given-names>Muhammad Mansoor Sadiq</given-names>
              <surname>Fareed</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app12136424</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Predicting employee attrition using machine learning approaches</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>435-445</page-range>
          <issue>11</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Nurul</given-names>
              <surname>Mansor</surname>
            </name>
            <name>
              <given-names>Nur Syazana</given-names>
              <surname>Sani</surname>
            </name>
            <name>
              <given-names>Mohd</given-names>
              <surname>Aliff</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher"/>
          <article-title>Machine learning to predict employee attrition</article-title>
          <source>Int. J. Adv. Comput. Sci. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>60447-60458</page-range>
          <issue/>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Najeh Ben</given-names>
              <surname>Yahia</surname>
            </name>
            <name>
              <given-names>Jihene</given-names>
              <surname>Hlel</surname>
            </name>
            <name>
              <given-names>Ricardo</given-names>
              <surname>Colomo-Palacios</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3074559</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>From big data to deep data to support people analytics for employee attrition prediction</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume/>
          <page-range>1323-1329</page-range>
          <issue/>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Ronke</given-names>
              <surname>Babatunde</surname>
            </name>
            <name>
              <given-names>Sulaiman Olaniyi</given-names>
              <surname>Abdulsalam</surname>
            </name>
            <name>
              <given-names>Olanshile Abdulkabir</given-names>
              <surname>Abdulsalam</surname>
            </name>
            <name>
              <given-names>Micheal Olaolu</given-names>
              <surname>Arowolo</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.11591/ijai.v12.i3.pp1323-1329</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Classification of the customer churn prediction model for the telecommunications industry using analysis of variance</article-title>
          <source>IAES Int. J. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>267</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Federico</given-names>
              <surname>Guerranti</surname>
            </name>
            <name>
              <given-names>Giulio Maria</given-names>
              <surname>Dimitri</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app13010267</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>A comparison of machine learning approaches for predicting employee attrition</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume/>
          <page-range>1-9</page-range>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Fahad Kamal</given-names>
              <surname>Alsheref</surname>
            </name>
            <name>
              <given-names>Ibrahim Eldesouky</given-names>
              <surname>Fattoh</surname>
            </name>
            <name>
              <given-names>Waleed M.</given-names>
              <surname>Ead</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2022/7728668</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Automated prediction of employee attrition using ensemble model based on machine learning algorithms</article-title>
          <source>Comput. Intell. Neurosci.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>119</page-range>
          <issue>9</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Alvarado-Uribe</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Mejía-Almada</surname>
            </name>
            <name>
              <given-names>A. L.</given-names>
              <surname>Masetto Herrera</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Molontay</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Hilliger</surname>
            </name>
            <name>
              <given-names>V.</given-names>
              <surname>Hegde</surname>
            </name>
            <name>
              <given-names>J. E.</given-names>
              <surname>Montemayor Gallegos</surname>
            </name>
            <name>
              <given-names>R. A.</given-names>
              <surname>Ramírez Díaz</surname>
            </name>
            <name>
              <given-names>H. G.</given-names>
              <surname>Ceballos</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/data7090119</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Student dataset from Tecnologico de Monterrey in Mexico to predict dropout in higher education</article-title>
          <source>Data</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>34</volume>
          <page-range/>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>Ajoodha</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18489/sacj.v34i2.832</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Identifying academically vulnerable learners in first-year science programmes at a South African higher-education institution</article-title>
          <source>South Afr. Comput. J.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>87-105</page-range>
          <issue/>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H. Dang</given-names>
              <surname>Tran</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Le</surname>
            </name>
            <name>
              <given-names>V. H.</given-names>
              <surname>Nguyen</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.28945/5086</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Customer churn prediction in the banking sector using machine learning-based classification models</article-title>
          <source>Interdiscip. J. Inf. Knowl. Manag.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>49-66</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Pratt</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Boudhane</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Cakula</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22364/bjmc.2021.9.1.04</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Employee attrition estimation using random forest algorithm</article-title>
          <source>Balt. J. Mod. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>2022</volume>
          <page-range>1-9</page-range>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>D. K.</given-names>
              <surname>Dake</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Buabeng-Andoh</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2022/2670562</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Using machine learning techniques to predict learner drop-out rate in higher educational institutions</article-title>
          <source>Mob. Inf. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>562-567</page-range>
          <issue>4</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Shilbayeh</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Abonamah</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.34028/18/4/8</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Predicting student enrolments and attrition patterns in higher educational institutions using machine learning</article-title>
          <source>Int. Arab J. Inf. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range/>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>E. A.</given-names>
              <surname>Varela-Tapia</surname>
            </name>
            <name>
              <given-names>I. L.</given-names>
              <surname>Acosta-Guzmán</surname>
            </name>
            <name>
              <given-names>C. I.</given-names>
              <surname>Acosta-Varela</surname>
            </name>
            <name>
              <given-names>P. M.</given-names>
              <surname>Marcillo-Sanchez</surname>
            </name>
            <name>
              <given-names>D. G.</given-names>
              <surname>Patiño Pérez</surname>
            </name>
            <name>
              <given-names>J. D.</given-names>
              <surname>Tumbaco Bravo</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.18687/LACCEI2022.1.1.791</pub-id>
          <article-title>Intelligent predictive model of BMI in nutritionists' patients using machine learning algorithms: Logistic regression and neural networks</article-title>
          <source>Proceedings of the 20th LACCEI International Multi-Conference for Engineering, Education and Technology, Boca, Raton</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>