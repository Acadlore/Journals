<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">HF</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Healthcraft Frontiers</journal-title>
        <abbrev-journal-title abbrev-type="issn">Healthcraft. Front.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">HF</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">3005-799X</issn>
      <issn publication-format="print">3005-7981</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-5hrxXwyR35FZQ_8kGych0KmfxhjPaxbd</article-id>
      <article-id pub-id-type="doi">10.56578/hf010103</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A CNN Approach for Enhanced Epileptic Seizure Detection Through EEG Analysis</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7362-2079</contrib-id>
          <name>
            <surname>Yucel</surname>
            <given-names>Nadide</given-names>
          </name>
          <email>yucelnadide@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0009-2176-0192</contrib-id>
          <name>
            <surname>Mutlu</surname>
            <given-names>Hursit Burak</given-names>
          </name>
          <email>burakmutlu44@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0004-8363-1517</contrib-id>
          <name>
            <surname>Durmaz</surname>
            <given-names>Fatih</given-names>
          </name>
          <email>fth.drmz23@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4313-8694</contrib-id>
          <name>
            <surname>Cengil</surname>
            <given-names>Emine</given-names>
          </name>
          <email>ecengil@beu.edu.tr</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1866-4721</contrib-id>
          <name>
            <surname>Yildirim</surname>
            <given-names>Muhammed</given-names>
          </name>
          <email>muhammed.yildirim@ozal.edu.tr</email>
        </contrib>
        <aff id="aff_1">Department of Computer Engineering, Faculty of Engineering and Natural Sciences, Malatya Turgut Ozal University, 44200 Malatya, Turkey</aff>
        <aff id="aff_2">Department of Computer Engineering, Faculty of Engineering and Architecture, Bitlis Eren University, 13000 Bitlis, Turkey</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>30</day>
        <month>11</month>
        <year>2023</year>
      </pub-date>
      <volume>1</volume>
      <issue>1</issue>
      <fpage>33</fpage>
      <lpage>43</lpage>
      <page-range>33-43</page-range>
      <history>
        <date date-type="received">
          <day>11</day>
          <month>10</month>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <day>23</day>
          <month>11</month>
          <year>2023</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2023 by the author(s)</copyright-statement>
        <copyright-year>2023</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Epilepsy, the most prevalent neurological disorder, is marked by spontaneous, recurrent seizures due to widespread neuronal discharges in the brain. This condition afflicts approximately 1% of the global population, with only two-thirds responding to antiepileptic drugs and a smaller fraction benefiting from surgical interventions. The social stigma and emotional distress associated with epilepsy underscore the importance of timely and accurate seizure detection, which can significantly enhance patient outcomes and quality of life. This research introduces a novel convolutional neural network (CNN) architecture for epileptic seizure detection, leveraging electroencephalogram (EEG) signals. Contrasted with traditional machine-learning methodologies, this innovative approach demonstrates superior performance in seizure prediction. The accuracy of the proposed CNN model is established at 97.52%, outperforming the highest accuracy of 93.65% achieved by the Discriminant Analysis classifier among the various classifiers evaluated. The findings of this study not only present a groundbreaking method in the realm of epileptic seizure recognition but also reinforce the potential of deep learning techniques in medical diagnostics.</p></abstract>
      <kwd-group>
        <kwd>Artificial intelligence</kwd>
        <kwd>Convolutional neural network</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Electroencephalography</kwd>
        <kwd>Epileptic seizure detection</kwd>
        <kwd>Machine learning</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="5"/>
        <fig-count count="10"/>
        <table-count count="7"/>
        <ref-count count="24"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Epilepsy, a neurological condition characterized by recurrent, unanticipated seizures, arises from abnormalities in brain's electrical activity. These irregularities disrupt normal neuronal communication, manifesting in varied seizures that temporarily impair brain functions, altering consciousness, movement, sensory perception, or behavior. The manifestations of epilepsy, potentially stemming from underlying conditions such as brain tumors, traumatic injuries, or congenital anomalies, exhibit a broad spectrum of symptoms, including muscle spasms, loss of consciousness, memory gaps, and altered emotional or behavioral states. While pharmacological interventions often effectively manage epilepsy, reducing seizure frequency or controlling them entirely, some cases may witness spontaneous improvement without medication. Diagnosis typically involves a neurological assessment focused on seizure type and frequency, supplemented by EEG tests to record brain's electrical activity. Given the profound impact of seizures on individuals' lives, the development of artificial intelligence-based systems for seizure detection is gaining prominence.</p><p style="text-align: justify">Recent advancements in technology have led to the increasing application of artificial intelligence in biomedical fields (<xref ref-type="bibr" rid="ref_23">Yildirim, 2023</xref>; <xref ref-type="bibr" rid="ref_10">Eroglu et al., 2023</xref>; <xref ref-type="bibr" rid="ref_8">Eroğlu et al., 2023</xref>), particularly in developing computer-aided systems that alleviate experts' workload and facilitate use in non-expert settings. This study focuses on the detection of epileptic seizures using an artificial intelligence-based model, a topic also explored in existing literature. For instance, <xref ref-type="bibr" rid="ref_17">Sarić et al. (2020)</xref>, employed a Field Programmable Gate Array (FPGA)-based feed-forward multilayer neural network architecture (MLP ANN) to categorize generalized and localized seizure types. Utilizing 822 signals from the Temple University Hospital Seizure Detection Corpus (TUH EEG Corpus), they achieved a diagnostic accuracy of 95.14% with their (5-12-3) MLP ANN on FPGA. <xref ref-type="bibr" rid="ref_16">Prathaban &amp;amp; Balasubramanian (2021)</xref> proposed an adaptive optimization method using a nonlinear conjugate gradient technique, a Sparsity-based EEG Reconstruction (SER), and a three-dimensional Optimized CNN (3D OCNN) classifier based on the Fletcher Reeves (FR) algorithm. Tested on three different databases (CHB-MIT, NINC, and SRM) with 300 entries, their empirical findings indicated a remarkable 98% accuracy. In another significant contribution, <xref ref-type="bibr" rid="ref_22">Wang et al. (2021)</xref> introduced a novel CNN for assessing time, frequency, and channel information of EEG signals. Incorporating three-dimensional kernels for facilitated feature extraction, their model was evaluated using the CHB-MIT EEG database, achieving an accuracy of 80.5%, surpassing existing state-of-the-art technologies.</p><p>In the evolving landscape of epileptic seizure detection, <xref ref-type="bibr" rid="ref_11">Mao et al. (2020)</xref> introduced a CNN-based model, integrating continuous wavelet transform (CWT) for the categorization of epileptic episodes. This model, transforming EEG signal data into time-frequency domain images via wavelet algorithms, achieved an accuracy of 72.49%. <xref ref-type="bibr" rid="ref_2">Almustafa (2020)</xref> explored the classification of the epileptic seizure dataset using various classifiers. The study highlighted the superiority of the random forest classifier over others like naïve Bayes, logistic regression, and decision trees, achieving a no<xref ref-type="table" rid="table_97">table 97</xref>.08% accuracy. <xref ref-type="bibr" rid="ref_19">Shen et al. (2022)</xref> proposed an EEG-based real-time method for the detection of epileptic seizures, employing eigenvalue techniques and discrete wavelet transforms for feature extraction from lower-frequency bands. The RUSBoosted tree ensemble approach, coupled with a support vector machine for three-class categorization, was utilized, demonstrating a 97% accuracy rate across two datasets: the CHB-MIT long-term and the UB short-term datasets.</p><p><xref ref-type="bibr" rid="ref_12">Mian Qaisar &amp;amp; Subasi (2020)</xref> developed a framework for the efficient diagnosis of epileptic seizures, achieving real-time compression and effective signal processing and transfer in EEG signal capture. Utilizing a standard three-class EEG dataset, their system demonstrated a maximum classification accuracy of 97% for a single class and an average of 96.4% across three classes. <xref ref-type="bibr" rid="ref_5">Beeraka et al. (2022)</xref> implemented the short-term Fourier transform block on an FPGA within deep learning models to enhance epileptic seizure detection. Their approach, integrating Bidirectional Long Short-Term Memory (Bi-LSTM) and CNN, utilized the Bonn EEG dataset, achieving an average classification accuracy of 93.9%, with the CNN and Bi-LSTM models reaching 97.2%.</p><p>The contributions and innovations of the current study are summarized as follows:</p><p><p>Development of a CNN-based model for EEG signal classification.</p><p>The model, comprising 12 layers including the input layer, offers expedited processing due to its reduced layer count.</p><p>The model achieves a 97.52% accuracy in early diagnosis of epileptic seizures from EEG signals.</p><p>It promises to reduce the workload of specialists and can be utilized for preliminary diagnosis in non-expert settings.</p></p><p>The structure of the study includes the materials and methods section, followed by application findings, discussion, and conclusion in subsequent sections.</p>
    </sec>
    <sec sec-type="">
      <title>2. Methodology</title>
      <p>This section delineates the dataset utilized in the study, along with the CNN architectures, layers, and activation functions applied to EEG signals of epilepsy patients.</p>
      
        <sec>
          
            <title>2.1. Dataset</title>
          
          <p style="text-align: justify">The dataset employed in this research, sourced from Kaggle (<xref ref-type="bibr" rid="ref_7">Epileptic Seizure Recognition., n.d.</xref>), is a modified version of a commonly used dataset for epileptic seizure detection. Originally, the dataset comprised five distinct classes, each containing 100 files, with each file recording 23.6 seconds of an individual's brain activity. These files were sampled to 4,097 data points per individual, representing the EEG recording values for 23.5 seconds. <xref ref-type="fig" rid="fig_1">Figure 1</xref> illustrates the first five lines of the epileptic seizure dataset.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Image of the epileptic seizure dataset example</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_2R1T8FJztNTcWzVi.png"/>
            </fig>
          
          <p>The original data, consisting of 4,097 points per recording, was segmented into 23 parts and reorganized to form a matrix of 23×500 = 11,500 data points. This restructuring resulted in each row comprising 178 data points for one second of recording, with the final column (column 179, labeled 'y') denoting the class (1-5). <xref ref-type="table" rid="table_1">Table 1</xref> presents the label value for each class.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Label value of each class</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Class</p></td><td colspan="1" rowspan="1"><p>Class Description</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>Recordings indicative of seizure activity.</p></td></tr><tr><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>EEG signals from regions with tumor presence.</p></td></tr><tr><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>EEG activity recorded from healthy brain regions, aiding in the identification of tumor locations.</p></td></tr><tr><td colspan="1" rowspan="1"><p>4</p></td><td colspan="1" rowspan="1"><p>Data captured with the patient's eyes closed.</p></td></tr><tr><td colspan="1" rowspan="1"><p>5</p></td><td colspan="1" rowspan="1"><p>Data captured while the patient's eyes were open.</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>In this dataset obtained from the Kaggle platform, subjects in the first class exhibited epileptic seizures, while those in the second, third, fourth, and fifth classes did not. The dataset underwent preprocessing, with all non-seizure activities labeled as class '0' and seizure activities as class '1'. It was subsequently divided into an 80% training set and a 20% test set.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Cnn</title>
          
          <p>CNN architecture, a cornerstone of deep learning neural networks, is prevalently applied in image classification and signal processing. Distinct from traditional machine learning architectures, deep learning models autonomously execute these tasks, eliminating the need for manual feature extraction and preprocessing. CNN architectures, bypassing the necessity for expert knowledge in feature extraction, directly extract features through the model itself, facilitating the learning process. This advantage has led to a surge in the use of CNN architectures in recent years. Fundamentally, CNNs comprise four layers: convolution, activation, pooling, and fully connected layers (<xref ref-type="bibr" rid="ref_20">Tripathy &amp;amp; Singh, 2022</xref>; <xref ref-type="bibr" rid="ref_4">Başaran, 2022</xref>).</p><p>CNN architectures, with their layered structure, are typically divided into two segments. The first encompasses the feature extraction process, employing combinations of input, convolution, and pooling layers. The second segment consists of a fully connected layer, executing the classification task. The arrangement of these layers is not standardized, allowing for the creation of novel models through adjustment of layer sequences and parameter values within the network.</p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Cnn layers</title>
          
          <p>This subsection elucidates the various layers and activation functions employed in the design of CNN architectures.</p>
          
            <sec>
              
                <title>2.3.1 Input layer</title>
              
              <p>Contrary to classical neural networks where data entry is a one-dimensional array, in CNN architectures, multidimensional array formats are utilized. The input layer transmits the raw image data, formatted as a matrix, to the convolutional layer (<xref ref-type="bibr" rid="ref_1">Alizard et al., 2022</xref>).</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.2 Convolutional layer</title>
              
              <p>The convolutional layer's objective is to extract features from the input image using diverse-sized filters, referred to as kernels. It is within these regions that features, defined by each filter, are discerned in the output generated by the convolution process (<xref ref-type="bibr" rid="ref_15">Pandian et al., 2022</xref>).</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.3 Pooling layer</title>
              
              <p>The pooling layer operates by moving specific filters across the image with a predetermined stepping value. This action reduces the input size for subsequent network layers, thereby diminishing computational load. This layer is instrumental in decreasing data size and computational costs, and it aids in preventing network overfitting<span style="color: windowtext">.</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.4 Activation layer</title>
              
              <p>Commonly preferred activation functions in CNN architectures include Softmax and Rectified Linear Unit (ReLU). However, other functions like Sigmoid, Tanh, and Leaky ReLU are also utilize (<xref ref-type="bibr" rid="ref_24">Yildirim &amp;amp; Cinar, 2022</xref>).</p><p>ReLU: Employed frequently in nonlinear and CNN architectures' intermediate layers, ReLU activates neurons selectively. It outputs zero for negative input values, thus deactivating neurons in such scenarios. While advantageous in reducing simultaneous neuron activation, its drawback lies in converting all negative values to zero (<xref ref-type="bibr" rid="ref_3">Bai et al., 2023</xref>).</p>
              
                <disp-formula>
                  <label>(1)</label>
                  <mml:math id="mqjlaoz5hs">
                    <mml:mrow>
                      <mml:mi>f</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>x</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>x</mml:mi>
                    </mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mi>maks</mml:mi>
                    <mml:mn>0</mml:mn>
                  </mml:math>
                </disp-formula>
              
              <p>Softmax: Primarily used for multi-class classification problems, Softmax differs from the binary classification-oriented sigmoid function. In multi-class models, the output layer's neuron count corresponds to the number of target classes (<xref ref-type="bibr" rid="ref_6">Dubey et al., 2022</xref>).</p>
              
                <disp-formula>
                  <label>(2)</label>
                  <mml:math id="mcl8pyfoky">
                    <mml:mi>σ</mml:mi>
                    <mml:mi>z</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>K</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>…</mml:mo>
                    <mml:mo>.</mml:mo>
                    <mml:mo>.</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mfrac>
                      <mml:msup>
                        <mml:mi>e</mml:mi>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>z</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:msup>
                      <mml:mrow>
                        <mml:munderover>
                          <mml:mo>∑</mml:mo>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mi>K</mml:mi>
                        </mml:munderover>
                        <mml:msup>
                          <mml:mi>e</mml:mi>
                          <mml:mi>z</mml:mi>
                        </mml:msup>
                        <mml:mi>k</mml:mi>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mtext> for </mml:mtext>
                    <mml:mn>1</mml:mn>
                  </mml:math>
                </disp-formula>
              
              <p>Sigmoid: This function, converting input values into a range between 0 and 1, is widely applied for its continuous differentiability and consistent neuron output signs.</p>
              
                <disp-formula>
                  <label>(3)</label>
                  <mml:math id="moi8fn8l7a">
                    <mml:mi>f</mml:mi>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mrow>
                      <mml:mo>/</mml:mo>
                    </mml:mrow>
                    <mml:msup>
                      <mml:mi>e</mml:mi>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(4)</label>
                  <mml:math id="mtjvtqlxf0">
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>f</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>′</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mrow>
                      <mml:mi>x</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>x</mml:mi>
                    </mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mi>sigmoid</mml:mi>
                  </mml:math>
                </disp-formula>
              
              <p>The choice of activation function varies based on the specific task at hand. For example, in classification problems, sigmoid functions might yield better results. However, the use of sigmoid and tanh is sometimes avoided due to the vanishing gradient issue, especially in hidden layers.</p><p>In the methodology, the ReLU activation function is predominantly applied in the hidden layers of the neural network architecture. This preference is attributed to the derivative of ReLU being one, which facilitates the learning process in these layers (<xref ref-type="bibr" rid="ref_18">Sharma et al., 2017</xref>).</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.5 Dropout layer</title>
              
              <p>To avert overfitting during training with large datasets, the dropout technique is applied, selectively deactivating nodes in the fully connected layer (<xref ref-type="bibr" rid="ref_21">Tufail et al., 2022</xref>).</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.6 Flatten layer</title>
              
              <p>The flatten layer converts matrix-sized data from convolution and pooling layers into a one-dimensional array, facilitating its processing in the fully connected layer (<xref ref-type="bibr" rid="ref_13">Nguyen et al., 2022</xref>).</p>
            </sec>
          
          
            <sec>
              
                <title>2.3.7 Fully connected and classifier layer</title>
              
              <p>In CNN architecture, preceding the classification layer, is a fully connected layer. This layer transforms multidimensional feature maps into a single dimension for classification. The fully connected layer's output is organized into classes equivalent to the target number of classes (<xref ref-type="bibr" rid="ref_14">Pal et al., 2022</xref>).</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec sec-type="results">
      <title>3. Results</title>
      <p>In this study, a CNN-based model was developed for the detection of epileptic seizures from EEG signals. To benchmark the performance of this model, established classifiers in the field were utilized. The model's efficacy was assessed using k-nearest neighbor (KNN), logistic regression, discriminant analysis, and AdaBoost classifiers, focusing on the classification of four distinct scenarios to predict epileptic seizure occurrences. A portion constituting 20% of the epileptic seizure dataset was allocated for testing purposes. The classification accuracy of the dataset, using the aforementioned classifiers, was determined via confusion matrices and accuracy rates. Various parameters, including accuracy, sensitivity, specificity, False Discovery Rate (FDR), False Positive Rate (FPR), False Negative Rate (FNR), and F1-score, were employed to gauge the models' performance (<xref ref-type="bibr" rid="ref_9">Eroğlu et al., 2021</xref>; <xref ref-type="bibr" rid="ref_23">Yildirim, 2023</xref>).</p>
      
        <sec>
          
            <title>3.1. Data preprocessing</title>
          
          <p>The preprocessing phase involved the EEG recording dataset. To achieve balance, classes were designated as '0' for non-seizure activities and '1' for seizure activities. Identification and rectification of any null or missing values were undertaken to maintain data integrity. The first five rows of the dataset, post-class assignment, are depicted in <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Preprocessed data image of the epileptic seizure dataset</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_GbpUYhKzvSX9KeBa.png"/>
            </fig>
          
          <p>Normalization of each EEG sample was conducted, encompassing 178 data points using the StandardScaler function. This normalization ensured a mean of 0 and a variance of 1 for all features. Adaptation of the data to meet the input requirements of the CNN was executed, resulting in the division of the dataset into an 80% training set and a 20% testing set.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Classification of eeg signals using classifiers</title>
          
          <p>In the current investigation, four different classifiers were evaluated for their efficacy in comparison with the proposed model. The first classifier under consideration was the KNN classifier. The confusion matrix generated by the KNN classifier is depicted in <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>KNN confusion matrix</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_IXQAmY81l7OBGXjs.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_KNad2v0fVSBCmlWa.png"/>
            </fig>
          
          <p>Analysis of the KNN confusion matrix (<xref ref-type="fig" rid="fig_3">Figure 3</xref>) revealed an accuracy rate of 92.48% in classifying the test data. Of the 2,300 data points allocated for testing, the KNN classifier accurately predicted 2,127 instances, with 173 being incorrectly classified. The classifier exhibited equivalent performance in both “0” (non-seizure) and “1” (seizure) classes. <xref ref-type="table" rid="table_2">Table 2</xref> presents the performance measurement metrics for the KNN classifier.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>KNN performance metric</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>FPR</p></td><td colspan="1" rowspan="1"><p>FNR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td></tr><tr><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>92.48%</p></td><td colspan="1" rowspan="1"><p>0.91</p></td><td colspan="1" rowspan="1"><p>1.00</p></td><td colspan="1" rowspan="1"><p>1.00</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.00</p></td><td colspan="1" rowspan="1"><p>0.09</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>92.48%</p></td><td colspan="1" rowspan="1"><p>1.00</p></td><td colspan="1" rowspan="1"><p>0.91</p></td><td colspan="1" rowspan="1"><p>0.63</p></td><td colspan="1" rowspan="1"><p>0.77</p></td><td colspan="1" rowspan="1"><p>0.09</p></td><td colspan="1" rowspan="1"><p>0.00</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Examination of the KNN classifier's performance metrics indicated a highest accuracy rate of 92.48% for both “0” and “1” classes. The logistic regression classifier was another tool used for analysis. <xref ref-type="fig" rid="fig_4">Figure 4</xref> illustrates the confusion matrix produced by this classifier.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Logistic regression confusion matrix</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_pK0fMfHZg566-6Ew.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_nk_0S65si-5n6NM7.png"/>
            </fig>
          
          <p>Upon scrutinizing the Logistic Regression confusion matrix (<xref ref-type="fig" rid="fig_4">Figure 4</xref>), an accuracy rate of 83.17% was observed in classifying the test dataset. The Logistic Regression classifier correctly identified 1,913 out of the 2, 300 test data, while incorrectly classifying 387 instances. Performance metrics for the logistic regression classifier are summarized in <xref ref-type="table" rid="table_3">Table 3</xref>.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Logistic regression performance metrics</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p></p></td><td colspan="1" rowspan="1"><p>Accuracy</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>FPR</p></td><td colspan="1" rowspan="1"><p>FNR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td></tr><tr><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>83.17%</p></td><td colspan="1" rowspan="1"><p>0.83</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>1.00</p></td><td colspan="1" rowspan="1"><p>0.90</p></td><td colspan="1" rowspan="1"><p>0.05</p></td><td colspan="1" rowspan="1"><p>0.17</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>83.17%</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.83</p></td><td colspan="1" rowspan="1"><p>0.18</p></td><td colspan="1" rowspan="1"><p>0.30</p></td><td colspan="1" rowspan="1"><p>0.17</p></td><td colspan="1" rowspan="1"><p>0.05</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The logistic regression classifier's performance metrics showed that the highest accuracy rate for both "0" and "1" classes was 83.17%. Additionally, discriminant analysis was utilized as a classifier for EEG signal categorization. The confusion matrix computed by the discriminant analysis classifier is shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>Discriminant analysis confusion matrix</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img__8-v7m2xoH_MsDvY.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_m02hgsxOToVszeG3.png"/>
            </fig>
          
          <p>Upon analysis of the discriminant analysis classifier's confusion matrix, as depicted in <xref ref-type="fig" rid="fig_5">Figure 5</xref>, a classification accuracy rate of 93.65% was observed for the test dataset. Of the 2,300 test data points, 2,154 were correctly identified and 146 misclassified by the discriminant analysis classifier. The classifier's performance demonstrated parity in both the “0” (non-seizure) and “1” (seizure) classes. <xref ref-type="table" rid="table_4">Table 4</xref> delineates the performance measurement metrics for the discriminant analysis classifier.</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Discriminant analysis performance metrics</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p> </p></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>FPR</p></td><td colspan="1" rowspan="1"><p>FNR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td></tr><tr><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>93.65%</p></td><td colspan="1" rowspan="1"><p>0.97</p></td><td colspan="1" rowspan="1"><p>0.82</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.96</p></td><td colspan="1" rowspan="1"><p>0.18</p></td><td colspan="1" rowspan="1"><p>0.03</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>93.65%</p></td><td colspan="1" rowspan="1"><p>0.82</p></td><td colspan="1" rowspan="1"><p>0.97</p></td><td colspan="1" rowspan="1"><p>0.88</p></td><td colspan="1" rowspan="1"><p>0.85</p></td><td colspan="1" rowspan="1"><p>0.03</p></td><td colspan="1" rowspan="1"><p>0.18</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The Discriminant Analysis classifier's performance metrics underscored an equal highest accuracy rate of 93.65% for both the "0" and "1" classes. Further, the AdaBoost classifier was evaluated, and its corresponding confusion matrix is presented in <xref ref-type="fig" rid="fig_6">Figure 6</xref>.</p>
          
            <fig id="fig_6">
              <label>Figure 6</label>
              <caption>
                <title>AdaBoost confusion matrix</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_kreogQ3fWFtsH2t8.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_3xSWOYeK1GHAk3rV.png"/>
            </fig>
          
          <p>The examination of the AdaBoost confusion matrix (<xref ref-type="fig" rid="fig_6">Figure 6</xref>) revealed an accuracy rate of 87.87% in classifying the test data. The AdaBoost classifier accurately predicted 2,021 instances, with 279 being incorrect classifications, out of the 2,300 data points allocated for testing. The classifier maintained consistent performance across the “0” and “1” classes. <xref ref-type="table" rid="table_5">Table 5</xref> displays the performance measurement metrics for the AdaBoost classifier.</p>
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>AdaBoost performance metrics</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p> </p></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>FPR</p></td><td colspan="1" rowspan="1"><p>FNR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td></tr><tr><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>87.87%</p></td><td colspan="1" rowspan="1"><p>0.90</p></td><td colspan="1" rowspan="1"><p>0.75</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.93</p></td><td colspan="1" rowspan="1"><p>0.25</p></td><td colspan="1" rowspan="1"><p>0.10</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>87.87%</p></td><td colspan="1" rowspan="1"><p>0.75</p></td><td colspan="1" rowspan="1"><p>0.90</p></td><td colspan="1" rowspan="1"><p>0.60</p></td><td colspan="1" rowspan="1"><p>0.67</p></td><td colspan="1" rowspan="1"><p>0.10</p></td><td colspan="1" rowspan="1"><p>0.25</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>An analysis of the AdaBoost classifier's performance metrics indicated the highest accuracy rate of 87.87% for both "0" and "1" classes.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Classification of eeg signals with the proposed cnn-based model</title>
          
          <p>The proposed model, employing a multilayer CNN, has been developed for the analysis and prediction of epileptic seizures from EEG data. A schematic representation of this model is provided in <xref ref-type="fig" rid="fig_7">Figure 7</xref>.</p>
          
            <fig id="fig_7">
              <label>Figure 7</label>
              <caption>
                <title>The proposed model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_x87LzWJjxlJYnL1N.png"/>
            </fig>
          
          <p>The primary architecture of the model is a CNN, which is particularly adept at processing time-series data, such as EEG readings. This CNN-based model encompasses an input layer, succeeded by alternating Conv1D and MaxPool1D layers. Each Conv1D layer is distinct in its filter count and kernel size and utilizes the ReLU activation function. MaxPool1D layers contribute to dimensionality reduction of the input, thereby decreasing the model's computational complexity. The reduced number of layers in the model ensures enhanced speed and efficiency in processing. The model is designed to alleviate the workload of experts and is feasible for use in non-specialist environments.</p><p>Incorporated after each convolution and max pooling layer is a dropout layer. This layer randomly disables a fraction of input units during each update in the training phase, a strategy intended to prevent overfitting.</p><p>The model culminates in a flatten layer, which collapses the spatial dimensions of the input into the channel size. This is followed by a dense layer comprising two neurons, employing the 'softmax' activation function. This layer is responsible for classifying the input into two categories: seizure and non-seizure, providing output probabilities.</p><p>For training, stochastic gradient descent is utilized as the optimization technique, and binary cross-entropy serves as the loss function. The performance of the model is assessed using various evaluation metrics. The confusion matrix corresponding to the classifier of the proposed model is illustrated in <xref ref-type="fig" rid="fig_8">Figure 8</xref>.</p>
          
            <fig id="fig_8">
              <label>Figure 8</label>
              <caption>
                <title>Confusion matrix of the proposed model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_UVspgb1mPhiK_ylJ.png"/>
            </fig>
          
          <p>Upon examining the confusion matrix of the proposed CNN-based model, as illustrated in <xref ref-type="fig" rid="fig_8">Figure 8</xref>, an accuracy rate of 97.65% was achieved in the classification of the test data. The model correctly classified 2,246 out of the 2,300 data points allocated for testing, with 54 instances of misclassification. Uniform performance was observed in both the "0" (non-seizure) and "1" (seizure) classes. To assess the model's performance more intricately, precision, recall, and F1-score for each class were considered, alongside the creation of confusion matrices and classification reports. The accuracy and loss curves for the training and test sets of the proposed model are displayed in <xref ref-type="fig" rid="fig_9">Figure 9</xref>.</p>
          
            <fig id="fig_9">
              <label>Figure 9</label>
              <caption>
                <title>Accuracy and loss curves of the proposed model: (a) Accuracy curve; (b) Loss curves</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_uGuiFu_lmCAHHC_a.png"/>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_ocnOsjqn-JUdf9Pi.png"/>
            </fig>
          
          <p>A comparative analysis between the proposed model and other classifiers revealed a smaller disparity between the training and test accuracy curves in the proposed model, as opposed to the wider differences observed in the accuracy curves of other classifiers. This suggests a higher rate of correct prediction for each class in the proposed model's confusion matrix, compared to other models. <xref ref-type="table" rid="table_6">Table 6</xref> presents the performance measurement metrics derived from the proposed model.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Performance metrics of the proposed model</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p> </p></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Sensitivity</p></td><td colspan="1" rowspan="1"><p>Specificity</p></td><td colspan="1" rowspan="1"><p>F1</p></td><td colspan="1" rowspan="1"><p>FPR</p></td><td colspan="1" rowspan="1"><p>FNR</p></td><td colspan="1" rowspan="1"><p>FDR</p></td></tr><tr><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>97.65%</p></td><td colspan="1" rowspan="1"><p>0.98</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.99</p></td><td colspan="1" rowspan="1"><p>0.99</p></td><td colspan="1" rowspan="1"><p>0.05</p></td><td colspan="1" rowspan="1"><p>0.02</p></td></tr><tr><td colspan="1" rowspan="1"><p>1</p></td><td colspan="1" rowspan="1"><p>97.65%</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>0.98</p></td><td colspan="1" rowspan="1"><p>0.93</p></td><td colspan="1" rowspan="1"><p>0.94</p></td><td colspan="1" rowspan="1"><p>0.02</p></td><td colspan="1" rowspan="1"><p>0.05</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>An examination of the proposed model's performance metrics underscored the highest accuracy rate of 97.65% for both "0" and "1" classes. <xref ref-type="table" rid="table_7">Table 7</xref> lists the accuracy values obtained in the proposed model alongside the four other classifiers used in the study.</p>
          
            <table-wrap id="table_7">
              <label>Table 7</label>
              <caption>
                <title>Accuracy values of the classifiers and the proposed model</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>KNN</p></td><td colspan="1" rowspan="1"><p>Logistic Regression</p></td><td colspan="1" rowspan="1"><p>Discriminant Analysis</p></td><td colspan="1" rowspan="1"><p>AdaBoost</p></td><td colspan="1" rowspan="1"><p>Proposed Model</p></td></tr><tr><td colspan="1" rowspan="1"><p>92.48</p></td><td colspan="1" rowspan="1"><p>83.17</p></td><td colspan="1" rowspan="1"><p>93.65</p></td><td colspan="1" rowspan="1"><p>87.87</p></td><td colspan="1" rowspan="1"><p>97.65</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>In the classification process of two distinct conditions derived from the epileptic seizure dataset, the proposed CNN-based model attained the highest accuracy rate, recorded at 97.65%. This performance was comparatively superior to that of other classifiers: discriminant analysis achieved an accuracy of 93.65%, KNN reached 92.48%, AdaBoost obtained 87.87%, and logistic regression was at 83.17%.</p><p>The proposed model, which yielded the highest accuracy, accurately predicted 2,246 out of 2,300 test data points, with 54 instances of misclassification. Analysis of the performance metrics indicated that both classes "0" and "1" achieved an equivalent highest accuracy of 97.65%.</p><p>Conversely, the classifier with the lowest accuracy was logistic regression, which correctly classified 1,913 out of 2,300 data points, misclassifying 387. Upon reviewing the performance metrics of the logistic regression classifier, it was observed that both the "0" class and the "1" class attained an accuracy rate of 83.17%.</p>
        </sec>
      
    </sec>
    <sec sec-type="discussion">
      <title>4. Discussion</title>
      <p>In the present study, a multilayer CNN model was developed for the automated detection of epileptic seizures from EEG recordings. The process encompassing data preprocessing, model training, and testing revealed that the model is capable of detecting seizures with an accuracy of 97.65%. This high degree of accuracy was also mirrored in the sensitivity, specificity, and F1-score metrics.</p><p>When compared to traditional classifiers such as discriminant analysis, KNN, AdaBoost, and Logistic Regression, which achieved accuracies of 93.65%, 92.48%, 87.87%, and 83.17% respectively, the proposed CNN model exhibited superior performance. This enhanced efficacy can be attributed to the deep learning capabilities of the CNN, which are adept at extracting complex features from time-series data. The comparative performance of the proposed model and these classifiers is depicted in <xref ref-type="fig" rid="fig_10">Figure 10</xref>.</p>
      
        <fig id="fig_10">
          <label>Figure 10</label>
          <caption>
            <title>Accuracy of the proposed model and classifiers</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/11/img_W4vNtHG3n7IhDGSI.png"/>
        </fig>
      
      <p>However, the model is not without limitations. The performance is notably contingent on the distribution and quality of the training dataset. To address this, future work will focus on training the model using larger and more varied EEG datasets. This approach is anticipated to further enhance the performance and robustness of the model.</p><p>In conclusion, the CNN model developed in this study has demonstrated its effectiveness as a tool for the automatic diagnosis of epileptic seizures. Such advancements in seizure detection hold the potential to significantly improve the management and monitoring of epilepsy treatment, ultimately contributing to better patient quality of life.</p>
    </sec>
    <sec sec-type="">
      <title>5. Conclusion</title>
      <p>Epileptic seizures, resulting from cerebral abnormalities, affect approximately 1% of the global population and can have indirect impacts on patient health. Accurate prediction and early intervention are crucial in managing these seizures. In response to this need, a computer-aided model based on CNN technology was developed in this study. This method facilitates early diagnosis of epileptic seizures, potentially enabling more timely treatment.</p><p>The CNN-based model exhibited a high degree of effectiveness, achieving an accuracy of 97.65%. Such performance indicates that the model not only reduces the workload of healthcare professionals but also minimizes the likelihood of conventional diagnostic errors. Moreover, its utility extends beyond expert settings, suggesting its applicability in broader, non-specialist environments.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>073902</page-range>
          <issue>7</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Alizard</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Gibis</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Selent</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Rist</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Wenzel</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1103/physrevfluids.7.073902.</pub-id>
          <article-title>Stochastic receptivity of laminar compressible boundary layers: An input-output analysis</article-title>
          <source>Phys. Rev. Fluids</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>100444</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Almustafa</surname>
              <given-names>K. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.imu.2020.100444.</pub-id>
          <article-title>Classification of epileptic seizure dataset using different machine learning algorithms</article-title>
          <source>Inf. Med. Unlocked</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>446-474</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bai</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Gautam</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Sojoudi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1137/21m1467134.</pub-id>
          <article-title>Efficient global optimization of two-layer relu networks: Quadratic-time algorithms and adversarial training</article-title>
          <source>SIAM J. Appl. Math. Data Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>148</volume>
          <page-range>105857</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Başaran</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compbiomed.2022.105857.</pub-id>
          <article-title>A new brain tumor diagnostic model: Selection of textural feature extraction algorithms and convolution neural network features with optimization algorithms</article-title>
          <source>Comput. Biol. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>41</volume>
          <page-range>461-484</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Beeraka</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Sameer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ghosh</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Accuracy enhancement of epileptic seizure detection: A deep learning approach with hardware realization of STFT.</article-title>
          <source>Circuits, Syst., Sign. Proces.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>503</volume>
          <page-range>92-108</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dubey</surname>
              <given-names>S. R.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Chaudhuri</surname>
              <given-names>B. B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neucom.2022.06.111.</pub-id>
          <article-title>Activation functions in deep learning: A comprehensive survey and benchmark</article-title>
          <source>Neurocomputing</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="webpage">
          <article-title>Epileptic Seizure Recognition.</article-title>
          <source>, https://www.kaggle.com/datasets/harunshimanto/epileptic-seizure-recognition</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>342-349</page-range>
          <issue>4</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eroğlu</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Eroğlu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Yıldırım</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Karlıdag</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Çınar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Akyiğit</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kaygusuz</surname>
              <given-names>İ.</given-names>
            </name>
            <name>
              <surname>Yıldırım</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Keleş</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Yalçın</surname>
              <given-names>Ş.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">https://doi.org/10.5152/iao.2023.221004.</pub-id>
          <article-title>Comparison of computed tomography-based artificial intelligence modeling and magnetic resonance imaging in diagnosis of cholesteatoma.</article-title>
          <source>J Int Adv Otol.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>133</volume>
          <page-range>104407</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eroğlu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Yildirim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Çinar</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compbiomed.2021.104407.</pub-id>
          <article-title>CNNs based classification of breast ultrasonography images by hybrid method with respect to benign, malignant, and normal using mRMR</article-title>
          <source>Comput. Biol. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>4543-4550</page-range>
          <issue>8</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Eroglu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Yildirim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cinar</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Diagnosis of periventricular leukomalacia in children with artificial intelligence-based models developed using brain magnetic resonance images.</article-title>
          <source>Signal, Image Video Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>1456</volume>
          <page-range>012017</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mao</surname>
              <given-names>W. L.</given-names>
            </name>
            <name>
              <surname>Fathurrahman</surname>
              <given-names>H. I. K.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>T. W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1742-6596/1456/1/012017.</pub-id>
          <article-title>EEG dataset classification using CNN method</article-title>
          <source>J. Phys.: Conf. Ser.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <page-range>1-13</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mian Qaisar</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Subasi</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Effective epileptic seizure detection based on the event-driven processing and machine learning for mobile healthcare.</article-title>
          <source>J. Ambient Intell. Humanized Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>2071</page-range>
          <issue>10</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nguyen</surname>
              <given-names>H. T.</given-names>
            </name>
            <name>
              <surname>Crittenden</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Weiss</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Bardaweel</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/polym14102071.</pub-id>
          <article-title>Experimental modal analysis and characterization of additively manufactured polymers</article-title>
          <source>Polymers</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>150</volume>
          <page-range>106083</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pal</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Reddy</surname>
              <given-names>P. B.</given-names>
            </name>
            <name>
              <surname>Roy</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compbiomed.2022.106083</pub-id>
          <article-title>Attention UW-Net: A fully connected model for automatic segmentation and annotation of chest X-ray</article-title>
          <source>Comput. Biol. Med.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>1266</page-range>
          <issue>8</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pandian</surname>
              <given-names>J. A.</given-names>
            </name>
            <name>
              <surname>Kanchanadevi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>V. D.</given-names>
            </name>
            <name>
              <surname>Jasińska</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Goňo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Leonowicz</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Jasiński</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A five convolutional layer deep convolutional neural network for plant leaf disease detection.</article-title>
          <source>Electron.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>170</volume>
          <page-range>114533</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Prathaban</surname>
              <given-names>B. P.</given-names>
            </name>
            <name>
              <surname>Balasubramanian</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.eswa.2020.114533.</pub-id>
          <article-title>Dynamic learning framework for epileptic seizure prediction using sparsity based EEG Reconstruction with Optimized CNN classifier</article-title>
          <source>Expert Syst. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>62</volume>
          <page-range>102106</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sarić</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Jokić</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Beganović</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Pokvić</surname>
              <given-names>L. G.</given-names>
            </name>
            <name>
              <surname>Badnjević</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.bspc.2020.102106.</pub-id>
          <article-title>FPGA-based real-time epileptic seizure classification using artificial neural network</article-title>
          <source>Biomed. Signal Process. Control</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>310-316</page-range>
          <issue>12</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sharma</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sharma</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Athaiya</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Activation functions in neural networks.</article-title>
          <source>Towards Data Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>77</volume>
          <page-range>103820</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wen</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.bspc.2022.103820.</pub-id>
          <article-title>An EEG based real-time epilepsy seizure detection approach using discrete wavelet transform and machine learning methods</article-title>
          <source>Biomed. Signal Process. Control</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conf-paper">
          <page-range>pp.145-153</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tripathy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Convolutional neural network: An overview and application in image classification.</article-title>
          <source>In Proceedings of Third International Conference on Sustainable Computing: SUSCOM 2021, Jaipur, India</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>14695</page-range>
          <issue>22</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tufail</surname>
              <given-names>A. B.</given-names>
            </name>
            <name>
              <surname>Ullah</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>R. A.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>Y. K.</given-names>
            </name>
            <name>
              <surname>Khokhar</surname>
              <given-names>N. H.</given-names>
            </name>
            <name>
              <surname>Sadiq</surname>
              <given-names>M. T.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Shafiq</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Eldin</surname>
              <given-names>E. T.</given-names>
            </name>
            <name>
              <surname>Ghamry</surname>
              <given-names>N. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/su142214695.</pub-id>
          <article-title>On disharmony in batch normalization and dropout methods for early categorization of Alzheimer’s disease</article-title>
          <source>Sustainability</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <page-range>pp.1-4</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Sawan</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/aicas51828.2021.9458571.</pub-id>
          <article-title>A novel multi-scale dilated 3D CNN for epileptic seizure prediction</article-title>
          <source>In 2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS), Washington, DC, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>9926</page-range>
          <issue>17</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yildirim</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app13179926.</pub-id>
          <article-title>Image visualization and classification using hydatid cyst images with an explainable hybrid model</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>32</volume>
          <page-range>155-162</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yildirim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cinar</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1002/ima.22623.</pub-id>
          <article-title>Classification with respect to colon adenocarcinoma and colon benign tissue of coon histlopathological images with a new CNN model: MA_ColonNET</article-title>
          <source>Int. J. Imaging Syst. Technol.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>