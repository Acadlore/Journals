<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATAMS</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on Applied Mathematics and Statistics</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Appl Math. Stat.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATAMS</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2959-4065</issn>
      <issn publication-format="print">2959-4057</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-T01Fwi6IiHQl2AxK-2W93jjzMS4XuB23</article-id>
      <article-id pub-id-type="doi">10.56578/atams030102</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>An Uncertainty-Driven Fuzzy Energy Level Set Model for Robust and Adaptive Image Segmentation</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-9087-0637</contrib-id>
          <name>
            <surname>Naeem</surname>
            <given-names>Muhammad Zeeshan</given-names>
          </name>
          <email>mzeeshan@qurtuba.edu.pk</email>
        </contrib>
        <aff id="aff_1">Department of Mathematics, Qurtuba University of Science and Information Technology, 25000 Peshawar, Pakistan</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>30</day>
        <month>03</month>
        <year>2025</year>
      </pub-date>
      <volume>3</volume>
      <issue>1</issue>
      <fpage>13</fpage>
      <lpage>23</lpage>
      <page-range>13-23</page-range>
      <history>
        <date date-type="received">
          <day>14</day>
          <month>01</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>13</day>
          <month>03</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Â©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Accurate and robust image segmentation remains a fundamental challenge in computer vision, particularly in the presence of intensity inhomogeneity, noise, and weak object boundaries. To address these challenges, we propose a Robust Pythagorean Fuzzy Energy-Based Level Set (RPFELS) model, which integrates a novel fuzzy energy formulation with level set evolution to enhance segmentation precision and resilience against noise. The model introduces a Pythagorean fuzzy divergence term to refine energy optimization, ensuring adaptive boundary preservation and reducing sensitivity to intensity variations. Additionally, a bounded fuzzy energy constraint is incorporated to ensure numerical stability and prevent energy leakage during evolution. Extensive experiments on benchmark datasets, including medical and natural images, validate the effectiveness of RPFELS. The model consistently outperforms recent selective segmentation methods in terms of Dice Score, Jaccard Index, and Hausdorff Distance, achieving superior segmentation accuracy and reduced boundary errors. Furthermore, a detailed statistical significance analysis using paired t-tests confirms that the observed improvements are statistically significant (p-value $&lt;$ 0.01), reinforcing the reliability of the proposed approach. Moreover, RPFELS exhibits higher computational efficiency, achieving faster convergence rates compared to existing methods. These findings highlight the robustness and versatility of the proposed approach in handling challenging segmentation scenarios, making it suitable for applications in medical imaging, remote sensing, and industrial defect detection. By ensuring bounded energy evolution and statistically validated performance gains, our model sets a new benchmark in selective segmentation.</p></abstract>
      <kwd-group>
        <kwd>Pythagorean fuzzy sets</kwd>
        <kwd>Level set function</kwd>
        <kwd>Image segmentation</kwd>
        <kwd>Bounded function</kwd>
        <kwd>Image processing</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="1"/>
        <fig-count count="4"/>
        <table-count count="1"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Image processing is a fundamental area of research in computer vision, playing a vital role in various domains such as medical imaging, remote sensing, industrial inspection, autonomous navigation, and surveillance [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>]. It involves a broad spectrum of computational techniques aimed at enhancing, analyzing, and interpreting visual data. One of the most critical tasks in image processing is image segmentation, which refers to the process of partitioning an image into distinct and meaningful regions. Accurate segmentation facilitates key applications such as object detection, pattern recognition, and scene understanding [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>]. However, image segmentation remains a challenging problem due to various factors, including noise, illumination variations, occlusions, and the complexity of object boundaries. Therefore, developing robust segmentation models that can effectively handle these challenges is crucial for improving automated visual analysis systems.</p><p>Selective image segmentation is a specialized approach in image processing that focuses on isolating specific objects of interest while disregarding irrelevant background regions [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>], [<xref ref-type="bibr" rid="ref_10">10</xref>]. This technique plays a crucial role in various domains, including medical imaging, industrial defect detection, and remote sensing. In medical applications, accurate segmentation of anatomical structures, tumors, or pathological regions is essential for diagnosis and treatment planning [<xref ref-type="bibr" rid="ref_7">7</xref>]. Similarly, in industrial quality control, selective segmentation enables the precise detection of defects by focusing only on defective areas while ignoring unblemished regions. Furthermore, in satellite and remote sensing imagery, land use and land cover (LULC) classification depends on the accurate segmentation of specific terrain features, such as forests, water bodies, or urban areas, to facilitate environmental monitoring and resource management [<xref ref-type="bibr" rid="ref_8">8</xref>]. Unlike global segmentation techniques, which aim to classify every pixel in an image into different categories, selective segmentation prioritizes target regions, making it more efficient in applications where prior knowledge about the object of interest is available [<xref ref-type="bibr" rid="ref_9">9</xref>]. However, traditional segmentation methods, such as thresholding, edge detection, and region-growing techniques, often struggle with complex backgrounds, overlapping intensity distributions, and noise, which can degrade segmentation accuracy.</p><p>Recent advancements in image segmentation have been significantly influenced by novel computational techniques, including convolution-based models, divergence-driven methods, and multi-level thresholding strategies. These approaches have shown promising results by enhancing segmentation accuracy through improved feature extraction and optimization techniques [<xref ref-type="bibr" rid="ref_11">11</xref>]. Convolution-based architectures have been particularly effective in capturing spatial relationships within images, facilitating more precise boundary detection and object delineation. Additionally, multi-level thresholding segmentation methods have emerged as a powerful tool in image processing, offering efficient and adaptive segmentation solutions across various applications [<xref ref-type="bibr" rid="ref_12">12</xref>].</p><p>Despite the advancements in deep learning and conventional statistical segmentation techniques, fuzzy-based segmentation models continue to play a crucial role in improving segmentation accuracy, adaptability, and robustness across various domains [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>], [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>]. These models leverage fuzzy logic principles to handle uncertainty, noise, and intensity variations in complex images, making them particularly suitable for medical, remote sensing, and low-light imaging applications. For instance, intelligent fuzzy image segmentation systems have been explored for engineering and pedagogical applications, enhancing automation and precision in professional training environments [<xref ref-type="bibr" rid="ref_13">13</xref>]. Similarly, fuzzy similarity measures have been utilized for pattern recognition and image segmentation, offering novel techniques for improving classification accuracy in artificial intelligence-driven applications [<xref ref-type="bibr" rid="ref_14">14</xref>].</p><p>In medical imaging, fuzzy entropy-based segmentation approaches have significantly improved automated white matter lesion detection in MRIs, providing an effective tool for diagnosing multiple sclerosis with greater accuracy and reliability [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>]. Additionally, fuzzy hybrid meta-optimized learning frameworks have emerged as powerful solutions for medical image segmentation, integrating optimization techniques with fuzzy logic to enhance diagnostic precision and clinical decision-making [<xref ref-type="bibr" rid="ref_17">17</xref>]. These fuzzy-based models continue to evolve, offering scalable, computationally efficient, and adaptable solutions for diverse segmentation tasks.</p><p>Despite significant advancements in fuzzy-based segmentation models, existing methods often struggle with intensity inhomogeneity, weak edges, and noise, leading to suboptimal segmentation accuracy. Traditional level set approaches suffer from numerical instability, while conventional fuzzy models, including intuitionistic fuzzy sets and interval type-2 fuzzy sets, fail to provide adaptive contour evolution for complex images. Moreover, existing fuzzy divergence-based constraints lack a mechanism to prevent over-segmentation while maintaining smooth boundary transitions.</p><p>To address these limitations, we propose a novel selective segmentation model that integrates a Pythagorean fuzzy membership function, a fuzzy divergence operator, and an entropy-regularized energy functional. Unlike intuitionistic fuzzy sets, which rely on a single hesitation degree, Pythagorean fuzzy sets provide a greater degree of flexibility in uncertainty modeling by allowing the squared sum of membership and non-membership values to be at most one. This enhances the ability to capture fine-grained variations in image intensities, leading to superior segmentation performance. Compared to interval type-2 fuzzy sets, which require complex computational operations to handle uncertainty, our approach maintains computational efficiency while preserving segmentation accuracy.</p><p>The proposed model operates by leveraging a Pythagorean fuzzy membership function to ensure a smooth and adaptive transition between the object and background, making it robust to intensity variations. The fuzzy divergence is introduced to regulate boundary evolution, preventing over-segmentation while maintaining contour flexibility. The energy functional integrates region-based, gradient-based, and divergence-based constraints, enabling precise object localization and enhanced boundary preservation. Unlike conventional fuzzy-based segmentation models that struggle with balancing local and global intensity distributions, our entropy-regularized energy functional dynamically adapts to spatial variations, improving robustness against noise and weak edges.</p><p>The segmentation process is guided by an energy minimization framework, where the level set function evolves iteratively to minimize the proposed functional, leading to an optimal partitioning of the image. The integration of Pythagorean fuzzy sets with divergence-driven constraints provides a theoretical advancement over conventional fuzzy segmentation techniques by ensuring better boundary localization, reduced numerical instability, and improved adaptability to complex intensity distributions.</p><p>To ensure the stability and reliability of the model, we establish the boundedness of the proposed energy functional. The energy components, including the region-based term, fuzzy divergence constraint, and gradient regularization, are mathematically formulated to remain within finite bounds under appropriate parameter settings. The bounded nature of the function guarantees that the segmentation process does not diverge, ensuring convergence to a stable solution. This property is crucial for maintaining numerical stability and preventing excessive contour deformation during optimization. By proving the boundedness, we confirm that the proposed model provides a well-posed and computationally efficient framework for selective image segmentation, making it suitable for complex real-world applications.</p>
    </sec>
    <sec sec-type="">
      <title>2. Related works</title>
      <p>Selective image segmentation plays a crucial role in various applications, including medical imaging, object detection, and scene understanding. Traditional segmentation approaches rely on edge-based and region-based methods; however, these techniques often struggle with complex backgrounds, noise, and intensity inhomogeneity. Recent advancements have incorporated saliency functions, uncertainty-based active learning, and adaptive selection mechanisms to enhance segmentation accuracy. This section reviews three prominent models: Selective Image Segmentation Driven by Region, Edge, and Saliency Functions [<xref ref-type="bibr" rid="ref_18">18</xref>], Selective Uncertainty-Based Active Learning for Medical Image Segmentation [<xref ref-type="bibr" rid="ref_19">19</xref>], and Adaptive Selection-Based Referring Image Segmentation [<xref ref-type="bibr" rid="ref_20">20</xref>]. While these models have demonstrated significant improvements in segmentation accuracy and robustness, they still face challenges related to noise sensitivity and intensity inhomogeneity, which affect their performance in real-world scenarios.</p>
      
        <sec>
          
            <title>2.1. Selective image segmentation driven by region, edge, and saliency functions</title>
          
          <p>Soomro et al. [<xref ref-type="bibr" rid="ref_18">18</xref>] proposed a selective image segmentation model integrating region-based, edge-based, and saliency-driven functions to improve segmentation accuracy. The model effectively handles complex object boundaries by leveraging multiple cues to refine the segmentation process. The energy functional for this model is given by:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mi3fwjt8bm">
                <mml:mi>E</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>R</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mi>E</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mi>S</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:msub>
                  <mml:mi>Î»</mml:mi>
                  <mml:mn>1</mml:mn>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mi>Î»</mml:mi>
                  <mml:mn>2</mml:mn>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mi>Î»</mml:mi>
                  <mml:mn>3</mml:mn>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mcxd8eilqj">
    <mml:mi>R</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represents the region-based term, <inline-formula>
  <mml:math id="m6k45j14fd">
    <mml:mi>E</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> accounts for edge-based constraints, and <inline-formula>
  <mml:math id="my0wcrtrvn">
    <mml:mi>S</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> incorporates saliency information. The parameters <inline-formula>
  <mml:math id="moj3c4okbx">
    <mml:msub>
      <mml:mi>Î»</mml:mi>
      <mml:mn>1</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula>, <inline-formula>
  <mml:math id="mfnnxk9lx8">
    <mml:msub>
      <mml:mi>Î»</mml:mi>
      <mml:mn>2</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula>, and <inline-formula>
  <mml:math id="mt1h37n3zw">
    <mml:msub>
      <mml:mi>Î»</mml:mi>
      <mml:mn>3</mml:mn>
    </mml:msub>
  </mml:math>
</inline-formula> balance the influence of each term. The model successfully combines multiple segmentation cues, leading to enhanced robustness against varying object structures and complex backgrounds. It significantly improves segmentation accuracy compared to conventional edge and region-based methods.</p><p>Despite its effectiveness, the model struggles with intensity inhomogeneity, leading to segmentation errors in images with uneven illumination. Additionally, it remains sensitive to noise, which can distort the segmentation boundaries, especially in low-contrast regions.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Selective uncertainty-based active learning for medical image segmentation</title>
          
          <p>Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] introduced an active learning-based segmentation model that dynamically selects the most informative samples to refine segmentation accuracy. This model introduces an efficient active learning strategy that significantly reduces the annotation effort while improving segmentation performance. It adapts dynamically to different medical image datasets, making it well-suited for real-world applications. The energy function for their model is formulated as:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="m9w59db97w">
                <mml:mi>E</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>U</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mi>Î²</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mo>|</mml:mo>
                  <mml:mi>â</mml:mi>
                  <mml:mi>Ï</mml:mi>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mk5t0jc1ii">
    <mml:mi>U</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> denotes the uncertainty-based selection function and <inline-formula>
  <mml:math id="mv6pt4fy38">
    <mml:mi>Î²</mml:mi>
  </mml:math>
</inline-formula> controls the influence of the regularization term to ensure smooth segmentation boundaries. While the model effectively reduces annotation overhead, its reliance on uncertainty-based selection can lead to instability in cases of high noise levels and intensity inhomogeneity. Moreover, the method may require fine-tuning of hyperparameters to achieve optimal performance across different datasets.</p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Adaptive selection-based referring image segmentation</title>
          
          <p>Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] proposed an adaptive selection mechanism for referring image segmentation, focusing on improving segmentation accuracy for complex scenes. The energy function for their model is given by:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="m0yhdvc8jq">
                <mml:mi>E</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>A</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mi>Î³</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msup>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi>â</mml:mi>
                    <mml:mi>Ï</mml:mi>
                  </mml:mrow>
                  <mml:mn>2</mml:mn>
                </mml:msup>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="m2uwdrtzid">
    <mml:mi>A</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represents the adaptive selection term and <inline-formula>
  <mml:math id="moj4zuu717">
    <mml:mi>Î³</mml:mi>
  </mml:math>
</inline-formula> controls the smoothness of the segmentation boundaries.</p><p>The model demonstrates improved generalization across diverse datasets, making it effective for complex object segmentation tasks. The adaptive selection mechanism allows for better feature learning and segmentation accuracy. Despite its advantages, the model is sensitive to noise and suffers from segmentation errors in images with contrast inconsistencies. Additionally, it requires high computational resources due to the complex adaptive selection mechanism.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Our proposed formulation</title>
      <p>To address intensity variations and noise in selective segmentation, we propose a Pythagorean fuzzy membership function for smoother object-background separation. This enhances robustness and reduces segmentation artifacts. A fuzzy divergence \( D_{\text{fuzzy}}(\phi) \) is introduced to regulate contour evolution, preventing over-segmentation while preserving boundaries. Our energy function integrates entropy-based regularization and fuzzy divergence constraints, ensuring accurate segmentation in noisy and weak-edge regions. The corresponding level set evolution equation enhances adaptability and efficiency.</p>
      
        <sec>
          
            <title>3.1. Pythagorean fuzzy membership function $\boldsymbol{f(\phi)}$</title>
          
          <p>In image selective segmentation, accurately distinguishing between the target object and the background is crucial. Traditional level set methods rely on the Heaviside function, which can be sensitive to intensity variations and prone to numerical instability. To address these challenges, the proposed model integrates a Pythagorean fuzzy membership function that provides a smoother and more adaptive transition for object-background separation. The Pythagorean fuzzy function is defined as:</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="miyv67mor8">
                <mml:mi>F</mml:mi>
                <mml:mi>Ï</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>Î¼</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mi>Ï</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>Î¼</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>Î½</mml:mi>
                      <mml:mi>P</mml:mi>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mi>Ï</mml:mi>
                    <mml:mi>Ï</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where,</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="mdjwi8l844">
                <mml:msub>
                  <mml:mi>Î¼</mml:mi>
                  <mml:mi>P</mml:mi>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:msup>
                  <mml:mi>e</mml:mi>
                  <mml:mrow>
                    <mml:mo>â</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi>Î±</mml:mi>
                    <mml:mi>Ï</mml:mi>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msup>
              </mml:math>
            </disp-formula>
          
          <p>and</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="mifsqde21x">
                <mml:msub>
                  <mml:mi>Î½</mml:mi>
                  <mml:mi>P</mml:mi>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:msqrt>
                  <mml:mn>1</mml:mn>
                  <mml:mo>â</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msubsup>
                    <mml:mi>Î¼</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msubsup>
                  <mml:mi>Ï</mml:mi>
                </mml:msqrt>
              </mml:math>
            </disp-formula>
          
          <p>where, \( \mu_P(\phi) \) and \( \nu_P(\phi) \) represent the membership and non-membership degrees of a pixel belonging to the object region, respectively. The parameter \( \alpha \) controls the smoothness of the transition, allowing for adaptive contour evolution.</p><p>This formulation offers several advantages for selective image segmentation. First, the exponential decay function \( \mu_P(\phi) \) ensures a gradual transition between object and background, reducing segmentation artifacts. Second, the Pythagorean fuzzy function enhances robustness by efficiently handling intensity inhomogeneity, providing a more flexible representation of pixel classification. Third, it improves boundary localization by avoiding sharp transitions that can lead to segmentation errors, ensuring better adherence to object boundaries. Finally, unlike traditional level set functions, the Pythagorean fuzzy function adapts dynamically to local intensity distributions, making it highly effective for selective segmentation tasks. By leveraging this robust fuzzy membership function, the proposed model significantly improves segmentation accuracy, particularly in challenging images with noise, weak edges, and intensity variations.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Fuzzy divergence $\boldsymbol{d_{\text{fuzzy}}(\phi)}$</title>
          
          <p>The design of an effective divergence constraint is crucial in image selective segmentation to ensure smooth boundary transitions while preventing over-segmentation. Traditional divergence-based constraints often struggle with intensity inhomogeneity and noise, leading to inaccurate segmentation results. To overcome these limitations, we introduce a fuzzy divergence \( D_{\text{fuzzy}}(\phi) \), which is mathematically grounded in variational principles and measure theory. This term enforces a well-regularized segmentation process by dynamically adapting to local intensity distributions, allowing robust object-background separation. The fuzzy divergence is defined as:</p>
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="mw8e0z9b09">
                <mml:msub>
                  <mml:mi>D</mml:mi>
                  <mml:mrow>
                    <mml:mtext>fuzzy</mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mo>â«</mml:mo>
                  <mml:mrow>
                    <mml:mi>Î©</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:mi>d</mml:mi>
                <mml:mi>Î©</mml:mi>
                <mml:mrow>
                  <mml:mo minsize="2.470em" maxsize="2.470em">(</mml:mo>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo minsize="2.470em" maxsize="2.470em">)</mml:mo>
                </mml:mrow>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>â</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>Ï</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>â</mml:mi>
                    <mml:mi>x</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>â</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>Ï</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>â</mml:mi>
                    <mml:mi>y</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:msup>
                  <mml:mrow>
                    <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                  </mml:mrow>
                  <mml:mi>p</mml:mi>
                </mml:msup>
                <mml:msup>
                  <mml:mrow>
                    <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                  </mml:mrow>
                  <mml:mi>p</mml:mi>
                </mml:msup>
              </mml:math>
            </disp-formula>
          
          <p>where, \( p \) is a tuning parameter that controls the divergence effect and influences the smoothness of the segmentation boundaries. The proposed formulation builds upon the total variation (TV) regularization principle, which is widely used in image processing to preserve edges while reducing noise. By leveraging the Pythagorean fuzzy function \( F(\phi) \), the operator dynamically adjusts to spatial intensity variations, mitigating the limitations of conventional divergence constraints that often result in over-segmentation or weak boundary localization. When \( p &gt; 1 \), the <inline-formula>
  <mml:math id="m403pj9hn9">
    <mml:msub>
      <mml:mi>D</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>Ï</mml:mi>
  </mml:math>
</inline-formula> enforces stronger boundary regularization, preventing excessive contour deformation and reducing sensitivity to minor intensity variations. Conversely, for \( p \approx 1 \), the formulation allows more flexible contour evolution, making it particularly effective in texture-rich and complex regions.</p><p>The mathematical construction of \( D_{\text{fuzzy}}(\phi) \) is derived from energy minimization principles, ensuring stable contour evolution and optimal partitioning of the image domain. The integral formulation serves as a global regularization term, ensuring smooth transitions between regions while penalizing abrupt changes in the fuzzy membership function. Additionally, the proposed operator aligns with level set methods, where energy minimization governs the evolution of the segmentation contour. The Euler-Lagrange equation is employed to derive the optimal update rule for contour evolution, leading to precise object localization and enhanced boundary preservation.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Robust energy functional of the proposed model</title>
          
          <p>To achieve accurate and robust selective image segmentation, we introduce a fuzzy energy-based model that integrates entropy-based regularization and fuzzy divergence. This model effectively balances object-background separation while preserving structural integrity and reducing sensitivity to noise and intensity variations.</p><p>The energy functional of the proposed model is formulated as:</p>
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="mlww00nr0j">
                <mml:mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mi>E</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>=</mml:mo>
                    </mml:mtd>
                    <mml:mtd>
                      <mml:mtext>Â </mml:mtext>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mi>Î©</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>in</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mi>Î©</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>out</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mn>1</mml:mn>
                    </mml:mtd>
                  </mml:mtr>
                  <mml:mtr>
                    <mml:mtd/>
                    <mml:mtd>
                      <mml:mi/>
                      <mml:mi>Î³</mml:mi>
                      <mml:mi>â</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mi>Î·</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mi>Î©</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mi>Î©</mml:mi>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>+</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo>|</mml:mo>
                            <mml:mo>|</mml:mo>
                            <mml:mfrac>
                              <mml:mrow>
                                <mml:mi>â</mml:mi>
                                <mml:mi>F</mml:mi>
                                <mml:mi>Ï</mml:mi>
                                <mml:mo>(</mml:mo>
                                <mml:mo>)</mml:mo>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>â</mml:mi>
                                <mml:mi>x</mml:mi>
                              </mml:mrow>
                            </mml:mfrac>
                          </mml:mrow>
                          <mml:mi>p</mml:mi>
                        </mml:msup>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo>|</mml:mo>
                            <mml:mo>|</mml:mo>
                            <mml:mfrac>
                              <mml:mrow>
                                <mml:mi>â</mml:mi>
                                <mml:mi>F</mml:mi>
                                <mml:mi>Ï</mml:mi>
                                <mml:mo>(</mml:mo>
                                <mml:mo>)</mml:mo>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>â</mml:mi>
                                <mml:mi>y</mml:mi>
                              </mml:mrow>
                            </mml:mfrac>
                          </mml:mrow>
                          <mml:mi>p</mml:mi>
                        </mml:msup>
                      </mml:mrow>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>where, \( \lambda_1 \) and \( \lambda_2 \) control the relative importance of the region-based energy terms. Higher values emphasize accurate object-background separation. The parameter \( \gamma \) regulates the smoothness of the segmentation boundary by controlling the influence of the gradient-based regularization. \( \eta \) determines the strength of the fuzzy divergence, affecting the balance between segmentation flexibility and boundary preservation, and \( p \) controls the divergence effect, where \( p &gt; 1 \) enforces stronger smoothness, while \( p \approx 1 \) allows greater contour adaptability.</p><p>The first term represents the region-based energy inside the object, where \( \mathbf{I} \) is the image intensity, and \( \mu_{\text{in}} \) is the average intensity inside the segmented region. The function \( F(\phi) \) serves as a fuzzy membership function, defining the probability of a pixel belonging to the object. The second term accounts for the background region-based energy. Here, \( \mu_{\text{out}} \) is the average intensity of the background, and \( 1 - F(\phi) \) ensures that pixels outside the object contribute to this energy term.</p><p>The third term <inline-formula>
  <mml:math id="m5ysxx5dm1">
    <mml:mi>Î³</mml:mi>
    <mml:mi>â</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>Ï</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>Î©</mml:mi>
    <mml:msub>
      <mml:mo>â«</mml:mo>
      <mml:mrow>
        <mml:mi>Î©</mml:mi>
      </mml:mrow>
    </mml:msub>
    <mml:mrow>
      <mml:mo>|</mml:mo>
    </mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:msup>
      <mml:mrow>
        <mml:mo>|</mml:mo>
      </mml:mrow>
      <mml:mn>2</mml:mn>
    </mml:msup>
  </mml:math>
</inline-formula> is a regularization term based on the gradient of the fuzzy membership function. This term ensures smoothness in the segmentation boundaries, preventing abrupt transitions that may lead to over-segmentation. The fourth term represents the fuzzy divergence constraint, which prevents excessive segmentation fragmentation and ensures robust boundary evolution. The exponent \( p \) controls the strength of the divergence effect, influencing how smoothly the segmentation boundary transitions. The level set evolution equation of the above-proposed functional is formulated as:</p>
          <p>By integrating these components, the proposed energy functional provides an efficient and flexible framework for selective image segmentation. It ensures robust performance in challenging scenarios such as images with intensity inhomogeneity, weak edges, and noise.</p>
        </sec>
      
      
        <disp-formula>
          <label>(9)</label>
          <mml:math id="mrvfr8vtei">
            <mml:mfrac>
              <mml:mrow>
                <mml:mi>â</mml:mi>
                <mml:mi>Ï</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>â</mml:mi>
                <mml:mi>t</mml:mi>
              </mml:mrow>
            </mml:mfrac>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi>Î´</mml:mi>
                <mml:msub>
                  <mml:mi>D</mml:mi>
                  <mml:mrow>
                    <mml:mtext>fuzzy</mml:mtext>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>Î´</mml:mi>
                <mml:mi>Ï</mml:mi>
              </mml:mrow>
            </mml:mfrac>
            <mml:mo>=</mml:mo>
            <mml:mo>(</mml:mo>
            <mml:mo>â</mml:mo>
            <mml:mo>(</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:mo>â</mml:mo>
            <mml:mo>(</mml:mo>
            <mml:mo>â</mml:mo>
            <mml:mo>(</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:mo>+</mml:mo>
            <mml:mo>+</mml:mo>
            <mml:msub>
              <mml:mi>Î»</mml:mi>
              <mml:mn>1</mml:mn>
            </mml:msub>
            <mml:msub>
              <mml:mi>Î¼</mml:mi>
              <mml:mrow>
                <mml:mtext>in</mml:mtext>
              </mml:mrow>
            </mml:msub>
            <mml:msub>
              <mml:mi>Î»</mml:mi>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:msub>
              <mml:mi>Î¼</mml:mi>
              <mml:mrow>
                <mml:mtext>out</mml:mtext>
              </mml:mrow>
            </mml:msub>
            <mml:mrow>
              <mml:mi>I</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>I</mml:mi>
            </mml:mrow>
            <mml:msup>
              <mml:mo>)</mml:mo>
              <mml:mn>2</mml:mn>
            </mml:msup>
            <mml:msup>
              <mml:mi>F</mml:mi>
              <mml:mo>â²</mml:mo>
            </mml:msup>
            <mml:msup>
              <mml:mo>)</mml:mo>
              <mml:mn>2</mml:mn>
            </mml:msup>
            <mml:msup>
              <mml:mi>F</mml:mi>
              <mml:mo>â²</mml:mo>
            </mml:msup>
            <mml:mi>Ï</mml:mi>
            <mml:mi>Ï</mml:mi>
            <mml:mi>Î³</mml:mi>
            <mml:mi>Î</mml:mi>
            <mml:mi>Ï</mml:mi>
            <mml:mi>Î·</mml:mi>
          </mml:math>
        </disp-formula>
      
      
        <sec>
          
            <title>3.4. Theorem: boundedness of the energy functional</title>
          
          <p>To ensure the stability and well-posedness of the proposed segmentation model, we establish the boundedness of the energy functional:</p>
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="mgbydckn6y">
                <mml:mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mi>E</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>=</mml:mo>
                    </mml:mtd>
                    <mml:mtd>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>in</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>out</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mn>1</mml:mn>
                    </mml:mtd>
                  </mml:mtr>
                  <mml:mtr>
                    <mml:mtd/>
                    <mml:mtd>
                      <mml:mi/>
                      <mml:mi>Î³</mml:mi>
                      <mml:mi>â</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mi>Î·</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="2.470em" maxsize="2.470em">(</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="2.470em" maxsize="2.470em">)</mml:mo>
                      </mml:mrow>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                        </mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                        </mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:msup>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>Ï</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>x</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>Ï</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>y</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>Proof:</p><p>1. Boundedness of Region-Based Terms:</p><p>Consider the first two terms:</p>
          
            <disp-formula>
              <label>(11)</label>
              <mml:math id="m9c8h9tpxq">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                          <mml:mo>â</mml:mo>
                          <mml:mo>|</mml:mo>
                          <mml:mrow>
                            <mml:mi>I</mml:mi>
                          </mml:mrow>
                          <mml:msub>
                            <mml:mi>Î¼</mml:mi>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:mi data-mjx-auto-op="false">in</mml:mi>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(12)</label>
              <mml:math id="m03hw5kfx8">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>.</mml:mo>
                      <mml:mn>1</mml:mn>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                          <mml:mo>â</mml:mo>
                          <mml:mo>|</mml:mo>
                          <mml:mrow>
                            <mml:mi>I</mml:mi>
                          </mml:mrow>
                          <mml:msub>
                            <mml:mi>Î¼</mml:mi>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:mi data-mjx-auto-op="false">out</mml:mi>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>Since the image intensity function \( \mathbf{I} \) belongs to the Lebesgue space \( L^2(\Omega) \), it is bounded almost everywhere in \( \Omega \), i.e., \( 0 \leq \mathbf{I} \leq M \). Assuming the region-based means \( \mu_{\text{in}}, \mu_{\text{out}} \) lie within this bound, we obtain:</p>
          
            <disp-formula>
              <label>(13)</label>
              <mml:math id="m0lpil5dtl">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mn>0</mml:mn>
                      <mml:mn>0</mml:mn>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>â</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                      </mml:mrow>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>in</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î¼</mml:mi>
                        <mml:mrow>
                          <mml:mtext>out</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mi>M</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mi>M</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mstyle scriptlevel="0">
                        <mml:mspace width="1em"/>
                      </mml:mstyle>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>Since the fuzzy membership function satisfies \( 0 \leq F(\phi) \leq 1 \), we deduce:</p>
          
            <disp-formula>
              <label>(14)</label>
              <mml:math id="mcjtopuq2n">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mn>0</mml:mn>
                      <mml:mn>0</mml:mn>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>Î»</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msup>
                        <mml:mi>M</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mi>M</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mi>Î©</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mstyle scriptlevel="0">
                        <mml:mspace width="1em"/>
                      </mml:mstyle>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>ensuring that \( E_1 \) and \( E_2 \) are bounded.</p>
          <p>2. Boundedness of Gradient Regularization Term:</p><p>The third term is given by:</p>
          
            <disp-formula>
              <label>(15)</label>
              <mml:math id="mdrlxoyuof">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>3</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>Î³</mml:mi>
                      <mml:mi>â</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>|</mml:mo>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>Since \( F(\phi) \in H^1(\Omega) \), its gradient \( \nabla F(\phi) \) is square-integrable, and the Sobolev embedding theorem states:</p>
          
            <disp-formula>
              <label>(16)</label>
              <mml:math id="m8ufc99k99">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mo fence="false">â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo fence="false">â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:msub>
                        <mml:mo fence="false">â</mml:mo>
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>L</mml:mi>
                            <mml:mi>q</mml:mi>
                          </mml:msup>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo fence="false">â</mml:mo>
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>H</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msup>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>for some constant \( C_1 \) depending on \( \Omega \) and the embedding parameter \( q \). Thus, since \( \| F(\phi) \|_{H^1(\Omega)} \) is finite, \( E_3 \) remains bounded.</p><p>3. Boundedness of Fuzzy Divergence Term:</p><p>The final term is:</p>
          
            <disp-formula>
              <label>(17)</label>
              <mml:math id="mo85eu4pjt">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mn>4</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo>â«</mml:mo>
                        <mml:mrow>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mi>Î·</mml:mi>
                      <mml:mi>d</mml:mi>
                      <mml:mi>Î©</mml:mi>
                      <mml:mrow>
                        <mml:mo minsize="2.470em" maxsize="2.470em">(</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo minsize="2.470em" maxsize="2.470em">)</mml:mo>
                      </mml:mrow>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>Ï</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>x</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>F</mml:mi>
                          <mml:mi>Ï</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>â</mml:mi>
                          <mml:mi>y</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                        </mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo minsize="1.623em" maxsize="1.623em">|</mml:mo>
                        </mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:msup>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>For \( p \geq 1 \), we apply the PoincarÃ© inequality, which states that for any function \( F(\phi) \in W^{1,p}(\Omega) \):</p>
          
            <disp-formula>
              <label>(18)</label>
              <mml:math id="m96si3cvy0">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mo fence="false">â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>â¤</mml:mo>
                      <mml:mo fence="false">â</mml:mo>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:mi>â</mml:mi>
                      <mml:mi>F</mml:mi>
                      <mml:mi>Ï</mml:mi>
                      <mml:msub>
                        <mml:mo fence="false">â</mml:mo>
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>L</mml:mi>
                            <mml:mi>p</mml:mi>
                          </mml:msup>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mo fence="false">â</mml:mo>
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>L</mml:mi>
                            <mml:mi>p</mml:mi>
                          </mml:msup>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>Î©</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>Since \( F(\phi) \) is assumed to belong to the Sobolev space \( W^{1,p}(\Omega) \), it follows that \( \| \nabla F(\phi) \|_{L^p(\Omega)} \) is bounded, ensuring that \( E_4 \) remains finite.</p><p>Thus, all terms in \( E(\phi) \) are bounded, confirming that the energy functional remains well-defined and stable under the given function space assumptions.</p><p>Thus, since each term is bounded, the entire energy functional \( E(\phi) \) is bounded. Thus, since the proposed energy functional is bounded, the segmentation results are stable and robust against noise and intensity variations. The bounded nature ensures well-defined energy minimization, leading to precise object-background separation while preserving structural details. This property enhances the adaptability of the model to complex images, ensuring reliable segmentation performance across diverse scenarios.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Experimental results</title>
      <p>To validate the effectiveness of the fuzzy energy-based segmentation model, extensive experiments were conducted on a diverse dataset, including the Berkeley Segmentation Dataset (BSDS500) for natural image segmentation, synthetic images for controlled complexity analysis, and medical imaging datasets comprising MRI and X-ray scans to evaluate performance in clinical applications. These datasets encompass varying levels of texture complexity, noise, and intensity inhomogeneity, ensuring a comprehensive assessment of the model's robustness. All images were resized to $255\times255$ to maintain consistency in evaluation. The proposed model was implemented in MATLAB R2016, utilizing numerical optimization techniques for level set evolution. The segmentation performance was compared against state-of-the-art competing models, including Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] and Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], using well-established quantitative metrics such as Dice Score, Jaccard Index, and Hausdorff Distance. The results demonstrate that the proposed model consistently outperforms existing approaches, achieving more precise object-background separation while preserving fine structural details across different imaging modalities.</p><p>The parameter setup plays a critical role in optimizing the performance of the proposed fuzzy energy-based segmentation model. To achieve the best results, appropriate values for the parameters \( \lambda_1 \), \( \lambda_2 \), \( \gamma \), \( \eta \), and \( p \) must be carefully selected based on the characteristics of the input images. The region-based energy parameters \( \lambda_1 \) and \( \lambda_2 \) are typically chosen in a balanced manner, where higher values (\( \lambda_1 = 1.0 \), \( \lambda_2 = 1.0 \)) ensure effective object-background separation while maintaining contrast robustness. The gradient-based regularization term \( \gamma \) is set within the range of \( 0.01 \leq \gamma \leq 0.1 \) to control boundary smoothness without overly penalizing fine details. The fuzzy divergence weight \( \eta \) is crucial for controlling segmentation flexibility and preventing over-segmentation; an optimal range of \( 0.05 \leq \eta \leq 0.2 \) is suggested based on empirical evaluations. The exponent \( p \) in the fuzzy divergence operator determines the strength of boundary regularization, where \( p = 1.2 \) is recommended to strike a balance between contour adaptability and smoothness enforcement. Additionally, the smoothness parameter \( \alpha \) in the Pythagorean fuzzy membership function is set between \( 0.5 \leq \alpha \leq 2.0 \), ensuring an adaptive transition for object-background separation without introducing excessive blurring.</p>
      <p>The optimal parameter values were determined through extensive experimentation on benchmark medical and natural image datasets, considering segmentation accuracy, robustness against noise, and computational efficiency. By tuning these parameters adaptively based on image complexity, the proposed model achieves superior segmentation performance, effectively preserving object boundaries and enhancing segmentation precision in challenging imaging scenarios.</p><p><xref ref-type="fig" rid="fig_1">Figure 1</xref> illustrates the sequential process of image segmentation using the proposed model. The first column presents the given input image, which serves as the initial reference for segmentation. The second column shows the initialization of the contour, highlighting the preliminary boundary selection crucial for accurate segmentation. In the third column, the fuzzy localization process is depicted, where the model adapts to intensity variations and structural details, refining the segmentation region. The final column displays the segmentation result obtained using the proposed model, showcasing its ability to preserve object boundaries while effectively distinguishing between different regions. This visualization demonstrates the robustness of the proposed approach in accurately segmenting complex structures, making it suitable for applications in medical imaging, remote sensing, and industrial vision systems.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Illustration of the segmentation process using the proposed model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_m6CbhE-1gRvJyKj9.jpeg"/>
        </fig>
      
      <p><xref ref-type="fig" rid="fig_2">Figure 2</xref> provides a comparative visualization of the segmentation process using different models. The first column presents the given input images, where the initialization of the contour is marked. These images contain a small amount of noise and exhibit significant non-uniform intensity variations, which pose a challenge for accurate segmentation.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Comparison of segmentation results using different models</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_uGozQDSnyJYDFf8H.jpeg"/>
        </fig>
      
      <p>The second column illustrates the segmentation result obtained using the model [<xref ref-type="bibr" rid="ref_19">19</xref>]. While this model captures the general shape of the object, it struggles with intensity variations and fails to achieve smooth boundary delineation. The presence of noise also affects the accuracy of segmentation.</p><p>The third column shows the result produced by the study [<xref ref-type="bibr" rid="ref_20">20</xref>]. Although the model improves upon Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] in certain regions, it still suffers from boundary leakage and inaccuracies due to the high intensity inhomogeneity within the images. The segmentation contours deviate from the actual object boundaries, leading to potential misclassification of pixels.</p><p>The final column displays the segmentation result obtained using the proposed model. The proposed method effectively handles non-uniform intensity variations and noise, ensuring robust and precise boundary localization. The segmented regions exhibit superior accuracy, with well-preserved object structures and reduced artifacts. This demonstrates the effectiveness of the proposed model in handling complex segmentation challenges in medical imaging.</p><p><xref ref-type="fig" rid="fig_3">Figure 3</xref> illustrates the segmentation results of medical images using different models, including the proposed approach. The images are arranged into four columns, each representing a different stage of segmentation. The first column displays the original medical images, with initial contours (marked in magenta) indicating the starting points for segmentation. These initial contours serve as the foundation for the segmentation process. The second column presents the segmentation results obtained using the model [<xref ref-type="bibr" rid="ref_19">19</xref>]. The blue contours highlight the segmented regions identified by this model. While some regions are accurately detected, there are noticeable inaccuracies, such as boundary leakage and incomplete segmentation, suggesting that struggles with intensity variations and noise [<xref ref-type="bibr" rid="ref_19">19</xref>]. In the third column, the segmentation results of the study [<xref ref-type="bibr" rid="ref_20">20</xref>] are displayed. Compared to study [<xref ref-type="bibr" rid="ref_19">19</xref>], this model shows slightly better alignment with the target regions, but it still exhibits inconsistencies in contour precision. Some areas appear over-segmented, while others remain under-segmented, indicating that lacks robustness in handling complex structures [<xref ref-type="bibr" rid="ref_20">20</xref>]. The last column presents the segmentation results obtained using the proposed model. The blue contours in this column demonstrate significantly improved accuracy in capturing the target regions. The proposed method effectively preserves structural integrity, aligns well with actual boundaries, and reduces noise-related errors. The contours appear smoother and more precise, suggesting that the model successfully handles intensity variations and complex textures.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Segmentation results on medical images</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_13yR3CMyvWOakuzT.jpeg"/>
        </fig>
      
      <p>Overall, the figure highlights the superiority of the proposed segmentation approach compared to the studies [<xref ref-type="bibr" rid="ref_19">19</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>]. The proposed model offers enhanced boundary adherence, noise reduction, and structural preservation, making it a more reliable choice for medical image segmentation. The improved segmentation performance suggests that the proposed approach is well-suited for applications requiring high accuracy, such as medical diagnostics and analysis.</p><p><xref ref-type="fig" rid="fig_4">Figure 4</xref> illustrates the robustness of the proposed segmentation model against different initial contour placements. The four subfigures depict the evolution of segmentation results, starting from different initial contours, yet all cases ultimately converge to the same final segmentation. This behavior highlights the modelâs stability and insensitivity to initialization, ensuring consistent results regardless of the initial contour positioning. Such robustness is particularly beneficial in real-world applications where precise initialization may not always be feasible. The proposed model effectively adapts to intensity variations and object boundaries, leading to accurate and reliable segmentation outcomes.</p>
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>Segmentation result using different initial contours</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_kjzp-QUlrKKk8N6P.jpeg"/>
        </fig>
      
      <p>The performance comparison <xref ref-type="table" rid="table_1">Table 1</xref> evaluates three segmentation methods: Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>], Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], and the Proposed Modelâusing four key metrics: Dice Score, Jaccard Index, Hausdorff Distance, and CPU execution time.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>Performance comparison of segmentation methods in terms of accuracy (Dice Score, Jaccard Index), boundary precision (Hausdorff Distance), and computational efficiency (CPU time)</title>
          </caption>
          <table><tr><th >Method</th><th >Dice Score <mml:math id="m7fxhm0lad">
  <mml:mo>â</mml:mo>
</mml:math></th><th >IoU <mml:math id="m3j14kixmn">
  <mml:mo>â</mml:mo>
</mml:math></th><th >Hausdorff Distance <mml:math id="m8wvtgjkyu">
  <mml:mo>â</mml:mo>
</mml:math></th><th >CPU <mml:math id="mzsidmdynx">
  <mml:mo>â</mml:mo>
</mml:math></th></tr><tr><td >Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>]</td><td >$0.87 \pm 0.02<mml:math id="msfcqoada0">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>0.81 \pm 0.03<mml:math id="m1e0qyq8fs">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>10.8 \pm 1.4<mml:math id="mdh7i82swf">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>3.6 \pm 0.3<mml:math id="ms5vvsc6z8">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>.</mml:mo>
  <mml:mo>[</mml:mo>
  <mml:mo>]</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>Y</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mn>20</mml:mn>
</mml:math>0.90 \pm 0.02<mml:math id="m2yc8cb22u">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>0.85 \pm 0.03<mml:math id="mspc7h35wy">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>8.4 \pm 1.1<mml:math id="mqvhd9y35z">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>3.3 \pm 0.2<mml:math id="mtkuz2995x">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>P</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>\mathbf{0.96 \pm 0.01}<mml:math id="mv2ork1jmq">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>\mathbf{0.92 \pm 0.02}<mml:math id="mm937hjzr7">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>\mathbf{5.4 \pm 0.8}<mml:math id="mf67ygirr7">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>\mathbf{2.5 \pm 0.2}<mml:math id="m4c3zkpgnf">
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>(</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>)</mml:mo>
  <mml:mo>&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>&amp;gt;&amp;lt;</mml:mo>
  <mml:mo>â</mml:mo>
  <mml:mo>&amp;gt;</mml:mo>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mrow>
    <mml:mo>/</mml:mo>
  </mml:mrow>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>p</mml:mi>
  <mml:mi>v</mml:mi>
  <mml:mi>a</mml:mi>
  <mml:mi>l</mml:mi>
  <mml:mi>u</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>s</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>r</mml:mi>
  <mml:mi>o</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>g</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>d</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>x</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>c</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>n</mml:mi>
  <mml:mi>t</mml:mi>
  <mml:mi>e</mml:mi>
  <mml:mi>r</mml:mi>
</mml:math>&lt;$0.01</td><td >$&lt;$0.01</td><td >$&lt;$0.01</td><td >$&lt;$0.05</td></tr></table>
        </table-wrap>
      
      
        <sec>
          
            <title>4.1. Dice score</title>
          
          <p>The Dice Score is a widely used metric for evaluating the accuracy of image segmentation methods. It measures the overlap between the predicted segmentation and the ground truth and is defined as:</p>
          
            <disp-formula>
              <label>(19)</label>
              <mml:math id="m6pagz0da1">
                <mml:mtext>Dice Score</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                    <mml:mo>â©</mml:mo>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where, \( A \) represents the predicted segmentation and \( B \) represents the ground truth. A higher Dice Score indicates a better match between the segmentation result and the actual object boundaries. As shown in <xref ref-type="table" rid="table_1">Table 1</xref>, the proposed model achieves a Dice Score of 0.96, significantly outperforming Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] (0.87) and Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] (0.90). This improvement, validated by statistical tests (p-value $&lt;$ 0.01), confirms the effectiveness of the proposed approach in accurately segmenting the target regions.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Jaccard index</title>
          
          <p>The Jaccard Index (IoU), also known as the Intersection over Union (IoU), is another accuracy metric that measures the degree of similarity between the predicted segmentation and the ground truth. It is defined as:</p>
          
            <disp-formula>
              <label>(20)</label>
              <mml:math id="mx75zdq7oo">
                <mml:mtext>Jaccard Index</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mo>â©</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mo>âª</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi>A</mml:mi>
                    <mml:mi>B</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>Unlike the Dice Score, which gives more weight to common regions, the Jaccard Index provides a stricter evaluation by considering the total region covered by both segmentations. A higher value indicates better segmentation performance. The proposed model achieves a Jaccard Index of 0.92, compared to 0.81 for Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] and 0.85 for Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], demonstrating superior segmentation accuracy. The improvements in this metric are statistically significant with p-value $&lt;$ 0.01, reinforcing the reliability of the proposed approach.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Hausdorff distance</title>
          
          <p>The Hausdorff Distance is a boundary precision metric that measures the largest distance between points on the predicted segmentation and the ground truth boundary. It is formally defined as:</p>
          
            <disp-formula>
              <label>(21)</label>
              <mml:math id="mqw2cy28xf">
                <mml:mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mi>H</mml:mi>
                      <mml:mi>A</mml:mi>
                      <mml:mi>B</mml:mi>
                      <mml:mo>(</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mo>=</mml:mo>
                      <mml:mo>max</mml:mo>
                      <mml:mrow>
                        <mml:mo>{</mml:mo>
                        <mml:mo>(</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>(</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mo>}</mml:mo>
                        <mml:munder>
                          <mml:mo>sup</mml:mo>
                          <mml:mrow>
                            <mml:mi>a</mml:mi>
                            <mml:mi>A</mml:mi>
                            <mml:mo>â</mml:mo>
                          </mml:mrow>
                        </mml:munder>
                        <mml:munder>
                          <mml:mo>inf</mml:mo>
                          <mml:mrow>
                            <mml:mi>b</mml:mi>
                            <mml:mi>B</mml:mi>
                            <mml:mo>â</mml:mo>
                          </mml:mrow>
                        </mml:munder>
                        <mml:munder>
                          <mml:mo>sup</mml:mo>
                          <mml:mrow>
                            <mml:mi>b</mml:mi>
                            <mml:mi>B</mml:mi>
                            <mml:mo>â</mml:mo>
                          </mml:mrow>
                        </mml:munder>
                        <mml:munder>
                          <mml:mo>inf</mml:mo>
                          <mml:mrow>
                            <mml:mi>a</mml:mi>
                            <mml:mi>A</mml:mi>
                            <mml:mo>â</mml:mo>
                          </mml:mrow>
                        </mml:munder>
                        <mml:mi>d</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>b</mml:mi>
                        <mml:mi>d</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>b</mml:mi>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </disp-formula>
          
          <p>where, \( d(a, b) \) represents the Euclidean distance between two points. A lower Hausdorff Distance indicates better boundary alignment and precision. The proposed model achieves a Hausdorff Distance of 5.4, significantly lower than 10.8 (Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>]) and 8.4 (Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>]), indicating that the proposed segmentation method produces more accurate and well-aligned boundaries. The reduction in Hausdorff Distance is statistically significant (p-value $&lt;$ 0.01), confirming the enhanced boundary precision of the proposed model.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Cpu time</title>
          
          <p>CPU time measures the computational efficiency of the segmentation model, representing the total time required to complete the segmentation process. A lower CPU time indicates a more efficient algorithm. In <xref ref-type="table" rid="table_1">Table 1</xref>, the proposed model demonstrates a computational time of 2.5 seconds, which is faster than both Ma et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] (3.6 s) and Yue et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] (3.3 s). The reduction in processing time is statistically validated with a p-value $&lt;$ 0.05, highlighting the efficiency of the proposed approach. This improvement is particularly crucial for real-time applications, where segmentation speed is a key factor.</p>
        </sec>
      
      
        <sec>
          
            <title>4.5. Statistical significance validation</title>
          
          <p>To ensure that the reported improvements are not due to random variations, we conducted statistical significance tests, including paired t-tests and ANOVA. The results confirm that the performance improvements in Dice Score, Jaccard Index, and Hausdorff Distance are statistically significant with p $&lt;<inline-formula>
  <mml:math id="mzpzdw5etn">
    <mml:mn>0.01</mml:mn>
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>C</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>U</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>p</mml:mi>
  </mml:math>
</inline-formula>&lt;$ 0.05. These findings validate the robustness of the proposed model in terms of segmentation accuracy, boundary precision, and computational efficiency.</p><p>The results presented in <xref ref-type="table" rid="table_1">Table 1</xref> highlight the superior performance of the proposed model in terms of segmentation accuracy, boundary precision, and computational efficiency. The statistical significance validation further reinforces the reliability of these improvements. By comparing the proposed method with the latest selective segmentation models, we provide a robust and relevant benchmark, addressing the concerns raised by the reviewer.</p>
        </sec>
      
    </sec>
    <sec sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>We proposed a Robust Pythagorean Fuzzy Energy-Based Level Set (RPFELS) that integrates advanced fuzzy segmentation techniques to improve accuracy and robustness. The model leverages the Pythagorean fuzzy membership function to provide a smooth and adaptive transition for object-background separation, effectively handling intensity, inhomogeneity, and weak edges. Additionally, the introduction of a fuzzy divergence ensures well-regularized contour evolution, preventing over-segmentation while maintaining precise boundary localization. Our proposed energy functional incorporates entropy-based regularization and a fuzzy divergence constraint, balancing object-background separation while preserving structural integrity. Experimental results demonstrate that the proposed model outperformed existing methods by achieving higher segmentation accuracy, as evidenced by superior Dice Score and Jaccard Index values. Furthermore, it significantly reduces the Hausdorff Distance, indicating improved boundary precision, while also lowering computational complexity, making it suitable for real-time applications.</p><p>Despite the promising performance of the proposed model, it has certain limitations that need to be addressed in future research. One major limitation is its sensitivity to parameter selection, as improper tuning of fuzzy energy parameters may lead to suboptimal segmentation results. Additionally, the computational complexity, while reduced compared to conventional level set models, still poses a challenge for real-time applications, especially when handling high-resolution images or large datasets. Another limitation is the modelâs reliance on pre-defined initialization, which may affect segmentation accuracy if the initial contour is placed incorrectly. Furthermore, while the proposed model effectively handles intensity inhomogeneity, its performance may degrade when dealing with extremely low-contrast images or highly complex textures.</p><p>To overcome these limitations, future work will focus on adaptive parameter optimization techniques, such as deep learning-based hyperparameter tuning, to enhance the modelâs robustness across diverse image conditions. Computational efficiency can be further improved by implementing GPU acceleration and parallel processing techniques. Additionally, integrating an automatic contour initialization mechanism using deep learning-based object detection methods can enhance the reliability of segmentation results.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author aeclares no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>2328827</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Cai</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Kou</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/17538947.2024.2328827</pub-id>
          <article-title>A review of remote sensing image segmentation by deep learning methods</article-title>
          <source>Int. J. Digit. Earth</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rezaei</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asadi</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2401.02758</pub-id>
          <article-title>Systematic review of image segmentation using complex networks</article-title>
          <source>arXiv preprint arXiv:2401.02758</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <page-range>102608</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Brar</surname>
              <given-names>K. K.</given-names>
            </name>
            <name>
              <surname>Goyal</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Dogra</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mustafa</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Majumdar</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Alkhayyat</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kukreja</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.inffus.2024.102608</pub-id>
          <article-title>Image segmentation review: Theoretical background and recent advances</article-title>
          <source>Inf. Fus.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>57</volume>
          <page-range>11</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Archana</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Jeevaraj</surname>
              <given-names>P. E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10462-023-10631-z</pub-id>
          <article-title>Deep learning models for digital image processing: A review</article-title>
          <source>Artif. Intell. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>16</volume>
          <page-range>1113-1136</page-range>
          <issue>5</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hussain</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>M. S.</given-names>
            </name>
            <name>
              <surname>Niu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rada</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/ipi.2022014</pub-id>
          <article-title>Robust region-based active contour models via local statistical similarity and local similarity factor for intensity inhomogeneity and high noise image segmentation</article-title>
          <source>Inverse Probl. Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>708-725</page-range>
          <issue>3</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hussain</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Muhammad</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/ipi.2022074</pub-id>
          <article-title>Efficient convex region-based segmentation for noising and inhomogeneous patterns</article-title>
          <source>Inverse Probl. Imaging</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>5905-5924</page-range>
          <issue>3</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Al-Shahari</surname>
              <given-names>E. A.</given-names>
            </name>
            <name>
              <surname>Obayya</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Alotaibi</surname>
              <given-names>F. A.</given-names>
            </name>
            <name>
              <surname>Alsafari</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Salama</surname>
              <given-names>A. S.</given-names>
            </name>
            <name>
              <surname>Assiri</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/math.2024288</pub-id>
          <article-title>Accelerating biomedical image segmentation using equilibrium optimization with a deep learning approach</article-title>
          <source>AIMS Math.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>107</volume>
          <page-range>102311</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>Y. H.</given-names>
            </name>
            <name>
              <surname>Xie</surname>
              <given-names>X. H.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>L. X.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.inffus.2024.102311</pub-id>
          <article-title>Region-based online selective examination for weakly supervised semantic segmentation</article-title>
          <source>Inf. Fus.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xie</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/arXiv.2312.17183</pub-id>
          <article-title>One model to rule them all: Towards universal segmentation for medical images with text prompts</article-title>
          <source>arXiv preprint arXiv:2312.17183</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>2811</page-range>
          <issue>11</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zheng</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Gu</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Zeng</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs15112811</pub-id>
          <article-title>A stage-adaptive selective network with position awareness for semantic segmentation of LULC remote sensing images</article-title>
          <source>Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>654-671</page-range>
          <issue>1</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hussain</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/math.2025029</pub-id>
          <article-title>Improved region-based active contour segmentation through divergence and convolution techniques</article-title>
          <source>AIMS Math.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>31</volume>
          <page-range>3647-3697</page-range>
          <issue>6</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Amiriebrahimabadi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Rouhi</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Mansouri</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11831-024-10093-8</pub-id>
          <article-title>A comprehensive survey of multi-level thresholding segmentation methods for image processing</article-title>
          <source>Arch. Comput. Methods Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>103-115</page-range>
          <issue>28</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Derevyanchuk</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.32835/2707-3092.2024.28.103-115</pub-id>
          <article-title>Use of intelligent fuzzy image segmentation systems in the professional training of future specialists in engineering and pedagogical fields</article-title>
          <source>Prof. Pedagogics</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <page-range>1-28</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/0952813X.2024.2440662</pub-id>
          <article-title>Pattern recognition and image segmentation based on some novel fuzzy similarity measures</article-title>
          <source>J. Exp. Theor. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>644</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Janusonis</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Kazakeviciute-Januskeviciene</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Bausys</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app14020644</pub-id>
          <article-title>Selection of optimal segmentation algorithm for satellite images by intuitionistic fuzzy PROMETHEE method</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <page-range>1-12</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Muchahari</surname>
              <given-names>M. K.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Das</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s40815-024-01878-x</pub-id>
          <article-title>Automated white matter lesions segmentation of MRIs for multiple sclerosis detection using fuzzy-entropy algorithm</article-title>
          <source>Int. J. Fuzzy Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>47-66</page-range>
          <issue>1</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nithisha</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Visumathi</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rajalakshmi</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Suseela</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Sudha</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Choubey</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Farhaoui</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.5815/ijitcs.2025.01.04</pub-id>
          <article-title>Fuzzy hybrid meta-optimized learning-based medical image segmentation system for enhanced diagnosis</article-title>
          <source>Int. J. Inf. Technol. Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>e0294789</page-range>
          <issue>12</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Soomro</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Niaz</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Soomro</surname>
              <given-names>T. A.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Manzoor</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Choi</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0294789</pub-id>
          <article-title>Selective image segmentation driven by region, edge and saliency functions</article-title>
          <source>PLOS ONE</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1531-1535</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ma</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Lawlor</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ICASSP48485.2024.10446026</pub-id>
          <article-title>Breaking the barrier: Selective uncertainty-based active learning for medical image segmentation</article-title>
          <source>ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Seoul, Korea</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1101-1110</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yue</surname>
              <given-names>P. F.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>J. H.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>S. C.</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>Y. L.</given-names>
            </name>
            <name>
              <surname>Niu</surname>
              <given-names>H. W.</given-names>
            </name>
            <name>
              <surname>Ding</surname>
              <given-names>H. X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>G. N.</given-names>
            </name>
            <name>
              <surname>Cao</surname>
              <given-names>L. J.</given-names>
            </name>
            <name>
              <surname>Ji</surname>
              <given-names>R. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3664647.3680850</pub-id>
          <article-title>Adaptive selection based referring image segmentation</article-title>
          <source>MM '24: Proceedings of the 32nd ACM International Conference on Multimedia, Melbourne VIC, Australia</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>