<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ATG</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Acadlore Transactions on Geosciences</journal-title>
        <abbrev-journal-title abbrev-type="issn">Acadlore Trans. Geosci.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ATG</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1877</issn>
      <issn publication-format="print">2958-1869</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-yr0tbS8Eu06p14Q9OBq4AcLWBfGrpSUY</article-id>
      <article-id pub-id-type="doi">10.56578/atg010102</article-id>
      <title-group>
        <article-title>Comparing Artificial Neural Networks with Multiple Linear Regression for Forecasting Heavy Metal Content</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Chaal</surname>
            <given-names>Rachid El</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6399-3471</contrib-id>
          <email>rachid.elchaal@uit.ac.ma</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Aboutafail</surname>
            <given-names>Moulay Othman</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false"/>
          <email/>
        </contrib>
        <aff id="1">ENSA of Kenitra, Engineering Sciences Laboratory, Data Analysis, Mathematical Modeling and Optimization Team, Ibn Tofail University, 14000 Kenitra, Morocco</aff>
      </contrib-group>
      <year>2022</year>
      <volume>1</volume>
      <issue>1</issue>
      <fpage>2</fpage>
      <lpage>11</lpage>
      <page-range>2-11</page-range>
      <history>
        <date date-type="received">
          <month>07</month>
          <day>09</day>
          <year>2022</year>
        </date>
        <date date-type="accepted">
          <month>09</month>
          <day>04</day>
          <year>2022</year>
        </date>
        <date date-type="pub">
          <month>11</month>
          <day>14</day>
          <year>2022</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2022 by the author(s)</copyright-statement>
        <copyright-year>2022</copyright-year>
        <license>. Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the <a href='https://creativecommons.org/licenses/by/4.0/' target='_blank' class='text-yellow-700 hover:underline'>CC BY 4.0 license</a>.</license>
      </permissions>
      <abstract><p>This paper adopts two modeling tools, namely, multiple linear regression (MLR) and artificial neural networks (ANNs), to predict the concentrations of heavy metals (zinc, boron, and manganese) in surface waters of the Oued Inaouen watershed flowing towards Inaouen, using a set of physical-chemical parameters. XLStat was employed to perform multiple linear and nonlinear regressions, and Statista 10 was chosen to construct neural networks for modeling and prediction. The effectiveness of the ANN- and MLR-based stochastic models was assessed by the determination coefficient (R²), the sum squared error (SSE) and a review of fit graphs. The results demonstrate the value of ANNs for prediction modeling. Drawing on supervised learning and back propagation, the ANN-based prediction models adopt an architecture of [18-15-1] for zinc, [18-11-1] for manganese, and [18-8-1] for boron, and perform effectively with a single cached layer. It was found that the MLR-based prediction models are substantially less accurate than those based on the ANNs. In addition, the physical-chemical parameters being investigated are nonlinearly correlated with the levels of heavy metals in the surface waters of the Oued Inaouen watershed flowing towards Inaouen.</p></abstract>
      <kwd-group>
        <kwd>Artificial neural networks (ANN)</kwd>
        <kwd>Mathematical modelling</kwd>
        <kwd>Multiple linear regression (MLR)</kwd>
        <kwd>Heavy metal</kwd>
        <kwd>Residual</kwd>
        <kwd>Prediction</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors">2</count>
        <fig-count>7</fig-count>
        <table-count>3</table-count>
        <ref-count>34</ref-count>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec disp-level="level1" sec-type="intro">
      <title>1. Introduction</title>
      <p>Water can be polluted by many things, namely, wastewater, industrial products, and domestic products. &amp;amp;nbsp;The discharge of pollutants, particularly those containing harmful nanoparticles or metallic heavy metals, makes the water toxic and poses risks to human health, biological life, and environmental security. Metals have a special status in water pollution, because they are employed frequently in many applications. The heavy metal elements are brought up the food chain by water. These elements are often only present in tiny amounts, but when they bioaccumulate in living organisms, they pose an increasingly dangerous problem [<xref ref-type="bibr" rid="ref_1">1</xref>]. </p><p>Public agencies have set limitations to manage emissions, examine threats, and protect our ecosystem against the toxicity of heavy metals. The scientific community and Moroccan government officials are working hard on environmental issues [<xref ref-type="bibr" rid="ref_2">2</xref>]. Morocco's environmental plans introduce the management and management of natural resources, and consider the preservation of our ecosystem and the preservation of natural resources [<xref ref-type="bibr" rid="ref_3">3</xref>].</p><p>This paper aims to create mathematical models that can predict the presence of heavy metals like manganese, boron, and zinc based on various environmental factors. The objects are the surface waters in the Oued Inaouen watershed. Two prediction models, namely, artificial neural network (ANN) and multiple linear regression (MLR) were compared on Statista 10 and XLSTAT 2017.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>2. Methodology</title>
      
        <sec disp-level="level2">
          
            <title>2.1. Database</title>
          
          <p>Our database consists of 100 surface water samples (observations) from the province of Taza. The collection, transportation, and storage of water samples in 2014 and 2015 were accomplished in accordance with the policies and practices of the National Drinking Water Office. The lab run by the University Sidi Mohamed Ben Abdellah (USMBA) of Fez, known as the Regional University Interface Center (CURI), executed part analysis, part fabrication, and part manufacturing [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>].</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.2. Input selection</title>
          
          <p><span style="color: rgb(0, 0, 0);">A tota</span>l of 16 p<span style="color: rgb(0, 0, 0);">hysical-chemical features are identified in these samples, and taken as independent (explanatory) factors, namely, total dissolved solids (TDS), conductivity (Cond), temperature (T/°C), dissolved oxygen (DO), pH, potassium (K), magnesium (Mg), calcium (Ca), nitrate (NO</span><sub>3</sub><span style="color: rgb(0, 0, 0);">), chloride (Cl), phosphorus (P), ammoniacal nitrogen (NH</span><sub>4</sub><span style="color: rgb(0, 0, 0);">), total alkalinity (CaCO</span><sub>3</sub><span style="color: rgb(0, 0, 0);">), sodium (Na), and sulfates (SO</span><sub>4</sub><span style="color: rgb(0, 0, 0);">) </span>[<xref ref-type="bibr" rid="ref_5">5</xref>]<span style="color: rgb(0, 0, 0);">. Manganese (Mn), zinc (Zn), and boron(B) levels were identified as the three dependent variables to be predicted.</span></p><p>From the overall database, 70% of the data were selected randomly to train the dependent variable forecast model [<xref ref-type="bibr" rid="ref_7">7</xref>]. The remaining 30% of data were used to prevent over fitting, and assess the prediction effect of the trained model.</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.3. Data preprocessing</title>
          
          <p><span style="color: rgb(0, 0, 0);">Data normalization makes models less difficult.</span> The in<span style="color: rgb(0, 0, 0);">put data are made up of the 16 independent variables above, which are of various magnitudes. The data are transformed into a standardized variable to equalize the measuring scales. The I values of each independent variable are adjusted to match their means and standard deviations, using the connection <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>X</mi>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <mo data-mjx-texclass="CLOSE">)</mo>
      <msub>
        <mi>v</mi>
        <mi>i</mi>
      </msub>
    </mrow>
  </math>
</inline-formula>:</span></p>
          
            <disp-formula>
              <label>(1)</label>
              <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                <msub>
                  <mi>X</mi>
                  <mi>s</mi>
                </msub>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <msub>
                    <mi>v</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <mrow>
                      <mi>X</mi>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>v</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <mover>
                          <mi>X</mi>
                          <mo stretchy="false">¯</mo>
                        </mover>
                      </mrow>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>v</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                      <mo>−</mo>
                    </mrow>
                    <mrow>
                      <mi>σ</mi>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>v</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                    </mrow>
                  </mfrac>
                </mrow>
                <mo>=</mo>
                <mo>,</mo>
                <mo>∈</mo>
                <mo fence="false" stretchy="false">{</mo>
                <mo>…</mo>
                <mo>…</mo>
                <mo fence="false" stretchy="false">}</mo>
                <mi>i</mi>
                <mn>1</mn>
                <mn>16</mn>
              </math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="normal">X</mi>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="normal">s</mi>
        </mrow>
      </mrow>
    </msub>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <mo data-mjx-texclass="CLOSE">)</mo>
      <msub>
        <mi>v</mi>
        <mi>i</mi>
      </msub>
    </mrow>
  </math>
</inline-formula>, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">X</mi>
    </mrow>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <mo data-mjx-texclass="CLOSE">)</mo>
      <msub>
        <mi>v</mi>
        <mi>i</mi>
      </msub>
    </mrow>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mrow data-mjx-texclass="ORD">
      <mover>
        <mi>X</mi>
        <mo stretchy="false">¯</mo>
      </mover>
    </mrow>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <mo data-mjx-texclass="CLOSE">)</mo>
      <msub>
        <mi>v</mi>
        <mi>i</mi>
      </msub>
    </mrow>
  </math>
</inline-formula> are the standardized, measured, and mean values, respectively. The mean value can be calculated by:</p>
          
            <disp-formula>
              <label>(2)</label>
              <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                <mrow data-mjx-texclass="ORD">
                  <mover>
                    <mi>X</mi>
                    <mo stretchy="false">¯</mo>
                  </mover>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <msub>
                    <mi>v</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <msub>
                    <mi>v</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mo>=</mo>
                <mfrac>
                  <mn>1</mn>
                  <mn>100</mn>
                </mfrac>
                <munderover>
                  <mo data-mjx-texclass="OP">∑</mo>
                  <mrow data-mjx-texclass="ORD">
                    <mi>k</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                  <mrow data-mjx-texclass="ORD">
                    <mn>100</mn>
                  </mrow>
                </munderover>
                <msub>
                  <mi>X</mi>
                  <mi>k</mi>
                </msub>
              </math>
            </disp-formula>
          
          <p><span style="color: rgb(0, 0, 0);">The standard deviation </span><inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>σ</mi>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <mo data-mjx-texclass="CLOSE">)</mo>
      <msub>
        <mi>v</mi>
        <mi>i</mi>
      </msub>
    </mrow>
  </math>
</inline-formula> <span style="color: rgb(0, 0, 0);">can be expressed </span>as:</p>
          
            <disp-formula>
              <label>(3)</label>
              <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                <mi>σ</mi>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <msub>
                    <mi>v</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mo>=</mo>
                <msqrt>
                  <mfrac>
                    <mn>1</mn>
                    <mn>100</mn>
                  </mfrac>
                  <munderover>
                    <mo data-mjx-texclass="OP">∑</mo>
                    <mrow data-mjx-texclass="ORD">
                      <mi>k</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <mrow data-mjx-texclass="ORD">
                      <mn>100</mn>
                    </mrow>
                  </munderover>
                  <msup>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>−</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>X</mi>
                        <mi>k</mi>
                      </msub>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>v</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <mover>
                          <mi>X</mi>
                          <mo stretchy="false">¯</mo>
                        </mover>
                      </mrow>
                      <mrow data-mjx-texclass="INNER">
                        <mo data-mjx-texclass="OPEN">(</mo>
                        <mo data-mjx-texclass="CLOSE">)</mo>
                        <msub>
                          <mi>v</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                    </mrow>
                    <mn>2</mn>
                  </msup>
                </msqrt>
              </math>
            </disp-formula>
          
          <p><span style="color: rgb(0, 0, 0);">The values of all variables are standardized to prevent computing excessively large or small exponents, and thus reduce the variability of the me</span>an [<xref ref-type="bibr" rid="ref_8">8</xref>]. <span style="color: rgb(0, 0, 0);">The data of the explanatory variable was also normalized to the range of [0,1] to meet the constraints of the transfer function used by the neural networks. The normalization can be realized by the following relation</span>ship [<xref ref-type="bibr" rid="ref_9">9</xref>]:</p>
          
            <disp-formula>
              <label>(4)</label>
              <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                <msub>
                  <mi>Y</mi>
                  <mi>n</mi>
                </msub>
                <mo>=</mo>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">(</mo>
                  <mo data-mjx-texclass="CLOSE">)</mo>
                  <mfrac>
                    <mrow>
                      <mi>Y</mi>
                      <mo>−</mo>
                      <msub>
                        <mi>Y</mi>
                        <mrow data-mjx-texclass="ORD">
                          <mo data-mjx-texclass="OP" movablelimits="true">min</mo>
                        </mrow>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>Y</mi>
                        <mrow data-mjx-texclass="ORD">
                          <mo data-mjx-texclass="OP" movablelimits="true">max</mo>
                        </mrow>
                      </msub>
                      <msub>
                        <mi>Y</mi>
                        <mrow data-mjx-texclass="ORD">
                          <mo data-mjx-texclass="OP" movablelimits="true">min</mo>
                        </mrow>
                      </msub>
                      <mo>−</mo>
                    </mrow>
                  </mfrac>
                </mrow>
              </math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>Y</mi>
      <mi>n</mi>
    </msub>
    <msub>
      <mi>Y</mi>
      <mrow data-mjx-texclass="ORD">
        <mo data-mjx-texclass="OP" movablelimits="true">min</mo>
      </mrow>
    </msub>
    <mo>,</mo>
    <mo>,</mo>
    <mi>Y</mi>
  </math>
</inline-formula> and <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>Y</mi>
      <mrow data-mjx-texclass="ORD">
        <mo data-mjx-texclass="OP" movablelimits="true">max</mo>
      </mrow>
    </msub>
  </math>
</inline-formula> are the standardized, measured, minimum, and maximum values, respectively.</p>
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>2.4. Data analysis</title>
          
          <p>Two methods are adopted to realize the modelling process, namely, MLR and MLP-type ANN, aiming to optimize the link between manganese (Mn), zinc (Zn), and boron (B), and physicochemical elements [<xref ref-type="bibr" rid="ref_10">10</xref>].</p>
          
            <sec disp-level="level3">
              
                <title>2.4.1 Mlr</title>
              
              <p><span style="color: rgb(0, 0, 0);">Regression analysis is a statistical technique that enables the examination of the potential relationships between a dependent variable and one or more independent vari</span>ables [<xref ref-type="bibr" rid="ref_11">11</xref>].</p><p><span style="color: rgb(0, 0, 0);">Linear regression uses a straight line to summarize, interpret, and forecast the fluctuations of a dependent variable (Y) according to another independent variable (X). Regardless of the objective, the success of regression analysis is substantially influenced by the relationships between the explanatory variab</span>les [<xref ref-type="bibr" rid="ref_12">12</xref>].</p><p><span style="color: rgb(0, 0, 0);">A statistical technique known as MLR describes the fluctuations of an endogenous variable connected to numerous exogenous variab</span>les [<xref ref-type="bibr" rid="ref_13">13</xref>]<span style="color: rgb(0, 0, 0);">. </span>It a<span style="color: rgb(0, 0, 0);">ddresses the same problem as the simple linear regression (SLR). The difference is that MLR seeks to explain the values of Y not by a single variable X, but by several variables {<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula>} known as explanatory variables. After slightly modifying the previous notations, it is assumed that Y and {<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula>} has a linear relationshi</span>p [<xref ref-type="bibr" rid="ref_13">13</xref>]:</p>
              
                <disp-formula>
                  <label>(5)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>Y</mi>
                    <mi>ε</mi>
                    <mo>=</mo>
                    <mo>+</mo>
                    <mo>+</mo>
                    <mo>+</mo>
                    <mo>…</mo>
                    <mo>+</mo>
                    <mo>+</mo>
                    <msub>
                      <mi>a</mi>
                      <mn>0</mn>
                    </msub>
                    <msub>
                      <mi>a</mi>
                      <mn>1</mn>
                    </msub>
                    <msub>
                      <mi>X</mi>
                      <mn>1</mn>
                    </msub>
                    <msub>
                      <mi>a</mi>
                      <mn>2</mn>
                    </msub>
                    <msub>
                      <mi>X</mi>
                      <mn>2</mn>
                    </msub>
                    <msub>
                      <mi>a</mi>
                      <mi>p</mi>
                    </msub>
                    <msub>
                      <mi>X</mi>
                      <mi>p</mi>
                    </msub>
                  </math>
                </disp-formula>
              
              <p>where, <span style="color: rgb(0, 0, 0);">Y is the dependent variable; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mn>1</mn>
    </msub>
    <msub>
      <mi>X</mi>
      <mn>2</mn>
    </msub>
    <msub>
      <mi>X</mi>
      <mi>p</mi>
    </msub>
    <mo>,</mo>
    <mo>,</mo>
    <mo>…</mo>
    <mo>,</mo>
  </math>
</inline-formula> are the independent variables; p is the number of explanatory variables; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>a</mi>
      <mn>0</mn>
    </msub>
    <msub>
      <mi>a</mi>
      <mn>1</mn>
    </msub>
    <msub>
      <mi>a</mi>
      <mn>2</mn>
    </msub>
    <msub>
      <mi>a</mi>
      <mi>p</mi>
    </msub>
    <mo>,</mo>
    <mo>,</mo>
    <mo>,</mo>
    <mo>…</mo>
    <mo>,</mo>
  </math>
</inline-formula> are the parameters to be estimated; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>a</mi>
      <mn>0</mn>
    </msub>
  </math>
</inline-formula> is the estimated intercept; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>a</mi>
      <mn>1</mn>
    </msub>
    <msub>
      <mi>a</mi>
      <mn>2</mn>
    </msub>
    <msub>
      <mi>a</mi>
      <mi>p</mi>
    </msub>
    <mo>,</mo>
    <mo>,</mo>
    <mo>…</mo>
    <mo>,</mo>
  </math>
</inline-formula> are the slopes (partial regression coefficients); </span><italic>ε</italic><span style="color: rgb(0, 0, 0);"> is the error of the model that expresses or summarizes the missing information in the linear explanation of Y values from <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mn>1</mn>
    </msub>
    <msub>
      <mi>X</mi>
      <mn>2</mn>
    </msub>
    <msub>
      <mi>X</mi>
      <mi>p</mi>
    </msub>
    <mo>,</mo>
    <mo>,</mo>
    <mo>…</mo>
    <mo>,</mo>
  </math>
</inline-formula></span> [<xref ref-type="bibr" rid="ref_14">14</xref>].</p><p><span style="color: rgb(0, 0, 0);">The MLR coefficients can be interpreted the same as the SLR coefficients: The intercept represents the expected value of Y when the values of all the <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula> are fixed at 0. Each slope <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>a</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula> indicates the expected change in Y for a change of one unit in <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula>, while all other things are equal. The last rule is important, for it requires all other <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula> to have fixed values</span> [<xref ref-type="bibr" rid="ref_15">15</xref>].</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>2.4.2 Mlp-type ann</title>
              
              <p><span style="color: rgb(0, 0, 0);">The ANN is a computational model mimicking biological behaviors of the human nervous </span>system [<xref ref-type="bibr" rid="ref_16">16</xref>]. The <span style="color: rgb(0, 0, 0);">human brain is composed of a vast number of neurons, which correspond to the nodes, the fundamental elements of an ANN. The ANN is an excellent tool for data a</span>nalysis [<xref ref-type="bibr" rid="ref_17">17</xref>].</p><p><span style="color: rgb(0, 0, 0);">Each ANN contains many nodes that communicate with each other by sending signals through links called synaptic connections. In general, there are three kinds of nodes in the neural syste</span>m [<xref ref-type="bibr" rid="ref_18">18</xref>]:<span style="color: rgb(0, 0, 0);"> Input nodes that receive data, output nodes that send data as the system output; hidden nodes whose input and output signals remain in the system.</span></p><p><span style="color: rgb(0, 0, 0);">(a) Formal node</span></p><p><span style="color: rgb(0, 0, 0);">In statistics, a formal node is a parameterized algebraic function with nonlinear paramet</span>ers [<xref ref-type="bibr" rid="ref_19">19</xref>] and<span style="color: rgb(0, 0, 0);"> bounded values:</span></p>
              
                <disp-formula>
                  <label>(6)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>Y</mi>
                    <mi>f</mi>
                    <mo>=</mo>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo>,</mo>
                      <mo>,</mo>
                      <mo>…</mo>
                      <mo>,</mo>
                      <mo>;</mo>
                      <mo>,</mo>
                      <mo>,</mo>
                      <mo>…</mo>
                      <mo>,</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>X</mi>
                        <mn>1</mn>
                      </msub>
                      <msub>
                        <mi>X</mi>
                        <mn>2</mn>
                      </msub>
                      <msub>
                        <mi>X</mi>
                        <mi>n</mi>
                      </msub>
                      <msub>
                        <mi>W</mi>
                        <mn>1</mn>
                      </msub>
                      <msub>
                        <mi>W</mi>
                        <mn>2</mn>
                      </msub>
                      <msub>
                        <mi>W</mi>
                        <mi>n</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>where,<span style="color: rgb(0, 0, 0);"> <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> is the model input; <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="normal">w</mi>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="normal">i</mi>
        </mrow>
      </mrow>
    </msub>
  </math>
</inline-formula> is the model parameter; </span><italic>f</italic><span style="color: rgb(0, 0, 0);"> is the activation function of the no</span>de [<xref ref-type="bibr" rid="ref_20">20</xref>].</p>
              
                <fig id="fig_1">
                  <label>Figure 1</label>
                  <caption>Mapping biological node to artificial node</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_W36Mj8tyT3XVj0s5.png"/>
                </fig>
              
              
                <fig id="fig_2">
                  <label>Figure 2</label>
                  <caption>Schematic of a formal node</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_rtCtfnHRUVkMf4lJ.png"/>
                </fig>
              
              <p><xref ref-type="fig" rid="fig_1">Figure 1</xref> com<span style="color: rgb(0, 0, 0);">pares the structure of an artificial node with that of a human neuron. The artificial node (an elementary processor) receives some inputs from upstream nodes. Each input is associated with a weight W, which represents the strength of the connection, and an output function, whose output is imported to other similar n</span>odes [<xref ref-type="bibr" rid="ref_21">21</xref>].</p><p><span style="color: rgb(0, 0, 0);">The formal node is the essential element of a neural network. It is a straightforward mathematical operator whose numerical value can easily be calculated. A typical node has N inputs, each with a synaptic weig</span>ht (<xref ref-type="fig" rid="fig_2">Figure 2</xref>), <span style="color: rgb(0, 0, 0);">an output function, an output which in turn serves as an input to other similar no</span>des [<xref ref-type="bibr" rid="ref_22">22</xref>]. T<span style="color: rgb(0, 0, 0);">he result is a nonlinear function f of a linear combination of the inputs (<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula>). The most frequently used potential v is the weighted sum of the inputs <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula> weighted by the coefficients (<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>w</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula>) also called connection w</span>eights [<xref ref-type="bibr" rid="ref_23">23</xref>].</p><p><span style="color: rgb(0, 0, 0);">Then, a formal node can be characterized as fo</span>llows [<xref ref-type="bibr" rid="ref_24">24</xref>]:<span style="color: rgb(0, 0, 0);"> The input signals are accepted by a set of synaptic connections, which are defined by synaptic weights determining the effect of the signal by node </span><italic>i</italic><span style="color: rgb(0, 0, 0);"> on node </span><italic>j</italic><span style="color: rgb(0, 0, 0);">. In addition, a combination function or adder performs the weighted activation sum that converges to node</span><italic> j</italic><span style="color: rgb(0, 0, 0);">. This weighted sum can be expressed as:</span></p>
              
                <disp-formula>
                  <label>(7)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>A</mi>
                      <mi>j</mi>
                    </msub>
                    <msub>
                      <mi>W</mi>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mi>j</mi>
                      </mrow>
                    </msub>
                    <msub>
                      <mi>X</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>=</mo>
                    <munder>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mi>i</mi>
                    </munder>
                  </math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>W</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>i</mi>
        <mi>j</mi>
      </mrow>
    </msub>
  </math>
</inline-formula><span style="color: rgb(0, 0, 0);"> is the synaptic weight;</span><italic> </italic><inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>i</mi>
    </msub>
  </math>
</inline-formula><span style="color: rgb(0, 0, 0);"> is the input value. An activation (or transfer) function drives a node by determining its activation as the no</span>de output [<xref ref-type="bibr" rid="ref_25">25</xref>]:</p>
              
                <disp-formula>
                  <label>(8)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mo data-mjx-texclass="OP">∑</mo>
                    <mo>+</mo>
                    <msub>
                      <mi>W</mi>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mi>j</mi>
                      </mrow>
                    </msub>
                    <msub>
                      <mi>X</mi>
                      <mi>i</mi>
                    </msub>
                    <msub>
                      <mi>θ</mi>
                      <mi>j</mi>
                    </msub>
                  </math>
                </disp-formula>
              
              <p><span style="color: rgb(0, 0, 0);">On this basis, a transfer function </span><italic>φ</italic><span style="color: rgb(0, 0, 0);"> computes the value of the node state, called activation <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <msub>
      <mi>X</mi>
      <mi>j</mi>
    </msub>
  </math>
</inline-formula>. It is then transmitted to the forward nodes:</span></p>
              
                <disp-formula>
                  <label>(9)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                      <mi>Y</mi>
                      <mi>j</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>φ</mi>
                    <mrow data-mjx-texclass="INNER">
                      <mo data-mjx-texclass="OPEN">(</mo>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mo>+</mo>
                      <mo data-mjx-texclass="CLOSE">)</mo>
                      <msub>
                        <mi>W</mi>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mi>j</mi>
                        </mrow>
                      </msub>
                      <msub>
                        <mi>X</mi>
                        <mi>i</mi>
                      </msub>
                      <msub>
                        <mi>θ</mi>
                        <mi>j</mi>
                      </msub>
                    </mrow>
                  </math>
                </disp-formula>
              
              <p>where, <italic>θ</italic><sub><italic>j</italic></sub><italic> </italic><span style="color: rgb(0, 0, 0);">is the bias of node j based on a kind of local weight, i.e., an inhibitory input employed in many types of activation functions. The input makes the network more flexible by varying the node’s trigger threshold through weight adjustment via training. This is adopted in several types of activation functio</span>ns [<xref ref-type="bibr" rid="ref_26">26</xref>].</p><p><span style="color: rgb(0, 0, 0);">(b) Activation function</span></p><p><span style="color: rgb(0, 0, 0);">The activation function non-linearizes the functioning of the node. It generally has three interval</span>s [<xref ref-type="bibr" rid="ref_27">27</xref>]: <span style="color: rgb(0, 0, 0); font-family: 宋体;">T</span><span style="color: rgb(0, 0, 0);">he node is inactive, when the value of the function is below the threshold (the output is often 0 or -1); the node is in the transitional state, when the value of the function is around the threshold; the node is active, when the value of the function is above the threshold (the output is often 1).</span></p><p>There are several activation functions, including hyperbolic tangent, Gaussian, sigmoid, affine function, and arc tangent function. The most popular one is the sigmoid function (<xref ref-type="fig" rid="fig_3">Figure 3</xref>) [<xref ref-type="bibr" rid="ref_28">28</xref>]:</p>
              
                <disp-formula>
                  <label>(10)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>f</mi>
                    <mi>x</mi>
                    <mo stretchy="false">(</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mrow>
                        <mn>1</mn>
                        <mo>+</mo>
                        <msup>
                          <mi>e</mi>
                          <mrow data-mjx-texclass="ORD">
                            <mo>−</mo>
                            <mi>x</mi>
                          </mrow>
                        </msup>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              
                <fig id="fig_3">
                  <label>Figure 3</label>
                  <caption>Graphical representation of the sigmoid function</caption>
                  <abstract/>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_poOWCt7CyTPNZIZe.png"/>
                </fig>
              
            </sec>
          
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>3. Results and discussion</title>
      <p><span style="color: rgb(0, 0, 0);">The Results section may be divided into subsections. It should describe the results concisely and precisely, provide their interpretation, and draw possible conclusions from the results. The results from the STATISTICA neural network method are displayed in </span><xref ref-type="table" rid="table_1">Table 1</xref>. U<span style="color: rgb(0, 0, 0);">sing the Broyden-Fletcher-Goldfarb-Shanno algo</span>rithm [<xref ref-type="bibr" rid="ref_29">29</xref>], A<span style="color: rgb(0, 0, 0);">ccording to the topology, they provide the two layers' determination factors, cycles, and training algorithm (BFGS).</span></p><p><span style="color: rgb(0, 0, 0);">By changing the total number of hidden nodes and the number of training cycles, we changed the network's design (number of iterations). We gradually changed the number of hidden nodes to achieve this (1, ..., 15). The findings demonstrated that the optimum prediction model for heavy metal concentrations is obtained when the number of hidden nodes equals eleven for Mn, eight for B, and fifteen for Zn. At this moment, the lowest mean square error, the most iterations, and the highest determination coefficient have been achieved.</span></p><p>The network's training in the Boron scenario is shown in <xref ref-type="fig" rid="fig_4">Figure 4</xref>. After 102 steps, the outcome is reached. The learning error and test gradients converge properly with eight nodes in the caching layer.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>The balance of the best architectures obtained by Statistica for the three metals</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p></p></td><td colspan="1" rowspan="1"><p>Architecture</p></td><td colspan="1" rowspan="1"><p>Training algorithm</p></td><td colspan="1" rowspan="1"><p>Error function</p></td><td colspan="1" rowspan="1"><p>Activation function of the hidden layer</p></td><td colspan="1" rowspan="1"><p>Output layer activation function</p></td><td colspan="1" rowspan="1"><p>Number of iterations</p></td></tr><tr><td colspan="1" rowspan="1"><p>Zn</p></td><td colspan="1" rowspan="1"><p>16-15-1</p></td><td colspan="1" rowspan="1"><p>BFGS</p></td><td colspan="1" rowspan="1"><p>SOS</p></td><td colspan="1" rowspan="1"><p>Tanh</p></td><td colspan="1" rowspan="1"><p>Logistic</p></td><td colspan="1" rowspan="1"><p>217</p></td></tr><tr><td colspan="1" rowspan="1"><p>B</p></td><td colspan="1" rowspan="1"><p>16-8-1</p></td><td colspan="1" rowspan="1"><p>BFGS</p></td><td colspan="1" rowspan="1"><p>SOS</p></td><td colspan="1" rowspan="1"><p>Tanh</p></td><td colspan="1" rowspan="1"><p>Exponential</p></td><td colspan="1" rowspan="1"><p>102</p></td></tr><tr><td colspan="1" rowspan="1"><p>Mn</p></td><td colspan="1" rowspan="1"><p>16-11-1</p></td><td colspan="1" rowspan="1"><p>BFGS</p></td><td colspan="1" rowspan="1"><p>SOS</p></td><td colspan="1" rowspan="1"><p>Logistic</p></td><td colspan="1" rowspan="1"><p>Exponential</p></td><td colspan="1" rowspan="1"><p>228</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>Eight nodes in the cache layer and the development of the RMSE in the case of Boron</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_k_tZvd9cZMD4DNUR.png"/>
        </fig>
      
      
        <table-wrap id="table_2">
          <label>Table 2</label>
          <caption>Changes in the root mean square sum of errors (RMSE), the iteration number (IN), and the determination coefficient R² for the elements boron, manganese, and zinc as a function of the number of hidden layer nodes (NHLN)</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p></p></td><td colspan="3" rowspan="1"><p>NHLN=8</p></td><td colspan="3" rowspan="1"><p>NHLN=11</p></td><td colspan="3" rowspan="1"><p>NHLN=15</p></td></tr><tr><td colspan="1" rowspan="1"><p>Metals</p></td><td colspan="1" rowspan="1"><p>R²</p></td><td colspan="1" rowspan="1"><p>IN</p></td><td colspan="1" rowspan="1"><p>RMSE</p></td><td colspan="1" rowspan="1"><p>R²</p></td><td colspan="1" rowspan="1"><p>IN</p></td><td colspan="1" rowspan="1"><p>RMSE</p></td><td colspan="1" rowspan="1"><p>R²</p></td><td colspan="1" rowspan="1"><p>IN</p></td><td colspan="1" rowspan="1"><p>RSME</p></td></tr><tr><td colspan="1" rowspan="1"><p>B</p></td><td colspan="1" rowspan="1"><p>0.99</p></td><td colspan="1" rowspan="1"><p>102</p></td><td colspan="1" rowspan="1"><p>0.0001</p></td><td colspan="1" rowspan="1"><p>0.98</p></td><td colspan="1" rowspan="1"><p>199</p></td><td colspan="1" rowspan="1"><p>2.07</p></td><td colspan="1" rowspan="1"><p>0.95</p></td><td colspan="1" rowspan="1"><p>81</p></td><td colspan="1" rowspan="1"><p>5.96</p></td></tr><tr><td colspan="1" rowspan="1"><p>Mn</p></td><td colspan="1" rowspan="1"><p>0.93</p></td><td colspan="1" rowspan="1"><p>75</p></td><td colspan="1" rowspan="1"><p>4.25</p></td><td colspan="1" rowspan="1"><p>0.99</p></td><td colspan="1" rowspan="1"><p>228</p></td><td colspan="1" rowspan="1"><p>0.003</p></td><td colspan="1" rowspan="1"><p>0.96</p></td><td colspan="1" rowspan="1"><p>123</p></td><td colspan="1" rowspan="1"><p>1.13</p></td></tr><tr><td colspan="1" rowspan="1"><p>Zn</p></td><td colspan="1" rowspan="1"><p>0.97</p></td><td colspan="1" rowspan="1"><p>58</p></td><td colspan="1" rowspan="1"><p>0.98</p></td><td colspan="1" rowspan="1"><p>0.94</p></td><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>2,98</p></td><td colspan="1" rowspan="1"><p>0.99</p></td><td colspan="1" rowspan="1"><p>217</p></td><td colspan="1" rowspan="1"><p>0,001</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <table-wrap id="table_3">
          <label>Table 3</label>
          <caption>Between the heavy metal concentrations observed and those anticipated by the MRL, a coefficient of determination ANN</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p></p></td><td colspan="1" rowspan="1"><p>Boron</p></td><td colspan="1" rowspan="1"><p>Manganese</p></td><td colspan="1" rowspan="1"><p>Zinc</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="1" rowspan="1"><p>MLR</p></td><td colspan="1" rowspan="1"><p>R² = 0.17</p></td><td colspan="1" rowspan="1"><p>R² = 0,22</p></td><td colspan="1" rowspan="1"><p>R² = 0,4</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="1" rowspan="8"><p>ANN</p></td><td colspan="4" rowspan="1"><p>Architectures of the selected models</p></td></tr><tr><td colspan="1" rowspan="1"><p>[16-8 -1]</p></td><td colspan="1" rowspan="1"><p>[16-11 -1]</p></td><td colspan="1" rowspan="1"><p>[16-15 -1]</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="4" rowspan="1"><p>Learning</p></td></tr><tr><td colspan="1" rowspan="1"><p>R² = 0,997</p></td><td colspan="1" rowspan="1"><p>R² = 0,998</p></td><td colspan="1" rowspan="1"><p>R² = 0,9998</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="1" rowspan="1"><p>SSE = 0,0001</p></td><td colspan="1" rowspan="1"><p>SSE = 0,003</p></td><td colspan="1" rowspan="1"><p>SSE=0,001</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="4" rowspan="1"><p>Test</p></td></tr><tr><td colspan="1" rowspan="1"><p>R² = 0,996</p></td><td colspan="1" rowspan="1"><p>R² = 0,997</p></td><td colspan="1" rowspan="1"><p>R² = 0,997</p></td><td colspan="1" rowspan="1"><p></p></td></tr><tr><td colspan="1" rowspan="1"><p>SSE = 0,008</p></td><td colspan="1" rowspan="1"><p>SSE = 4.291</p></td><td colspan="1" rowspan="1"><p>SSE = 3.902</p></td><td colspan="1" rowspan="1"><p></p></td></tr></tbody></table>
        </table-wrap>
      
      <p><span style="color: rgb(0, 0, 0);">Overlearning has occurred due to the network's extensive training; this occurrence has occurred 102 times.</span></p><p><span style="color: rgb(0, 0, 0);">Comparing neural network models to those discovered using MLR, increases in the explanation of variance of up to 82% are possible. For manganese, boron, and zinc, it is 77%, 82%, and 59% respectively. The coefficients of determination rise from 0.224 to 0.99, 0.172 to 0.99, and 0.40 to 0.99, respectively. The outcomes sho</span>wn in <xref ref-type="table" rid="table_2">Table 2</xref> dem<span style="color: rgb(0, 0, 0);">onstrate that the models created by the ANN are superior to those discovered by the MLR approach. In fact, the models created by the ANN have estimated coefficients of determination that are substantially higher (above 0.9), while the models created by the MLR have calculated coefficients that are lower (between 0.17 and 0.40). Referring to in subgraphs (a) and (b) of </span><xref ref-type="fig" rid="fig_5">Figure 5</xref> <span style="color: rgb(0, 0, 0);">and the subsequen</span>t <xref ref-type="table" rid="table_2">Table 2</xref> and <xref ref-type="table" rid="table_3">Table 3</xref> ma<span style="color: rgb(0, 0, 0);">kes this clear.</span></p><p>It may be deduced from the determination coefficients found when analyzing the accuracy of the ANN models that they closely match learning-related models. On the other hand, there are some differences between the determination coefficients found during training and those used to assess the models' applicability to MLR. This reveals that there are nonlinear correlations between the Physico-chemical characteristics of the environment and the concentrations of heavy metals in the waters of the Oued Inaouen catchment area. What typically manifests itself in an aquatic environment [<xref ref-type="bibr" rid="ref_30">30</xref>], [<xref ref-type="bibr" rid="ref_31">31</xref>].</p>
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>(a) MLR (MLR) models' estimates of boron, manganese, and zinc concentrations and the values actually measured. (b) ANN study relating the predicted amounts of boron, manganese, and zinc (ANN)</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_puvSeLqnIgB8SAzJ.png"/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_SA9JGb-YGQNTv-95.png"/>
        </fig>
      
      
        <fig id="fig_6">
          <label>Figure 6</label>
          <caption>Design of the three-layer configuration neural network [16-8-1] employed in this research</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_RM0JEUIC8bnT8oC-.png"/>
        </fig>
      
      
        <fig id="fig_7">
          <label>Figure 7</label>
          <caption>Relationship between the estimated values and their residuals from the NR and relative MLR model</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_fUCEWoPeUqoDU93n.png"/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2022/11/img_bLdqvCcVWzuWZiaZ.png"/>
        </fig>
      
      <p><span style="color: rgb(0, 0, 0);">The ANN architecture we employed for Boron prediction is shown i</span>n <xref ref-type="fig" rid="fig_6">Figure 6</xref>.</p><p><span style="color: rgb(0, 0, 0);">A topology network [16-8-1] is what it is.</span></p><p>The connections between measured and estimated amounts of heavy metals for models created using the ANN and MLR approaches are shown in subgraphs (a) and (b) of <xref ref-type="fig" rid="fig_5">Figure 5</xref>. The effectiveness of the ANN technique is established by the other two metals and manganese, which both demonstrate a high coefficient of determination of 0.99. (Boron and Zinc). We can show that the models discovered by the ANN are more effective by contrasting them with those produced by the MLR. We are looking at in subgraphs (a) and (b) of <xref ref-type="fig" rid="fig_5">Figure 5</xref>, it is simple to observe this.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>4. Residual studies</title>
      <p><span style="color: rgb(0, 0, 0);">The relative error is the error made by the models created using each method on a specific member of the sample used to build the m</span>odel [<xref ref-type="bibr" rid="ref_32">32</xref>].</p><p><span style="color: rgb(0, 0, 0);">For starters, it enables us to spot any outliers or observations crucial in deciding the regression. This examines the residuals (Yi-Yi') essentia</span>l [<xref ref-type="bibr" rid="ref_33">33</xref>]. <span style="color: rgb(0, 0, 0);">Second, the only way to empirically test the accuracy of the model's assumptions is frequently reviewed these residuals.</span></p><p><span style="color: rgb(0, 0, 0);">The relationships between the estimated heavy metal values from the neural network and MLR models and their residuals are depicted in the following figures. These graphs demonstrate that for the four metals under investigation, the residuals generated by neural network approach models are less d</span>ispersed [<xref ref-type="bibr" rid="ref_34">34</xref>]<span style="color: rgb(0, 0, 0);"> (near zero) than those obtained by MLR models. This demonstrates once more that the current method, which is based on the principle of ANNs, is more effective than the method based on MLR, which is typically used in the development of linear prediction models for predicting the heavy metal contents of the surface water from Physico-chemical parameters.</span></p><p><span style="color: rgb(0, 0, 0);">The relationships between the predicted heavy metal levels using the neural network (NN) and MLR (MLR) models and their residual</span>s are shown in <xref ref-type="fig" rid="fig_7">Figure 7</xref>.</p><p><span style="color: rgb(0, 0, 0);">The analysis of the residuals, which represent the differences between the estimated and observed values, shows that the models developed using the method based on the neural network principle are more efficient than those generated using MLR for the three metals studied. This proof shows a nonlinear relationship between the surface water heavy metal levels and the examined Physico-chemical parameters.</span></p>
    </sec>
    <sec disp-level="level1" sec-type="conclusions">
      <title>5. Conclusions</title>
      <p><span style="color: rgb(0, 0, 0);">This study used MLR and ANNs to estimate the concentrations of heavy metals (manganese, boron, and zinc) in the surface waters of the Inaouen watershed based on their Physico-chemical parameters.</span></p><p><span style="color: rgb(0, 0, 0);">There are benefits and drawbacks to these statistical methods. Although more effective and efficient, neural networks do not clearly explain the relationship between the input and output data. Because there is no linear relationship between the independent and dependent variables, MLR allows for the determination of equations that describe the relationship between the explanatory input variables and the output variables.</span></p><p><span style="color: rgb(0, 0, 0);">The calculations of the mean square errors performed in this study revealed that a three-layer architecture with an input layer, a hidden layer, and an output layer is preferable for the establishment of prediction models using ANNs related to the metals studied in the surface waters of the Inaouen catchment area. They also demonstrated that, when employing a backpropagation algorithm and supervised learning, a hidden layer with 15 nodes for zinc, 11 for manganese, and 8 for boron produces mathematical models that are more accurate at predicting the future than those that use fewer nodes.</span></p><p><span style="color: rgb(0, 0, 0);">The three heavy metals found in the surface waters of the Inaouen watershed have shown significant learning and predictive capabilities thanks to ANNs.</span></p><p><span style="color: rgb(0, 0, 0);">To put things in perspective, the following ideas can help us develop this topic further:</span></p><p><span style="color: rgb(0, 0, 0);">• Work with different network types, like recurrent networks;</span></p><p><span style="color: rgb(0, 0, 0);">• Utilize other activation methods;</span></p><p><span style="color: rgb(0, 0, 0);">• To predict the contents of these metals in the surface waters of the Moroccan watershed, try extrapolating the effective models developed by ANNs related to the prediction of metal contents studied in the surface waters of the Inaouen watershed.</span></p><p>• The outcomes encourage further consideration of the approach that enhances the work done thus far. To test another RNA architecture to see which one yields the best results, or to investigate the possibility of simultaneously predicting the three parameters, for instance, would be very interesting.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      <p></p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p><span style="color: rgb(0, 0, 0);">The data used to support the findings of this study are available from the corresponding author upon request.</span></p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p><span style="color: rgb(0, 0, 0);">The authors declare that they have no conflicts of interest.</span></p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S. S.</given-names>
              <surname>Sonone</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Jadhav</surname>
            </name>
            <name>
              <given-names>M. S.</given-names>
              <surname>Sankhla</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Kumar</surname>
            </name>
          </person-group>
          <article-title>Water contamination by heavy metals and their toxic effect on aquaculture and human health through food Chain</article-title>
          <source>Lett. Appl. NanoBioScience</source>
          <year>2020</year>
          <volume>10</volume>
          <issue>2</issue>
          <page-range>2148-2166</page-range>
          <fpage>2148</fpage>
          <lpage>2166</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.33263/LIANBS102.21482166</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>Q. H.</given-names>
              <surname>Vuong</surname>
            </name>
          </person-group>
          <article-title>From children’s literature to sustainability science, and young scientists for a more sustainable Earth</article-title>
          <source>J. Sustain. Educ.</source>
          <year>2020</year>
          <volume>24</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>H. A.</given-names>
              <surname>Kacem</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Bouroubi</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Khomalli</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Elyaagoubi</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Maanan</surname>
            </name>
          </person-group>
          <article-title>The economic benefit of coastal blue carbon stocks in a Moroccan Lagoon ecosystem: A case study at Moulay Bousselham Lagoon</article-title>
          <source>Wetlands</source>
          <year>2022</year>
          <volume>42</volume>
          <issue>2</issue>
          <page-range>1-15</page-range>
          <fpage>1</fpage>
          <lpage>15</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s13157-022-01533-x</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>El Chaal</surname>
            </name>
            <name>
              <given-names>M. O.</given-names>
              <surname>Aboutafail</surname>
            </name>
          </person-group>
          <article-title>Statistical modelling by topological maps of kohonen for classification of the physicochemical quality of surface waters of the inaouen watershed under matlab</article-title>
          <source>J. Niger. Soc. Phys. Sci.</source>
          <year>2022</year>
          <volume>4</volume>
          <issue>2</issue>
          <page-range>223-230</page-range>
          <fpage>223</fpage>
          <lpage>230</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.46481/jnsps.2022.608</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>El Chaal</surname>
            </name>
            <name>
              <given-names>M. O.</given-names>
              <surname>Aboutafail</surname>
            </name>
          </person-group>
          <article-title>Development of stochastic mathematical models for the prediction of heavy metal content in surface waters using artificial neural network and multiple linear regression</article-title>
          <source>E3S Web of Conferences</source>
          <year>2021</year>
          <volume>314</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1051/e3sconf/202131402001</pub-id>
          <pub-id pub-id-type="publisher-id">02001</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>El Chaal</surname>
            </name>
            <name>
              <given-names>M. O.</given-names>
              <surname>Aboutafail</surname>
            </name>
          </person-group>
          <article-title>A comparative study of back-propagation algorithms: Levenberg-Marquart and BFGS for the formation of multilayer neural networks for estimation of fluoride</article-title>
          <source>Commun. Math. Biol. Neurosci.</source>
          <year>2022</year>
          <volume>2022</volume>
          <issue/>
          <page-range>1-17</page-range>
          <fpage>1</fpage>
          <lpage>17</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.28919/cmbn/7355</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Gheziel</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Hanini</surname>
            </name>
            <name>
              <given-names>B.</given-names>
              <surname>Mohamedi</surname>
            </name>
          </person-group>
          <article-title>Artificial neural network (ANN) for prediction indoor airborne particle concentration</article-title>
          <source>Int. J. Vent.</source>
          <year>2022</year>
          <volume>21</volume>
          <issue>1</issue>
          <page-range>74-87</page-range>
          <fpage>74</fpage>
          <lpage>87</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1080/14733315.2021.1876408</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>Magallanes-Quintanar</surname>
            </name>
            <name>
              <given-names>C. E.</given-names>
              <surname>Galván-Tejada</surname>
            </name>
            <name>
              <given-names>J. I.</given-names>
              <surname>Galván-Tejada</surname>
            </name>
            <name>
              <given-names>S. J.</given-names>
              <surname>Méndez-Gallegos</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>García-Domínguez</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Gamboa-Rosales</surname>
            </name>
          </person-group>
          <article-title>Narx neural networks models for prediction of standardized precipitation index in central Mexico</article-title>
          <source>Atmosphere-Basel</source>
          <year>2022</year>
          <volume>13</volume>
          <issue>8</issue>
          <page-range>1254-1254</page-range>
          <fpage>1254</fpage>
          <lpage>1254</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.3390/atmos13081254</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Lause</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Berens</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Kobak</surname>
            </name>
          </person-group>
          <article-title>Analytic Pearson residuals for normalization of single-cell RNA-seq UMI data</article-title>
          <source>Genome Biol.</source>
          <year>2021</year>
          <volume>22</volume>
          <issue>1</issue>
          <page-range>1-20</page-range>
          <fpage>1</fpage>
          <lpage>20</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1186/s13059-021-02451-7</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>A. E. H. H.</given-names>
              <surname>Alayat</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>El Badaoui</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Abdallaoui</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Abrid</surname>
            </name>
          </person-group>
          <article-title>Development of mathematical models for predicting the iron concentrations of lake oubeira waters (ne Algerian)</article-title>
          <source>J. Fundam. Appl. Sci.</source>
          <year>2018</year>
          <volume>10</volume>
          <issue>1</issue>
          <page-range>83-96</page-range>
          <fpage>83</fpage>
          <lpage>96</lpage>
          <pub-id pub-id-type="doi">http://dx.doi.org/10.4314/jfas.v10i1.6</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>D.</given-names>
              <surname>Chicco</surname>
            </name>
            <name>
              <given-names>M. J.</given-names>
              <surname>Warrens</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Jurman</surname>
            </name>
          </person-group>
          <article-title>The coefficient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation</article-title>
          <source>PeerJ Comput. Sci.</source>
          <year>2021</year>
          <volume>7</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.7717/peerj-cs.623</pub-id>
          <pub-id pub-id-type="publisher-id">e623</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <given-names>P.</given-names>
              <surname>Roback</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Legler</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <article-title/>
          <source>Beyond multiple linear regression: applied generalized linear models and multilevel models in R, New York, NY</source>
          <publisher-loc>USA</publisher-loc>
          <publisher-name>Chapman and Hall/CRC</publisher-name>
          <year>2021</year>
          <volume/>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1201/9780429066665</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>G.</given-names>
              <surname>Ciulla</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>D'Amico</surname>
            </name>
          </person-group>
          <article-title>Building energy performance forecasting: A multiple linear regression approach</article-title>
          <source>Appl. Energy</source>
          <year>2019</year>
          <volume>253</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1016/j.apenergy.2019.113500</pub-id>
          <pub-id pub-id-type="publisher-id">113500</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>N. A. F.</given-names>
              <surname>Sulaiman</surname>
            </name>
            <name>
              <given-names>S. M.</given-names>
              <surname>Shaharudin</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Ismail</surname>
            </name>
            <name>
              <given-names>N. H.</given-names>
              <surname>Zainuddin</surname>
            </name>
            <name>
              <given-names>M. L.</given-names>
              <surname>Tan</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Abd Jalil</surname>
            </name>
          </person-group>
          <article-title>Predictive modelling of statistical downscaling based on hybrid machine learning model for daily rainfall in east-coast peninsular malaysia</article-title>
          <source>Symmetry-Basel</source>
          <year>2022</year>
          <volume>14</volume>
          <issue>5</issue>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.3390/sym14050927</pub-id>
          <pub-id pub-id-type="publisher-id">927</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>L.</given-names>
              <surname>Plonsky</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Ghanbar</surname>
            </name>
          </person-group>
          <article-title>Multiple regression in L2 research: A methodological synthesis and guide to interpreting R2 values</article-title>
          <source>Mod. Lang. J.</source>
          <year>2018</year>
          <volume>102</volume>
          <issue>4</issue>
          <page-range>713-731</page-range>
          <fpage>713</fpage>
          <lpage>731</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1111/modl.12509</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>T.</given-names>
              <surname>Dalgaty</surname>
            </name>
            <name>
              <given-names>J. P.</given-names>
              <surname>Miller</surname>
            </name>
            <name>
              <given-names>E.</given-names>
              <surname>Vianello</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Casas</surname>
            </name>
          </person-group>
          <article-title>Bio-inspired architectures substantially reduce the memory requirements of neural network models</article-title>
          <source>Front. Neurosci.</source>
          <year>2021</year>
          <volume>15</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.3389/fnins.2021.612359</pub-id>
          <pub-id pub-id-type="publisher-id">612359</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>K.</given-names>
              <surname>Ostad-Ali-Askari</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Shayan</surname>
            </name>
          </person-group>
          <article-title>Subsurface drain spacing in the unsteady conditions by HYDRUS-3D and artificial neural networks</article-title>
          <source>Arab. J. Geosci.</source>
          <year>2021</year>
          <volume>14</volume>
          <issue>8</issue>
          <page-range>1-14</page-range>
          <fpage>1</fpage>
          <lpage>14</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s12517-021-08336-0</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>B.</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Yao</surname>
            </name>
          </person-group>
          <article-title>Precipitable water vapor fusion based on a generalized regression neural network</article-title>
          <source>J. Geod.</source>
          <year>2021</year>
          <volume>95</volume>
          <issue>3</issue>
          <page-range>1-14</page-range>
          <fpage>1</fpage>
          <lpage>14</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s00190-021-01482-z</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Scardapane</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Wang</surname>
            </name>
          </person-group>
          <article-title>Randomness in neural networks: An overview</article-title>
          <source>Wiley Interdiscip. Rev. Data Min. Knowl. Discov.</source>
          <year>2017</year>
          <volume>7</volume>
          <issue>2</issue>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1002/widm.1200</pub-id>
          <pub-id pub-id-type="publisher-id">e1200</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Eger</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Youssef</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Gurevych</surname>
            </name>
          </person-group>
          <article-title>Is it time to swish? Comparing deep learning activation functions across NLP tasks</article-title>
          <source>arXiv Prepr.</source>
          <year>2019</year>
          <volume>2019</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.48550/arXiv.1901.02671</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>V.</given-names>
              <surname>Sitzmann</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Martel</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Bergman</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Lindell</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Wetzstein</surname>
            </name>
          </person-group>
          <article-title>Implicit neural representations with periodic activation functions</article-title>
          <source>Adv. Neural Inf. Process. Syst.</source>
          <year>2020</year>
          <volume>33</volume>
          <issue/>
          <page-range>7462-7473</page-range>
          <fpage>7462</fpage>
          <lpage>7473</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Chavlis</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Poirazi</surname>
            </name>
          </person-group>
          <article-title>Drawing inspiration from biological dendrites to empower artificial neural networks</article-title>
          <source>Curr. Opin. Neurobiol.</source>
          <year>2021</year>
          <volume>70</volume>
          <issue/>
          <page-range>1-10</page-range>
          <fpage>1</fpage>
          <lpage>10</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1016/j.conb.2021.04.007</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>Shukla</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Kumar</surname>
            </name>
            <name>
              <given-names>D. K.</given-names>
              <surname>Vishwakarma</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Ali</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Kumar</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Kuriqi</surname>
            </name>
          </person-group>
          <article-title>Modeling of stage-discharge using back propagation ANN-, ANFIS-, and WANN-based computing techniques</article-title>
          <source>Theor. Appl. Climatol.</source>
          <year>2022</year>
          <volume>147</volume>
          <issue>3</issue>
          <page-range>867-889</page-range>
          <fpage>867</fpage>
          <lpage>889</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s00704-021-03863-y</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>M. G.</given-names>
              <surname>Semenenko</surname>
            </name>
            <name>
              <given-names>I. V.</given-names>
              <surname>Kniazeva</surname>
            </name>
            <name>
              <given-names>L. S.</given-names>
              <surname>Beckel</surname>
            </name>
            <name>
              <given-names>V. N.</given-names>
              <surname>Rutskiy</surname>
            </name>
          </person-group>
          <article-title>How to use neural network and web technologies in modeling complex technical systems</article-title>
          <source>in IOP Conference Series: Materials Science and Engineering</source>
          <year>2019</year>
          <volume>537</volume>
          <issue>3</issue>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1088/1757-899X/537/3/032095</pub-id>
          <pub-id pub-id-type="publisher-id">32095</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>Y.</given-names>
              <surname>Koçak</surname>
            </name>
            <name>
              <given-names>G. Ü.</given-names>
              <surname>Şiray</surname>
            </name>
          </person-group>
          <article-title>New activation functions for single layer feedforward neural network</article-title>
          <source>Expert Syst. Appl.</source>
          <year>2021</year>
          <volume>164</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1016/j.eswa.2020.113977</pub-id>
          <pub-id pub-id-type="publisher-id">113977</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Sharma</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Sharma</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Athaiya</surname>
            </name>
          </person-group>
          <article-title>Activation functions in neural networks</article-title>
          <source>Towar. data Sci.</source>
          <year>2017</year>
          <volume>6</volume>
          <issue>2</issue>
          <page-range>310-316</page-range>
          <fpage>310</fpage>
          <lpage>316</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>B.</given-names>
              <surname>Karlik</surname>
            </name>
            <name>
              <given-names>A. V.</given-names>
              <surname>Olgac</surname>
            </name>
          </person-group>
          <article-title>Performance analysis of various activation functions in generalized MLP architectures of neural networks</article-title>
          <source>Int. J. Artif. Intell. Expert Syst.</source>
          <year>2011</year>
          <volume>1</volume>
          <issue>4</issue>
          <page-range>111-122</page-range>
          <fpage>111</fpage>
          <lpage>122</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="conf-paper">
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Han</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Moraga</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <article-title>The influence of the sigmoid function parameters on the speed of backpropagation learning</article-title>
          <source/>
          <publisher-loc/>
          <publisher-name>typeset</publisher-name>
          <conf-name>International Workshop on Artificial Neural Networks, Malaga-Torremolinos</conf-name>
          <conf-acronym/>
          <conf-loc>Spain</conf-loc>
          <conf-date>June 7-9, 1995</conf-date>
          <year>1995</year>
          <volume/>
          <issue/>
          <page-range>195-201</page-range>
          <fpage>195</fpage>
          <lpage>201</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>X.</given-names>
              <surname>Cui</surname>
            </name>
            <name>
              <given-names>Q.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Qiao</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Teng</surname>
            </name>
          </person-group>
          <article-title>Laser-induced breakdown spectroscopy (LIBS) for classification of wood species integrated with artificial neural network (ANN)</article-title>
          <source>Appl. Phys. B</source>
          <year>2019</year>
          <volume>125</volume>
          <issue>4</issue>
          <page-range>1-12</page-range>
          <fpage>1</fpage>
          <lpage>12</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/3-540-59497-3_175</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>H. E. B.</given-names>
              <surname>A Abdallaoui</surname>
            </name>
          </person-group>
          <article-title>Prédiction des teneurs en métaux lourds des sédiments à partir de leurs caractéristiques physico-chimiques</article-title>
          <source>J. Phys. Chem. News</source>
          <year>2011</year>
          <volume>58</volume>
          <issue/>
          <page-range>90-97</page-range>
          <fpage>90</fpage>
          <lpage>97</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>El El Badaoui</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Abdallaoui</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Manssouri</surname>
            </name>
          </person-group>
          <article-title>Elaboration de modèles mathématiques stochastiques pour la prédiction des teneurs en métaux lourds des eaux superficielles en utilisant les réseaux de neurones artificiels et la régression linéaire multiple</article-title>
          <source>J. Hydrocarb. Mines Environ. Res.</source>
          <year>2012</year>
          <volume>3</volume>
          <issue>2</issue>
          <page-range>31-36</page-range>
          <fpage>31</fpage>
          <lpage>36</lpage>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>S. O.</given-names>
              <surname>Giwa</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Sharifpur</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Goodarzi</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Alsulami</surname>
            </name>
            <name>
              <given-names>J. P.</given-names>
              <surname>Meyer</surname>
            </name>
          </person-group>
          <article-title>Influence of base fluid, temperature, and concentration on the thermophysical properties of hybrid nanofluids of alumina-ferrofluid: Experimental data, modeling through enhanced ANN, ANFIS, and curve fitting</article-title>
          <source>J. Therm. Anal. Calorim.</source>
          <year>2021</year>
          <volume>143</volume>
          <issue>6</issue>
          <page-range>4149-4167</page-range>
          <fpage>4149</fpage>
          <lpage>4167</lpage>
          <pub-id pub-id-type="doi">https://doi.org/10.1007/s10973-020-09372-w</pub-id>
          <pub-id pub-id-type="publisher-id"/>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>Rubin-Falcone</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Fox</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Wiens</surname>
            </name>
          </person-group>
          <article-title>Deep residual time-series forecasting: Application to blood glucose prediction</article-title>
          <source>KDHECAI</source>
          <year>2020</year>
          <volume>2675</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher-id">18</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Pyo</surname>
            </name>
            <name>
              <given-names>S. M.</given-names>
              <surname>Hong</surname>
            </name>
            <name>
              <given-names>Y. S.</given-names>
              <surname>Kwon</surname>
            </name>
            <name>
              <given-names>M. S.</given-names>
              <surname>Kim</surname>
            </name>
            <name>
              <given-names>K. H.</given-names>
              <surname>Cho</surname>
            </name>
          </person-group>
          <article-title>Estimation of heavy metals using deep neural network with visible and infrared spectroscopy of soil</article-title>
          <source>Sci. Total Environ.</source>
          <year>2020</year>
          <volume>741</volume>
          <issue/>
          <page-range/>
          <fpage/>
          <lpage/>
          <pub-id pub-id-type="doi">https://doi.org/10.1016/j.scitotenv.2020.140162</pub-id>
          <pub-id pub-id-type="publisher-id">140162</pub-id>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>