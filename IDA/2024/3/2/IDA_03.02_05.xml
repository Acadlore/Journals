<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IDA</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Information Dynamics and Applications</journal-title>
        <abbrev-journal-title abbrev-type="issn">Inf. Dyn. Appl.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IDA</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1494</issn>
      <issn publication-format="print">2958-1486</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-yvVDiQmgxE3ETLcRRjHS2kfbryD32irH</article-id>
      <article-id pub-id-type="doi">10.56578/ida030205</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>DV-Hop Positioning Method Based on Multi-Strategy Improved Sparrow Search Algorithm</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-8980-4288</contrib-id>
          <name>
            <surname>Lei</surname>
            <given-names>Wenli</given-names>
          </name>
          <email>ydlwl@yau.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-0788-2770</contrib-id>
          <name>
            <surname>Han</surname>
            <given-names>Jinping</given-names>
          </name>
          <email>jpinghan@yau.edu.cn</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0004-4321-1294</contrib-id>
          <name>
            <surname>Bao</surname>
            <given-names>Jiawei</given-names>
          </name>
          <email>1396900189@qq.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-5667-0361</contrib-id>
          <name>
            <surname>Jia</surname>
            <given-names>Kun</given-names>
          </name>
          <email>jk@yau.edu.cn</email>
        </contrib>
        <aff id="aff_1">College of Physics and Electronic Information, Yan’an University, 716000 Yan’an, China</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>29</day>
        <month>06</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>2</issue>
      <fpage>138</fpage>
      <lpage>145</lpage>
      <page-range>138-145</page-range>
      <history>
        <date date-type="received">
          <day>21</day>
          <month>04</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>14</day>
          <month>06</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>In order to address the problem of large positioning errors in non-ranging positioning algorithms for wireless sensor networks (WSN), this study proposes a Distance Vector-Hop (DV-Hop) positioning method based on the multi-strategy improved sparrow search algorithm (SSA). The method first introduces circle chaotic mapping, adaptive weighting factor, Gaussian variation and an inverse learning strategy to improve the iteration speed and optimization accuracy of the sparrow algorithm, and then uses the improved SSA to estimate the position of the unknown node. Experimental results show that, compared with the original method, the improved DV-Hop algorithm has significantly improved the positioning accuracy.</p></abstract>
      <kwd-group>
        <kwd>Wireless sensor networks (WSN)</kwd>
        <kwd>Node positioning</kwd>
        <kwd>Distance Vector-Hop (DV-Hop) algorithm</kwd>
        <kwd>Sparrow search algorithm (SSA)</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="4"/>
        <fig-count count="5"/>
        <table-count count="3"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>WSN is a specific type of self-organizing network formed by multiple nodes configured with small or miniature sensors, where accurate node localization is key to WSN applications [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>]. Current WSN localization algorithms are usually divided into two main categories: ranging-based localization algorithms and non-ranging ones [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>]. The latter is characterized by low energy consumption, low implementation costs and no hardware support, and meets the needs of many applications at the same time. Thus, non-ranging positioning algorithms are of even greater research importance.</p><p>The DV-Hop localization algorithm, as a classical non-ranging localization algorithm, has the advantages of simple steps and a large localization coverage area, but also has the obvious disadvantages of being highly influenced by the network topology and having large localization errors. In response to the problem of large DV-Hop localization errors, many scholars have proposed improvements. Zhou et al. [<xref ref-type="bibr" rid="ref_6">6</xref>] improved the two-step hop count and location estimation by receiving different anchor node information for hop count correction and calculating the coordinates of the unknown node using weighted least squares. Zhao and Ma [<xref ref-type="bibr" rid="ref_7">7</xref>] proposed a refined hop numerical method for dividing the dual communication radius to bring the inter-node distance closer to the true value. Shi et al. [<xref ref-type="bibr" rid="ref_8">8</xref>] corrected the average hop distance between beacon nodes based on the similarity coefficients of multi-hop shortest paths between nodes and optimized the node initialization locations using a simulated annealing algorithm. Li [<xref ref-type="bibr" rid="ref_9">9</xref>] first reduced the hopping error by selecting beacon nodes, weighted the hopping distance of anchor nodes according to the distance, and finally optimized the estimation of node positions using a particle swarm algorithm. Chu and Lv [<xref ref-type="bibr" rid="ref_10">10</xref>] proposed a node localisation method based on differential evolution, but differential evolution is greatly affected by parameters, and the control parameters are not appropriately selected, so the diversity is easily lost in the population evolution and the optimal solution cannot be found. Jia et al. [<xref ref-type="bibr" rid="ref_11">11</xref>] used RSSI and error correction to improve the DV-Hop algorithm, which improved the positioning accuracy of unknown nodes to a certain extent, but it is not ideal yet.</p><p>The above schemes have improved the positioning accuracy to some extent, but there are still limitations. In order to further improve the positioning accuracy of the DV-Hop algorithm, this study proposes a DV-Hop positioning method based on the modified SSA (MSSADV-Hop). Firstly, the ability of the SSA to jump out of the local optimum and the accuracy of global optimization were improved through multi-strategy improvement. Then the improved SSA was used to solve the optimal value of the node localization objective function in the localization stage, aiming to reduce the localization error. Finally, the validity of the improved method was verified through experimental simulation.</p>
    </sec>
    <sec sec-type="">
      <title>2. Relevant theories</title>
      
        <sec>
          
            <title>2.1. Dv-hop algorithm</title>
          
          <p>The positioning process of the DV-Hop algorithm is divided into the following three steps:</p><p>Step 1: Obtaining the minimum number of hops. Each anchor node sends a packet to the surrounding nodes by means of a broadcast, which contains information such as coordinates and hop count. At the end of the broadcast, all nodes obtain the minimum number of hops according to the update mechanism.</p><p>Step 2: Estimating the average jump distance. After combining the position information between any two anchor nodes with the minimum hop value, the average hop distance can be obtained through Eq. (1). When unknown node $u<inline-formula>
  <mml:math id="mw256gj3zh">
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
  </mml:math>
</inline-formula>Hopsize_i<inline-formula>
  <mml:math id="mhjw4u8ijp">
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>i$, the estimated distance between the two is calculated using Eq. (2).</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="meu5hktr1c">
                <mml:mi>H</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>z</mml:mi>
                <mml:msub>
                  <mml:mi>e</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                        <mml:mo>≠</mml:mo>
                      </mml:mrow>
                      <mml:mi>N</mml:mi>
                    </mml:munderover>
                    <mml:msqrt>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mo>+</mml:mo>
                    </mml:msqrt>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                        <mml:mo>≠</mml:mo>
                      </mml:mrow>
                      <mml:mi>N</mml:mi>
                    </mml:munderover>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="m60phm8x56">
                <mml:msub>
                  <mml:mi>d</mml:mi>
                  <mml:mrow>
                    <mml:mi>u</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mi>e</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>h</mml:mi>
                  <mml:mrow>
                    <mml:mi>u</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>∗</mml:mo>
                <mml:mi>H</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>z</mml:mi>
              </mml:math>
            </disp-formula>
          
          <p>Step 3: The coordinates of the unknown nodes can be estimated using the trilateration method.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Ssa</title>
          
          <p>The SSA is a heuristic optimization algorithm based on the foraging behaviour of sparrows in nature, proposed by Xue and Shen [<xref ref-type="bibr" rid="ref_12">12</xref>] in 2020. The individuals of the population in the sparrow algorithm can be divided into finders, followers and vigilantes in the process of foraging, and all three have their own foraging duties. The algorithm has the advantages of fewer parameters, simple implementation, easy adjustment and optimization, as well as strong foraging ability and fast convergence. It is widely used in solving optimization problems [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>].</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Dv-hop positioning method based on multi-strategy improved ssa</title>
      
        <sec>
          
            <title>3.1. Dv-hop positioning method based on ssa</title>
          
          <p>Since there is a large error between the unknown node coordinates calculated by the original DV-Hop algorithm and the true value, this study introduces a SSA into the original localization algorithm to solve for the optimal unknown node coordinates using iterated sparrow particles. The distance between the unknown node and the beacon node was calculated and subtracted from the node distance obtained by the DV-Hop algorithm. Finally, the difference between these two was converted into an adaptation function. The position of the unknown node was obtained by solving for the particle with the smallest adaptation value [<xref ref-type="bibr" rid="ref_15">15</xref>]. The adaptability function constructed in this study is as follows:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mqbiflkp9o">
                <mml:mi>f</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>M</mml:mi>
                </mml:munderover>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mo>|</mml:mo>
                  <mml:msqrt>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>−</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mi>x</mml:mi>
                      </mml:mrow>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>−</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:msub>
                          <mml:mi>y</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mi>y</mml:mi>
                      </mml:mrow>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:mo>+</mml:mo>
                  </mml:msqrt>
                  <mml:msub>
                    <mml:mi>d</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, \( f(x, y) \) represents the fitness function value of particle \( (x, y) \), \( M \) represents the number of beacon nodes, \( x_i \) and \( y_i \) represent the horizontal and vertical coordinates of the beacon nodes \( i \), respectively, and \( d_i \) represents the distance between the unknown node and the beacon node \( i \).</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Circle chaos initialization</title>
          
          <p>Chaotic mappings are often applied in improving population initialization due to their non-linearity, randomness, ergodicity and fractal nature. This strategy can enhance population diversity and improve shortcomings such as small global search range and tendency to fall into local optimality [<xref ref-type="bibr" rid="ref_16">16</xref>]. Commonly used chaotic mappings are logistic mapping, tent mapping, sine mapping, singer mapping, circle mapping, etc. The chaotic sequence distribution is shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Chaotic sequence distribution </title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_vxGKdSsKGNWMJIen.png"/>
            </fig>
          
          <p>In order to make the initial solution of the sparrow population more uniformly distributed, the circle chaotic mapping with higher stability was chosen in this study. The expression of this chaotic mapping is shown below.</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mvxrrccdqo">
                <mml:mrow>
                  <mml:mo>{</mml:mo>
                  <mml:mo fence="true"/>
                  <mml:mtable columnspacing="1em" rowspacing="4pt">
                    <mml:mtr>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mi>r</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>n</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>+</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mi>m</mml:mi>
                        <mml:mi>o</mml:mi>
                        <mml:mi>d</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>×</mml:mo>
                          <mml:mo>,</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mi>b</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:mfrac>
                              <mml:mi>a</mml:mi>
                              <mml:mrow>
                                <mml:mn>2</mml:mn>
                                <mml:mi>π</mml:mi>
                              </mml:mrow>
                            </mml:mfrac>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>×</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:mn>2</mml:mn>
                            <mml:mi>π</mml:mi>
                            <mml:msub>
                              <mml:mi>x</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mstyle scriptlevel="0">
                            <mml:mspace width="1em"/>
                          </mml:mstyle>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, $a<inline-formula>
  <mml:math id="m6qlxq0i2y">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>b<inline-formula>
  <mml:math id="m0gnchxane">
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>a<inline-formula>
  <mml:math id="mwb484a9rp">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mn>0.5</mml:mn>
  </mml:math>
</inline-formula>b$ as 0.2.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Adaptive weighting factor</title>
          
          <p>In the traditional sparrow algorithm, there is the problem of the discoverer not being able to search the initial space sufficiently to make the solution fall into a local optimum, thus failing to achieve the required optimization accuracy. In order to extend the search range of the discoverer, this study first makes the current discoverer position acted upon by the previous generation of discoverers together with the global optimal position. Then, a dynamic weighting factor was introduced in the iterative formula of the discoverer [<xref ref-type="bibr" rid="ref_17">17</xref>]. This improved strategy allows the algorithm to search more widely in the early iterations to avoid falling into a local optimum too early. As the number of iterations increases, the weight factor adaptively decreases and the algorithm performs a deep search for the optimal position, improving the algorithm's optimization search accuracy.</p><p>The dynamic weighting factors <inline-formula>
  <mml:math id="mjh7w9yj03">
    <mml:mi>ω</mml:mi>
  </mml:math>
</inline-formula> and the formulae for the new discoverer positions are as follows:</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="mpaqktof6u">
                <mml:mi>ω</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:msup>
                    <mml:mi>e</mml:mi>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>−</mml:mo>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>t</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mrow>
                            <mml:mo>/</mml:mo>
                          </mml:mrow>
                          <mml:msub>
                            <mml:mi>r</mml:mi>
                            <mml:mrow>
                              <mml:mo>max</mml:mo>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                  </mml:msup>
                  <mml:msup>
                    <mml:mi>e</mml:mi>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>+</mml:mo>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mi>t</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mrow>
                            <mml:mo>/</mml:mo>
                          </mml:mrow>
                          <mml:msub>
                            <mml:mi>r</mml:mi>
                            <mml:mrow>
                              <mml:mo>max</mml:mo>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                  </mml:msup>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="mppsxsaqfw">
                <mml:msubsup>
                  <mml:mi>x</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>t</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:mo>{</mml:mo>
                  <mml:mo fence="true"/>
                  <mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt">
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msubsup>
                            <mml:mi>x</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mi>j</mml:mi>
                              <mml:mo>,</mml:mo>
                            </mml:mrow>
                          </mml:msubsup>
                          <mml:mi>ω</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mo>−</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:msubsup>
                              <mml:mi>f</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>g</mml:mi>
                                <mml:mo>,</mml:mo>
                              </mml:mrow>
                            </mml:msubsup>
                            <mml:msubsup>
                              <mml:mi>f</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                                <mml:mo>,</mml:mo>
                              </mml:mrow>
                            </mml:msubsup>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mo>∗</mml:mo>
                        <mml:mi>r</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>n</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>R</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msub>
                        <mml:mo>&lt;</mml:mo>
                        <mml:mi>S</mml:mi>
                        <mml:mi>T</mml:mi>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:msubsup>
                          <mml:mi>x</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mo>,</mml:mo>
                          </mml:mrow>
                        </mml:msubsup>
                        <mml:mo>+</mml:mo>
                        <mml:mo>∗</mml:mo>
                        <mml:mi>Q</mml:mi>
                        <mml:mi>L</mml:mi>
                      </mml:mtd>
                      <mml:mtd>
                        <mml:msub>
                          <mml:mi>R</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msub>
                        <mml:mo>&gt;</mml:mo>
                        <mml:mi>S</mml:mi>
                        <mml:mi>T</mml:mi>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="mgy6em20bq">
    <mml:msubsup>
      <mml:mi>f</mml:mi>
      <mml:mi>t</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> is the fitness value of the $j<inline-formula>
  <mml:math id="mrvs59gjh3">
    <mml:mo>−</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
  </mml:math>
</inline-formula>i<inline-formula>
  <mml:math id="mfbgt24fvo">
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>t, f_{i, g}^t<inline-formula>
  <mml:math id="mkyzi8fz0f">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>Q<inline-formula>
  <mml:math id="m2ijrc7o15">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>L<inline-formula>
  <mml:math id="mye2f07ah2">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
  </mml:math>
</inline-formula>1 \times d$ matrix with all elements of 1.</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Perturbation based on gaussian variation and backward learning strategies</title>
          
          <p>The introduction of a Gaussian variational operator to perturb the globally optimal solution obtained at each iteration prevents the algorithm from falling into a local optimum and premature maturity, while also maintaining the diversity of individuals in the population [<xref ref-type="bibr" rid="ref_18">18</xref>]. The Gaussian probability density formula is shown below.</p>
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="myp165tper">
                <mml:mi>f</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mrow>
                    <mml:msqrt>
                      <mml:mn>2</mml:mn>
                      <mml:mi>π</mml:mi>
                    </mml:msqrt>
                    <mml:mi>σ</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mi>x</mml:mi>
                      <mml:mi>μ</mml:mi>
                      <mml:msup>
                        <mml:mo>)</mml:mo>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                      <mml:msup>
                        <mml:mi>σ</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The variation formula for carrying out specific variation operations is shown below.</p>
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="mt9u7sh703">
                <mml:mi>G</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>N</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msubsup>
                    <mml:mi>x</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>j</mml:mi>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>t</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:msubsup>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mo>×</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:msubsup>
                  <mml:mi>x</mml:mi>
                  <mml:mi>t</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mn>1</mml:mn>
                <mml:mn>0</mml:mn>
                <mml:mn>1</mml:mn>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="mghwczfp4t">
    <mml:msubsup>
      <mml:mi>x</mml:mi>
      <mml:mi>t</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula> is the value of the parameter after the normal algorithm iteration, <inline-formula>
  <mml:math id="mjowa1olsl">
    <mml:mi>G</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msubsup>
        <mml:mi>x</mml:mi>
        <mml:mrow>
          <mml:mi>i</mml:mi>
          <mml:mi>j</mml:mi>
          <mml:mo>,</mml:mo>
        </mml:mrow>
        <mml:mrow>
          <mml:mi>t</mml:mi>
          <mml:mo>+</mml:mo>
          <mml:mn>1</mml:mn>
        </mml:mrow>
      </mml:msubsup>
    </mml:mrow>
  </mml:math>
</inline-formula> is the value after the variation, and <inline-formula>
  <mml:math id="m1m9b5brhe">
    <mml:mi>N</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mn>0</mml:mn>
    <mml:mn>1</mml:mn>
  </mml:math>
</inline-formula> denotes a random number conforming to a normal distribution with mathematical expectation of 0 and standard deviation of 1.</p><p>The introduction of an elite backward learning strategy can discard individual backward solutions whose fitness values are inferior to the original solution and retain the better solution, thus expanding the search range of the algorithm and improving the ability to find the best [<xref ref-type="bibr" rid="ref_19">19</xref>]. The strategy is expressed in the following formula:</p>
          
            <disp-formula>
              <label>(9)</label>
              <mml:math id="mbkgbib81y">
                <mml:msubsup>
                  <mml:mi>x</mml:mi>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:mi>g</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>′</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mi>t</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:msub>
                  <mml:mi>n</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>x</mml:mi>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:mi>g</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:msub>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mi>u</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p> where, <inline-formula>
  <mml:math id="muqgkui6ci">
    <mml:msub>
      <mml:mi>n</mml:mi>
      <mml:mi>j</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> denotes a $j<inline-formula>
  <mml:math id="m9460nbaum">
    <mml:mo>−</mml:mo>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
  </mml:math>
</inline-formula>(0,1)<inline-formula>
  <mml:math id="mpcezc9r54">
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>x_{j, g}(t)<inline-formula>
  <mml:math id="makyqtf7jm">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>j<inline-formula>
  <mml:math id="m1c40bh0t3">
    <mml:mo>−</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
  </mml:math>
</inline-formula>t<inline-formula>
  <mml:math id="md2auh5apn">
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>x_{j,g}^{\prime}(t)$ denotes the generated inverse solution.</p>
          <p>In order to further improve the algorithm's merit-seeking capability, this study adopts a dynamic selection strategy such that the Gaussian variation strategy and the backward learning strategy were executed alternately with a certain probability to dynamically update the target position. The specific choice of which strategy to perform the target position update is determined by the selection probability <italic>p</italic>, which is calculated as follows:</p>
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="me3cnuk9f1">
                <mml:mi>p</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:mi>c</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>s</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mi>t</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>t</mml:mi>
                        <mml:mi>e</mml:mi>
                        <mml:mrow>
                          <mml:mo>/</mml:mo>
                        </mml:mrow>
                        <mml:msub>
                          <mml:mi>r</mml:mi>
                          <mml:mrow>
                            <mml:mi>m</mml:mi>
                            <mml:mi>a</mml:mi>
                            <mml:mi>x</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mi>π</mml:mi>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mn>2</mml:mn>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>The specific way to choose the strategy is to select the Gaussian variation strategy if <italic>rand＜p</italic>, and vice versa for the reverse learning strategy. Although the ability of the algorithm to jump out of the local optimum solution was improved to some extent by the two perturbation strategies mentioned above, there is no guarantee that the new solution is better than the original solution. Therefore, after the perturbation, it is necessary to determine whether to update the target position by comparing the fitness values of both.</p>
        </sec>
      
      
        <sec>
          
            <title>3.5. Dv-hop positioning method based on multi-strategy improved ssa</title>
          
          <p>The specific steps of the MSSADV-Hop are as follows:</p><p>Step 1: A number of WSN nodes were deployed in the target area and the minimum number of hops between the anchor and unknown nodes and the respective average distance per hop were estimated.</p><p>Step 2: Several parameters of the improved sparrow algorithm were set, such as the population size, the proportion of individuals with three identities (discoverer, follower and alert), the maximum number of iterations, the alert value, the safety value, the dimension size, etc. Then the population was initialized using the circle chaos mapping.</p><p>Step 3: The fitness of individual sparrows was calculated and ranked to select the current best fitness value and the worst fitness value, as well as the corresponding position.</p><p>Step 4: From the individual sparrows with better fitness values, some of them were selected as discoverers to update their positions according to Formula (6), followed by the original algorithm to update the positions of followers and vigilantes. </p><p>Step 5: Optimally positioned individuals were perturbed using Gaussian variation and backward learning strategies to produce new solutions.</p><p>Step 6: The retention of the perturbation locations was determined by comparing the fitness values of the old and new solutions.</p><p>Step 7: If the new solution was not retained, the process returned to Step 4. Otherwise, the iteration was concluded, and the optimal solution for the objective function was identified as the position of the unknown node.</p><p>The exact process is shown in <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Flow chart of the DV-Hop localization method based on improved SSA</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_G-uM0LhQ_zVX1SyI.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Influence of experimental environment parameters on positioning error</title>
      <p>In order to verify the effectiveness of the MSSADV-Hop, the traditional DV-Hop algorithm, the DV-Hop based on Particle Swarm Optimization (PSODV-Hop) algorithm [<xref ref-type="bibr" rid="ref_20">20</xref>], the Distance Vector-Hop based on SSA (SSADV-Hop) optimized by the original SSA and the MSSADV-Hop proposed in this study were tested for comparison. To investigate the effectiveness of each algorithm for localization under different node densities, different anchor node densities and communication radii. In order to reduce the error caused by the randomness of the experiment, the average value of each algorithm after 100 experiments was selected in this study. The localization effect of the algorithm was shown by comparing the average error size of all nodes. The average error formula is as follows:</p>
      
        <disp-formula>
          <label>(11)</label>
          <mml:math id="mr0rtxa7t4">
            <mml:mover>
              <mml:mrow>
                <mml:mi>e</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>r</mml:mi>
              </mml:mrow>
              <mml:mo accent="true">―</mml:mo>
            </mml:mover>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>100</mml:mn>
                  </mml:mrow>
                </mml:munderover>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>d</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>M</mml:mi>
                </mml:munderover>
                <mml:msqrt>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>X</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>Y</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>y</mml:mi>
                        <mml:mi>d</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                  <mml:mo>+</mml:mo>
                </mml:msqrt>
              </mml:mrow>
              <mml:mrow>
                <mml:mn>100</mml:mn>
                <mml:mi>M</mml:mi>
                <mml:mi>R</mml:mi>
              </mml:mrow>
            </mml:mfrac>
          </mml:math>
        </disp-formula>
      
      <p> where, $i<inline-formula>
  <mml:math id="m1x93reyi9">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>M<inline-formula>
  <mml:math id="mfk8vnm0n9">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>\left(X_d, Y_d\right)<inline-formula>
  <mml:math id="m32cy0b20n">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>\left(x_d, y_d\right)<inline-formula>
  <mml:math id="mi32ea224d">
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>d<inline-formula>
  <mml:math id="m6x2gsrg75">
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>\overline{\text { error }}$ denotes the average error of all unknown nodes after 100 experiments.</p>
      
        <sec>
          
            <title>4.1. Effect of different node densities on positioning error</title>
          
          <p>The experimental parameters are shown in <xref ref-type="table" rid="table_1">Table 1</xref>, and the effect of different node densities on positioning is shown in <xref ref-type="fig" rid="fig_3">Figure 3</xref>.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Parameter setting of the test environment</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1" colwidth="188"><p>Parameter</p></td><td colspan="1" rowspan="1" colwidth="190"><p>Experimental Environment 1</p></td><td colspan="1" rowspan="1" colwidth="192"><p>Experimental Environment 2</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="188"><p>Network area range</p></td><td colspan="1" rowspan="1" colwidth="190"><p>100m×100m</p></td><td colspan="1" rowspan="1" colwidth="192"><p>200m×200m</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="188"><p>Total number of nodes</p></td><td colspan="1" rowspan="1" colwidth="190"><p>80, 120, 160, 200, 240</p></td><td colspan="1" rowspan="1" colwidth="192"><p>100, 150, 200, 250, 300</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="188"><p>Anchor node density (%)</p></td><td colspan="1" rowspan="1" colwidth="190"><p>20</p></td><td colspan="1" rowspan="1" colwidth="192"><p>30</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="188"><p>Communication radius (m)</p></td><td colspan="1" rowspan="1" colwidth="190"><p>30</p></td><td colspan="1" rowspan="1" colwidth="192"><p>50</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="188"><p>Number of experiments</p></td><td colspan="1" rowspan="1" colwidth="190"><p>100</p></td><td colspan="1" rowspan="1" colwidth="192"><p>100</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Positioning errors of four algorithms with different node densities</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_mTDIz3KcPBebZZba.png"/>
            </fig>
          
          <p>As can be seen from <xref ref-type="fig" rid="fig_3">Figure 3</xref>, the overall localization error of the four algorithms gradually decreases as the node density increases. When the node density is small, the localization error decreases more. After the number of nodes exceeds 200, the localization error curve of each algorithm starts to level off. The reason for this is that within a fixed sensing network area, when the density of nodes exceeds a certain percentage, the interference between nodes increases, resulting in a decrease in the signal-to-noise ratio, which affects the positioning accuracy. Compared to the rest of the algorithms, the localization error of the MSSADV-Hop is always optimal for different node densities.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Effect of different anchor node densities on positioning error</title>
          
          <p>The simulation parameters are shown in <xref ref-type="table" rid="table_2">Table 2</xref>, and the effect of different anchor node densities on positioning is shown in <xref ref-type="fig" rid="fig_4">Figure 4</xref>.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Parameter setting of the test environment</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1" colwidth="242"><p>Parameter</p></td><td colspan="1" rowspan="1" colwidth="238"><p>Experimental Environment 3</p></td><td colspan="1" rowspan="1" colwidth="240"><p>Experimental Environment 4</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="242"><p>Network area range</p></td><td colspan="1" rowspan="1" colwidth="238"><p>100m×100m</p></td><td colspan="1" rowspan="1" colwidth="240"><p>200m×200m</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="242"><p>Total number of nodes</p></td><td colspan="1" rowspan="1" colwidth="238"><p>100</p></td><td colspan="1" rowspan="1" colwidth="240"><p>200</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="242"><p>Anchor node density (%)</p></td><td colspan="1" rowspan="1" colwidth="238"><p>10, 15, 20, 25, 30</p></td><td colspan="1" rowspan="1" colwidth="240"><p>20, 25, 30, 35, 40</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="242"><p>Communication radius (m)</p></td><td colspan="1" rowspan="1" colwidth="238"><p>30</p></td><td colspan="1" rowspan="1" colwidth="240"><p>50</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="242"><p>Number of experiments</p></td><td colspan="1" rowspan="1" colwidth="238"><p>100</p></td><td colspan="1" rowspan="1" colwidth="240"><p>100</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Positioning errors of four algorithms with different anchor node densities</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_AI38Csaf2IrTMo9F.png"/>
            </fig>
          
          <p>As can be seen from <xref ref-type="fig" rid="fig_4">Figure 4</xref>, there is an overall decreasing trend in the localization error of the four algorithms as the density of anchor nodes increases. It is due to the fact that as the number of anchor nodes increases, the average jump distance error for each node decreases and the distance between the unknown node and the anchor node is estimated more accurately. Compared to the other three algorithms, the MSSADV-Hop always has the smallest positioning error under the same conditions.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Effect of different communication radius on positioning error</title>
          
          <p>The experimental parameters are shown in <xref ref-type="table" rid="table_3">Table 3</xref>, and the effect of different node densities on positioning is shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Parameter setting of the test environment</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1" colwidth="211"><p>Parameter</p></td><td colspan="1" rowspan="1" colwidth="206"><p>Experimental Environment 5</p></td><td colspan="1" rowspan="1" colwidth="178"><p>Experimental Environment 6</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="211"><p>Network area range</p></td><td colspan="1" rowspan="1" colwidth="206"><p>100m×100m</p></td><td colspan="1" rowspan="1" colwidth="178"><p>200m×200m</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="211"><p>Total number of nodes</p></td><td colspan="1" rowspan="1" colwidth="206"><p>100</p></td><td colspan="1" rowspan="1" colwidth="178"><p>200</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="211"><p>Anchor node density (%)</p></td><td colspan="1" rowspan="1" colwidth="206"><p>20</p></td><td colspan="1" rowspan="1" colwidth="178"><p>30</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="211"><p>Communication radius (m)</p></td><td colspan="1" rowspan="1" colwidth="206"><p>20, 25, 30, 35, 40</p></td><td colspan="1" rowspan="1" colwidth="178"><p>40, 45, 50, 55, 60</p></td></tr><tr><td colspan="1" rowspan="1" colwidth="211"><p>Number of experiments</p></td><td colspan="1" rowspan="1" colwidth="206"><p>100</p></td><td colspan="1" rowspan="1" colwidth="178"><p>100</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>As can be seen from <xref ref-type="fig" rid="fig_5">Figure 5</xref>, the overall localization error of the four algorithms tends to decrease as the communication radius increases. This is because when the communication radius is small, the number of anchor nodes within the communication range of the unknown node is small and cannot accurately obtain its own position. When comparing the four algorithms, the MSSADV-Hop consistently has lower positioning errors than the other algorithms under the same conditions. The MSSADV-Hop also has a significant advantage in terms of positioning accuracy under different communication radius conditions.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>Positioning errors of four algorithms at different communication radii</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/8/img_e1hMwU4rbVaLAfjp.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Conclusion</title>
      <p>To address the problem of low positioning accuracy of the traditional DV-Hop algorithm, this study proposes a DV-Hop positioning method based on multi-strategy improved SSA to optimize the positioning steps that generate errors. The method first uses circle chaotic mapping to optimize the sparrow population distribution. Then a dynamic weighting factor was introduced into the discoverer position iteration formula, which enables the algorithm to increase the global search range at the beginning of the iteration and to perform better local search at the end of the iteration. Reverse learning and Gaussian variation were added for position perturbation to improve the algorithm's ability to jump out of local optima. Finally, the improved sparrow algorithm was substituted into the calculation of unknown node coordinates, making the calculation of the unknown node coordinates by the localization algorithm more accurate. The experimental results show that the MSSADV-Hop proposed in this study has a significant improvement in localization accuracy and has good localization performance.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      <p>Conceptualization, W.L. and K.J.; methodology, W.L., K.J., J.B. and Y.L.; software, J.B. and K.J.; validation, W.L. and Y.L.; investigation, W.L. and J.B.; data curation, W.L. and K.J.; writing---original draft preparation, K.J. and J.B.; writing---review and editing, K.J. All authors have read and agreed to the published version of the manuscript.</p>
    </notes>
    <notes>
      <title>Funding</title>
      <p>This work was supported by the Shaanxi Province Natural Science Basic Research Program Project (Grant No.: 2024JCYBMS-572), partially funded by Yan’an University Graduate Education Innovation Program Project (Grant No.: YCX2023032, YCX2023033, YCX2024094, YCX2024097) and the “Medium- and Long-Term Major Scientific Research Project in the 14th Five-Year Plan” (Grant No.: 2021ZCQ015) of Yan’an University.</p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>241</volume>
          <page-range>110199</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lei</surname>
              <given-names>Wen Li</given-names>
            </name>
            <name>
              <surname>Lei</surname>
              <given-names>Yang</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>Hong Bo</given-names>
            </name>
            <name>
              <surname>Jia</surname>
              <given-names>Kun</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.comnet.2024.110199</pub-id>
          <article-title>Research on energy-saving relay selection algorithm based on olive forwarding area in IoT</article-title>
          <source>Comput. Netw.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>688-692</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jin</surname>
              <given-names>Yong</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Lin</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Lu</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>Zhen Tao</given-names>
            </name>
            <name>
              <surname>Han</surname>
              <given-names>Jing</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/LWC.2021.3140063</pub-id>
          <article-title>A novel range-free node localization method for wireless sensor networks</article-title>
          <source>IEEE Wirel. Commun. Lett.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>2796</page-range>
          <issue>5</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Fawad</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>M. Z.</given-names>
            </name>
            <name>
              <surname>Ullah</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Alasmary</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Shehzad</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s23052796</pub-id>
          <article-title>Enhancing localization efficiency and accuracy in wireless sensor networks</article-title>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>3931</page-range>
          <issue>18</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pita</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Utrilla</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rodriguez-Zurrunero</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Araujo</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s19183931</pub-id>
          <article-title>Experimental evaluation of an RSSI-based localization algorithm on IoT end-devices</article-title>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>4469</page-range>
          <issue>12</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Huang</surname>
              <given-names>S. C.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>F. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s18124469</pub-id>
          <article-title>A novel positioning system based on coverage area pruning in wireless sensor networks</article-title>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>53</volume>
          <page-range>137-143</page-range>
          <issue>4</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhou</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>P. Z.</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>W. H.</given-names>
            </name>
            <name>
              <surname>Wei</surname>
              <given-names>S. F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.16163/j.cnki.22-1123/n.2021.04.021</pub-id>
          <article-title>Research on improved DV-hop localization algorithm for wireless sensor networks</article-title>
          <source>J. Northeast Norm. Univ. Nat. Sci. Ed.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>48</volume>
          <page-range>1406-1410</page-range>
          <issue>12</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>Jian Ping</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>Shu Li</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3969/j.issn.1002-0802.2015.12.017</pub-id>
          <article-title>DV-Hop improvement algorithm based on dual communication radius</article-title>
          <source>Commun. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>33</volume>
          <page-range>113-119</page-range>
          <issue>1</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shi</surname>
              <given-names>Q. Q.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>D. Y.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>J. P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.13382/j.jemi.B1801620</pub-id>
          <article-title>Application of path similarity factor to DV-Hop improvement</article-title>
          <source>J. Electron. Meas. Instrum.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="thesis">
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Research on DV-Hop based localization algorithm for wireless sensor networks</article-title>
          <source>, undefined</source>
          <year>2018</year>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>40</volume>
          <page-range>33-37</page-range>
          <issue>6</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chu</surname>
              <given-names>Yin Fei</given-names>
            </name>
            <name>
              <surname>Lv</surname>
              <given-names>Hui Fang</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.19652/j.cnki.femt.2102623</pub-id>
          <article-title>DV-Hop localisation algorithm based on differential evolution with ranging correction</article-title>
          <source>Electron. Meas. Technol. Abroad</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>2020</volume>
          <page-range>9275603</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jia</surname>
              <given-names>Yan Fei</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Ke Xin</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Li Quan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2020/9275603</pub-id>
          <article-title>Improved DV-Hop location algorithm based on mobile anchor node and modified hop count for wireless sensor network</article-title>
          <source>J. Electr. Comput. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>22-34</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Xue</surname>
              <given-names>Jian Kai</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>Bo</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/21642583.2019.1708830</pub-id>
          <article-title>A novel swarm intelligence optimization approach: Sparrow search algorithm</article-title>
          <source>Syst. Sci. Control Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>40</volume>
          <page-range>2009-2017</page-range>
          <issue>5</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lei</surname>
              <given-names>Wen Li</given-names>
            </name>
            <name>
              <surname>Lei</surname>
              <given-names>Yang</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Bin</given-names>
            </name>
            <name>
              <surname>Jia</surname>
              <given-names>Kun</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.18280/ts.400519</pub-id>
          <article-title>Support vector machines optimisation for face recognition using sparrow search algorithm</article-title>
          <source>Trait. Signal</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>2023</volume>
          <page-range>5567629</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lei</surname>
              <given-names>W. L.</given-names>
            </name>
            <name>
              <surname>Jia</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Lei</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2023/5567629</pub-id>
          <article-title>Research on chaotic chimp optimization algorithm based on adaptive tuning and its optimization for engineering application</article-title>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>11-14</page-range>
          <issue>13</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Lu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Ye</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>An optimized DV-Hop localization algorithm based on the sparrow algorithm</article-title>
          <source>Wirel. Internet Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>3988</page-range>
          <issue>8</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Si</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>C. Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s23083988</pub-id>
          <article-title>Indoor robot path planning using an improved whale optimization algorithm</article-title>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>6147</page-range>
          <issue>16</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>L. H.</given-names>
            </name>
            <name>
              <surname>Di</surname>
              <given-names>M. Z.</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Z. X.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Z. Q.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s22166147</pub-id>
          <article-title>Feature selection model based on IWOA for behavior identification of chicken</article-title>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>3191-3215</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Liu</surname>
              <given-names>Xiang</given-names>
            </name>
            <name>
              <surname>Tian</surname>
              <given-names>Min</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>Jie</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>Jin Yan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3934/mbe.2023150</pub-id>
          <article-title>An efficient coverage method for SEMWSNs based on adaptive chaotic Gaussian variant snake optimization algorithm</article-title>
          <source>Math. Biosci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>56</volume>
          <page-range>2811-2869</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sahoo</surname>
              <given-names>Saroj Kumar</given-names>
            </name>
            <name>
              <surname>Saha</surname>
              <given-names>Apu Kumar</given-names>
            </name>
            <name>
              <surname>Nama</surname>
              <given-names>Sukanta</given-names>
            </name>
            <name>
              <surname>Masdari</surname>
              <given-names>Mohammad</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10462-022-10218-0</pub-id>
          <article-title>An improved moth flame optimization algorithm based on modified dynamic opposite learning strategy</article-title>
          <source>Artif. Intell. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>29</volume>
          <page-range>69-72, 76</page-range>
          <issue>12</issue>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>Ji</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Yi</given-names>
            </name>
            <name>
              <surname>Mei</surname>
              <given-names>Juan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3969/j.issn.1000-386x.2012.12.020</pub-id>
          <article-title>An Improved DV-Hop localization algorithm based on particle swarm algorithm</article-title>
          <source>Comput. Appl. Softw.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>