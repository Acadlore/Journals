<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">OF</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Organic Farming</journal-title>
        <abbrev-journal-title abbrev-type="issn">Org. Farming</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">OF</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2297-6485</issn>
      <issn publication-format="print"/>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-8YfZk34_rQ9An4t5JFy40XVJ0hl78kkS</article-id>
      <article-id pub-id-type="doi">10.56578/of110103</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Automated Evaluation of Onion Seed Quality Using Physical Characteristics via Image Processing and Machine Learning Techniques</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-6207-4568</contrib-id>
          <name>
            <surname>Surse</surname>
            <given-names>Monika</given-names>
          </name>
          <email>sursemonika@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-4174-5813</contrib-id>
          <name>
            <surname>Yawalkar</surname>
            <given-names>Prashant</given-names>
          </name>
          <email>prashant25yawalkar@gmail.com</email>
        </contrib>
        <aff id="aff_1">Department of Computer Engineering, MET's Institute of Engineering, Savitribai Phule Pune University, 422207 Nashik, Maharashtra, India</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>30</day>
        <month>03</month>
        <year>2025</year>
      </pub-date>
      <volume>11</volume>
      <issue>1</issue>
      <fpage>39</fpage>
      <lpage>48</lpage>
      <page-range>39-48</page-range>
      <history>
        <date date-type="received">
          <day>09</day>
          <month>02</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>22</day>
          <month>03</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Seed Quality is an important area of agriculture and directly influences crop yield and germination percentage. Visual examination forms the foundation of traditional seed testing techniques, which are cumbersome, inflexible, and inefficient for effective assessment. This study proposed an automated approach to seed quality assessment based on physical measurement using machine learning and image processing techniques. Snapshots of the new seeds were captured and underwent feature extraction, segmentation, and image improvement to explore notable morphological attributes, such as size and colour. To tag seeds as "good" or "bad" based on physical characteristics, Support Vector Machines (SVMs) are used as a reference model. Rather, Convolutional Neural Networks (CNNs) have been utilised for deep feature extraction and classification. Experimental findings indicate that CNNs perform better than conventional machine learning models, with a scalable and highly accurate method of seed quality assessment. Future use will utilise quantum machine learning to improve prediction and facilitate sustainable, precision agriculture. The improved framework, optimised with great care for onion seeds, is a major breakthrough in increasing the agricultural productivity of onion cultivation.</p></abstract>
      <kwd-group>
        <kwd>Onion seeds</kwd>
        <kwd>Seed quality</kwd>
        <kwd>Image processing</kwd>
        <kwd>Machine learning</kwd>
        <kwd>Seed germination prediction</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="2"/>
        <fig-count count="5"/>
        <table-count count="2"/>
        <ref-count count="21"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>A central factor that contributes to crop production, agricultural productivity, and food security is seed quality. The demand for effective, precise, and non-destructive techniques of assessing seed quality is growing very fast with the growing technological trends in agriculture. Conventional techniques of seed assessment, such as eye inspection or hand testing, are usually labor-intensive, time-consuming, and prone to human error. For this purpose, a good substitute for seed quality assessment through automation based on physical attributes such as size, shape, color, and texture is the combination of Machine Learning (ML) and Image Processing (IP techniques).</p><p>The research on seed quality evaluation through machine learning and image processing techniques has increased exponentially over the past decade, reflecting a growing recognition of the value of accurate and effective evaluation methods in agriculture. The procedure begins with the study by <xref ref-type="bibr" rid="ref_19">Saeed et al. (2015)</xref>, which identifies the application of machine vision to identify not only healthy but also defective canola seeds. This basic work emphasizes the importance of digital image processing tools, such as the Matlab Digital Image Processing toolkit, in performing high-accuracy seed classification, although it admits some shortcomings in the segregation of good and defective seeds. On this foundation, <xref ref-type="bibr" rid="ref_15">Nkemelu et al. (2018)</xref> introduced deep convolutional neural networks (CNNs) as an even more advanced technique for plant seedling classification. Their work, based on a dataset of over 4,000 images, demonstrates how CNNs can potentially revolutionize farming automation and crop yield optimization, and hence map out a revolutionary future for machine learning applications in agriculture. <xref ref-type="bibr" rid="ref_7">ElMasry et al. (2019)</xref> push the frontiers of imaging techniques further with a discussion of multispectral imaging for seed phenotyping and quality evaluation. They emphasize the effectiveness and non-destructive methods of imaging as increasingly favored when it comes to defining the quality parameters like purity and germination potential of seeds. This article illustrates the transition towards using more objective and high-speed test means in seed testing from the yesteryear time-consuming procedures.</p><p>In 2020, <xref ref-type="bibr" rid="ref_2">Beck et al. (2020)</xref> investigated the marriage of machine learning and autonomous image tagging systems, highlighting the absolute need for high-quality training data to develop efficient ML solutions in agriculture. Based on their research, they lay out the limitation of hand annotation and the ability of other methods like transfer learning to enhance the training data sets on hand for use in CNNs.</p><p><xref ref-type="bibr" rid="ref_1">Ahmed et al. (2020)</xref> also contributed to this conversation by examining the use of X-ray imaging for watermelon seed inspection. They lay out the argument of the speed and accuracy of this method over conventional quality testing, advocating for the synergy of machine vision and deep learning for practical usage in seed quality testing.</p><p><xref ref-type="bibr" rid="ref_12">Margapuri &amp;amp; Neilsen (2021)</xref> addressed the problem of data scarcity in training CNNs for seed classification with new techniques like domain randomization and contrastive learning. Their work illustrates the potential of self-supervised learning models to overcome constraints in labeled datasets, a recurring theme in the literature.</p><p><xref ref-type="bibr" rid="ref_11">Kulkarni et al. (2021)</xref> shifted focus to plant disease detection and show how image processing and machine learning can be used to identify diseases and prevent yield loss. Their research highlights the efficacy of automated systems in monitoring vast fields of agriculture, a general trend towards applying technology in the pursuit of precision agriculture. <xref ref-type="bibr" rid="ref_4">Darbyshire et al. (2023)</xref> touched on practical weed spraying object detection, emphasizing the necessity of robust machine vision systems in precision agriculture. They introduced metrics for field deployment, representing a growing sense of the practicality of using ML solutions within agricultural settings.</p><p><xref ref-type="bibr" rid="ref_5">Dericquebourg et al. (2022)</xref> explored the complexity of seed maturity estimation from UAV multispectral images, proposing a scheme for automating data labeling to enhance deep learning model accuracy. The research emphasizes the importance of advanced imaging techniques in the realization of climate change optimized agricultural interventions. <xref ref-type="bibr" rid="ref_6">Du et al. (2023)</xref> proposed a new technique for cotton seed quality detection through an improved ResNet50 model with high levels of accuracy in distinguishing between seed qualities. The research demonstrates the advancement in machine vision-based detection technology, which has grown increasingly advanced and trustworthy over the years.</p><p><xref ref-type="bibr" rid="ref_3">Chen et al. (2024)</xref> offered a comprehensive overview of the use of artificial intelligence in agrifood systems, noting the potential offered by machine learning approaches in crop quality assessment and grading process automation. They advocate for the integration of ML with traditional agricultural practices to enhance productivity and efficiency.</p><p>Finally, <xref ref-type="bibr" rid="ref_16">Opara et al. (2024)</xref> highlighted the potential of machine learning technologies for reducing postharvest losses in fresh fruits and vegetables. They indicated a paradigm shift towards mechanizing sorting and grading operations as part of a broader trend of integrating advanced technologies into agriculture.</p><p>The studies as a collection demonstrate an interactive relationship between machine learning, image processing, and farming practices, highlighting the revolutionary capabilities of these technologies in seed quality testing and total agricultural output.</p>
    </sec>
    <sec sec-type="">
      <title>2. Overview of seed quality assessment</title>
      <p>The good quality of seed is one of the most important factors in the performance of agriculture, which mainly manifests directly by affecting the final crop yield and sustainable management. Conventional methods of seed quality estimation, which are based on size, colour, and shape, and are executed manually, are cumbersome and subject to human judgment. However, the novel developments in machine learning (ML) and image processing allow for the revolution of seed quality analysis with their efficient, accurate, and automated solutions.</p>
      
        <sec>
          
            <title>2.1. Machine learning in agricultural applications</title>
          
          <p>Machine learning methods are widely used in various applications in the food industry, such as detecting diseases, predicting yields, and testing food quality. In particular, supervised learning algorithms, such as Support Vector Machines (SVM), Decision Trees, and Convolutional Neural Networks, are very effective for classification tasks such as determining seed quality. These algorithms study the labelled dataset patterns and then are able to be used in previously revealed data, which is a remarkable base for automated decision-making.</p><p>For example, the study by <xref ref-type="bibr" rid="ref_20">Santos et al. (2020)</xref> has shown that DL can achieve high accuracy in detecting and classifying defects in seeds and fruits when applied to datasets in agriculture. These advancements highlight the potential of integrating machine learning techniques into seed quality analysis.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Image processing techniques for seed analysis</title>
          
          <p>Image processing techniques like segmentation, feature extraction, and morphological analysis are crucial in identifying seed characteristics. These methods enable the extraction of critical features like seed dimensions, shape, and color from digital images. Thresholding and edge detection algorithms are commonly used to segment seeds from the background, while feature descriptors quantify the extracted properties for further analysis.</p><p><xref ref-type="bibr" rid="ref_14">Medeiros et al. (2020)</xref> discussed the case study with optical sensors combined with machine learning algorithms for seed quality assessment, parameters such as width, height, and detected colour are fundamental indicators. By using these parameters, image processing algorithms can distinguish between good and bad seeds as demonstrated in studies focusing on the quality assessment of grains and legumes.</p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Integration of machine learning and image processing</title>
          
          <p>The integration of machine learning and image processing creates a powerful pipeline for seed quality assessment. The process typically involves:</p><p>Image Acquisition: Capturing high-resolution images of seeds.Preprocessing: Removing noise and enhancing the images for better analysis.Feature Extraction: Measuring seed dimensions (e.g., width and height) and detecting color.Classification: Using machine learning algorithms to classify seeds as “Good” or “Bad.”</p><p>In this study, images of onion seeds were analyzed using a combination of these techniques. The results showed accurate classification based on seed dimensions and color, validating the effectiveness of this integrated approach.</p>
        </sec>
      
      
        <sec>
          
            <title>2.4. Related work</title>
          
          <p>Several studies have demonstrated the utility of combining machine learning and image processing for agricultural quality assessment:</p><p><xref ref-type="bibr" rid="ref_18">Ravichandran et al. (2022)</xref> studied rice grain estimation quality parameters: They used SVC, LDA, CNN, and image processing techniques to classify rice grains based on size, shape, and texture.<xref ref-type="bibr" rid="ref_17">Pande et al. (2019)</xref> discussed the application of CNNs in fruit sorting: They applied convolutional neural networks to classify fruits based on size, color, and surface defects, achieving high efficiency in automated sorting systems.<xref ref-type="bibr" rid="ref_10">Jin et al. (2022)</xref> presented a method for seed viability testing: They utilized PCA, LR, and CNN to extract features of seed embryos and applied decision trees to classify them, achieving accurate predictions of seed viability.</p>
        </sec>
      
      
        <sec>
          
            <title>2.5. Comparative analysis and review</title>
          
          <p>The literature review highlights the advancements in seed quality assessment methods, showcasing a combination of machine learning and image processing as a robust approach. Below is a comparative <xref ref-type="table" rid="table_1">Table 1</xref> summarizing key methodologies from related works.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Key work done in seed analysis</title>
              </caption>
              <table><tbody><tr><td><p>Study</p></td><td><p>Technique Used</p></td><td><p>Application</p></td><td><p>Accuracy</p></td><td><p>Key Features</p></td></tr><tr><td><p><xref ref-type="bibr" rid="ref_18">Ravichandran et al. (2022)</xref> </p></td><td><p>SVC + LDA + CNN</p></td><td><p>Rice Grain Classification</p></td><td><p>High</p></td><td><p>Size, Shape, Texture</p></td></tr><tr><td><p><xref ref-type="bibr" rid="ref_17">Pande et al. (2019)</xref> </p></td><td><p>CNN</p></td><td><p>Fruit Sorting</p></td><td><p>High</p></td><td><p>Size, Color, Surface Defects</p></td></tr><tr><td><p><xref ref-type="bibr" rid="ref_10">Jin et al. (2022)</xref></p></td><td><p>PCA + LR + CNN</p></td><td><p>Seed Viability Analysis</p></td><td><p>High</p></td><td><p>Embryo Features</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>This study builds on previous research by integrating advanced ML algorithms with precise image processing techniques tailored to onion seed quality assessment. Unlike studies that focus on specific grains or fruits, this work addresses the challenges associated with onion seeds. While methodologies are consistent with state-of-the-art practices, including features like seed width and height with high-resolution imaging sets this study apart. The comparative analysis underscores the broader applicability and effectiveness of these combined techniques in agricultural contexts.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      <p><xref ref-type="fig" rid="fig_1">Figure 1</xref> shows the analysis of the seed quality parameter identification, starting with a single image of nine seeds. The previous steps were to convert the image to a standard input size, adjust the pixel values to determine the standard measurement of seed, and use the augmentation technique to increase the data level.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Seed analysis workflow</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_6Mmz7hmZFGY6PoZX.png"/>
        </fig>
      
      <p>After preprocessing, a model is selected that matches the expected seed physical parameters, and the data is divided into training and testing sets for training and evaluating the model. The model’s performance in classifying or analyzing seed quality is cross-validated with the seeds' physical measurements. The model output helps in identifying the best seeds (“good seeds”) that can be used as a good farmer saved seeds. Through this systematic approach, a robust and systematic analysis of onion seeds can be provided. </p>
      
        <sec>
          
            <title>3.1. Dataset preparation</title>
          
          <p>The data set comprised 9 onion seeds harvested from a farm, with an assortment of broken, mid-sized, and big seeds for variability. The seeds were captured under controlled illumination using a 1x magnifying camera in a stationary experimental setup to provide consistent brightness and contrast. The images were transformed into the HSV color space, and an existing mask was used to segment seeds depending on their black color range. Gaussian blur (σ = 9) was applied for noise reduction, then Canny edge detection (50,100) was applied to obtain the contours that were cleaned up using morphological operations (erosion and dilation). The very first contour detected was utilized as a reference object to determine a pixel-to-cm ratio (0.3 cm) for accurate size measurement. The seed dimensions were calculated using Euclidean distance, and their average color was taken for classification. Seeds were labeled as "good" if they had dimensions more than 2.2 mm and "bad" otherwise. The results were finally visualized using bar charts and superimposed contours to evaluate quality.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Image processing</title>
          
          <p>The prototype code utilizes OpenCV and other libraries to process seed images and extract relevant features (<xref ref-type="bibr" rid="ref_8">Ghimire et al., 2023</xref>):</p><p><p>Color Segmentation</p></p><p>The input image is first converted from the RGB color space to the HSV (Hue, Saturation, Value) color space. <xref ref-type="bibr" rid="ref_10">Jin et al. (2022)</xref> suggested that the HSV model is more intuitive for color segmentation as it separates chromatic content (hue) from intensity (value). Hue represents the color type, saturation indicates the vibrancy, and value reflects the brightness of the pixel. This conversion ensures that variations in lighting and intensity have minimal impact on the segmentation process.</p><p>Based on predefined thresholds for hue, saturation, and value, <xref ref-type="bibr" rid="ref_21">Toda et al. (2020)</xref> presented a binary mask that is created to isolate the regions corresponding to the seeds. These thresholds are determined through an experimental process where the range of color values corresponding to the seeds is identified. For example, seeds that appear black or dark in color would have specific ranges of low saturation and brightness values. The mask filters out all other regions of the image, retaining only the areas matching the seed color characteristics.</p><ol start="2"><p>Morphological Analysis</p></p><p><xref ref-type="bibr" rid="ref_13">Martín-Gómez et al. (2024)</xref> studied Morphological operations performed on the segmented binary mask to enhance seed detection and extract key geometric features.</p><p>After applying the mask, contours are detected using image processing techniques such as the Canny edge detector or similar contour-finding algorithms. Contours are the boundaries that outline the detected seed regions. These boundaries are essential for identifying the seed shapes and locations in the image.</p><p>For each detected seed, the bounding box is computed, which is the smallest rectangle that encloses the contour. Using the bounding box, dimensions such as width, height, and aspect ratio are calculated.</p><p>Width is the horizontal size of the bounding box.</p><p>Height is the vertical size of the bounding box.</p><p>Aspect Ratio is the ratio of width to height, which helps characterize the shape of the seed.</p><ol start="3"><p>Color Feature Extraction</p></p><p>Color is a key feature for identifying seed quality, as healthy seeds often exhibit specific color characteristics.</p><p>For each segmented seed region, the average Red, Green, and Blue (RGB) color intensities are computed. This involves summing the RGB values of all pixels within the seed region and dividing by the total number of pixels. The resulting values represent the overall color tone of the seed.</p><p><xref ref-type="bibr" rid="ref_9">Haque &amp;amp; Haque (2018)</xref> computed RGB values are then mapped to the nearest named color using the Euclidean distance metric. The Euclidean distance is calculated between the RGB values of the seed and a set of predefined RGB values corresponding to standard colors. The named color with the smallest distance is assigned to the seed. This mapping allows for an intuitive interpretation of seed color, such as "black," "dark brown," or "gray."</p><p>In our image processing project, we focused on analyzing high-resolution images of onion seeds. We started by converting these images into the HSV color space, which allowed us to apply a specific color mask to isolate the seeds based on their black hues. To enhance the clarity of the images, we used a Gaussian blur with a standard deviation of 9, which helped reduce any unwanted noise.</p><p>Next, we employed Canny edge detection with threshold values set between 50 and 100 to carefully extract the contours of the seeds. To further refine these edges, we applied morphological operations like dilation and erosion, which helped to clean up the results.</p><p>After identifying the first contour, we used it as a reference object to create a pixel-to-centimeter ratio of 0.3 cm. This allowed us to measure each seed's width and height using Euclidean distance. We also analyzed the average color of each seed to classify them according to a predefined color set.</p><p>In our classification process, we labeled seeds as "good" if their dimensions were greater than 2.2 mm and "bad" if they fell short of that measurement. Finally, we visualized our findings with bar charts and overlaid contours to clearly showcase the results of our seed classification efforts. This approach helped us better understand the quality of the onion seeds we were analyzing.</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Feature selection</title>
          
          <p>The extracted features included:</p><p>1) Dimensions: Width and height of seeds (in mm).</p><p>2) Color: Dominant color category.</p><p>3)  Morphology: Shape attributes such as aspect ratio and area.</p>
        </sec>
      
      
        <sec>
          
            <title>3.4. Classification</title>
          
          <p>A threshold-based classification was applied for initial quality assessment:</p><p>Seeds with dimensions &amp;amp;lt;= 2.2 mm were classified as “bad seeds.”Seeds with dimensions &amp;amp;gt; 2.2 mm were classified as “good seeds.”</p><p>For advanced prediction, the dataset was fed into machine learning algorithms, including Yolo, to enhance classification accuracy.</p>
        </sec>
      
    </sec>
    <sec sec-type="results">
      <title>4. Results</title>
      
        <sec>
          
            <title>4.1. Prototype outputs</title>
          
          <p>1. Segmentation accuracy</p><p>The segmentation step, represented by the illustration in subgraph (b) of <xref ref-type="fig" rid="fig_2">Figure 2</xref> as the "Mask" image, performs the task with very good precision in finding the seed regions from subgraph (a) of <xref ref-type="fig" rid="fig_2">Figure 2</xref> as the "Original Image". The design accurately extracts individual seeding areas and suppresses the noise of the background.</p><p>This accuracy, demonstrated in the segmentation process, acknowledges the strength of the algorithm in the visual detection of the required objects. What is more, the object-oriented mask generation technique was able to remove the confrontation problem of the overlapping, irrelevant areas. This, in turn, guarantees the accuracy of the extracted mask. The ability to segment and distinguish seeds of different sizes and shapes is clear evidence of the flexibility of the method.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Different stages of onion seed</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_iMIHNYg374DajgSo.png"/>
            </fig>
          
          <p><span style="font-family: Times New Roman, serif">2. Geometrical Measurements</p><p><span style="font-family: Times New Roman, serif">Innovative guidance to the multistage image segmentation process for the final analysis of seeds is depicted in subgraph (c) of <xref ref-type="fig" rid="fig_2">Figure 2</xref>. <span style="font-family: Times New Roman, serif">Where each seed is surrounded by a bounding box, where its dimensions (length and width) are annotated on the image directly. For instance, the upper-left seed is 2.6 mm × 2.9 mm, while the center-left seed is 3.0 mm × 2.3 mm. The determined dimensions coincide with the observed footage and manual measurements, confirming the validity of the method used. This approach provides two advantages: it gives us a way to graph the seed sizes, and it allows us to analyze all our samples uniformly.</p><p><span style="font-family: Times New Roman, serif">Furthermore, the visualization of the "Seed Size" shown in subgraph (c) of <xref ref-type="fig" rid="fig_2">Figure 2</xref> demonstrates the organized output of the geometrical characteristics obtained from the exploration. The prototype automates the process of measuring the file size, thereby reducing human error while providing the ability to process large datasets much faster, demonstrating its scalability and use in real-world applications.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Prototype efficiency</title>
          
          <p><span style="font-family: Times New Roman, serif">The results confirm that the images implemented are of various resolutions and complexities. Even in the face of potential challenges like variations in lighting and slightly distorted original images, segmentation and measurement from the model provided are still robust. An automated approach minimizes the involvement of human experts, which significantly improves reproducibility and the time it consumes. This is especially important in applications such as agriculture or food quality control, where large amounts of seeds must often be analyzed.</p><p><span style="font-family: Times New Roman, serif">This process required precise measurements and evaluations to ascertain the suitability of the seeds for further agricultural use. The results indicated that the majority of the seeds met acceptable standards; however, a few deviated from the predefined criteria because some exhibited irregular attributes. Although the findings were largely positive, the existence of these anomalies is noteworthy.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Summary of seed quality assessment</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Seed</p></td><td colspan="1" rowspan="1"><p>Width (mm)</p></td><td colspan="1" rowspan="1"><p>Height (mm)</p></td><td colspan="1" rowspan="1"><p>Detected Color</p></td><td colspan="1" rowspan="1"><p>Seed Quality</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 1</p></td><td colspan="1" rowspan="1"><p>3</p></td><td colspan="1" rowspan="1"><p>2.3</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 2</p></td><td colspan="1" rowspan="1"><p>2.6</p></td><td colspan="1" rowspan="1"><p>2.9</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 3</p></td><td colspan="1" rowspan="1"><p>2.8</p></td><td colspan="1" rowspan="1"><p>2.5</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 4</p></td><td colspan="1" rowspan="1"><p>2.9</p></td><td colspan="1" rowspan="1"><p>1.8</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 5</p></td><td colspan="1" rowspan="1"><p>2.3</p></td><td colspan="1" rowspan="1"><p>2.2</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 6</p></td><td colspan="1" rowspan="1"><p>2.2</p></td><td colspan="1" rowspan="1"><p>1.8</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Bad Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 7</p></td><td colspan="1" rowspan="1"><p>1.8</p></td><td colspan="1" rowspan="1"><p>2.3</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Good Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 8</p></td><td colspan="1" rowspan="1"><p>1.5</p></td><td colspan="1" rowspan="1"><p>2.2</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Bad Seed</p></td></tr><tr><td colspan="1" rowspan="1"><p>Seed 9</p></td><td colspan="1" rowspan="1"><p>2.1</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>Black</p></td><td colspan="1" rowspan="1"><p>Bad Seed</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Among the nine seeds analyzed (<xref ref-type="table" rid="table_2">Table 2</xref>), six were cla<span style="font-family: Times New Roman, serif">ssified as Good Seeds, as they met the requisite dimensional thresholds and quality standards. These seeds displayed consistent geometrical properties, which indicate a notable uniformity and high quality. For instance, Seed 1 (3.0 mm × 2.3 mm), Seed 2 (2.6 mm × 2.9 mm), and Seed 3 (2.8 mm × 2.5 mm) all exhibited optimal sizes and were thus deemed good. Similarly, Seeds 4, 5, and 7 conformed to the established standards, further underscoring the reliability of the batch.</p><p><span style="font-family: Times New Roman, serif">However, three seeds were categorized as Bad Seeds due to their suboptimal dimensions, which likely suggest underdevelopment or deformities. For example, Seed 6 (2.2 mm × 1.8 mm) and Seed 8 (1.5 mm × 2.2 mm) had the smallest dimensions among the samples, falling considerably below the acceptable range. Seed 9 (2.1 mm × 2.0 mm) also slightly failed to meet the threshold, which resulted in its classification as a bad seed. These deviations highlight the necessity of rigorous quality control measures because only high-quality seeds should be selected for further use.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Seed quality distribution</title>
          
          <p><xref ref-type="fig" rid="fig_3">Figure 3</xref><span style="font-family: Times New Roman, serif"> clearly outlines a comparative count comparison of bad seeds and good seeds, where their respective values are displayed. This visualisation proves critical in describing the pattern of distribution within the dataset since the viewer is made to visually comprehend the relative proportions of each type.</p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Bar chart comparing good seeds with bad seeds</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_aCV--S0BcXkyFJbu.png"/>
            </fig>
          
          <p><span style="font-family: Times New Roman, serif">By adding numerical values or percentage values, the impact of the visualization would be greater still, providing a clearer and more precise description of the ratio of the two groups. The additions would not merely facilitate a better understanding of the quantity of good seeds versus bad seeds but would also assist in the identification of trends or outliers in the dataset.</p><p><xref ref-type="fig" rid="fig_4">Figure 4</xref><span style="font-family: Times New Roman, serif"> provides a detailed graphical representation of the seed quality distribution, properly dividing the seeds into two primary categories: "Good Seeds" and "Bad Seeds." Such categorisation is crucial to realising the general quality of the batch of seeds since it identifies the different parameters responsible for seed viability, germination rates, and overall health.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Seed quality distribution</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_8G5cbIXV6EWutxlj.png"/>
            </fig>
          
          <p><span style="font-family: Times New Roman, serif">The "Good Seeds" category generally consists of those displaying best-of-their traits, like responsible size, consistency, and wholesomeness, indicating a better chance for optimal growth. Conversely, the "Bad Seeds" category can consist of those that are broken, coloured, or otherwise fail to meet set quality requirements. By presenting this clear synopsis, the figure allows for improved comprehension of the seed quality and supports decision-making associated with planting and agricultural planning.</p><p><xref ref-type="fig" rid="fig_5">Figure 5</xref><span style="font-family: Times New Roman, serif"> shows a scatter plot of the distribution of seed sizes. The x-axis of the graph measures seed width in millimeters, covering an approximate range from 2.0 mm to 3.0 mm. The y-axis, on the other hand, is probably reserved for measuring either frequency or density of seeds in given size ranges. This visualization plays a vital role in studying the variation of seed sizes, offering useful information for vital classification and quality assessment processes.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>Scatter plot of seed size distribution</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/3/img_j7xF9MrOBCIv2WvQ.png"/>
            </fig>
          
          <p><span style="font-family: Times New Roman, serif">Through the observation of the distribution pattern, researchers can discover any trends or irregularities of seed sizes, which might be reflections of genetic variations, environmental impacts, or agricultural and horticultural applications. This high-degree analysis assists with efficient seed improvement and selection policies based on characteristics of size.</p>
        </sec>
      
    </sec>
    <sec sec-type="discussion">
      <title>5. Discussion</title>
      <p>One of the observations of interest is the accuracy of classification at 88.89%, which suggests that the model is fairly good at distinguishing between good-quality seeds and bad seeds. Nevertheless, note that there can be classification mistakes caused by similarity in visual features between borderline examples, like seeds with marginal variation in size or analogous color features that might lie near the established threshold values (e.g., ≤2.2 mm width and height). This restriction indicates the necessity of fine-tuning the decision boundaries or incorporating more features like texture, surface morphology, or 3D shape descriptors to enhance the robustness of the model.</p><p>The bar chart illustrating good and bad seeds shows the dataset to be moderately imbalanced. Most of the seeds plot just above or below the predetermined quality threshold, which can have the effect of introducing bias within classification because it is a hard cutoff. Use of a soft classification margin or probabilistic thresholding might make this less problematic in future development. The seed size distribution scatter plot further supports the existence of a cluster of seeds at the 2.2 mm cutoff, supporting the notion that misclassifications would likely result from slight dimensional differences. This plot can also be employed to determine if a more dynamic or data-based threshold would more effectively distinguish the classes.</p><p>Classification by color, also demonstrated by stacked bar charts (which aren't part of existing visualizations), also has its limitations. Because lighting and shadows can influence the appearance of colors, color averaging by itself can be insufficient as a quality measure. A more sophisticated color calibration method or machine learning model that learns the RGB histogram or the HSV color space may better increase classification accuracy. Additionally, the model has no adaptive processes to correct misclassifications. The integration of a feedback-driven learning mechanism or confusion matrix analysis would identify patterns where the model repeatedly goes wrong and help drive retraining processes.</p>
    </sec>
    <sec sec-type="conclusions">
      <title>6. Conclusions</title>
      <p>This research introduces a vision-based classifier method for estimating onion seed quality using image processing methods based on dimensional and color characteristics. In the experimental work, it was shown that the model registered a classification rate of 88.89% and thus proposed a promising base for low-cost, non-destructive seed quality estimation.</p><p>The results validate that seed size—i.e., width and height thresholds—can be an effective measure for distinguishing between good and bad seeds. Nevertheless, seeds near the decision boundary presented difficulties in correct classification, indicating the requirement of more advanced feature extraction and adaptive thresholding in subsequent work. Furthermore, although color-based features offer complementary information, their sensitivity to variations in lighting conditions could restrict reliability unless sophisticated preprocessing or calibration methods are employed.</p><p>This method provides potential value to agricultural professionals and seed processing industries for automated, scalable, and cost-effective seed quality screening platforms. However, potential future enhancement involves incorporating machine learning algorithms, increasing the dataset, and integrating comparative benchmarking with state-of-the-art techniques to improve model generalizability and performance.</p><p>In short, the method presented here establishes a solid foundation for automated seed classification but also highlights the need for ongoing improvement, particularly in error analysis, adaptive classification methods, and verification against current literature and commercial systems.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      <p>Conceptualization, M.S.; methodology, M.S.; validation, P.Y.; formal analysis, writing—original draft preparation, M.S.; writing—review and editing, M.S.; supervision, P.Y.; project administration, P.Y. All authors have read and agreed to the published version of the manuscript.</p>
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the findings of this study are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>6753</page-range>
          <issue>23</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahmed</surname>
              <given-names>M. R.</given-names>
            </name>
            <name>
              <surname>Yasmin</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Park</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Moon S.</given-names>
            </name>
            <name>
              <surname>Wakholi</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Mo</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Cho</surname>
              <given-names>B. K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s20236753</pub-id>
          <article-title>Classification of watermelon seeds using morphological patterns of X-ray imaging: A comparison of conventional machine learning and deep learning</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>e0243923</page-range>
          <issue>12</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Beck</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>C. Y.</given-names>
            </name>
            <name>
              <surname>Bidinosti</surname>
              <given-names>C. P.</given-names>
            </name>
            <name>
              <surname>Henry</surname>
              <given-names>C. J.</given-names>
            </name>
            <name>
              <surname>Godee</surname>
              <given-names>C. M.</given-names>
            </name>
            <name>
              <surname>Ajmani</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0243923</pub-id>
          <article-title>An embedded system for the automated generation of labeled plant images to enable machine learning applications in agriculture</article-title>
          <source>PLOS One</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>57</volume>
          <page-range>1-37</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Lv</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>et al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3698589</pub-id>
          <article-title>Empowering agrifood system with artificial intelligence: A survey of the progress, challenges and opportunities</article-title>
          <source>ACM Computing Surveys</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>1183277</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Darbyshire</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Salazar-Gomez</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Sklar</surname>
              <given-names>Elizabeth I.</given-names>
            </name>
            <name>
              <surname>Parsons</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/fpls.2023.1183277</pub-id>
          <article-title>Towards practical object detection for weed spraying in precision agriculture</article-title>
          <source>Frontiers in Plant Science</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>5238</page-range>
          <issue>20</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dericquebourg</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Hafiane</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Canals</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs14205238</pub-id>
          <article-title>Generative-model-based data labeling for deep network regression: Application to seed maturity estimation from UAV multispectral images</article-title>
          <source>Remote Sens.,</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>e0273057</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Du</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Si</surname>
              <given-names>L. Q.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>P. F.</given-names>
            </name>
            <name>
              <surname>Yun</surname>
              <given-names>Z. H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0273057</pub-id>
          <article-title>A method for detecting the quality of cotton seeds based on an improved ResNet50 model</article-title>
          <source>PLOS One</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>1090</page-range>
          <issue>5</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>ElMasry</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Mandour</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Al-Rejaie</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Belin</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Rousseau</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s19051090</pub-id>
          <article-title>Recent applications of multispectral imaging in seed phenotyping and quality monitoring—An overview</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>3078</page-range>
          <issue>17</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ghimire</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>S.-H.</given-names>
            </name>
            <name>
              <surname>Cho</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jang</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ahn</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Islam</surname>
              <given-names>M. S.</given-names>
            </name>
            <name>
              <surname>Mansoor</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Chung</surname>
              <given-names>Y. S.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/plants12173078</pub-id>
          <article-title>Automatic evaluation of soybean seed traits using RGB image data and a Python algorithm</article-title>
          <source>Plants</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1919-1925</page-range>
          <issue>2</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Haque</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Haque</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.21917/ijivp.2018.0272</pub-id>
          <article-title>Plant recognition system using leaf shape features and minimum Euclidean distance</article-title>
          <source>ICTACT J. Image Video Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>122</volume>
          <page-range>104097</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jin</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Qi</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Jia</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Tang</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.infrared.2022.104097</pub-id>
          <article-title>Determination of viability and vigor of naturally-aged rice seeds using hyperspectral imaging with machine learning</article-title>
          <source>Infrared Phys. Technol.,</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="webpage">
          <article-title>Plant disease detection using image processing and machine learning</article-title>
          <year>2021</year>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="conference-proceedings">
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Margapuri</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Neilsen</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ssci50451.2021.9659998</pub-id>
          <article-title>Classification of seeds using domain randomization on self-supervised learning frameworks</article-title>
          <source>, </source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>285</page-range>
          <issue>3</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Martín-Gómez</surname>
              <given-names>J. J.</given-names>
            </name>
            <name>
              <surname>Rodríguez-Lorenzo</surname>
              <given-names>J. L.</given-names>
            </name>
            <name>
              <surname>Gutiérrez del Pozo</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Cabello Sáez de Santamaría</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Muñoz-Organero</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Tocino</surname>
              <given-names>Á.</given-names>
            </name>
            <name>
              <surname>Cervantes</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/horticulturae10030285</pub-id>
          <article-title>Seed morphological analysis in species of Vitis and relatives</article-title>
          <source>Horticulturae,</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>4319</page-range>
          <issue>15</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Medeiros</surname>
              <given-names>A. D. D.</given-names>
            </name>
            <name>
              <surname>Silva</surname>
              <given-names>L. J. D.</given-names>
            </name>
            <name>
              <surname>Ribeiro</surname>
              <given-names>J. P. O.</given-names>
            </name>
            <name>
              <surname>Ferreira</surname>
              <given-names>K. C.</given-names>
            </name>
            <name>
              <surname>Rosas</surname>
              <given-names>J. T. F.</given-names>
            </name>
            <name>
              <surname>Santos</surname>
              <given-names>A. A.</given-names>
            </name>
            <name>
              <surname>Silva</surname>
              <given-names>C. B. D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s20154319</pub-id>
          <article-title>Machine learning for seed quality classification: An advanced approach using merger data from FT-NIR spectroscopy and X-ray imaging</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <article-title>Deep convolutional neural network for plant seedlings classification</article-title>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Nkemelu</surname>
              <given-names>Daniel K.</given-names>
            </name>
            <name>
              <surname>Omeiza</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Lubalo</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1811.08404</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>1200</page-range>
          <issue>9</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Opara</surname>
              <given-names>I. K.</given-names>
            </name>
            <name>
              <surname>Opara</surname>
              <given-names>U. L.</given-names>
            </name>
            <name>
              <surname>Okolie</surname>
              <given-names>Jude A.</given-names>
            </name>
            <name>
              <surname>Fawole</surname>
              <given-names>O. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/plants13091200</pub-id>
          <article-title>Machine learning application in horticulture and prospects for predicting fresh produce losses and waste: A review</article-title>
          <source>Plants</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>1-7</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pande</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Munot</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sreeemathy</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bakare</surname>
              <given-names>R.V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/i2ct45611.2019.9033957</pub-id>
          <article-title>An efficient approach to fruit classification and grading using deep convolutional neural network</article-title>
          <source>, http://dx.doi.org/10.1109/I2CT45611.2019.9033957</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>99</volume>
          <page-range>907-919</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ravichandran</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Viswanathan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ravichandran</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pan</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>Young K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1002/cche.10546</pub-id>
          <article-title>Estimation of grain quality parameters in rice for high‐throughput screening with near‐infrared spectroscopy and deep learning</article-title>
          <source>Cereal Chem.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>36-43</page-range>
          <issue>1</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saeed</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Tariq</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ibrahim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ahmad</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ahmad</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Aftab</surname>
              <given-names>R. S.</given-names>
            </name>
            <name>
              <surname>Mehdi</surname>
              <given-names>S. M.</given-names>
            </name>
          </person-group>
          <article-title>Identification of canola seeds using nearest neighbor and K-nearest neighbor algorithms</article-title>
          <source>Aust. J. Bus. Sci. Des. Lit.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="conference-proceedings">
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Santos</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Santos</surname>
              <given-names>F. N.</given-names>
            </name>
            <name>
              <surname>Oliveira</surname>
              <given-names>P. M.</given-names>
            </name>
            <name>
              <surname>Shinde</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/978-3-030-35990-4_12</pub-id>
          <article-title>Deep learning applications in agriculture: A short review</article-title>
          <source>, </source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>173</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Toda</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Okura</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Ito</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Okada</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kinoshita</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Tsuji</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Saisho</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s42003-020-0905-5</pub-id>
          <article-title>Training instance segmentation neural network with synthetic datasets for crop seed phenotyping</article-title>
          <source>Commun. Biol.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>