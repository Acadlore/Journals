<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JIMD</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Journal of Intelligent Management Decision</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Intell. Manag. Decis.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JIMD</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-0080</issn>
      <issn publication-format="print">2958-0072</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-NBIM1jq-os1oT8yErOJHFDuRhIp32Yky</article-id>
      <article-id pub-id-type="doi">10.56578/jimd040304</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>AI–Driven Frameworks for Strategic Risk Management: A Systematic Review and Model for Organizational Resilience and Decision Support</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0004-4766-6886</contrib-id>
          <name>
            <surname>Zeriouh</surname>
            <given-names>Khalid</given-names>
          </name>
          <email>zeriouhkhalid@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0005-5194-7354</contrib-id>
          <name>
            <surname>Amara</surname>
            <given-names>Mehdi</given-names>
          </name>
          <email>m.amara@univ-soukahras.dz</email>
        </contrib>
        <aff id="aff_1">Department of Management and Entrepreneurship, Higher National School of Management, 42003 Kolea, Algeria</aff>
        <aff id="aff_2">Laboratory of Research and Economic Studies, Mohamed Cherif Messaadia University, 41043 Souk Ahras, Algeria</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>11</day>
        <month>08</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>3</issue>
      <fpage>224</fpage>
      <lpage>234</lpage>
      <page-range>224-234</page-range>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>06</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>04</day>
          <month>08</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>In an era defined by digital transformation and systemic volatility, conventional approaches to strategic risk management have been increasingly challenged by the complexity and unpredictability of modern operational environments. To address these limitations, a novel artificial intelligence (AI)–driven framework has been developed to enhance organizational resilience and optimize strategic decision-making. Constructed through a systematic review conducted in accordance with PRISMA 2020 guidelines, this study synthesizes current academic literature and industry publications to identify critical enablers, practical gaps, and methodological advancements in AI-enabled risk governance. The proposed framework integrates real-time analytics, predictive modelling, and adaptive governance mechanisms, aligning them with enterprise-wide strategic objectives to support decision-making under volatile, uncertain, complex, and ambiguous (VUCA) conditions. Anchored in dynamic capabilities theory and decision support systems (DSS) literature, the framework is designed to facilitate proactive risk anticipation, reduce cognitive and algorithmic biases in decision-making, and foster strategic alignment in rapidly evolving contexts. Its adaptability to small and medium-sized enterprises (SMEs), as well as its cross-sectoral relevance, underscores its scalability and practical utility. Nonetheless, the effectiveness of the framework is contingent upon the availability of high-quality data, the level of digital maturity within organizations, and the implementation of responsible AI principles. By bridging the gap between theoretical innovation and real-world applicability, this study contributes a robust foundation for future empirical validation and sector-specific customization. The framework is expected to inform governance and technology leaders aiming to institutionalize AI-based resilience capabilities, thereby supporting sustainable strategic outcomes in both developed and emerging markets.</p></abstract>
      <kwd-group>
        <kwd>Artificial Intelligence (AI)</kwd>
        <kwd>Strategic risk management</kwd>
        <kwd>Organizational resilience</kwd>
        <kwd>Decision support system (DSS)</kwd>
        <kwd>Corporate governance</kwd>
        <kwd>Dynamic capabilities</kwd>
        <kwd>Volatile</kwd>
        <kwd>uncertain</kwd>
        <kwd>complex</kwd>
        <kwd>and ambiguous (VUCA)</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="2"/>
        <fig-count count="5"/>
        <table-count count="3"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>In an era of escalating volatility, digital disruption, and growing global interconnectedness, effective risk management has become pivotal to ensuring organizational success and resilience across industries. Yet, traditional approaches, often reactive and reliant on subjective judgment, increasingly struggle to address complex, interconnected risks such as cybersecurity threats, supply chain disruptions, and market uncertainties [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>]. The rapid pace of technological change and dynamic business environments further underscore the urgent need for innovative tools that strengthen strategic decision-making and corporate governance [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>].</p><p>AI, with its capacity to process vast amounts of data, identify emerging patterns, and enable adaptive learning, holds transformative potential to redefine risk management and align it with broader enterprise objectives [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>]. Unlike conventional risk frameworks, AI-driven approaches can reduce decision biases, enable real-time risk detection, and enhance precision in VUCA contexts [<xref ref-type="bibr" rid="ref_7">7</xref>]. However, challenges such as algorithmic opacity, data bias, and ethical concerns highlight the need for robust frameworks that guide responsible and transparent AI integration [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_9">9</xref>].</p><p>Addressing this gap, this study proposes an original AI-based strategic risk management framework designed to enhance organizational resilience and support informed decision-making, while contributing to the fields of corporate governance and technology management. Unlike existing sector-specific studies [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>], the proposed framework provides a scalable, cross-sectoral solution, with particular relevance for SMEs and high-risk industries [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>]. The findings demonstrate how this approach improves strategic alignment, anticipates emerging risks through predictive analytics, and fosters resilience, thereby offering actionable insights for organizations navigating today’s complex business landscape.</p>
    </sec>
    <sec sec-type="">
      <title>2. Literature review</title>
      <p>AI in Strategic Risk Management</p><p>The integration of AI into strategic risk management is transforming how organizations navigate VUCA environments. AI enhances resilience, improves decision-making, and strengthens corporate governance. This systematic literature review (SLR) synthesizes peer-reviewed studies and industry reports (2019–2025), examining conceptual frameworks, practical applications, implementation challenges, and current gaps. It highlights AI’s potential to overcome traditional risk management limitations while identifying the need for a unified, governance-oriented framework.</p><p>Conceptual Frameworks for AI-Driven Risk Management</p><p>Several recent studies propose conceptual models that integrate AI into strategic risk management, with a shared emphasis on data-driven decision-making and strategic alignment.</p><p>Carayannis et al. [<xref ref-type="bibr" rid="ref_4">4</xref>] offer a framework for SMEs that merges AI-driven predictive analytics with strategic foresight to enhance resilience, though it lacks integration with enterprise risk management (ERM) systems. Žigiene et al. [<xref ref-type="bibr" rid="ref_13">13</xref>] focus on supply chain risk for SMEs using analytics to manage external threats but omit governance elements. Bussmann et al. [<xref ref-type="bibr" rid="ref_1">1</xref>] introduce explainable AI (XAI) frameworks for fintech to improve transparency, yet these lack applicability across sectors. López-Solís et al. [<xref ref-type="bibr" rid="ref_7">7</xref>] explore generative AI in scenario planning but overlook AI-specific risks such as bias. Biloslavo et al. [<xref ref-type="bibr" rid="ref_3">3</xref>] advocate for AI in strategic planning within VUCA environments, although their model requires more explicit governance integration.</p><p>Together, these frameworks reflect AI’s transformative potential but remain fragmented, reinforcing the need for a more integrated model that aligns AI use with governance and strategic objectives.</p><p>Practical Applications of AI in Strategic Risk Management</p><p>Applied studies further demonstrate AI’s ability to improve decision-making and resilience across various industries. Javaid [<xref ref-type="bibr" rid="ref_6">6</xref>] shows how predictive analytics enable real-time risk identification in finance, though without addressing algorithmic risks. Adeoye et al. [<xref ref-type="bibr" rid="ref_10">10</xref>] apply AI in oil and gas HSE systems, mitigating operational risks, but highlight the need for structured governance. Kalisetty et al. [<xref ref-type="bibr" rid="ref_2">2</xref>] and Kassa et al. [<xref ref-type="bibr" rid="ref_12">12</xref>] examine AI’s role in enhancing supply chain resilience, but their findings are limited by sectoral focus. Milojević and Redzepagic [<xref ref-type="bibr" rid="ref_14">14</xref>] assess AI’s use in banking compliance, yet provide limited insight into SME adoption. Bi and Bao [<xref ref-type="bibr" rid="ref_11">11</xref>] demonstrate the value of AI in financial risk management, enhancing data-driven insights, though without extending to enterprise-wide integration.</p><p>These applications confirm AI’s potential but also reveal the absence of standardized, cross-sectoral frameworks to guide responsible and scalable implementation [<xref ref-type="bibr" rid="ref_5">5</xref>].</p><p>Organizational and Implementation Challenges</p><p>Despite its potential, integrating AI into strategic risk management presents several challenges, particularly around governance, resource availability, and transparency. Habbal et al. [<xref ref-type="bibr" rid="ref_8">8</xref>] introduce the AI Trust, Risk, and Security Management (AI TRiSM) framework to address algorithmic bias, data quality, and human oversight, yet it lacks strategic application. Novelli et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] highlight regulatory ambiguity, such as the EU AI Act, requiring robust governance structures. Stahl et al. [<xref ref-type="bibr" rid="ref_9">9</xref>] underscore transparency challenges in AI impact assessments, which are critical for stakeholder trust. Maghfirah and Eni [<xref ref-type="bibr" rid="ref_16">16</xref>] point to common resource constraints, especially for SMEs, such as limited data infrastructure and technical capacity.</p><p>These barriers highlight the absence of a practical, governance-based framework that balances AI’s analytical strengths with scalability and ethical responsibility [<xref ref-type="bibr" rid="ref_17">17</xref>].</p><p>Gaps in the Current Literature</p><p>The literature reveals several critical gaps that underscore the need for a comprehensive framework. First, few studies empirically validate the long-term effectiveness of AI-based risk models, as many remain theoretical or sector-specific [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>]. Second, while SMEs are central to many economies, their unique constraints and adoption contexts remain underexplored [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>]. Third, most frameworks lack alignment with established ERM standards such as ISO 31000, limiting practical utility [<xref ref-type="bibr" rid="ref_1">1</xref>]. Lastly, discussions on ethical trade-offs such as transparency, bias, and AI-related vulnerabilities are still limited [<xref ref-type="bibr" rid="ref_8">8</xref>], [<xref ref-type="bibr" rid="ref_18">18</xref>].</p><p>These gaps signal the need for a scalable, cross-sectoral AI framework that integrates strategic governance, operational feasibility, and responsible AI principles.</p><p>Synthesis</p><p>This review affirms AI’s transformative potential for strategic risk management, enhancing decision support, resilience, and governance. While several frameworks and applications show promise, their fragmented and sector-specific nature limits broader adoption. Implementation challenges such as bias, resource limitations, and evolving regulations further complicate integration. The lack of empirical validation, SME-focused solutions, and standardized ERM alignment emphasizes the need for a robust, governance-oriented framework that is both scalable and practical. Such a model can bridge the gap between AI innovation and responsible organizational implementation, contributing meaningfully to both academic literature and professional practice.</p>
    </sec>
    <sec sec-type="">
      <title>3. Methodology</title>
      <p>This study employs an SLR to identify and synthesize existing research on the integration of AI into strategic risk management. The goal is to develop an original conceptual framework that supports organizational resilience and strengthens corporate governance.</p>
      
        <sec>
          
            <title>3.1. Research questions</title>
          
          <p>The review is guided by four research questions:</p><p>• RQ1. How does AI transform traditional risk management to support strategic decision-making?</p><p>• RQ2. What are the primary frameworks for integrating AI into strategic risk management?</p><p>• RQ3. What challenges arise in adopting AI for strategic risk management?</p><p>• RQ4. What practical implications do AI-driven approaches offer for strategic decision-makers?</p><p>The review process follows the PRISMA 2020 guidelines, ensuring methodological rigor and transparency in identifying, screening, and synthesizing relevant literature [<xref ref-type="bibr" rid="ref_9">9</xref>]. Both descriptive and thematic analyses were conducted to interpret the findings, with particular emphasis on practical frameworks, technological enablers, governance challenges, and directions for future research [<xref ref-type="bibr" rid="ref_4">4</xref>].</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Data</title>
          
          <p>To ensure comprehensive coverage, data were collected from multiple reputable sources, including Scopus, Web of Science, IEEE Xplore, and ACM Digital Library, and supplemented by high-quality gray literature such as OECD and NIST reports [<xref ref-type="bibr" rid="ref_8">8</xref>]. Search strings combined keywords such as “artificial intelligence,” “machine learning,” “predictive analytics,” “risk management,” and “strategic resilience,” adapted using Boolean operators and database-specific syntax [<xref ref-type="bibr" rid="ref_7">7</xref>].</p><p>Inclusion criteria were:</p><p>• English-language publications from 2019 to 2025;</p><p>• Peer-reviewed journal articles, conference proceedings, book chapters, and reputable industry reports;</p><p>• Studies addressing AI in strategic or organizational risk management contexts.</p><p>Exclusion criteria included:</p><p>• Non-empirical opinion pieces and editorials;</p><p>• Technical AI studies without managerial relevance;</p><p>• Inaccessible full texts.</p>
          <p>The selection process was managed using Zotero for reference management, with discrepancies resolved through discussion among the researchers to ensure objectivity [<xref ref-type="bibr" rid="ref_1">1</xref>]. Methodological rigor was assessed using tools such as the CASP checklist for qualitative studies, bias assessments for quantitative research, and AMSTAR-2 for existing reviews [<xref ref-type="bibr" rid="ref_19">19</xref>].</p><p>A detailed overview of the systematic selection process is illustrated in <xref ref-type="fig" rid="fig_1">Figure 1</xref> using the PRISMA 2020 flow diagram.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>PRISMA 2020 flow diagram</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_U9o_UQ5uyZkaze0c.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="results">
      <title>4. Results</title>
      <p>This section presents findings from an SLR examining AI in strategic risk management, focusing on its transformative role in enhancing organizational resilience and decision support within corporate governance frameworks. The SLR, synthesizing 72 studies from 2019 to 2025, addresses four research questions: how AI transforms traditional risk management, primary frameworks, adoption challenges, and practical implications for strategic decision-makers. Findings are organized into four themes: trends in AI risk management research, distribution of AI applications across sectors and risk domains, comparative capabilities of AI approaches, and challenges with preliminary framework components. These findings highlight gaps and opportunities, laying the foundation for a novel AI-based strategic risk management framework.</p><p>Trends in AI Risk Management Research</p><p>SLR highlights a steady rise in research on the use of AI in risk management between 2019 and 2025. This growing trend reflects increasing academic and industry interest in using AI to enhance strategic resilience, governance, and decision-making [<xref ref-type="bibr" rid="ref_4">4</xref>]. Many of these studies focus on predictive analytics, AI-based governance tools, and applications that address volatility and complexity in today's business environment [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>].</p><p>To visually capture this evolution, <xref ref-type="fig" rid="fig_2">Figure 2</xref> presents the publication trends by type, showing a notable increase in peer-reviewed journal articles, conference papers, and high-quality industry reports. The figure supports the textual analysis by illustrating the shift from technical AI discussions to more strategic, governance-oriented studies.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Publication trends in AI and risk management (2019–2025) by publication type</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_1WRCjHRIDv-CdvnA.png"/>
        </fig>
      
      <p>This growing body of work reinforces the need for a unified and practical AI framework that can connect fragmented approaches and guide implementation across sectors.</p><p>Distribution of AI Applications Across Sectors and Risk Domains</p><p>AI applications vary across sectors and risk domains. Financial services lead, with a focus on cybersecurity and financial risk management, driven by data-rich environments and regulatory demands [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. The energy sector shows emerging interest in sustainability and operational risks [<xref ref-type="bibr" rid="ref_10">10</xref>], while supply chain management and healthcare are growing, though limited by resource constraints in smaller sectors like manufacturing and retail [<xref ref-type="bibr" rid="ref_2">2</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>]. Cybersecurity and financial risks dominate, but strategic risk management remains underexplored, highlighting a gap in enterprise-wide AI applications [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>Comparative Capabilities of AI Approaches</p><p>The review compares three major AI approaches - traditional machine learning, deep learning, and generative AI-across core strategic risk management capabilities: predictive accuracy, risk assessment, monitoring, explainability, adaptability, and decision support.</p><p>• Traditional machine learning performs well in explainability and system integration, making it ideal for compliance-driven tasks and regulated environments [<xref ref-type="bibr" rid="ref_1">1</xref>].</p><p>• Deep learning excels in predictive accuracy and complex risk monitoring due to its advanced pattern recognition capabilities [<xref ref-type="bibr" rid="ref_6">6</xref>].</p><p>• Generative AI offers strong adaptability and decision support, particularly in scenario planning and simulation. However, it poses challenges in explainability, which may limit its use in highly regulated sectors [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>These distinct yet complementary strengths suggest that no single AI approach is sufficient for managing strategic risks in isolation. Instead, an integrative framework that combines these technologies can better address the diverse needs of risk leaders balancing accuracy, agility, transparency, and governance.</p><p><xref ref-type="fig" rid="fig_3">Figure 3</xref> visually supports this analysis by comparing how each AI method performs across eight key dimensions relevant to strategic risk management. The radar chart demonstrates their individual strengths and highlights areas where they can be most effectively applied or combined.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Comparative capabilities of AI approaches for risk management</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_Fg07F92XET-GpzcX.png"/>
        </fig>
      
      <p>Preliminary Framework Components Identified in the Literature</p><p>SLR identifies five core components commonly proposed to support AI adoption in strategic risk management. Although these elements emerge across various sectors, they are often applied in isolation, without integration into a holistic framework. This synthesis lays the groundwork for a more scalable and unified approach.</p><p>(1) Strategic Governance: Involves defining clear policies, ethical guidelines, and oversight structures to align AI initiatives with organizational goals and regulatory standards [<xref ref-type="bibr" rid="ref_15">15</xref>].</p><p>(2) Dynamic Risk Assessment: Refers to systematic processes for identifying and evaluating emerging risks using AI-powered predictive analytics and scenario modelling [<xref ref-type="bibr" rid="ref_6">6</xref>].</p><p>(3) Technical Controls: Focuses on data validation, model auditing, and bias detection to ensure system reliability, accuracy, and trust [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>(4) Human Oversight: Stresses the role of human judgment, training, and ethical awareness to complement AI automation and maintain accountability [<xref ref-type="bibr" rid="ref_19">19</xref>].</p><p>(5) Continuous Improvement: Encourages the use of feedback loops and adaptive learning to refine AI tools and governance practices over time [<xref ref-type="bibr" rid="ref_4">4</xref>].</p><p>Although widely acknowledged, these components are rarely combined into a strategic, cross-sectoral model. Integrating them cohesively is essential for organizations, especially those with limited resources, to fully realize AI’s potential in managing strategic risks.</p><p> <xref ref-type="fig" rid="fig_4">Figure 4</xref> illustrates how these five interdependent components interact, based on findings from the literature. The visual aid supports understanding by positioning the components in a connected system rather than isolated functions.</p>
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>Proposed AI-based strategic risk management framework (synthesis from SLR)</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_JPt6i387YgBDfBAW.png"/>
        </fig>
      
      <p>Persistent Challenges in AI-Driven Risk Management</p><p>Despite the promise of the proposed framework, several persistent challenges still limit the effective use of AI in strategic risk management, particularly for SMEs and resource-constrained sectors.</p><p>(1) Data Quality and Availability: Many organizations struggle with incomplete, fragmented, or poorly governed data. This weakens the reliability and accuracy of AI predictions [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>].</p><p>(2) Regulatory Compliance: Changing regulations such as the EU AI Act require ongoing updates to governance practices. This poses difficulties for organizations without strong legal or compliance capacity [<xref ref-type="bibr" rid="ref_15">15</xref>].</p><p>(3) Explainability and Transparency: Advanced AI models like deep learning or generative AI often operate as “black boxes.” Their lack of interpretability reduces stakeholder trust and makes regulatory approval more challenging [<xref ref-type="bibr" rid="ref_1">1</xref>].</p><p>(4) Shortage of Technical Expertise: Many firms lack the internal skills needed to design, maintain, and oversee AI systems, leading to a reliance on costly external consultants or technology partners [<xref ref-type="bibr" rid="ref_19">19</xref>].</p><p>(5) Security Vulnerabilities: AI systems face new security risks, including data poisoning or adversarial attacks, which require advanced safeguards not yet widely adopted [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>These challenges show that while academic research has identified essential components, it still falls short of offering a fully integrated and actionable roadmap, especially for organizations across different sectors or with limited resources.</p><p>To address this gap, <xref ref-type="table" rid="table_1">Table 1</xref> summarizes the main risk types along with practical mitigation strategies proposed in the literature:</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>AI risk types and mitigation strategies</title>
          </caption>
          <table><tbody><tr><th colspan="1" rowspan="1"><p>Risk Type</p></th><th colspan="1" rowspan="1"><p>Mitigation Strategy</p></th><th colspan="1" rowspan="1"><p>Source</p></th></tr><tr><td colspan="1" rowspan="1"><p>Data Quality Issues</p></td><td colspan="1" rowspan="1"><p>Implement robust data validation protocols</p></td><td colspan="1" rowspan="1"><p>Žigienė et al. (2022) [<xref ref-type="bibr" rid="ref_13">13</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Regulatory Non-Compliance</p></td><td colspan="1" rowspan="1"><p>Develop adaptive governance policies</p></td><td colspan="1" rowspan="1"><p>Novelli et al. (2023) [<xref ref-type="bibr" rid="ref_15">15</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Lack of Explainability</p></td><td colspan="1" rowspan="1"><p>Use explainable AI models for critical tasks</p></td><td colspan="1" rowspan="1"><p>Bussmann et al. (2020) [<xref ref-type="bibr" rid="ref_1">1</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Expertise Shortage</p></td><td colspan="1" rowspan="1"><p>Invest in workforce training and partnerships</p></td><td colspan="1" rowspan="1"><p>Ferrara (2024) [<xref ref-type="bibr" rid="ref_19">19</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Security Vulnerabilities</p></td><td colspan="1" rowspan="1"><p>Apply encryption and secure model deployment</p></td><td colspan="1" rowspan="1"><p>Habbal et al. (2024) [<xref ref-type="bibr" rid="ref_8">8</xref>]</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>Summary of Key Findings</p><p>This SLR shows that interest in using AI for strategic risk management has grown significantly. However, its real-world application is still uneven and fragmented. Key findings include:</p><p>(1) Rising Research Interest: From 2019 to 2025, there has been a steady increase in studies on AI in risk management, highlighting its importance for resilience and governance, especially in VUCA environments [<xref ref-type="bibr" rid="ref_4">4</xref>].</p><p>(2) Narrow Sector Focus: Most applications focus on finance and cybersecurity. Broader, cross-sector use, especially for SMEs, remains limited despite their high exposure to risk and lack of AI resources [<xref ref-type="bibr" rid="ref_6">6</xref>].</p><p>(3) Isolated Use of AI Capabilities: Different AI types (e.g., machine learning, deep learning, generative AI) offer unique strengths like accuracy, explainability, or adaptability. Yet, these are often used separately, not combined in an integrated way [<xref ref-type="bibr" rid="ref_5">5</xref>].</p><p>(4) Persistent Adoption Barriers: Poor data quality, regulatory uncertainty, lack of transparency, limited skills, and growing security risks continue to block effective use, especially in low-resource organizations like SMEs [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_15">15</xref>].</p><p>(5) Scattered Framework Components: Many studies refer to core elements like governance, risk assessment, and human oversight. But they are rarely unified into one practical, cross-sectoral model [<xref ref-type="bibr" rid="ref_8">8</xref>].</p><p>Together, these insights show the need for a clear, scalable framework that combines these elements into a single strategy especially one suited to SMEs. The framework proposed in the next section responds to this gap by offering a more practical, integrated solution that connects theory with implementation.</p>
    </sec>
    <sec sec-type="discussion">
      <title>5. Discussion</title>
      <p>This systematic review confirms that although the transformative potential of AI in strategic risk management is increasingly recognized, existing applications remain fragmented and heavily concentrated in sectors such as finance and cybersecurity [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>]. This narrow sectoral focus has left a significant gap in enterprise-wide, cross-sectoral approaches that integrate AI within strategic governance, especially for organizations operating in VUCA environments.</p><p>To address this shortfall, the present study proposes an original AI-Driven Strategic Risk Management Framework that unifies disparate insights from the literature into a scalable, practical structure. Unlike traditional models that are primarily technical, sector-specific, or limited to compliance, such as the NIST AI Risk Management Framework or the finance-oriented model by Bi and Bao [<xref ref-type="bibr" rid="ref_11">11</xref>], this framework integrates predictive, explanatory, and generative AI capabilities into a governance-driven system. It is designed to be flexible and adaptable across industries and organizational sizes, including SMEs with limited digital resources.</p>
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Proposed AI-driven strategic risk management framework</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/7/img_LAnIm8yLV9NqmVpO.png"/>
        </fig>
      
      <p> <xref ref-type="fig" rid="fig_5">Figure 5</xref> presents the proposed framework and its six interdependent components: Strategic governance, dynamic risk assessment, technical controls, human oversight, continuous improvement, and stakeholder engagement. Together, these components form a cohesive system that supports real-time risk identification, ethical oversight, and iterative improvement. Strategic Governance sets direction and boundaries for AI use, enabling proactive risk identification through Dynamic Risk Assessment. Technical Controls safeguard system integrity, while Human Oversight ensures transparency and accountability. Continuous Improvement uses feedback loops to adapt to evolving threats and technologies, and Stakeholder Engagement builds trust through open communication and inclusivity.</p><p> <xref ref-type="table" rid="table_2">Table 2</xref> further clarifies the strategic contributions of each component, illustrating how they collectively align AI adoption with organizational objectives, evolving regulatory requirements, and the expectations of key stakeholders. By providing a concise mapping between framework components and their strategic functions, <xref ref-type="table" rid="table_2">Table 2</xref> enhances understanding of how this model bridges AI capabilities with enterprise-wide governance and resilience goals.</p>
      
        <table-wrap id="table_2">
          <label>Table 2</label>
          <caption>
            <title>Framework components and strategic contributions</title>
          </caption>
          <table><tbody><tr><th colspan="1" rowspan="1"><p>Component</p></th><th colspan="1" rowspan="1"><p>Description</p></th><th colspan="1" rowspan="1"><p>Strategic Contribution</p></th><th colspan="1" rowspan="1"><p>Key References</p></th></tr><tr><td colspan="1" rowspan="1"><p>Strategic Governance</p></td><td colspan="1" rowspan="1"><p>Policies aligning AI with objectives and compliance</p></td><td colspan="1" rowspan="1"><p>Ensures regulatory alignment and strategic fit</p></td><td colspan="1" rowspan="1"><p>Novelli et al. (2024) [<xref ref-type="bibr" rid="ref_15">15</xref>]; Milojević &amp;amp; Redzepagic (2021) [<xref ref-type="bibr" rid="ref_14">14</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Dynamic Risk Assessment</p></td><td colspan="1" rowspan="1"><p>Real-time predictive risk identification</p></td><td colspan="1" rowspan="1"><p>Supports proactive threat anticipation and scenario planning</p></td><td colspan="1" rowspan="1"><p>Javaid (2024) [<xref ref-type="bibr" rid="ref_6">6</xref>]; Adeoye et al. (2024) [<xref ref-type="bibr" rid="ref_10">10</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Technical Controls</p></td><td colspan="1" rowspan="1"><p>Data validation, bias detection, and model auditing</p></td><td colspan="1" rowspan="1"><p>Enhances reliability and trustworthiness</p></td><td colspan="1" rowspan="1"><p>Habbal et al. (2024) [<xref ref-type="bibr" rid="ref_8">8</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Human Oversight</p></td><td colspan="1" rowspan="1"><p>Training, ethical guidelines, and human judgment integration</p></td><td colspan="1" rowspan="1"><p>Balances automation with human insights and accountability</p></td><td colspan="1" rowspan="1"><p>Ferrara (2024) [<xref ref-type="bibr" rid="ref_19">19</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Continuous Improvement</p></td><td colspan="1" rowspan="1"><p>Feedback loops and adaptive learning mechanisms</p></td><td colspan="1" rowspan="1"><p>Drives long-term resilience and refinement</p></td><td colspan="1" rowspan="1"><p>Caravannis et al. (2025) [<xref ref-type="bibr" rid="ref_4">4</xref>]</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stakeholder Engagement</p></td><td colspan="1" rowspan="1"><p>Transparent communication and accountability frameworks</p></td><td colspan="1" rowspan="1"><p>Builds stakeholder trust and mitigates reputational risks</p></td><td colspan="1" rowspan="1"><p>Bussmann et al. (2020) [<xref ref-type="bibr" rid="ref_1">1</xref>]</p></td></tr></tbody></table>
        </table-wrap>
      
      
        <sec>
          
            <title>5.1. Originality of the framework</title>
          
          <p>This study presents a new AI-driven framework for strategic risk management with three key advances:</p><p>• Integrated Approach: The framework brings together governance, technology, and human factors into a single, unified model. While previous studies often focus on one aspect or a specific industry, this framework offers a more complete and cross-sectoral roadmap.</p><p>• Balanced AI Capabilities: It combines the strengths of traditional machine learning, deep learning, and generative AI. This allows for better prediction, greater flexibility, and improved explainability, key features often missing when only one method is used.</p><p>• Practical and Scalable: The framework is flexible enough for large corporations but also suitable for SMEs, which often face resource and expertise limitations.</p>
        </sec>
      
      
        <sec>
          
            <title>5.2. Implications</title>
          
          
            <sec>
              
                <title>5.2.1 Theoretical implications</title>
              
              <p>This study extends several streams of strategic management and organizational theory:</p><p>• Decision-Making Theory: Demonstrates how AI mitigates human cognitive biases and enhances strategic sensemaking under high uncertainty.</p><p>• Resource-Based View: Positions AI not merely as a tool, but as a dynamic, data-driven capability that can reinforce sustained competitive advantage when embedded in robust governance and risk structures.</p><p>• Dynamic Capabilities Theory: Shows how AI strengthens an organization’s capacity to sense, seize, and transform in response to emerging threats, creating adaptive resilience.</p>
            </sec>
          
          
            <sec>
              
                <title>5.2.2 Practical implications</title>
              
              <p>For practitioners, the framework offers a clear, actionable roadmap to deploy AI as a strategic enabler of resilience and decision-making. Below, we outline practical steps for each component, with specific guidance for SMEs and metrics to evaluate success.</p><p>• Strategic Governance: Organizations should establish policies aligning AI with business objectives and regulations like the EU AI Act or OECD AI Principles. For SMEs, this could involve adopting open-source governance templates or partnering with compliance consultants to ensure regulatory fit. Key Performance Indicator (KPI): Percentage of AI initiatives compliant with regulatory standards (target: 100% compliance).</p><p>• Dynamic Risk Assessment: Use predictive analytics to identify risks in real time, such as supply chain disruptions or cybersecurity threats. SMEs can leverage affordable cloud-based tools like Google Cloud AI or Amazon SageMaker to implement predictive models. KPI: Reduction in time to detect critical risks (e.g., from weeks to hours).</p><p>• Technical Controls: Implement data validation, bias detection, and model auditing to ensure AI reliability. For example, SMEs can use open-source tools like TensorFlow Model Analysis to monitor bias in predictive models. KPI: Percentage of AI models audited for bias and accuracy (target: 100% quarterly audits).</p><p>• Human Oversight: Train staff on AI ethics and integrate human judgment to balance automation. SMEs can access free online courses (e.g., Coursera’s AI Ethics) to build basic AI literacy. KPI: Number of employees trained in AI ethics annually (target: at least 80% of relevant staff).</p><p>• Continuous Improvement: Use feedback loops to refine AI tools as risks evolve. SMEs can start with simple feedback mechanisms, like monthly reviews of AI predictions versus actual outcomes. KPI: Number of AI model updates based on feedback (target: at least one update per quarter).</p><p>• Stakeholder Engagement: Communicate AI strategies transparently to build trust with customers, regulators, and employees. SMEs can engage stakeholders through regular updates or public dashboards showing risk management progress. KPI: Stakeholder trust score, measured via surveys (target: 75% positive feedback).</p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>5.3. Practical guidance for smes: adopting the ai-based strategic risk management framework</title>
          
          <p>To support SMEs in adopting the proposed AI-Based Strategic Risk Management Framework, this section offers a step-by-step implementation guide tailored to resource-constrained environments. While SMEs may lack extensive technical infrastructure or specialized AI teams, they can still benefit from lightweight, affordable tools and incremental adoption strategies.</p><p> <xref ref-type="table" rid="table_3">Table 3</xref> provides practical actions, suggested free or low-cost tools, and KPIs for each of the six framework components. This structured approach enables SMEs to translate the framework into operational steps that improve strategic decision-making, resilience, and regulatory compliance.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Step-by-step implementation overview for SMEs</title>
              </caption>
              <table><tbody><tr><th colspan="1" rowspan="1"><p>Framework Component</p></th><th colspan="1" rowspan="1"><p>Key Actions for SMEs</p></th><th colspan="1" rowspan="1"><p>Suggested Tools (Free/Low Cost)</p></th><th colspan="1" rowspan="1"><p>SME KPIs</p></th></tr><tr><td colspan="1" rowspan="1"><p>Strategic Governance</p></td><td colspan="1" rowspan="1"><p>Draft a lightweight AI use policy aligned with business goals and basic regulations</p></td><td colspan="1" rowspan="1"><p>OECD AI templates, NIST AI RMF</p></td><td colspan="1" rowspan="1"><p>% of AI activities compliant with legal/ethical standards</p></td></tr><tr><td colspan="1" rowspan="1"><p>Dynamic Risk Assessment</p></td><td colspan="1" rowspan="1"><p>Identify key strategic risks and apply pre-built predictive models to existing data</p></td><td colspan="1" rowspan="1"><p>Google Cloud AI, Azure AI, Amazon SageMaker</p></td><td colspan="1" rowspan="1"><p>Time reduction in detecting critical risks</p></td></tr><tr><td colspan="1" rowspan="1"><p>Technical Controls</p></td><td colspan="1" rowspan="1"><p>Clean datasets, audit models for bias, and validate outputs regularly</p></td><td colspan="1" rowspan="1"><p>OpenRefine, Fairlearn, TensorFlow Model Analysis</p></td><td colspan="1" rowspan="1"><p>% of models audited for bias/security quarterly</p></td></tr><tr><td colspan="1" rowspan="1"><p>Human Oversight</p></td><td colspan="1" rowspan="1"><p>Train key staff on AI basics and assign decision-review responsibilities</p></td><td colspan="1" rowspan="1"><p>Google's AI for Everyone, Coursera (AI Ethics)</p></td><td colspan="1" rowspan="1"><p>% of relevant staff trained in AI oversight</p></td></tr><tr><td colspan="1" rowspan="1"><p>Continuous Improvement</p></td><td colspan="1" rowspan="1"><p>Establish monthly feedback reviews to refine AI tools based on outcomes</p></td><td colspan="1" rowspan="1"><p>Google Data Studio, Power BI, SageMaker, retraining tools</p></td><td colspan="1" rowspan="1"><p>Frequency of model updates and performance tuning</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stakeholder Engagement</p></td><td colspan="1" rowspan="1"><p>Communicate AI-related practices to stakeholders through transparent channels</p></td><td colspan="1" rowspan="1"><p>Google Forms, Slack, Mailchimp</p></td><td colspan="1" rowspan="1"><p>Stakeholder trust score via periodic surveys</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>5.4. Limitations and directions for future research</title>
          
          <p>While the proposed framework offers theoretical depth and integrative innovation, several limitations suggest directions for future research and practical refinement:</p><p>(1) Sectoral Concentration</p><p>The current review draws heavily from finance and cybersecurity domains, where AI applications in risk management are most mature. This focus may limit the framework’s immediate generalizability to other sectors such as manufacturing, public services, or healthcare. Future studies should apply and evaluate the framework in these underexplored sectors using comparative case studies to test its adaptability and effectiveness in diverse operational contexts.</p><p>(2) Emerging AI Developments</p><p>The review covers literature up to 2025, and may not fully capture the most recent advancements in hybrid intelligence systems or advanced generative AI tools. As AI technologies evolve rapidly, ongoing research should focus on updating the framework to reflect these technological shifts, ensuring its continued relevance and strategic value.</p><p>(3) Lack of Empirical Validation</p><p>While the proposed framework is grounded in a robust synthesis of the existing literature, it remains conceptual at this stage. To enhance its practical relevance and credibility, empirical validation is a necessary next step. Future research should aim to pilot the framework in real-world organizational settings—particularly in high-risk industries and SMEs. Suitable methodologies may include mixed-method approaches, combining qualitative interviews with practitioners, quantitative surveys across diverse sectors, and performance metric analyses. Such evaluations could assess outcomes like reductions in risk exposure, improvements in scenario planning effectiveness, and faster detection of emerging threats. These validation efforts will be essential in translating the framework from a theoretical contribution into a practical tool for strategic decision-making and organizational resilience.</p><p>Future research should therefore empirically validate the framework in underexplored areas like public administration, sustainability risks, and SME governance, while also deepening the examination of ethical dimensions such as bias mitigation and algorithmic accountability to promote responsible AI adoption.</p>
        </sec>
      
    </sec>
    <sec sec-type="conclusions">
      <title>6. Conclusions</title>
      <p>This study presents an original AI-based strategic risk management framework, developed through a rigorous SLR covering research published between 2019 and 2025. The proposed framework integrates six interdependent components - Strategic Governance, Dynamic Risk Assessment, Technical Controls, Human Oversight, Continuous Improvement, and Stakeholder Engagement - to support proactive, data-driven decision-making in VUCA environments.</p><p>Unlike existing sector-specific or technically focused models, this framework offers cross-sectoral relevance and practical scalability, particularly for SMEs that often lack the resources to implement advanced AI governance systems. By bridging fragmented approaches and aligning AI capabilities with enterprise-wide goals, the framework responds to growing demands for more holistic and responsible AI integration in risk governance.</p><p>The study also contributes to strategic management theory by enhancing decision-making theory through AI-enabled bias reduction, extending the resource-based view by framing AI as a dynamic capability, and reinforcing dynamic capabilities theory by enabling organizations to sense, seize, and adapt in response to emerging risks.</p><p>Despite its conceptual strength, the study acknowledges certain limitations, including a focus on finance-sector literature and the absence of empirical validation. Nonetheless, it lays a solid foundation for future research. Subsequent studies should empirically test and refine the framework across various industries, regions, and regulatory environments, with particular attention to SME adoption and ethical AI governance.</p><p>Ultimately, this framework offers actionable guidance for organizations aiming to harness AI’s transformative power to strengthen strategic resilience, improve decision-making, and build stakeholder trust, laying the groundwork for more agile, robust, and ethically grounded risk management in an increasingly complex world.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>26</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bussmann</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Giudici</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Marinelli</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Papenbrock</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/frai.2020.00026</pub-id>
          <article-title>Explainable AI in fintech risk management</article-title>
          <source>Front. Artif. Intell.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>29-45</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kalisetty</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pandugula</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Mallesham</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.31586/jaibd.2023.1202</pub-id>
          <article-title>Leveraging artificial intelligence to enhance supply chain resilience: A study of predictive analytics and risk mitigation strategies</article-title>
          <source>J. Artif. Intell. Big Data</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Biloslavo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Edgar</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Aydin</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Bulut</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1108/MD-10-2023-1944</pub-id>
          <article-title>Artificial intelligence (AI) and strategic planning process within VUCA environments: A research agenda and guidelines</article-title>
          <source>Manag. Decis.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>81</volume>
          <page-range>102835</page-range>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Carayannis</surname>
              <given-names>E. G.</given-names>
            </name>
            <name>
              <surname>Dumitrescu</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Falkowski</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Papamichail</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Zota</surname>
              <given-names>N. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.techsoc.2025.102835</pub-id>
          <article-title>Enhancing SME resilience through artificial intelligence and strategic foresight: A framework for sustainable competitiveness</article-title>
          <source>Technol. Soc.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>66</volume>
          <page-range>111-126</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Feuerriegel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Hartmann</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Janiesch</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>et al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s12599-023-00834-7</pub-id>
          <article-title>Generative AI</article-title>
          <source>Bus. Inf. Syst. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>204</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Javaid</surname>
              <given-names>H. A.</given-names>
            </name>
          </person-group>
          <article-title>AI-driven predictive analytics in finance: Transforming risk assessment and decision-making</article-title>
          <source>Adv. Comput. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>66</page-range>
          <issue>2</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>López-Solís</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Luzuriaga-Jaramillo</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bedoya-Jara</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Naranjo-Santamaría</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bonilla-Jurado</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Acosta-Vargas</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/admsci15020066</pub-id>
          <article-title>Effect of generative artificial intelligence on strategic decision-making in entrepreneurial business initiatives: A systematic literature review</article-title>
          <source>Adm. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>240</volume>
          <page-range>122442</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Habbal</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>M. K.</given-names>
            </name>
            <name>
              <surname>Abuzaraida</surname>
              <given-names>M. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.eswa.2023.122442</pub-id>
          <article-title>Artificial intelligence trust, risk and security management (AI TRiSM): Frameworks, applications, challenges and future research directions</article-title>
          <source>Expert Syst. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>56</volume>
          <page-range>12799-12831</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Stahl</surname>
              <given-names>B. C.</given-names>
            </name>
            <name>
              <surname>Antoniou</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bhalla</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>et al.</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10462-023-10420-8</pub-id>
          <article-title>A systematic review of artificial intelligence impact assessments</article-title>
          <source>Artif. Intell. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>1-22</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Adeoye</surname>
              <given-names>T. A.</given-names>
            </name>
            <name>
              <surname>Olisakwe</surname>
              <given-names>H. C.</given-names>
            </name>
            <name>
              <surname>Adebayo</surname>
              <given-names>Y. A.</given-names>
            </name>
            <name>
              <surname>Esiri</surname>
              <given-names>A. E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.57219/crret.2024.2.1.0059</pub-id>
          <article-title>AI-driven HSE management systems for risk mitigation in the oil and gas industry</article-title>
          <source>Compr. Res. Rev. Eng. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>76-81</page-range>
          <issue>3</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bi</surname>
              <given-names>Sheng</given-names>
            </name>
            <name>
              <surname>Bao</surname>
              <given-names>Wei</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.62051/ijgem.v2n3.08</pub-id>
          <article-title>Innovative application of artificial intelligence technology in bank credit risk management</article-title>
          <source>Int. J. Glob. Econ. Manag.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>186</volume>
          <page-range>109714</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kassa</surname>
              <given-names>Amanuel</given-names>
            </name>
            <name>
              <surname>Kitaw</surname>
              <given-names>Daniel</given-names>
            </name>
            <name>
              <surname>Stache</surname>
              <given-names>Ulrich</given-names>
            </name>
            <name>
              <surname>Beshah</surname>
              <given-names>Berhanu</given-names>
            </name>
            <name>
              <surname>Degefu</surname>
              <given-names>Getachew</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.cie.2023.109714</pub-id>
          <article-title>Artificial intelligence techniques for enhancing supply chain resilience: A systematic literature review, holistic framework, and future research</article-title>
          <source>Comput. Ind. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>11827</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Žigienė</surname>
              <given-names>Greta</given-names>
            </name>
            <name>
              <surname>Rybakovas</surname>
              <given-names>Evaldas</given-names>
            </name>
            <name>
              <surname>Vaitkienė</surname>
              <given-names>Rasa</given-names>
            </name>
            <name>
              <surname>Gaidelys</surname>
              <given-names>Vaidas</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/su141911827</pub-id>
          <article-title>Setting the grounds for the transition from business analytics to artificial intelligence in solving supply chain risk</article-title>
          <source>Sustainability</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>41-57</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Milojević</surname>
              <given-names>Nemanja</given-names>
            </name>
            <name>
              <surname>Redzepagic</surname>
              <given-names>Srdjan</given-names>
            </name>
          </person-group>
          <article-title>Prospects of artificial intelligence and machine learning application in banking risk management</article-title>
          <source>J. Cent. Bank. Theory Pract.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>39</volume>
          <page-range>2493-2497</page-range>
          <issue>5</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Novelli</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Casolari</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Rotolo</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Taddeo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Floridi</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Taking AI risks seriously: A new assessment model for the AI act</article-title>
          <source>AI &amp; Soc.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>128-145</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Maghfirah</surname>
              <given-names>Putri</given-names>
            </name>
            <name>
              <surname>Eni</surname>
              <given-names>Yulinda</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.35409/ijbmer.2024.3584</pub-id>
          <article-title>The impact of artificial intelligence (AI) adoption on the productivity of small and medium enterprises (SMEs) industries in Indonesia: High cost, lack of knowledge, and inadequate infrastructure as mediation variables</article-title>
          <source>Int. J. Bus. Manag. Econ. Rev.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kopperapu</surname>
              <given-names>Ramesh</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2139/ssrn.5104927</pub-id>
          <article-title>Harnessing AI and machine learning for enhanced fraud detection and risk management in financial services</article-title>
          <source>SSRN</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Montealegre-López</surname>
              <given-names>Natalia</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11301-025-00526-4</pub-id>
          <article-title>Exploring the role of trust in AI-driven decision-making: A systematic literature review</article-title>
          <source>Manag. Rev. Q.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>3</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ferrara</surname>
              <given-names>Emilio</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/sci6010003</pub-id>
          <article-title>Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies</article-title>
          <source>Sci</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>235</volume>
          <page-range>121220</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Giudici</surname>
              <given-names>Paolo</given-names>
            </name>
            <name>
              <surname>Centurelli</surname>
              <given-names>Marco</given-names>
            </name>
            <name>
              <surname>Turchetta</surname>
              <given-names>Simone</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.eswa.2023.121220</pub-id>
          <article-title>Artificial intelligence risk measurement</article-title>
          <source>Expert Syst. Appl.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>