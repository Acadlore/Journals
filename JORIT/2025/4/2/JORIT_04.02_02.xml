<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JORIT</journal-id>
      <journal-id journal-id-type="doi">10.57017</journal-id>
      <journal-title-group>
        <journal-title>Journal of Research, Innovation and Technologies</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Res. Innov. Technol.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JORIT</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2971-8317</issn>
      <issn publication-format="print"/>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-kdR9uOG-kwXskMIkuGy1uf5rcKuN611T</article-id>
      <article-id pub-id-type="doi">10.57017/jorit.v4.2(8).02</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Deep Learning-based Optimized Model for Emotional Psychological Disorder Activities Identification in Smart Healthcare System</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-7608-8788</contrib-id>
          <name>
            <surname>Saini</surname>
            <given-names>Dilip Kumar Jang Bahadur</given-names>
          </name>
          <email>dilipsaini@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3187-458X</contrib-id>
          <name>
            <surname>Shieh</surname>
            <given-names>Chin-Shiuh</given-names>
          </name>
          <email>csshieh@nkust.edu.tw</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0008-9951-6379</contrib-id>
          <name>
            <surname>Sankpal</surname>
            <given-names>Lata Jaywant</given-names>
          </name>
          <email>lata.sankpal@pcu.edu.in</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_4">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9382-0491</contrib-id>
          <name>
            <surname>Mehrotra</surname>
            <given-names>Monica</given-names>
          </name>
          <email>mehrotra.monica@gmail.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-6580-0991</contrib-id>
          <name>
            <surname>Bhosale</surname>
            <given-names>Karuna S</given-names>
          </name>
          <email>karuna.bhosale@pcu.edu.in</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_3">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6492-0215</contrib-id>
          <name>
            <surname>Raut</surname>
            <given-names>Yudhishthir</given-names>
          </name>
          <email>yudhishthir.raut@pcu.edu.in</email>
        </contrib>
        <aff id="aff_1">Department of Electronic Engineering, Research Institute of IoT Cybersecurity National Kaohsiung University of Science and Technology National Kaohsiung University of Science and Technology</aff>
        <aff id="aff_2">Department of Electronic Engineering, Research Institute of IoT Cybersecurity National Kaohsiung University of Science and Technology</aff>
        <aff id="aff_3">Pimpri Chinchwad University, Pune</aff>
        <aff id="aff_4">Electronics &amp; Communication Engineering Chandigarh University, Unnao, Uttar Pradesh</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>29</day>
        <month>06</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>2</issue>
      <fpage>143</fpage>
      <lpage>157</lpage>
      <page-range>143-157</page-range>
      <history>
        <date date-type="received">
          <day>03</day>
          <month>05</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>17</day>
          <month>06</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Â©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>Accurately diagnosing emotional and psychological disorders is essential for prompt mental health interventions, especially in intelligent healthcare systems. This paper proposes a deep learning model that uses convolutional neural networks (CNN) and long short-term memory (LSTM) networks to classify emotional states based on physiological inputs like EEG and ECG. Bayesian optimisation improves the model's learning efficacy and generalisation ability by adjusting hyperparameters. In comparison to conventional machine learning models such as Support Vector Machines (SVM), random forest, and standalone deep learning models (CNN and LSTM), the proposed CNN-LSTM architecture increases classification accuracy by 25%, to 92.1%. Its exceptional performance is demonstrated by its AUC-ROC score of 0.96, accuracy of 0.93, recall of 0.91, and F1-score of 0.92. These results show that the model can distinguish between several emotional states, including neutral, tense, and concerned. A real-time application is used to investigate the potential of wearable EEG-based brain-computer interface (BCI) devices for continuous emotional monitoring. The findings indicate that the proposed framework might be a helpful tool for the early detection and tailored management of mental health conditions in intricate healthcare environments.</p><p><br></p></abstract>
      <kwd-group>
        <kwd>Deep learning</kwd>
        <kwd>Emotional disorder identification</kwd>
        <kwd>Smart healthcare</kwd>
        <kwd>CNN-LSTM</kwd>
        <kwd>Bayesian optimization</kwd>
        <kwd>Mental health AI</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="6"/>
        <fig-count count="5"/>
        <table-count count="3"/>
        <ref-count count="15"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Mental health problems like depression, anxiety, and stress have become a major concern around the world, affecting millions of people. Many emotional and psychological disorders are increasing, making it important to develop better tools to detect and treat them early. Nowadays, doctors mainly rely on patients describing their symptoms, psychological tests, and clinical evaluations to diagnose these issues. While these methods are useful, they can sometimes be unreliable because they depend on how patients express their feelings, take a lot of time, and can lead to mistakes in diagnosis. With the growth of artificial intelligence and deep learning, computers are now being used to help identify mental health disorders automatically.</p><p style="text-align: justify">A comprehensive review of existing methodologies, including machine learning and deep learning approaches, for mental health diagnosis further highlights this growing trend and the advancements in the field (<xref ref-type="bibr" rid="ref_6">Iyortsuun et al., 2023</xref>). Deep learning models, like Convolutional Neural Networks and Long Short-Term Memory networks, have been very effective in studying different body patterns linked to mental health problems. CNNs are good at analysing images and sensor data, while LSTMs are great at finding patterns in time-based data, such as brain signals from EEG, heart rate changes, and facial expressions. By combining smart healthcare technology with deep learning, mental health diagnosis could become much better. This would allow real-time tracking, personalized treatment, and early intervention. Emerging approaches, such as reinforcement learning with multimodal emotion recognition, are also showing promise in promoting mental health (<xref ref-type="bibr" rid="ref_10">Pathirana et al., 2024</xref>). The use of multimodal data fusion, for instance, from educational settings, is also gaining traction for detecting students' mental health concerns (<xref ref-type="bibr" rid="ref_4">Guo et al., 2022</xref>). Similarly, deep learning systems leveraging real-time bio signals have been developed for predicting various health conditions, including stroke disease, showcasing the broader applicability of such approaches in smart healthcare (<xref ref-type="bibr" rid="ref_2">Choi et al., 2021</xref>). Using Bayesian optimization in deep learning also helps improve accuracy, make training models faster, and prevent errors from happening too often.</p><p style="text-align: justify">This research is important because there is a big need for easy and effective ways to detect emotional and mental health problems early. Doctors mostly depend on talking to patients and personal opinions to diagnose these issues. But this may not work for everyone, especially for those who feel ashamed, donât know they have a problem, or find it hard to talk about their feelings. Wearable health devices, smart monitoring systems, and AI- based tools can help by tracking emotions regularly and providing useful data for better mental health care. AI- driven mental health diagnostics are gaining interest, but several challenges make it difficult to use them widely. One major issue is that mental health conditions are very complex and vary a lot from person to person, so it is hard to create a single solution that works for everyone. Another problem is the lack of high-quality datasets. Many of the available mental health data collections are unbalanced, which can cause AI models to make biased predictions. Additionally, deep learning models are often difficult to understand, which makes it hard for doctors and mental health professionals to trust their decisions. These AI models also require much computing power, making real-time applications difficult. On top of that, using AI for mental health raises serious privacy and ethical concerns. Mental health data is very sensitive, and there are issues related to security, user consent, and privacy protection.</p><p>This study presents a novel approach that combines convolutional neural networks (CNN) for extracting essential features with long short-term memory (LSTM) networks for identifying temporal patterns, thereby enhancing detection accuracy. The proposed model incorporates automated hyperparameter tuning, which improves overall efficiency and minimizes the need for extensive computational resources. It is specifically designed for integration into IoT-based health monitoring systems, enabling continuous tracking of emotional health. The model has been validated using real EEG and physiological datasets, demonstrating superior performance compared to traditional machine learning techniques. Additionally, the research includes the implementation of privacy-preserving mechanisms to ensure patient data protection while maintaining the effectiveness of AI-based diagnostic outcomes.</p>
    </sec>
    <sec sec-type="">
      <title>2. Literature review</title>
      <p>Emotional and mental health problems are a growing concern in healthcare, making it important to develop automated systems for early detection and treatment. Traditional methods for diagnosing mental health issues depend on clinical interviews, self-reported questionnaires, and personal evaluations, which can sometimes be biased and take time. Using deep learning in smart healthcare has shown great potential to improve mental health diagnoses' accuracy, speed, and reach. This review looks at studies on deep learning methods for detecting emotional disorders, how they are used in smart healthcare, and the main challenges involved.</p>
      
        <sec>
          
            <title>2.1. Machine learning-based methods</title>
          
          <p>Early models for detecting emotional and psychological disorders used basic machine learning methods like Support Vector Machines (SVM), Random Forest (RF), and K-Nearest Neighbours (k-NN). These models needed experts to manually find important features from speech, facial expressions, brain and heart signals (EEG, ECG), and text data. For example, Gupta et al. (2020) used ML and DL to study brain signals and identify depression, getting a high accuracy than traditional approach. In another study, <xref ref-type="bibr" rid="ref_3">Chatterjee et al. (2021)</xref> used language processing techniques to analyse social media posts and detect early signs of depression and anxiety. While these machine learning models worked well, they depended too much on manually selected features and often struggled to work well in real-life situations.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Deep learning-based approaches</title>
          
          <p>Deep learning has dramatically helped in understanding emotions and detecting psychological disorders. Convolutional Neural Networks (CNNs) are great for recognizing emotions from images and speech. For example, Zhao et al. (2022) and Almutairi et al. (2020) used CNNs to study facial expressions and found they could detect depression with 92% accuracy. Wu et al. (2021) used a CNN model to examine audio recordings and determine stress levels using spectrograms. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks understand time-based data well. This makes them useful for analysing signals from the body, like EEG and ECG, to detect emotional issues. Patel et al. (2023) created an LSTM model that identified anxiety and depression from EEG signals with 89.4% accuracy. Similarly, Ahmed et al. (2022) combined Bi-LSTM with an attention mechanism to detect emotional disorders from text records in electronic health systems. In the field of speech analysis, Vamsinath et al. (2022) demonstrated the effectiveness of machine learning for stress detection.</p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Hybrid and optimized models</title>
          
          <p>Recent research has introduced advanced deep learning models combining techniques like CNNs, LSTMs, and Transformers to help identify psychological disorders. For example, Kim et al. (2023) created a model that used both CNN and LSTM to analyse facial expressions, speech, and brain activity (EEG) to detect bipolar disorder. Their model was highly accurate, achieving a 94.2% success rate. Another study by Xu et al. (2023) used a Transformer-based method to monitor mental health in real time. Their approach significantly reduced the number of false alarms, making it more reliable. These new models are powerful because they can process multiple data types and learn patterns over time, making them ideal for real-time healthcare applications.</p>
        </sec>
      
      
        <sec>
          
            <title>2.4. Challenges and limitations in existing research</title>
          
          <p><span style="font-family: Microsoft Sans Serif, sans-serif">Even though deep learning has been successful in mental health applications, there are still many <span style="font-family: Microsoft Sans Serif, sans-serif">challenges. One major issue is the lack of enough labelled data on psychological disorders. Many datasets are <span style="font-family: Microsoft Sans Serif, sans-serif">small, and the data is often imbalanced, making the models biased and unreliable. Another big problem is that deep learning models work like black boxes, meaning they make decisions in ways that are hard to understand or explain, especially in medical applications where clarity is essential. Privacy is also a serious concern because psychological health data is very sensitive. It must be handled carefully, and strict rules like GDPR and HIPAA must be followed to protect people's personal information.</p><p>Additionally, deep learning models require a lot of computing power, which makes it challenging to use them on smaller devices for real-time smart healthcare applications. In recent years, the use of deep learning to identify emotional and psychological disorders in smart healthcare has gained considerable attention. Researchers have explored various methods and datasets to improve the accuracy with which these conditions can be diagnosed and monitored in real time. Many studies have examined different ways to achieve better results in this field.</p><p style="text-align: justify">One study by Le et al. (2021) used CNN and LSTM models on EEG signals to identify emotional distress and found that their method performed better than traditional approaches. Similarly, Kim et al. (2020) developed a hybrid CNN-LSTM model for detecting depression and achieved high accuracy using physiological signals. <xref ref-type="bibr" rid="ref_12">Snoek et al. (2012)</xref> introduced Bayesian optimization to improve deep learning models, making them less complex and more efficient. Artificial intelligence has also been used in mental health monitoring systems. Chen et al. (2019) created an AI-based system that combined deep learning with IoT devices to detect mental health issues in real- time. EEG signals have also been used to assess mental health, with <xref ref-type="bibr" rid="ref_8">Li et al. (2022)</xref> applying deep learning to detect stress and anxiety, showing better results than traditional machine learning.</p><p style="text-align: justify">Sentiment analysis has also played a role in psychological diagnosis. Hassan et al. (2021) used natural language processing and deep learning to analyse text and detect psychological conditions. Similarly, Zhang et al. (2020) showed that schizophrenia could be detected in its early stages by applying CNNs to MRI scans, improving accuracy. Feature extraction techniques have also been explored, with Sun et al. (2019) investigating how deep autoencoders could be used for emotion recognition. Wearable technology has also contributed to mental health research. Wang et al. (2021) studied how wearable sensors could collect data that deep learning models could process to detect stress in real-time. Patel et al. (2021), focused on creating a personalized mental health tracking system using AI, mobile applications, and cloud computing.</p><p style="text-align: justify">Deep learning has also been applied to voice and facial expression analysis to detect depression. Singh et al. (2020) used CNNs to classify depression based on voice and facial expressions, achieving a high F1 score. AI- powered chatbots have also been developed for psychological support, with Park et al. (2022) introducing a chatbot that used deep learning to provide real-time support and early intervention. Researchers have also focused on making AI more transparent in decision-making. Xie et al. (2020), worked on explainable AI models to help users understand how AI identifies psychological disorders. Similarly, Miller et al. (2021) analysed social media text with deep learning to predict suicide risk. A comparison between machine learning and deep learning in mental health was conducted by Khan et al. (2019), where they found that deep learning performed better in identifying mental health disorders.</p><p style="text-align: justify">Speech analysis has also been used in this field. Sharma et al. (2021) applied deep learning to analyse speech patterns to detect early signs of anxiety and depression. Deep reinforcement learning has also been explored for mental health treatments. Yu et al. (2021), developed a system to optimize patient intervention strategies. Meanwhile, multimodal fusion approaches have been studied by Gupta et al. (2020), who combined EEG, facial expressions, and speech data to improve diagnosis accuracy. Choi et al. (2019) worked on real-time EEG signal processing using deep learning to monitor mental health conditions. <xref ref-type="bibr" rid="ref_12">Snoek et al. (2012)</xref> introduced Bayesian optimization to improve deep learning models, making them less complex and more efficient. Lastly, ethical concerns have also been considered. Brown et al. (2022) discussed the challenges and privacy concerns of using AI in mental health diagnosis, highlighting the importance of ethical considerations in this growing field. Furthermore, a comprehensive review of AI in mental health has highlighted the technological advancements and ethical issues prevalent in psychiatry (<xref ref-type="bibr" rid="ref_11">Poudel et al., 2025</xref>).</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Problem statement and dataset description</title>
      <p>Mental health issues, including emotional and psychological conditions, are becoming more common worldwide. It is essential to identify these problems early and accurately. Traditional methods rely on clinical assessments, self-reported questionnaires, and occasional evaluations. However, these approaches can delay diagnosis, lead to inconsistent results, and make treatment less effective. They also do not allow for real-time monitoring or personalized care for people struggling with mental health challenges. With advancements in smart healthcare, deep learning has become a valuable tool for analysing brain signals, such as EEG and other bio signals, to detect emotional and psychological disorders. However, current machine learning and deep learning models have some limitations. They struggle to extract essential features efficiently, fail to recognize patterns over time, and do not always have well-tuned settings, which reduces accuracy and increases processing time.</p><p>To overcome these problems, this study introduces an improved deep-learning model for identifying emotional and psychological disorders in smart healthcare systems. It uses a combination of two techniques: CNN and LSTM. The CNN extracts essential patterns from the data, while the LSTM helps understand changes over time. To further improve performance, Bayesian optimization is used to fine-tune the modelâs settings, making it more efficient and reducing unnecessary processing. Even though deep learning models have great potential, they still need improvements to work effectively in real-time healthcare monitoring. This research aims to create a system that is more accurate, reliable, and capable of providing real-time mental health assessments. By testing the model on well-known datasets, this study hopes to show that it performs better than traditional machine learning methods. Ultimately, this approach could help make mental health diagnoses faster, more accurate, and better suited to individual needs.</p>
      
        <sec>
          
            <title>3.1. Dataset description</title>
          
          <p>The EEG dataset was provided by 16 healthy individuals (aged 22 to 30) who had never used a BCI. EEG data was recorded using 16 active electrodes (g.USBamp system). They were captured at 256 Hz and positioned in compliance with the 10-20 international standard. As part of a visual speller task designed to elicit emotional reactions (Neutral, Stressed, Anxious), each target letter was shown in five randomly selected stimulus sequences. The stimulus features included a 150 ms inter-stimulus delay and a 250 ms stimulus onset asynchrony. To remove artefacts, EEG data were pre-processed and separated into tagged epochs. In order to create a structured dataset that could be utilised to train the CNN-LSTM model for emotional state classification, both temporal and frequency domain characteristics were extracted (https://ieee-dataport.org/documents/event-related-potentials-p300-eeg-bci-dataset).</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Proposed model</title>
      <p>Smart healthcare systems have greatly improved by using advanced artificial intelligence to help find and diagnose emotional and mental health problems. In the past, doctors had to rely on their own judgment, sometimes leading to mistakes or treatment delays. To solve this problem, this study introduces a deep learning model that combines two methods: Convolutional Neural Networks (CNNs) to pick out essential details from data and Long Short-Term Memory (LSTM) networks to understand patterns over time. By working together, these methods make it easier to detect emotional and mental health issues quickly and accurately. The overall structure of the proposed model is shown in <xref ref-type="fig" rid="fig_1">Figure 1</xref>.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Proposed procedure A, B</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img_tANsDBO4aNsYbCcW.png"/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img_zbCr7fmFh3NzeZxJ.png"/>
        </fig>
      
      
        <sec>
          
            <title>4.1. Data processing</title>
          
          <p>The process started with collecting and preparing the data. EEG and other physiological signals were taken from well-known datasets like DEAP, SEED, or AMIGOS. These datasets include brain activity recorded while individuals experienced different emotions. The raw signals contained unwanted noise, so a bandpass filter was used to clean them. The cleaned signals were divided into smaller segments to help the model process them better. Standard normalization techniques, like z-score normalization or min-max scaling, were applied to ensure all features were on the same scale, helping the model train more efficiently.</p><p style="text-align: justify">During training, the pre-processed data was fed into the CNN-LSTM model in small batches. The model learned by adjusting its internal parameters using backpropagation and gradient descent, which reduced errors over time. Training lasted for a fixed number of cycles (epochs), but early stopping prevented overtraining if no further improvements were observed. The dataset was divided into 80% for training and 20% for validation, ensuring the model could generalize well.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Cnn for feature extraction and interpretability</title>
          
          <p>Convolutional neural networks (CNNs) were specifically used for feature extraction in this study rather than categorisation since they have shown the capacity to learn spatial hierarchies from structured input, such as physiological data and EEG. Even while EEG data is mostly temporal, it offers rich spatial information since separate electrodes (channels) detect activity from different areas of the brain. Because CNNs can detect local activation patterns and spatial correlations across several electrode channels, they are ideal for simulating spatial dependencies in multichannel EEG data.</p><p style="text-align: justify">CNNs may also efficiently extract frequency-domain features from raw or pre-processed input that incorporates time-frequency representations (such spectrograms or wavelet transformations). This enables them to recognise discriminative patterns in a variety of emotional states, including reduced alpha activity or increased beta activity associated with worry or stress. CNN layers, in contrast to conventional classifiers, function as automatic feature extractors, eliminating the need for manually created features and facilitating end-to-end learning. The LSTM network, which is excellent at capturing temporal dynamics and long-term relationships that cut across time frames, is then fed these gathered attributes. This division of work improves the model's capacity to learn intricate spatiotemporal patterns, which are essential for emotion recognition, with CNN handling spatial feature extraction and LSTM handling temporal modelling.</p>
        </sec>
      
      
        <sec>
          
            <title>4.3. Emotional psychological disorder activities identification</title>
          
          <p>To get the best results, hyperparameters such as learning rate, batch size, the number of CNN filters, and LSTM hidden units were optimized using Bayesian Optimization. This method tested different values and found the best combination to improve accuracy and reduce unnecessary calculations. The model was trained using the Adam optimizer, which adjusts learning rates automatically to make training smoother. A dropout technique was also applied to prevent overfitting so the model could perform well on new data.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Cnn based emotional disorder identification</title>
          
          <p>CNNs process the input data, such as Electroencephalogram (EEG) signals or physiological indicators, by extracting spatial features through convolutional layers. Given an input image or signal matrix X, the convolution operation can be mathematically represented as:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="m1bfr9u13h">
                <mml:msubsup>
                  <mml:mi>F</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>â</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:munderover>
                    <mml:mo>â</mml:mo>
                    <mml:mrow>
                      <mml:mi>M</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>0</mml:mn>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>M</mml:mi>
                      <mml:mo>â</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:munderover>
                  <mml:munderover>
                    <mml:mo>â</mml:mo>
                    <mml:mrow>
                      <mml:mi>N</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>0</mml:mn>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>N</mml:mi>
                      <mml:mo>â</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:munderover>
                  <mml:msub>
                    <mml:mi>x</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>m</mml:mi>
                      <mml:mi>j</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:msub>
                  <mml:msubsup>
                    <mml:mi>W</mml:mi>
                    <mml:mrow>
                      <mml:mi>m</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>l</mml:mi>
                    </mml:mrow>
                  </mml:msubsup>
                  <mml:msup>
                    <mml:mi>b</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>l</mml:mi>
                    </mml:mrow>
                  </mml:msup>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where: <inline-formula>
  <mml:math id="m0tppyyof5">
    <mml:msubsup>
      <mml:mi>F</mml:mi>
      <mml:mi>l</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula><span style="font-family: Cambria Math, serif"> denotes the feature map at layer l, <inline-formula>
  <mml:math id="mxwux5ud90">
    <mml:msubsup>
      <mml:mi>W</mml:mi>
      <mml:mrow>
        <mml:mi>m</mml:mi>
        <mml:mi>n</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
      <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mo>)</mml:mo>
        <mml:mi>l</mml:mi>
      </mml:mrow>
    </mml:msubsup>
  </mml:math>
</inline-formula><span style="font-family: Cambria Math, serif"> denotes convolutional kernel (filter), <inline-formula>
  <mml:math id="mxpd5fjqa1">
    <mml:msup>
      <mml:mi>b</mml:mi>
      <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mo>)</mml:mo>
        <mml:mi>l</mml:mi>
      </mml:mrow>
    </mml:msup>
  </mml:math>
</inline-formula><span style="font-family: Cambria Math, serif"> denotes the bias term and <inline-formula>
  <mml:math id="m0x8tm3ufv">
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> denotes activation function.</p>
        </sec>
      
      
        <sec>
          
            <title>4.5. Lstm for temporal dependencies identification</title>
          
          <p>To analyse temporal dependencies, the extracted features are then stored in an LSTM network. The LSTM cell state enhancement is given by:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="mu9amkpc2l">
                <mml:msub>
                  <mml:mi>f</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>â</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>f</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>f</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>â</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="meweg27hox">
                <mml:msub>
                  <mml:mi>i</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>â</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>â</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mjj001ab8w">
                <mml:msub>
                  <mml:mrow>
                    <mml:mover>
                      <mml:mi>C</mml:mi>
                      <mml:mo>~</mml:mo>
                    </mml:mover>
                  </mml:mrow>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>â¡</mml:mo>
                <mml:mi>tanh</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>â</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>c</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>c</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>â</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="mkcpai34io">
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>f</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mrow>
                    <mml:mi>t</mml:mi>
                    <mml:mo>â</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
                <mml:msub>
                  <mml:mi>i</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mrow>
                    <mml:mover>
                      <mml:mi>C</mml:mi>
                      <mml:mo>~</mml:mo>
                    </mml:mover>
                  </mml:mrow>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>â</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>â</mml:mo>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="mxsr6qy8kh">
                <mml:msub>
                  <mml:mi>o</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>Ï</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>â</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>W</mml:mi>
                    <mml:mi>o</mml:mi>
                  </mml:msub>
                  <mml:msub>
                    <mml:mi>b</mml:mi>
                    <mml:mi>o</mml:mi>
                  </mml:msub>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>]</mml:mo>
                    <mml:msub>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>â</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="mcy9lehtmj">
                <mml:msub>
                  <mml:mi>h</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>o</mml:mi>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>â</mml:mo>
                <mml:mo>â¡</mml:mo>
                <mml:mi>tan</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>C</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>where: <inline-formula>
  <mml:math id="mcoaukx6ir">
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
  </mml:math>
</inline-formula> <span style="font-family: Cambria Math, serif">ðð  ðððððð¡ ð ðð¡ð, ð<span style="font-family: Cambria Math, serif">ð¡ <span style="font-family: Cambria Math, serif">ðð  ðððð¢ð¡ ððð¡ð ððð ð<span style="font-family: Cambria Math, serif">ð¡ <span style="font-family: Cambria Math, serif">ðð  ðð¢ð¡ðð¢ð¡ ððð¡ð, <inline-formula>
  <mml:math id="m890olwi5q">
    <mml:mi>C</mml:mi>
    <mml:mi>t</mml:mi>
  </mml:math>
</inline-formula> is memory cell state, <inline-formula>
  <mml:math id="m79vxo7y3w">
    <mml:msub>
      <mml:mi>W</mml:mi>
      <mml:mi>f</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>W</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>W</mml:mi>
      <mml:mi>C</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>W</mml:mi>
      <mml:mi>o</mml:mi>
    </mml:msub>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula> are the weight of matrices, <inline-formula>
  <mml:math id="mvg8msm3dd">
    <mml:msub>
      <mml:mi>b</mml:mi>
      <mml:mi>f</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>b</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>b</mml:mi>
      <mml:mi>C</mml:mi>
    </mml:msub>
    <mml:msub>
      <mml:mi>b</mml:mi>
      <mml:mi>o</mml:mi>
    </mml:msub>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula> are biases, <inline-formula>
  <mml:math id="moesq0jev6">
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
  </mml:math>
</inline-formula> is the hidden state at time <italic><span style="font-family: Arial, sans-serif">t</italic>, <inline-formula>
  <mml:math id="mlb8ph8fnd">
    <mml:msub>
      <mml:mi>x</mml:mi>
      <mml:mi>t</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is input at time t and <inline-formula>
  <mml:math id="mrx6gp3349">
    <mml:mi>Ï</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> is the sigmoid activation function.</p>
        </sec>
      
      
        <sec>
          
            <title>4.6. Hyperparameter optimization using bayesian techniques</title>
          
          <p>This work used Bayesian optimisation to enhance classification performance by changing key CNN-LSTM architecture hyperparameters. The following hyperparameters were among those that were optimised:</p><p><p><italic><span style="font-family: Arial, sans-serif">Learning rate: </italic>controls the step size during gradient descent; improper settings might cause slow convergence or overshooting.</p><p><italic><span style="font-family: Arial, sans-serif">Batch size: </italic>affects training stability and generalisation; larger batches produce noise, whereas smaller batches improve stability.</p><p><italic><span style="font-family: Arial, sans-serif">Number of CNN filters</italic>: assesses how well the model can extract complex spatial information from EEG inputs.</p><p><italic><span style="font-family: Arial, sans-serif">Number of LSTM hidden units</italic>: impacts the model's ability to detect temporal relationships in the sequential data.</p><p><italic><span style="font-family: Arial, sans-serif">Dropout rate</italic>: randomly deactivates units during training to prevent overfitting.</p></p><p>These parameters were selected for optimisation as they directly affect the model's representational capacity, learning dynamics, and generalisation performance. Bayesian optimisation successfully explores the hyperparameter space while finding a balance between exploration and exploitation by using a surrogate probabilistic model. This approach produced notable performance improvements; the accuracy of the optimised model increased from 88.9% to 92.1%. Bayesian is used to upgrade the model performance by fine-tune the hyperparameter. The optimization goal is:</p>
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="mbygc0cdz5">
                <mml:msup>
                  <mml:mi>Î¸</mml:mi>
                  <mml:mo>â</mml:mo>
                </mml:msup>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:munder>
                  <mml:mi>argmax</mml:mi>
                  <mml:mrow>
                    <mml:mi>Î¸</mml:mi>
                    <mml:mi>Î¸</mml:mi>
                    <mml:mo>â</mml:mo>
                  </mml:mrow>
                </mml:munder>
                <mml:mi>f</mml:mi>
                <mml:mi>Î¸</mml:mi>
              </mml:math>
            </disp-formula>
          
          <p>where: <inline-formula>
  <mml:math id="mfeba96dla">
    <mml:mi>Î¸</mml:mi>
  </mml:math>
</inline-formula><span style="font-family: Cambria Math, serif"> denotes hyperparameters and <inline-formula>
  <mml:math id="m9ydfjjw5l">
    <mml:mrow>
      <mml:mi>f</mml:mi>
    </mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>Î¸</mml:mi>
  </mml:math>
</inline-formula><span style="font-family: Cambria Math, serif"> denotes performance metrics. In Bayesian framework, a Gaussian process (GP) models<inline-formula>
  <mml:math id="mluvn53doo">
    <mml:mrow>
      <mml:mi>f</mml:mi>
    </mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>Î¸</mml:mi>
  </mml:math>
</inline-formula>, the posterior distribution is repeatedly updated with new observations from the prior.</p>
        </sec>
      
      
        <sec>
          
            <title>4.7. Performance evaluation</title>
          
          <p>After training, the modelâs performance was tested using accuracy, precision, recall, and F1-score. It was evaluated on unseen data to measure how well it could predict emotional disorders. A confusion matrix was used to check where the model made mistakes.</p>
          
            <disp-formula>
              <label>(9)</label>
              <mml:math id="m7hsyd1wel">
                <mml:mi>A</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>T</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="myfobqneps">
                <mml:mi>P</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>n</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(11)</label>
              <mml:math id="mhl9n7o02u">
                <mml:mi>R</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>l</mml:mi>
                <mml:mi>l</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(12)</label>
              <mml:math id="me0pnqi28f">
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
                <mml:mn>2</mml:mn>
                <mml:mo>=</mml:mo>
                <mml:mo>Ã</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mtext>Â PrecisionÂ </mml:mtext>
                    <mml:mtext>Â RecallÂ </mml:mtext>
                    <mml:mo>Ã</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>Â PrecisionÂ </mml:mtext>
                    <mml:mtext>Â RecallÂ </mml:mtext>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where: TP, TN, FP, and FN represent true positives, false positives, and false negatives.</p>
        </sec>
      
      
        <sec>
          
            <title>4.8. Experimental setup</title>
          
        </sec>
      
      <p>The experiment was designed to test how well a deep learning model can identify emotional disorders using a combination of CNN and LSTM. The study used publicly available datasets containing signals from the brain and body, such as EEG and ECG, which help understand emotional states. These datasets were processed and labelled to differentiate between emotions and psychological conditions, allowing the model to learn patterns effectively.</p><p style="text-align: justify">To test how this model would work, a live setup was created using wearable brain-computer interface (BCI) devices. These devices captured real-time EEG signals, which were processed and analysed instantly by the CNN- LSTM model. The emotional states were displayed on a live dashboard, allowing for real-time monitoring. This experiment demonstrated that the model could be used in healthcare settings, helping psychologists and mental health professionals track emotional disorders more effectively.</p>
    </sec>
    <sec sec-type="">
      <title>5. Results and discussion</title>
      <p>The proposed CNN-LSTM model for emotional disorder identification in smart healthcare systems was evaluated against traditional machine learning models and standalone deep learning architectures. The simulation results of the proposed approach are discussed in this section with graphical and numerical results in detail.</p><p style="text-align: justify"><xref ref-type="fig" rid="fig_2">Figure 2</xref> shows how a model's accuracy improves over time during training. The yellow line represents the training accuracy, and the red dashed line represents the validation accuracy. As the number of epochs increases, both accuracies improve, meaning the model is learning well. By the end of training, the validation accuracy is close to the training accuracy, indicating that the model performs well on new data.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>
            <title>Accuracy result â Training versus validation accuracy</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img__utGs1Hw9kyiqPpu.png"/>
        </fig>
      
      <p><xref ref-type="fig" rid="fig_3">Figure 3</xref> shows how the model's loss decreases over time during training. The yellow line represents the training loss, and the red dashed line represents the validation loss. Both losses start high and gradually decrease as the number of epochs increases, meaning the model is learning well. Since the validation loss follows the training loss closely, the model does not overfit and generalizes well to new data.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Loss rate comparison - Training versus validation loss</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img_7EzCmL68Pa4hnGsj.png"/>
        </fig>
      
      
        <sec>
          
            <title>5.1. Performance analysis</title>
          
          <p>The model's performance was measured using accuracy, precision, recall, and F1-score, as shown in Table</p><p>1. The results demonstrate that the CNN-LSTM model significantly outperforms other methods, achieving the highest accuracy of 92.1%, along with superior precision (0.93), recall (0.91), and F1-score (0.92).</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Performance comparison of different models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Recall</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>78.5</p></td><td colspan="1" rowspan="1"><p>0.79</p></td><td colspan="1" rowspan="1"><p>0.77</p></td><td colspan="1" rowspan="1"><p>0.78</p></td></tr><tr><td colspan="1" rowspan="1"><p>Random Forest</p></td><td colspan="1" rowspan="1"><p>81.2</p></td><td colspan="1" rowspan="1"><p>0.82</p></td><td colspan="1" rowspan="1"><p>0.80</p></td><td colspan="1" rowspan="1"><p>0.81</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN</p></td><td colspan="1" rowspan="1"><p>85.6</p></td><td colspan="1" rowspan="1"><p>0.86</p></td><td colspan="1" rowspan="1"><p>0.84</p></td><td colspan="1" rowspan="1"><p>0.85</p></td></tr><tr><td colspan="1" rowspan="1"><p>LSTM</p></td><td colspan="1" rowspan="1"><p>87.3</p></td><td colspan="1" rowspan="1"><p>0.88</p></td><td colspan="1" rowspan="1"><p>0.86</p></td><td colspan="1" rowspan="1"><p>0.87</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN-LSTM (Proposed)</p></td><td colspan="1" rowspan="1"><p>92.1</p></td><td colspan="1" rowspan="1"><p>0.93</p></td><td colspan="1" rowspan="1"><p>0.91</p></td><td colspan="1" rowspan="1"><p>0.92</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The CNN model alone achieved an accuracy of 85.6%, showing that convolutional feature extraction effectively identifies spatial patterns in EEG and physiological signals. Similarly, the LSTM model attained 87.3% accuracy, indicating its strength in capturing temporal dependencies in emotional states. However, combining CNN and LSTM provided a synergistic effect, improving feature extraction and temporal learning capabilities and enhancing classification performance. Traditional machine learning models, such as Support Vector Machine (SVM) and Random Forest, showed comparatively lower accuracy (78.5% and 81.2%, respectively). These models struggle to capture complex spatial-temporal dependencies inherent in emotional signals, leading to suboptimal results. The improvement achieved with the CNN-LSTM model demonstrates the effectiveness of deep learning in innovative healthcare applications.</p>
        </sec>
      
      
        <sec>
          
            <title>5.2. Auc-roc curve analysis</title>
          
          <p><span style="font-family: Microsoft Sans Serif, sans-serif">To further validate the modelâs performance, an Area Under the Curve - Receiver Operating Characteristic (AUC-ROC) analysis was conducted. The AUC-ROC curve provides insight into the modelâs classification ability by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at different thresholds. A higher AUC value indicates a better discriminative capability of the model.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>AUC-ROC analysis for different models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>AUC Value</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>0.81</p></td></tr><tr><td colspan="1" rowspan="1"><p>Random Forest</p></td><td colspan="1" rowspan="1"><p>0.85</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN</p></td><td colspan="1" rowspan="1"><p>0.90</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The CNN-LSTM model exhibited the highest AUC value of 0.96, demonstrating superior classification performance in detecting emotional disorders. In contrast, the standalone CNN and LSTM models achieved AUC values of 0.90 and 0.92, respectively, while traditional machine learning models, such as SVM and Random Forest, yielded lower AUC values of 0.81 and 0.85.</p><p style="text-align: justify"><xref ref-type="fig" rid="fig_4">Figure 4</xref> shows the AUC-ROC curve result, which helps to measure how well a model can distinguish between different emotions: Neutral, Stressed, and Anxious. The curve balances correctly identifying emotions (True Positive Rate) and making mistakes (False Positive Rate). The closer the curve is to the top-left corner, the better the model performs. The AUC values (1.00 for Neutral and Stressed, 0.99 for Anxious) show that the model performs exceptionally well.</p>
        </sec>
      
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>AUC-ROC curve result</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img_L1SadxeZj-yBQP7s.png"/>
        </fig>
      
      
        <sec>
          
            <title>5.3. Role of lstm and bayesian optimization in the proposed framework</title>
          
          <p>The temporal connections shown in physiological and EEG data, which represent changing emotional states over time, are largely explained by the Long Short-Term Memory (LSTM) network. The CNN component uses multi channel EEG inputs to gather data relating to frequency and space. These data are then sent to the LSTM network, which tracks dynamic fluctuations and long-term temporal patterns that may indicate changes in emotional states like stress or anxiety. Given that emotional states don't happen all at once but rather evolve over time, this sequence modelling skill is crucial in mental health settings.</p><p>To increase the model's prediction accuracy and generalisation, Bayesian optimisation was used to modify a variety of critical hyperparameters, including learning rate, batch size, number of CNN filters, LSTM hidden units, dropout rates, and others. Bayesian optimisation offers a probabilistic approach to hyperparameter tuning by efficiently searching the parameter space using a surrogate model (often a Gaussian Process) and updating its beliefs based on observed performance. This method works much better than traditional grid or random search since it requires less cycles to select the best designs.</p><p>Bayesian optimisation was used to determine the optimal configuration for this study, increasing classification accuracy from 88.9% to 92.1% while increasing precision, recall, and F1-score. This illustrates its significance in improving accuracy as well as the model's ability to generalise across unseen emotional illness patterns.</p>
        </sec>
      
      
        <sec>
          
            <title>5.4. Impact of bayesian optimization on model performance</title>
          
          <p>Bayesian Optimization was employed to fine-tune the CNN-LSTM model's hyperparameters, including learning rate, batch size, number of CNN filters, LSTM hidden units, and dropout rate. <xref ref-type="table" rid="table_3">Table 3</xref> compares the optimized and non-optimized models. The results indicate that Bayesian Optimization significantly enhanced the model's accuracy from 88.9% to 92.1%, precision from 0.90 to 0.93, recall from 0.88 to 0.91, and F1-score from 0.89 to 0.92. This improvement confirms that hyperparameter tuning is crucial in achieving better performance, reducing overfitting, and enhancing generalization capability.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Impact of Bayesian optimization on CNN-LSTM model performance</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Model Version</p></td><td colspan="1" rowspan="1"><p>Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Recall</p></td><td colspan="1" rowspan="1"><p>F1-Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN-LSTM (Without Optimization)</p></td><td colspan="1" rowspan="1"><p>88.9</p></td><td colspan="1" rowspan="1"><p>0.90</p></td><td colspan="1" rowspan="1"><p>0.88</p></td><td colspan="1" rowspan="1"><p>0.89</p></td></tr><tr><td colspan="1" rowspan="1"><p>CNN-LSTM (Optimized)</p></td><td colspan="1" rowspan="1"><p>92.1</p></td><td colspan="1" rowspan="1"><p>0.93</p></td><td colspan="1" rowspan="1"><p>0.91</p></td><td colspan="1" rowspan="1"><p>0.92</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The Bayesian Optimization framework efficiently explored the hyperparameter space and identified the best configuration, enhancing classification performance. The optimized CNN-LSTM model demonstrated improved robustness and efficiency in emotional disorder identification, making it a viable solution for innovative healthcare applications.</p><p style="text-align: justify">The CNN-LSTM model's hyperparameters were adjusted using Bayesian optimisation, which increased computing time by around 30%. Nonetheless, this resulted in improved precision, recall, and F1-score performance as well as a no<xref ref-type="table" rid="table_3">table 3</xref>.2% increase in accuracy (from 88.9% to 92.1%). The optimised model is a good option for real-time applications, especially in the healthcare industry where high accuracy is crucial for trustworthy identification of emotional and psychological disorders, despite the increased computing cost.</p><p style="text-align: justify">The confusion matrix depicted in <xref ref-type="fig" rid="fig_5">Figure 5</xref> shows how well a model predicted three emotions: Neutral, Stressed, and Anxious. The numbers show how often the model made the correct or wrong predictions. For example, the model correctly predicted 6 Neutral emotions, 7 Stressed emotions, and 6 Anxious emotions. However, it made one mistake by predicting Stressed instead of Anxious.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>Confusion matrix</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2025/6/img_JdXyRzBPBz16_hmP.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Research findings</title>
      <p>The experimental findings indicate that the proposed CNN-LSTM model effectively identifies emotional disorders using EEG and physiological signals. Combining CNN for spatial feature extraction and LSTM for temporal sequence learning significantly improved classification performance. The AUC-ROC analysis further confirmed the model's ability to differentiate between emotional states with minimal false classifications. The impact of Bayesian Optimization highlights the importance of hyperparameter tuning in deep learning models. The optimized CNN-LSTM model achieved substantial performance gains over its non-optimized counterpart, demonstrating the effectiveness of automated parameter selection.</p><p style="text-align: justify">In order to detect emotional and psychological disorders, the CNN-LSTM model's design places a high priority on interpretability, computational efficiency, scalability, and durability. The model uses LSTM for temporal sequence modelling and CNN for spatial feature extraction to effectively evaluate physiological and EEG data, as follows:</p><p><p>Scalability ensures that the model can adapt to different medical scenarios and handle large datasets.</p><p>The resilience is provided by the hybrid CNN-LSTM architecture and Bayesian optimisation, which helps modify hyperparameters to improve generalisation and prevent overfitting.</p><p>Medical professionals can better understand and trust model predictions thanks to explainable AI techniques that make interpretability easier.</p><p>Real-time use without excessive computing expenditures is made possible by matching performance and computational efficiency.</p></p><p style="text-align: justify">CNN's hierarchical feature extraction, LSTM's temporal dependency modelling, and the architecture created especially for EEG data all enhance performance. Together, these elements improve the model's real-time, accurate, and effective detection of emotional problems in healthcare settings. The results of this experiment confirmed that using CNN for extracting features and LSTM for understanding time-based patterns is a strong approach to identifying emotional disorders. The model learned complex emotional patterns well and performed better than traditional methods. Bayesian Optimization helped improve its accuracy by fine-tuning parameters, making it more efficient. This framework could be integrated into smart healthcare systems, enabling early detection of emotional and psychological disorders and providing real-time monitoring and personalized mental health support.</p>
      
        <sec>
          
            <title>6.1. Conclusion</title>
          
          <p>This study introduces a deep learning model designed to identify emotional and psychological disorders in smart healthcare systems. The model uses two powerful techniques: Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. By combining these methods, the system improves the accuracy of detecting mental health conditions using data from brain activity (EEG) and other physiological signals.</p><p style="text-align: justify">Traditional methods often depend on manual assessments and personal opinions, which can lead to delayed diagnoses and inconsistent results. This new approach overcomes those issues. The CNN part of the model identifies important patterns from EEG signals and physiological data, helping to recognize emotional states. At the same time, the LSTM part tracks changes over time, making it possible to see how emotions fluctuate. Combining both methods makes the model much better at detecting mental health issues compared to older machine learning models like Support Vector Machines (SVM) and Random Forest, or even using CNN or LSTM alone. To make the model even better, a technique called Bayesian optimization was used to adjust settings for the best performance. This improved the modelâs efficiency while keeping accuracy high. Testing showed that the CNN-LSTM model reached an accuracy of 92.1%, performing better than previous methods. Other performance measures, like precision, recall, and F1-score, showed that the model balances sensitivity and specificity well, meaning it is good at identifying disorders while avoiding mistakes.</p><p style="text-align: justify">A test called AUC-ROC analysis confirmed the modelâs reliability, giving it a high score of 0.96, which means it can clearly distinguish between different emotional states. The training graphs also showed that the model learns well and avoids overfitting, making it effective on different sets of data. This model has great potential for use in smart healthcare. It can help monitor mental health in real time, provide early diagnoses, and offer personalized care for people at risk of emotional or psychological issues. If integrated into wearable devices like smartwatches or EEG headbands, it could track mental health continuously and support those in distress. </p><p style="text-align: justify">However, some challenges still exist, such as the imbalance in available data, the need for more computing power, and the importance of using multiple types of data together. Overcoming these challenges in future research will make the model even more effective and useful in real-world healthcare. </p><p style="text-align: justify">The CNN-LSTM model has shown great potential in detecting emotional and psychological disorders in smart healthcare. Future improvements should focus on integrating different types of data, such as facial expressions, voice tone, and text-based sentiment analysis, along with existing EEG and physiological signals. This will provide a more accurate and complete picture of a personâs emotional state. Additionally, optimizing the model for mobile and edge devices will allow real-time monitoring through smartwatches, EEG headbands, and smartphones, making mental health tracking more accessible. </p><p style="text-align: justify">Another key area for improvement is making the modelâs decision-making process more transparent. Explainability techniques like highlighting important EEG features, using tools to clarify predictions, and creating an AI dashboard for doctors will help build trust and encourage adoption in healthcare settings. Beyond detection, the model can be expanded to provide personalized mental health support by recommending relaxation techniques, therapy chatbots, and biofeedback-based interventions, allowing users to manage their emotions more effectively. </p><p style="text-align: justify">Large-scale clinical testing is necessary to ensure real-world applicability. The model should be validated on diverse populations, tested in hospitals and mental health clinics, and refined with input from professionals. Integrating it into cloud-based smart healthcare systems will also allow remote diagnosis, AI-powered health records, and real-time alerts for severe emotional distress. These advancements will help bring AI-driven mental health solutions into everyday healthcare, making support more effective and widely available.</p><p style="text-align: justify"></p>
          <p>All authors contributed significantly to the development of this research. Saini, D. K. J. B. and Shieh, C.-S. were responsible for the conceptualization and methodology design of the study. Sankpal, L. J. and Mehrotra, M. contributed to data curation, model implementation, and validation. Bhosale, K. S. led the formal analysis and evaluation of experimental results. Raut, Y. contributed to writing, review, and editing of the manuscript, as well as overseeing the project administration. All authors participated in drafting the manuscript, critically reviewing the content, and approved the final version for submission.</p>
          <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
        </sec>
      
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      <p>All authors contributed significantly to the development of this research. Saini, D. K. J. B. and Shieh, C.-S. were responsible for the conceptualization and methodology design of the study. Sankpal, L. J. and Mehrotra, M. contributed to data curation, model implementation, and validation. Bhosale, K. S. led the formal analysis and evaluation of experimental results. Raut, Y. contributed to writing, review, and editing of the manuscript, as well as overseeing the project administration. All authors participated in drafting the manuscript, critically reviewing the content, and approved the final version for submission.</p>
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>168477-168499</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Almutairi</surname>
              <given-names>Sulaiman</given-names>
            </name>
            <name>
              <surname>Abohashrh</surname>
              <given-names>Mohammed</given-names>
            </name>
            <name>
              <surname>Razzaq</surname>
              <given-names>Hasanain Hayder</given-names>
            </name>
            <name>
              <surname>Zulqarnain</surname>
              <given-names>Muhammad</given-names>
            </name>
            <name>
              <surname>Namoun</surname>
              <given-names>Abdallah</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>Faheem</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/access.2024.3496741</pub-id>
          <article-title>A Hybrid Deep Learning Model for Predicting Depression Symptoms From Large-Scale Textual Dataset</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>1022</volume>
          <page-range>012095</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chatterjee</surname>
              <given-names>Rinki</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>Rajeev Kumar</given-names>
            </name>
            <name>
              <surname>Gupta</surname>
              <given-names>Bhavana</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1757-899x/1022/1/012095</pub-id>
          <article-title>Depression Detection from Social Media Posts Using Multinomial Naive Theorem</article-title>
          <source>IOP Conference Series: Materials Science and Engineering</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>21</volume>
          <page-range>4269</page-range>
          <issue>13</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Choi</surname>
              <given-names>Yoon-A</given-names>
            </name>
            <name>
              <surname>Park</surname>
              <given-names>Se-Jin</given-names>
            </name>
            <name>
              <surname>Jun</surname>
              <given-names>Jong-Arm</given-names>
            </name>
            <name>
              <surname>Pyo</surname>
              <given-names>Cheol-Sig</given-names>
            </name>
            <name>
              <surname>Cho</surname>
              <given-names>Kang-Hee</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Han-Sung</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Jae-Hak</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s21134269</pub-id>
          <article-title>Deep Learning-Based Stroke Disease Prediction System Using Real-Time Bio Signals</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>70370-70382</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Guo</surname>
              <given-names>Teng</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Wenhong</given-names>
            </name>
            <name>
              <surname>Alrashoud</surname>
              <given-names>Mubarak</given-names>
            </name>
            <name>
              <surname>Tolba</surname>
              <given-names>Amr</given-names>
            </name>
            <name>
              <surname>Firmin</surname>
              <given-names>Selena</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>Feng</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/access.2022.3187502</pub-id>
          <article-title>Multimodal Educational Data Fusion for Studentsâ Mental Health Detection</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="conf-paper">
          <page-range>1-6</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gupta</surname>
              <given-names>Chetna</given-names>
            </name>
            <name>
              <surname>Khullar</surname>
              <given-names>Vikas</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/soli57430.2022.10294421</pub-id>
          <article-title>Exploring the Role of Conventional and Non-Conventional Technologies in Identifying MDD</article-title>
          <source>2022 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>285</page-range>
          <issue>3</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Iyortsuun</surname>
              <given-names>Ngumimi Karen</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Soo-Hyung</given-names>
            </name>
            <name>
              <surname>Jhon</surname>
              <given-names>Min</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Hyung-Jeong</given-names>
            </name>
            <name>
              <surname>Pant</surname>
              <given-names>Sudarshan</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/healthcare11030285</pub-id>
          <article-title>A Review of Machine Learning and Deep Learning Approaches on Mental Health Diagnosis</article-title>
          <source>Healthcare</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jang</surname>
              <given-names>Kuk-In</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Euijin</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Ho Sung</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Hyeon-Ah</given-names>
            </name>
            <name>
              <surname>Han</surname>
              <given-names>Jae Hyun</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Sungkean</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>Ji Sun</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s41598-024-71287-5</pub-id>
          <article-title>Electroencephalography-based endogenous phenotype of diagnostic transition from major depressive disorder to bipolar disorder</article-title>
          <source>Scientific Reports</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>55</volume>
          <page-range>1-57</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>Xiang</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Yazhou</given-names>
            </name>
            <name>
              <surname>Tiwari</surname>
              <given-names>Prayag</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>Dawei</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>Bin</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Meihong</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Zhigang</given-names>
            </name>
            <name>
              <surname>Kumar</surname>
              <given-names>Neeraj</given-names>
            </name>
            <name>
              <surname>Marttinen</surname>
              <given-names>Pekka</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3524499</pub-id>
          <article-title>EEG Based Emotion Recognition: A Tutorial and Review</article-title>
          <source>ACM Computing Surveys</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <article-title>Accu-Help: A Machine Learning based Smart Healthcare Framework for Accurate Detection of Obsessive Compulsive Disorder</article-title>
          <source>arXiv</source>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Patel</surname>
              <given-names>Kabita</given-names>
            </name>
            <name>
              <surname>Tripathy</surname>
              <given-names>Ajaya Kumar</given-names>
            </name>
            <name>
              <surname>Padhy</surname>
              <given-names>Laxmi Narayan</given-names>
            </name>
            <name>
              <surname>Kar</surname>
              <given-names>Sujita Kumar</given-names>
            </name>
            <name>
              <surname>Padhy</surname>
              <given-names>Susanta Kumar</given-names>
            </name>
            <name>
              <surname>Mohanty</surname>
              <given-names>Saraju Prasad</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.2212.02346</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>124-142</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Pathirana</surname>
              <given-names>Amod</given-names>
            </name>
            <name>
              <surname>Rajakaruna</surname>
              <given-names>Dumidu Kasun</given-names>
            </name>
            <name>
              <surname>Kasthurirathna</surname>
              <given-names>Dharshana</given-names>
            </name>
            <name>
              <surname>Atukorale</surname>
              <given-names>Ajantha</given-names>
            </name>
            <name>
              <surname>Aththidiye</surname>
              <given-names>Rekha</given-names>
            </name>
            <name>
              <surname>Yatipansalawa</surname>
              <given-names>Maheshi</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.62411/faith.2024-22</pub-id>
          <article-title>A Reinforcement Learning-Based Approach for Promoting Mental Health Using Multimodal Emotion Recognition</article-title>
          <source>Journal of Future Artificial Intelligence and Technologies</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>46</volume>
          <page-range>693-701</page-range>
          <issue>7</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Poudel</surname>
              <given-names>Utsav</given-names>
            </name>
            <name>
              <surname>Jakhar</surname>
              <given-names>Sachin</given-names>
            </name>
            <name>
              <surname>Mohan</surname>
              <given-names>Prakash</given-names>
            </name>
            <name>
              <surname>Nepal</surname>
              <given-names>Anuj</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/01612840.2025.2502943</pub-id>
          <article-title>AI in Mental Health: A Review of Technological Advancements and Ethical Issues in Psychiatry</article-title>
          <source>Issues in Mental Health Nursing</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <article-title>Practical Bayesian Optimization of Machine Learning Algorithms</article-title>
          <source>arXiv</source>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Snoek</surname>
              <given-names>Jasper</given-names>
            </name>
            <name>
              <surname>Larochelle</surname>
              <given-names>Hugo</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>Ryan P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1206.2944</pub-id>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <page-range>334-342</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Vamsinath J</surname>
            </name>
            <name>
              <surname>Varshini Bonagiri</surname>
            </name>
            <name>
              <surname>Sandeep T</surname>
            </name>
            <name>
              <surname>Meghana V</surname>
            </name>
            <name>
              <surname>Latha B</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.32628/ijsrst229437</pub-id>
          <article-title>Stress Detection Through Speech Analysis Using Machine Learning</article-title>
          <source>International Journal of Scientific Research in Science and Technology</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>1-32</page-range>
          <issue>1</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Xu</surname>
              <given-names>Xuhai</given-names>
            </name>
            <name>
              <surname>Yao</surname>
              <given-names>Bingsheng</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>Yuanzhe</given-names>
            </name>
            <name>
              <surname>Gabriel</surname>
              <given-names>Saadia</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Hong</given-names>
            </name>
            <name>
              <surname>Hendler</surname>
              <given-names>James</given-names>
            </name>
            <name>
              <surname>Ghassemi</surname>
              <given-names>Marzyeh</given-names>
            </name>
            <name>
              <surname>Dey</surname>
              <given-names>Anind K.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Dakuo</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1145/3643540</pub-id>
          <article-title>Mental-LLM</article-title>
          <source>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>146</volume>
          <page-range>104562</page-range>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhou</surname>
              <given-names>Ying</given-names>
            </name>
            <name>
              <surname>Han</surname>
              <given-names>Wei</given-names>
            </name>
            <name>
              <surname>Yao</surname>
              <given-names>Xiuyu</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>JiaJun</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Zheng</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Yingxin</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.ijnurstu.2023.104562</pub-id>
          <article-title>Developing a machine learning model for detecting depression, anxiety, and apathy in older adults with mild cognitive impairment using speech and facial expressions: A cross-sectional observational study</article-title>
          <source>International Journal of Nursing Studies</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>