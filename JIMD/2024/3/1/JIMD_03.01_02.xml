<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JIMD</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Journal of Intelligent Management Decision</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Intell. Manag. Decis.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JIMD</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-0080</issn>
      <issn publication-format="print">2958-0072</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-rGH58f53-WFXcDcb8sSEbgJ_asCwEmWL</article-id>
      <article-id pub-id-type="doi">10.56578/jimd030102</article-id>
      <title-group>
        <article-title>Deploying Mobile Applications for Emergency Flood Response in Geographically Isolated Areas: A Data-Driven Approach</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Nguyen</surname>
            <given-names>Hoang Ha</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-6986-4104</contrib-id>
          <email>nhha@husc.edu.vn</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="2">2</xref>
          <name>
            <surname>Nguyen</surname>
            <given-names>Ha Huy Cuong</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3223-2909</contrib-id>
          <email>nhhcuong@sdc.udn.vn</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="3">3</xref>
          <name>
            <surname>Jana</surname>
            <given-names>Chiranjibe</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-4541-5336</contrib-id>
          <email>jana.chiranjibe7@gmail.com</email>
        </contrib>
        <aff id="1">Department of Information Technology, Hue University ò Sciences, 49000 Hue, Vietnam</aff>
        <aff id="2">Software Development Centre, The University of Danang, 50000 Da Nang, Vietnam</aff>
        <aff id="3">Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences (SIMATS), 602105 Chennai, India</aff>
      </contrib-group>
      <year>2024</year>
      <volume>3</volume>
      <issue>1</issue>
      <fpage>15</fpage>
      <lpage>21</lpage>
      <page-range>15-21</page-range>
      <history>
        <date date-type="received">
          <month>01</month>
          <day>06</day>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <month>02</month>
          <day>22</day>
          <year>2024</year>
        </date>
        <date date-type="pub">
          <month>03</month>
          <day>04</day>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license>. Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the <a href='https://creativecommons.org/licenses/by/4.0/' target='_blank' class='text-yellow-700 hover:underline'>CC BY 4.0 license</a>.</license>
      </permissions>
      <abstract><p>In geographically isolated regions, where infrastructure limitations and remote locations pose significant challenges, a mobile application has been developed to facilitate an efficient emergency response system. This system, designed to bridge the gap in emergency support, employs a multi-faceted strategy that combines human expertise with advanced machine learning (ML) technologies. Upon activation through the application, a coordinated mechanism is triggered, dispatching local mechanics equipped with the necessary tools, resources, vehicles, and spare parts to the site of the emergency. This immediate on-site assistance is essential for addressing mechanical failures and ensuring timely support for individuals in remote areas.At the heart of the application lies a sophisticated ML model, trained on an extensive dataset comprising a wide array of emergencies likely to occur in rural settings. This model, characterized by its convolutional neural network (CNN) architecture and optimized for mobile deployment through TensorFlow Lite (TFLite), demonstrates an impressive diagnostic accuracy rate of 98%. Such precision significantly enhances the application’s capacity to diagnose issues accurately, prioritize response efforts, and optimize resource allocation.Moreover, the application leverages data-driven insights not only to streamline the emergency response process but also to facilitate predictive maintenance. By continuously learning from incoming data, the ML model can predict potential problems and suggest preventative measures to users, thereby minimizing the likelihood of future breakdowns. This predictive capability underscores the application’s role in promoting resilience within rural communities.Community engagement is further encouraged through the inclusion of local mechanics in the emergency response network. This initiative not only expands the pool of available skilled professionals but also fosters a sense of community solidarity, crucial for enhancing the system’s overall effectiveness.In summary, the development of this mobile application represents a significant advancement in emergency assistance for rural communities. By integrating real-time response capabilities with sophisticated ML models, the system not only addresses the immediate challenges of emergency support in remote areas but also contributes to the creation of a more resilient and interconnected community fabric.</p></abstract>
      <kwd-group>
        <kwd>Vehicle servicing and transporting (VSERV) emergency</kwd>
        <kwd>Machine learning (ML) classifier</kwd>
        <kwd>TensorFlow Lite (TFLite)</kwd>
        <kwd>Convolutional neural network (CNN)</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors">3</count>
        <fig-count>2</fig-count>
        <table-count>1</table-count>
        <ref-count>21</ref-count>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec disp-level="level1" sec-type="intro">
      <title>1. Introduction</title>
      <p>The VSERV Mobile app is a comprehensive solution designed to address the challenges faced by travelers during unexpected breakdowns. With its integrated ML system, the application provides a quick and accurate diagnosis of the vehicle's issues, allowing users to understand the nature of the problem promptly. The app ensures that travelers can stay informed about their vehicle's status, such as fuel levels, tire pressure, and overall mechanical condition, even before embarking on a journey. By providing real-time updates, users can take preventive measures to avoid breakdowns and ensure a smoother travel experience. In the event of a breakdown, the ML system within the VSERV Mobile app assists the traveler in identifying the specific problem with the vehicle. This not only saves valuable time but also empowers users with knowledge, enabling them to communicate effectively with locals or service personnel [<xref ref-type="bibr" rid="ref_1">1</xref>], [<xref ref-type="bibr" rid="ref_2">2</xref>]. The application goes beyond diagnosis by offering a range of support services. If the breakdown is severe, the VSERV Mobile app facilitates the arrangement of transportation for the traveler, ensuring they can continue their journey with minimal disruption. Simultaneously, it takes care of the servicing and delivery of the stranded vehicle, providing a seamless experience for the user [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>].</p><p>Moreover, the VSERV Mobile app eliminates the need for travelers to rely solely on local assistance, which may be limited or delayed. By streamlining the process of finding nearby service centers and arranging repairs, the app ensures a quicker resolution to the issue, minimizing downtime and enhancing safety [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>].</p><p>With the VSERV Mobile app, travelers can confidently navigate through unexpected challenges during their journeys [<xref ref-type="bibr" rid="ref_7">7</xref>], [<xref ref-type="bibr" rid="ref_8">8</xref>], knowing that they have a reliable and efficient solution at their fingertips. This innovative application not only enhances the overall travel experience but also promotes safety, convenience, and peace of mind for users on the move [<xref ref-type="bibr" rid="ref_9">9</xref>], [<xref ref-type="bibr" rid="ref_10">10</xref>].</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>2. Literature survey</title>
      <p>Delivering news content through social networks offers several advantages, including cost-effectiveness, easy accessibility, and rapid transmission. These benefits have led many individuals to prefer obtaining their news from these platforms. The expansive growth of social networks has transformed various social media platforms into efficient channels for news dissemination. The increasing reliance on social media for news consumption is primarily driven by its convenience. However, this convenience also poses a challenge, as false information can quickly spread and have detrimental effects on individuals and society. Microblogs like Twitter and Weibo, among the most widely used online platforms, enable the swift sharing and forwarding of tweets. Notably, tweets featuring both text and photos tend to attract more attention than those with only text.</p><p>ML is the dominant approach to employing these techniques, utilizing a significant body of research. By having a labeled dataset containing both genuine and false news, a classification model is trained using novel attributes. This model is then applied to assess the accuracy of the provided information. Two prevalent categories of characteristics are commonly utilized in these methods: (1) features reliant on content and (2) features dependent on context. Features derived from the text or the actual content of the news are known as content-based features.</p><p>This comprehensive review delves into the latest developments in auditory signal analysis, encompassing a range of applications. From COVID-19 identification using auditory signals to voice recognition and sound event categorization, this survey explores significant research contributions. The review highlights studies utilizing audio analysis, CNNs, and deep learning techniques, shedding light on their implications and relevance. Additionally, innovative approaches in automated surveillance systems and acoustic emissions analysis are examined, offering potential solutions for real-world challenges. The article provides an up-to-date insight into the evolving landscape of auditory signal analysis and its diverse applications.</p><p>In their groundbreaking research on COVID-19 identification through auditory signals, Jose Gomez Aleixandre and Mohamed Elgendi delved into an extensive analysis of 48 publications sourced from a comprehensive search spanning 659 databases, including reputable platforms such as PubMed, IEEE Xplore, Embase, and Google Scholar. The meticulous inclusion of both publicly available and researcher-obtained datasets underscored the thoroughness of their investigation. One notable aspect of their methodology was the utilization of crowdsourcing for data collection, reflecting a collaborative and inclusive approach to gathering diverse sets of information. However, a critical observation highlighted by the authors pertained to the size of some datasets employed in these studies, with a significant portion relying on relatively small datasets comprising fewer than 200 instances. Despite this limitation, the research outcomes demonstrated promise, with 13 out of the 48 publications showcasing encouraging results in the realm of COVID-19 identification via auditory signals [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>]. The success of these studies has far-reaching implications for the development of innovative diagnostic tools. In terms of algorithmic performance, CNNs and support vector machines (SVMs) emerged as the frontrunners, showcasing their efficacy in processing and interpreting auditory data for disease identification. The authors noted that these ML techniques exhibited superior capabilities, underscoring the potential for advanced technology in the field of healthcare.</p><p>Furthermore, the authors shed light on the specific features that contributed to the success of these algorithms. Mel-frequency cepstral coefficients (MFCCs) and zero-crossing rate emerged as the preferred features, showcasing their importance in extracting relevant information from auditory signals for accurate disease identification. Intriguingly, the exploration of non-linear characteristics in the auditory signals also yielded positive outcomes, expanding the repertoire of effective approaches beyond traditional linear methods. This innovation in analytical techniques holds promise for the continued development of robust and reliable systems for COVID-19 identification. The research spearheaded by Gomez Aleixandre and Elgendi represents a significant stride in leveraging auditory signals for COVID-19 identification. Their comprehensive review and analysis of the existing literature provide valuable insights into the potential of ML algorithms and specific features in advancing the field of medical diagnostics through auditory data analysis [<xref ref-type="bibr" rid="ref_13">13</xref>], [<xref ref-type="bibr" rid="ref_14">14</xref>].</p><p>Nasiri's [<xref ref-type="bibr" rid="ref_12">12</xref>] research introduced novel methods for sound event detection, acoustic emissions analysis, and ambient sound categorization. The AudioMask technique, based on Mask R-CNN and frame-level audio analysis, showed potential for identifying relevant audio events, especially those with distinctive forms in Mel spectrograms. The Audioset dataset, containing over 2 million labeled sound segments, facilitated the exploration of sound events. SoundCLR, a supervised contrastive learning-based system, demonstrated state-of-the-art performance in ambient sound categorization. Hybrid deep network models achieved remarkable accuracy on benchmark datasets, reinforcing the progress in sound event analysis [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>].</p><p>The review delves into an innovative online surveillance system proposed by Alain Dufaux, Laurent Besacier, and others. This system combines microphone recordings and detection modules to trigger recognition processes and subsequent human interventions. Acoustic emissions analysis, specifically in SiC composite deterioration, was investigated using a random forest approach and deep neural networks, contributing to material degradation assessment [<xref ref-type="bibr" rid="ref_17">17</xref>]. The article discusses advancements in voice recognition, emphasizing CNN-based approaches for tonal speech identification and continuous voice signals. These studies exhibit the potential of deep learning techniques to achieve remarkable accuracy rates, reinforcing the significance of feature extraction methodologies [<xref ref-type="bibr" rid="ref_18">18</xref>], [<xref ref-type="bibr" rid="ref_19">19</xref>]. Reviewed literature underscores the dynamic landscape of auditory signal analysis, spanning applications from healthcare to surveillance and voice recognition. Emerging technologies like CNNs and deep learning models exhibit considerable potential, fueling progress in the field. As researchers continue to push boundaries, this comprehensive survey offers valuable insights into the current state and potential future directions of auditory signal analysis [<xref ref-type="bibr" rid="ref_20">20</xref>], [<xref ref-type="bibr" rid="ref_21">21</xref>].</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>3. Dataset creation</title>
      <p>We met a few service center car mechanics to learn “how engine sounds vary for different vehicle problems." Surprisingly, we got to know about many problems with vehicles that can be “identified through engine sound." For the dataset, we went to different showrooms of car companies and service centers like Hyundai, Honda, Kia, etc. We explained the problem to the managers of the companies. Many of them were impressed by the idea and approved of us collecting data from their showrooms and service centers. In each showroom and service center, an experienced mechanic was assigned to explain the problem, the reason for the occurrence of the problem, and the solution. It took almost one month to collect data on 20 different classes of problems for different car companies. From this experience, we got to know the varieties of problems that can be identified through engine sound. Examples of some of the problems include starter motor faults, diesel injector noise, brake switch faults, turbo problems, etc. <xref ref-type="table" rid="table_1">Table 1</xref> illustrates the vehicle problems with the associated label.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>Vehicle problems with the associated label</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Label</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Fault of Vehicle</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Label</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Fault of Vehicle</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">1</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Starter motor fault</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">10</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Clipping loose</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">2</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Diesel injector noise</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">11</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Alternator output not coming</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">3</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Brake switch noise</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">12</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Injector not working</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">4</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">No problem</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">13</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Air filter damage hose</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">5</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">No problem</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">14</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Wall tappet clearance</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">6</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Turbo problem</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">15</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">AC compressor and air filter assembler fault</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">7</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Water leakage</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">16</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Timing chain noise</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">8</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Injector, spares fail/ wiring cuts</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">17</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">AC noise</span></p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">9</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Nozzle diesel flow stops</span></p></td><td colspan="1" rowspan="1" colwidth="429"><p style="text-align: center"><span style="font-family: Times New Roman, serif">18</span></p></td><td colspan="1" rowspan="1"><p style="text-align: center"><span style="font-family: Times New Roman, serif">Nozzle noise/ injector noise</span></p></td></tr></tbody></table>
        </table-wrap>
      
      <p>The dataset consists of 600 audio samples of engine sounds and other vehicle fault-related sounds. The dataset is split in the ratio 8:2, with 80%, i.e., 480 samples for training and 20%, i.e., 120 samples for testing. The samples are labeled from 0-18. The main goal of this paper is to detect problems in the vehicle by listening to the engine sound.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>4. Proposed method</title>
      <p>The proposed model, which is illustrated in <xref ref-type="fig" rid="fig_1">Figure 1</xref>, uses ANN (artificial neural networks).</p><p>Step 1: Extract the features from recorded audio using the MFCC technique.</p><p>Step 2: Feed the extracted features to the model with 7 dense layers and ReLu activation.</p><p>Step 3: Classify the vehicle problem based on the recorded sound.</p><p>Step 4: Convert the.h5 model into the TFLite model.</p><p>Step 5: Load the TFLite in the mobile app to predict the problem.</p><p>The Mel spectrum may be calculated by first sending the signal that has been processed by the Fourier transform through a bank of bandpass filters that are collectively referred to as the Mel-filter bank. Mels are used as a unit of measurement because they are based on the highest frequency that can be heard by humans. In the same way that the frequency spectrum of physical tones is not as linear as the mel spectrum, the human auditory system does not receive tones in a linear fashion either. The Mel scale is logarithmic for frequencies that are higher than 1 kHz but linear for frequencies that are lower than 1 kHz. Mel's approximation for the human ears’ perceived frequency can be expressed as Eq. (1). </p>
      
        <disp-formula>
          <label>(1)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mrow data-mjx-texclass="ORD">
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi>f</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>m</mi>
                </mrow>
              </msub>
            </mrow>
            <mrow data-mjx-texclass="ORD">
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi>g</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mn>10</mn>
                </mrow>
              </msub>
            </mrow>
            <mrow data-mjx-texclass="INNER">
              <mo data-mjx-texclass="OPEN">(</mo>
              <mo>+</mo>
              <mo data-mjx-texclass="CLOSE">)</mo>
              <mn>1</mn>
              <mfrac>
                <mi>f</mi>
                <mn>700</mn>
              </mfrac>
            </mrow>
            <mo>=</mo>
            <mo>∗</mo>
            <mn>2595</mn>
            <mi>l</mi>
            <mi>o</mi>
          </math>
        </disp-formula>
      
      <p>where, $f<inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>r</mi>
    <mi>e</mi>
    <mi>p</mi>
    <mi>r</mi>
    <mi>e</mi>
    <mi>s</mi>
    <mi>e</mi>
    <mi>n</mi>
    <mi>t</mi>
    <mi>s</mi>
    <mi>t</mi>
    <mi>h</mi>
    <mi>e</mi>
    <mi>f</mi>
    <mi>r</mi>
    <mi>e</mi>
    <mi>q</mi>
    <mi>u</mi>
    <mi>e</mi>
    <mi>n</mi>
    <mi>c</mi>
    <mi>y</mi>
    <mi>a</mi>
    <mi>s</mi>
    <mi>m</mi>
    <mi>e</mi>
    <mi>a</mi>
    <mi>s</mi>
    <mi>u</mi>
    <mi>r</mi>
    <mi>e</mi>
    <mi>d</mi>
    <mi>i</mi>
    <mi>n</mi>
    <mi>H</mi>
    <mi>z</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mi>d</mi>
    <mo>,</mo>
  </math>
</inline-formula>{{f}_{m}}$ denotes the frequency perceived by human ears as represented by the Mel-scale.</p><p>The model is used to classify the audio. So, we built the model using supervised learning classification algorithms. We used a dataset with 600 audio samples to construct the model. We utilized 480 of these audios for training and the rest for testing.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>Architecture of the model</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_ubbNETDhYNuqH2OE.gif"/>
        </fig>
      
      <p>The various problems identified from engine sound are starter motor fault, diesel injector noise, brake switch fault, turbo problem, water leakage, injector/spares fail, wiring cuts, nozzle diesel flow stops, steering sticky, noise, clipping loose, alternator output not coming, injector not working, air filter damage hose, wall tappet clearance, AC compressor, and air filter assembler, timing chain noise, AC noise, nozzle noise, and injector noise. For training the model, we generated features of the collected audio using MFCCs and performed encoding on labels, which converts labels into integers. Then we split the data into training and testing.</p><p>We built a web interface using the Python and Flask frameworks. We undertake the feature extraction tasks using Python code and then pass the extracted features to the model. The deployed model then classifies the features and outputs the probabilities.</p><p>The main goal is to build a mobile application, VSERV. A mobile application is developed where the proposed model is constructed and deployed. The app was developed using the Flutter framework. Because a mobile device has fewer resources and less power, we convert the ML model (.h5 file) into a TensorFlow Lite (TFLite) file. A TFLite file is a compressed version of the ML model, which consumes fewer resources and is compatible with low-end devices. We connected the app to Firebase for the backend. The user first needs to log in using a mobile number. We will send an OTP to the registered mobile number to verify the user. Later, the user needs to provide the care details in the form present in the app. The user can select the problem from the given list of concerns. If the user does not know about the issue, he can choose the audio option and find out the problem. All he needs to do is switch on the audio option and record the engine sound. The app automatically saves the audio clip and passes it on for processing. The ML model does its job and predicts the vehicle problem.</p><p>VSERV is a mobile application that is mainly developed to help people who have a breakdown in their vehicle in remote areas. The novelty of the VSERV app is to record the breakdown vehicle sound and predict the problem. There is no such kind of application available in the app store. This app best suits mid-range cars and is cost-effective. All the user needs to do is install and register the app on their mobile. In the application, the user needs to register with details about the car. In this app, the users can not only select their problem through a set of given options with common problems but also provide their problem through text if the problem is identifiable, like tire puncture or refilling the petrol. If the problem is unidentifiable, then the user needs to provide the audio of the engine so that we can identify the problem using an ML classifier. The model takes the audio sample as input and identifies the probabilities of the various problems. The model has an accuracy of around 95%. The main usage of this model is to give a basic condition of the vehicle, which helps the mechanic solve the problem quickly. The app also provides solutions to a particular problem and associated videos to solve it, which can be used by the user to solve the problem itself. The following <xref ref-type="fig" rid="fig_2">Figure 2</xref> illustrates the vehicle serving the mobile app.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>a: Home screen; b: Registration; c: OTP verification; d: User profile; e: Vechile profile; f: Recording engine sound; g: Diagonsis report</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/2/img_aJE4ILnR2yzLPhkb.png"/>
        </fig>
      
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>5. Conclusion</title>
      <p>The VSERV Mobile app's innovative approach to roadside assistance marks a significant departure from conventional solutions, setting a new standard in the industry. By harnessing the power of audio analysis, the app not only streamlines the assistance process but also enhances the accuracy and efficiency of identifying and resolving issues. This intelligent use of technology not only addresses immediate concerns but also contributes to a broader narrative of making travel safer and more secure. The seamless integration of cutting-edge features within the VSERV Mobile app speaks to a commitment to user-centric design and functionality. The user experience is elevated through intuitive interfaces, real-time communication capabilities, and a comprehensive suite of tools that empower users to navigate unexpected challenges with ease. This user-centric approach not only improves the overall satisfaction of the service but also fosters a sense of trust and confidence among users, reinforcing VSERV's position as an industry leader. Moreover, the VSERV Mobile app's contribution to minimizing travel disruptions is not just a matter of convenience but a strategic investment in optimizing road safety. By promptly addressing roadside issues and providing timely assistance, the app actively contributes to creating a safer environment for all road users. This commitment to safety underscores VSERV's dedication to not just resolving problems but actively preventing them, thereby creating a positive impact on the overall road ecosystem. As technology continues its relentless evolution, VSERV stands poised at the forefront, anticipating and adapting to emerging trends. The app's forward-thinking approach not only addresses current challenges but also lays the groundwork for a future where more intricate and sophisticated solutions become possible. Whether through the integration of artificial intelligence, further advancements in audio analysis, or other technological breakthroughs, VSERV is positioned to lead the charge in shaping the future of roadside assistance and road safety. </p><p>In conclusion, the VSERV Mobile app is not just a tool for addressing immediate roadside assistance needs; it is a catalyst for transformative change in how we perceive and manage road safety. Through its pioneering technologies, user-centric design, and unwavering commitment to innovation, VSERV is not merely keeping pace with the trajectory of technology but is actively steering it towards a safer and more efficient future for all travelers.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      <p></p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>114</page-range>
          <issue>5</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S</given-names>
              <surname>Helmstetter</surname>
            </name>
            <name>
              <given-names>H</given-names>
              <surname>Paulheim</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/fi13050114</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Collecting a large scale dataset for classifying fake news tweets using weak supervision</article-title>
          <source> Futur. Internet</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>573</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>A</given-names>
              <surname>Zakharchenko</surname>
            </name>
            <name>
              <given-names>T</given-names>
              <surname>Peráček</surname>
            </name>
            <name>
              <given-names>S</given-names>
              <surname>Fedushko</surname>
            </name>
            <name>
              <given-names>Y</given-names>
              <surname>Syerov</surname>
            </name>
            <name>
              <given-names>O</given-names>
              <surname>Trach</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/su13020573</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>When fact-checking and ‘BBC standards’ are helpless: ‘Fake newsworthy event’ manipulation and the reaction of the ‘high-quality media’ on it</article-title>
          <source>Sustainability</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>363-369</page-range>
          <issue>3</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J</given-names>
              <surname>Noureen</surname>
            </name>
            <name>
              <given-names>M</given-names>
              <surname>Asif</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.14569/issn.2156-5570</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Crowdsensing: Socio-technical challenges and opportunities</article-title>
          <source>Int. J. Adv. Comput. Sci. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>17</volume>
          <page-range>210–221</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>Reddy</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Raj</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Gala</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Basava</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11633-019-1216-5</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Text-mining-based fake news detection using ensemble methods</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="conf-paper">
          <volume>34</volume>
          <page-range>549–556</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>T.</given-names>
              <surname>Bian</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Xiao</surname>
            </name>
            <name>
              <given-names>T. Y.</given-names>
              <surname>Xu</surname>
            </name>
            <name>
              <given-names>P. L.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>W. B.</given-names>
              <surname>Huang</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Rong</surname>
            </name>
            <name>
              <given-names>J. Z.</given-names>
              <surname>Huang</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1609/aaai.v34i01.5393</pub-id>
          <article-title>Rumor detection on social media with bi-directional graph convolutional networks</article-title>
          <source>Proceedings of the AAAI Conference on Artificial Intelligence, New York, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>70</volume>
          <page-range>1978-1983</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>K. R.</given-names>
              <surname>Cao</surname>
            </name>
            <name>
              <given-names>B. H.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>H. Y.</given-names>
              <surname>Ding</surname>
            </name>
            <name>
              <given-names>L.</given-names>
              <surname>Lv</surname>
            </name>
            <name>
              <given-names>J. W.</given-names>
              <surname>Tian</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Hu</surname>
            </name>
            <name>
              <given-names>F. K.</given-names>
              <surname>Gong</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TVT.2021.3053093</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Achieving reliable and secure communications in wireless-powered NOMA systems</article-title>
          <source> IEEE Trans. Veh. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>65</volume>
          <page-range>2909-2925</page-range>
          <issue>11</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>P.</given-names>
              <surname>Chen</surname>
            </name>
            <name>
              <given-names>H. Y.</given-names>
              <surname>Liu</surname>
            </name>
            <name>
              <given-names>R. Y.</given-names>
              <surname>Xin</surname>
            </name>
            <name>
              <given-names>T.</given-names>
              <surname>Carval</surname>
            </name>
            <name>
              <given-names>J. L.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>Y. N.</given-names>
              <surname>Xia</surname>
            </name>
            <name>
              <given-names>Z. M.</given-names>
              <surname>Zhao</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1093/comjnl/bxac085</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Effectively detecting operational anomalies in large-scale IoT data infrastructures by using a GAN-based predictive model</article-title>
          <source>Comput. J.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>23</volume>
          <page-range>18855-18863</page-range>
          <issue>10</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Chen</surname>
            </name>
            <name>
              <given-names>Q. C.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>W. M.</given-names>
              <surname>Peng</surname>
            </name>
            <name>
              <given-names>H. T.</given-names>
              <surname>Xu</surname>
            </name>
            <name>
              <given-names>X. D.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names/>
              <surname>W. Q. Xu</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TITS.2022.3161977</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Disparity-based multiscale fusion network for transportation detection</article-title>
          <source>IEEE Trans. Intell. Transp. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>349-361</page-range>
          <issue>2</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <given-names>B.</given-names>
              <surname>Cheng</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Zhu</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Zhao</surname>
            </name>
            <name>
              <given-names>J. L.</given-names>
              <surname>Chen</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/TNSM.2016.2541171</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Situation-aware IoT service coordination using the event-driven SOA paradigm</article-title>
          <source> IEEE Trans. Netw. Serv. Manage.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>187</volume>
          <page-range>83-92</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>F. P.</given-names>
              <surname>Guo</surname>
            </name>
            <name>
              <given-names>W.</given-names>
              <surname>Zhou</surname>
            </name>
            <name>
              <given-names>Q. B.</given-names>
              <surname>Lu</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Zhang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.comcom.2022.02.002</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Path extension similarity link prediction method based on matrix algebra in directed networks</article-title>
          <source>Comput. Commun.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>612</volume>
          <page-range>384–398</page-range>
          <issue>3</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>B.</given-names>
              <surname>Li</surname>
            </name>
            <name>
              <given-names>X. L.</given-names>
              <surname>Zhou</surname>
            </name>
            <name>
              <given-names>Z. K.</given-names>
              <surname>Ning</surname>
            </name>
            <name>
              <given-names>X. Y.</given-names>
              <surname>Guan</surname>
            </name>
            <name>
              <given-names>K. F.</given-names>
              <surname>Yiu</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.ins.2022.08.093</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Dynamic event-triggered security control for networked control systems with cyber-attacks: A model predictive control approach</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="thesis">
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Nasiri</surname>
            </name>
          </person-group>
          <article-title>Deep learning based sound event detection and classification</article-title>
          <source/>
          <year>2021</year>
          <publisher-name>University of South Carolina, Columbia</publisher-name>
          <publisher-loc/>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>1–15</page-range>
          <issue>1-2</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H. H. C.</given-names>
              <surname>Nguyen</surname>
            </name>
            <name>
              <given-names>V. K.</given-names>
              <surname>Solanki</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Van Thang</surname>
            </name>
            <name>
              <given-names>T. T.</given-names>
              <surname>Nguyen</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.5296/npa.v9i1-2.11076</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Resource allocation for heterogeneous cloud computing</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>23-30</page-range>
          <issue>2</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Pala</given-names>
              <surname>Mahesh Kumar</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.51983/ajsat-2016.5.2.931</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>A new human voice recognition system</article-title>
          <source>Asian J. Sci. Appl. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>6223</page-range>
          <issue>12</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Dua</surname>
            </name>
            <name>
              <given-names>S.S.</given-names>
              <surname>Kumar</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Albagory</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Ramalingam</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Dumka</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Singh</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Rashid</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Gehlot</surname>
            </name>
            <name>
              <given-names>S.S.</given-names>
              <surname>Alshamrani</surname>
            </name>
            <name>
              <given-names>A.S.</given-names>
              <surname>AlGhamdi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app12126223</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Developing a speech recognition system for recognizing tonal speech signals using a convolutional neural network</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>181-205</page-range>
          <issue>3</issue>
          <year>2009</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M. A.</given-names>
              <surname>Anusuya</surname>
            </name>
            <name>
              <given-names>S. K.</given-names>
              <surname>Katti</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/proc.1976.10158</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Speech recognition by machine, a review</article-title>
          <source>Int. J. Comput. Sci. Inf. Sec.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>8114</page-range>
          <issue>21</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J G</given-names>
              <surname>Aleixandre</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Elgendi</surname>
            </name>
            <name>
              <given-names>C.</given-names>
              <surname>Menon</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s22218114</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>The use of audio signals for detecting COVID-19: A systematic review</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>7</volume>
          <page-range>175353-175361</page-range>
          <issue/>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Xie</surname>
            </name>
            <name>
              <given-names>K.</given-names>
              <surname>Hu</surname>
            </name>
            <name>
              <given-names>M. Y.</given-names>
              <surname>Zhu</surname>
            </name>
            <name>
              <given-names>J. H.</given-names>
              <surname>Yu</surname>
            </name>
            <name>
              <given-names>Q. B.</given-names>
              <surname>Zhu</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2019.2957572</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Investigation of different CNN-based models for improved bird sound classification</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="book">
          <volume/>
          <page-range/>
          <issue/>
          <year>2015</year>
          <publisher-name>Cham: Springer</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>H. H. C.</given-names>
              <surname>Nguyen</surname>
            </name>
            <name>
              <given-names>H. V.</given-names>
              <surname>Dang</surname>
            </name>
            <name>
              <given-names>N. M. N.</given-names>
              <surname>Pham</surname>
            </name>
            <name>
              <given-names>V. S.</given-names>
              <surname>Le</surname>
            </name>
            <name>
              <given-names>T. T.</given-names>
              <surname>Nguyen</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1007/978-3-319-19024-229</pub-id>
          <article-title>Deadlock detection for resource allocation in heterogeneous distributed platforms</article-title>
          <source>Recent Advances in Information and Communication Technology</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>5550–5559</page-range>
          <issue>5</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <given-names>V. N.</given-names>
              <surname>Thatha</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Donepudi</surname>
            </name>
            <name>
              <given-names>M. A.</given-names>
              <surname>Safali</surname>
            </name>
            <name>
              <given-names>S. P.</given-names>
              <surname>Praveen</surname>
            </name>
            <name>
              <given-names>T. T.</given-names>
              <surname>Nguyen</surname>
            </name>
            <name>
              <given-names>H. H. C.</given-names>
              <surname>Nguyen</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.11591/ijece.v13i5.pp5550-5559</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Security and risk analysis in the cloud with software defined networking architecture</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="conf-paper">
          <volume/>
          <page-range>5455–5466</page-range>
          <issue/>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Ma</surname>
            </name>
            <name>
              <given-names>W.</given-names>
              <surname>Gao</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.18653/v1/2020.coling-main.476</pub-id>
          <article-title>Debunking rumors on twitter with tree transformer</article-title>
          <source>Proceedings of the 28th International Conference on Computational Linguistics, Barcelona, Spain,</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>