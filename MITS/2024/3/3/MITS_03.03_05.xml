<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">MITS</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Mechatronics and Intelligent Transportation Systems</journal-title>
        <abbrev-journal-title abbrev-type="issn">Mechatron. Intell Transp. Syst.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">MITS</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-0218</issn>
      <issn publication-format="print">2958-020X</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-2ucvCms2IIgNeoWCQ1POQWQD3KQGsr2S</article-id>
      <article-id pub-id-type="doi">10.56578/mits030305</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>An Adaptive Multi-Stage Fuzzy Logic Framework for Accurate Detection and Structural Analysis of Road Cracks</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7540-6265</contrib-id>
          <name>
            <surname>Hussain</surname>
            <given-names>Ibrar</given-names>
          </name>
          <email>ibrar786@uop.edu.pk</email>
        </contrib>
        <aff id="aff_1">Department of Mathematics, University of Peshawar, 25120 Peshawar, Pakistan</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>29</day>
        <month>09</month>
        <year>2024</year>
      </pub-date>
      <volume>3</volume>
      <issue>3</issue>
      <fpage>190</fpage>
      <lpage>202</lpage>
      <page-range>190-202</page-range>
      <history>
        <date date-type="received">
          <day>01</day>
          <month>08</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>22</day>
          <month>09</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The degradation of road infrastructure presents significant challenges to public safety and maintenance budgets, with cracks serving as critical indicators of structural instability. Despite extensive advancements, existing detection methodologies frequently fail to address complex surface textures, variable illumination, and diverse crack geometries, resulting in inconsistent performance. An adaptive, multi-stage framework has been developed to mitigate these limitations, integrating advanced image processing techniques with fuzzy logic-based analysis. The proposed approach utilises dynamic contrast enhancement and multi-scale feature extraction to ensure accurate detection of both fine and extensive cracks across heterogeneous surfaces. A fuzzy graph-based methodology is employed to evaluate crack connectivity, while an adapted algorithm is applied to assess continuity and severity. The framework incorporates fuzzy wavelet transforms to enhance feature segmentation and employs morphological techniques for precise crack boundary delineation. Dijkstra’s algorithm is integrated to optimise connectivity analysis, facilitating the identification of critical structural deficiencies. The performance of the model has been rigorously validated through extensive experimental testing, achieving an accuracy rate of 94.2%, with high precision and recall metrics. Comparative analysis with conventional techniques reveals a significant reduction in false detection rates and an improved capacity for capturing intricate crack features. The results underscore the practical utility of the proposed model, demonstrating its scalability and reliability across diverse roadway conditions. By enabling early and accurate identification of structural anomalies, the framework enhances roadway safety, minimises maintenance costs, and supports proactive infrastructure management. The findings highlight its potential as a transformative solution for addressing modern challenges in road maintenance, with implications for improved public safety and resource optimisation.</p></abstract>
      <kwd-group>
        <kwd>Road crack detection</kwd>
        <kwd>Fuzzy logic</kwd>
        <kwd>Multi-scale feature extraction</kwd>
        <kwd>Morphological techniques</kwd>
        <kwd>Connectivity analysis</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="1"/>
        <fig-count count="6"/>
        <table-count count="2"/>
        <ref-count count="20"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>Road infrastructure plays a pivotal role in supporting economic development and ensuring public safety. High-quality roads facilitate the efficient movement of goods and services, promote trade, and enhance connectivity among communities. However, as traffic volume increases and environmental factors contribute to road deterioration, the timely detection and maintenance of road cracks have become critical. According to the Federal Highway Administration (FHWA), nearly 40% of U.S. roads are in poor or mediocre condition, which can lead to safety hazards and increased repair costs [<xref ref-type="bibr" rid="ref_1">1</xref>]. The economic implications of poorly maintained roads are significant, with studies indicating that inadequate infrastructure costs the U.S. economy approximately $3 trillion annually due to lost productivity and increased vehicle operating costs [<xref ref-type="bibr" rid="ref_2">2</xref>]. Consequently, effective road maintenance strategies that incorporate advanced technology for crack detection are essential to prolonging the lifespan of roadways and minimizing financial burdens. Traditional methods for crack inspection primarily rely on manual visual assessments, which are often time-consuming and subjective [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_4">4</xref>], [<xref ref-type="bibr" rid="ref_5">5</xref>], [<xref ref-type="bibr" rid="ref_6">6</xref>], [<xref ref-type="bibr" rid="ref_7">7</xref>]. Inspectors typically walk along the road or drive slowly, visually identifying cracks and other distresses. This approach, while still prevalent, has several drawbacks, including the risk of human error, inconsistency in judgments, and the inability to detect small or subtle cracks that could lead to severe structural failures over time. The subjectivity of manual assessments often results in inconsistent maintenance practices, where some cracks may be overlooked, leading to costly repairs down the line. Moreover, visual inspections may not provide a comprehensive view of the road’s condition, as inspectors may miss cracks that are not readily visible.</p><p>To address these shortcomings, automated techniques using computer vision and image processing have gained prominence in recent years. These methods leverage advanced algorithms to enhance detection accuracy and efficiency, minimizing the dependency on human judgment. Various techniques, including machine learning, deep learning, and mathematical morphology, have been proposed for crack detection, with each offering unique advantages and limitations.</p><p>For instance, machine learning approaches typically require extensive feature engineering and may struggle with complex backgrounds or varying illumination conditions [<xref ref-type="bibr" rid="ref_8">8</xref>]. Deep learning methods, while powerful, often require large labeled datasets for training and can be computationally intensive [<xref ref-type="bibr" rid="ref_9">9</xref>]. Furthermore, many existing methods may not adequately account for the diverse range of crack appearances and road surfaces, leading to potential misclassifications. Recent advancements in crack detection have led to the development of various methodologies [<xref ref-type="bibr" rid="ref_3">3</xref>], [<xref ref-type="bibr" rid="ref_10">10</xref>], [<xref ref-type="bibr" rid="ref_11">11</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>], [<xref ref-type="bibr" rid="ref_13">13</xref>], each with its own strengths and weaknesses. For example, Zhang and Cheng [<xref ref-type="bibr" rid="ref_8">8</xref>] proposed a deep learning-based approach for crack detection, which demonstrated promising results in detecting large cracks in well-lit environments. However, the effectiveness of deep learning is highly dependent on the quality and quantity of training data. Many datasets used for training are often limited in size and diversity, resulting in models that may not generalize well to unseen data or different environmental conditions.</p><p>Another study by Ahmadi et al. [<xref ref-type="bibr" rid="ref_9">9</xref>] employed image processing techniques coupled with machine learning classifiers for road crack detection. While their approach improved the accuracy of crack detection compared to traditional methods, it still faced challenges with noise and varying textures. The reliance on specific features extracted from the images made the model sensitive to changes in road surface conditions, such as shadows, dirt, and surface reflections. As a result, cracks that are partially obscured or located in shadowed areas may go undetected, undermining the overall efficacy of the method. </p><p>A further examination of existing methodologies reveals that many studies focus primarily on a single aspect of crack detection, whether it be segmentation, feature extraction, or classification [<xref ref-type="bibr" rid="ref_14">14</xref>], [<xref ref-type="bibr" rid="ref_15">15</xref>], [<xref ref-type="bibr" rid="ref_16">16</xref>], [<xref ref-type="bibr" rid="ref_17">17</xref>], [<xref ref-type="bibr" rid="ref_18">18</xref>], [<xref ref-type="bibr" rid="ref_19">19</xref>]. For instance, Ashraf et al. [<xref ref-type="bibr" rid="ref_17">17</xref>] utilized multi-scale feature aggregation and transformer (M-SFT)-based attention mechanisms that enable precise crack detection and segmentation on road pavement materials by capturing both global and local context, improving model accuracy. This approach effectively adapts to varying crack scales and orientations, enhancing the robustness of the detection model in real-world applications. The computational complexity of transformer-based attention mechanisms may lead to longer processing times, making real-time deployment challenging on devices with limited resources. Additionally, model performance can be sensitive to high-quality training data, which may not always be available or consistently labeled in road pavement images and did not incorporate subsequent classification stages, limiting the overall applicability of the approach in real-world scenarios where classification of detected cracks is essential for prioritizing maintenance.</p><p>Given these limitations, there is a clear need for a more comprehensive and integrated approach to road crack detection. The proposed multi-stage method aims to address the shortcomings of existing techniques [<xref ref-type="bibr" rid="ref_9">9</xref>], [<xref ref-type="bibr" rid="ref_17">17</xref>], [<xref ref-type="bibr" rid="ref_20">20</xref>] by combining advanced preprocessing fuzzy techniques, feature extraction, segmentation, and classification in a cohesive framework. This approach not only enhances the robustness of crack detection but also improves the ability to generalize across varying conditions and road types.</p><p>The proposed method begins with image preprocessing, where Gaussian filtering and fuzzy contrast enhancement improve image quality and enhance crack visibility. This is followed by multi-scale feature extraction using a fuzzy discrete wavelet transform, which captures both detailed and approximate crack structures across scales. The segmentation phase employs mathematical morphology to emphasize line-like structures characteristic of cracks, followed by fuzzy-based thresholding to optimize crack isolation, reducing sensitivity to noise and lighting variations. Next, a fuzzy graph-based modeling approach represents the detected crack structures, enabling an in-depth analysis of crack connectivity, topology, and continuity. Each crack pixel is treated as a graph node, allowing the model to assess continuity, directionality, and structure robustness using an adapted Dijkstra's algorithm. This graph-based assessment of crack connectivity and orientation provides valuable insights for prioritizing maintenance efforts based on crack severity and distribution.</p><p>The primary objective of this research is to develop a robust and adaptive multi-stage road crack detection model capable of addressing the challenges posed by complex road textures, varying lighting conditions, and diverse crack geometries. Specifically, the study aims to enhance detection accuracy by integrating advanced image processing techniques with fuzzy logic, ensuring reliable segmentation and multi-scale feature capture. The proposed model seeks to minimize false detection rates and effectively identify fine and irregular cracks, providing a scalable solution for accurate and proactive infrastructure management (refer to <xref ref-type="fig" rid="fig_1">Figure 1</xref>).</p><p>This study presents a novel model for road crack detection that effectively integrates fuzzy logic with graph theory to address the limitations of existing approaches. By employing fuzzy contrast enhancement, wavelet-based multi-scale feature extraction, and a graph-based representation of cracks, the proposed model achieves improved accuracy and robust performance under diverse conditions. These advancements facilitate the reliable detection of fine cracks and irregular patterns, providing distinct advantages over conventional models, such as those proposed by Ashraf et al. [<xref ref-type="bibr" rid="ref_17">17</xref>] and Xu et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], which often struggle with complex textures and branching cracks.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Graphical abstract of the propose model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_1JedIYyhjUVoo9Yg.png"/>
        </fig>
      
    </sec>
    <sec sec-type="">
      <title>2. Propose mathematical approach</title>
      <p>The proposed mathematical approach for road crack detection combines multiple advanced techniques to enhance image clarity, identify crack structures, and facilitate accurate feature extraction. First, the Gaussian filter smooths the image by reducing noise, improving the visibility of crack patterns without compromising edge information. Following this, fuzzy contrast enhancement adapts intensity levels using fuzzy membership functions, highlighting cracks more effectively in complex road textures.</p><p>The approach then employs a fuzzy wavelet transform, enabling multi-scale feature extraction and capturing fine details across varying scales for robust crack detection. Morphological operations, such as top-hat and bottom-hat transformations, further emphasize crack-like structures by isolating bright and dark patterns in the image.</p><p>To represent crack connectivity, a fuzzy graph-based model is applied, where each crack pixel is treated as a node in a graph. Fuzzy adjacency and degree matrices are used to construct a fuzzy graph Laplacian, which encapsulates the spatial and intensity-based relationships between nodes, allowing for effective connectivity analysis. Finally, feature extraction methods, including crack length and curvature, provide geometrical descriptors to support classification and analysis. These combined techniques offer a comprehensive and adaptable approach to accurately detect and characterize road cracks under varying conditions.</p>
      
        <sec>
          
            <title>2.1. Preprocessing</title>
          
          <p>Preprocessing is a critical step in road crack detection as it prepares raw input images for advanced analysis. In the proposed model, the Gaussian filter is employed for noise reduction and image smoothing, a necessary process to enhance crack visibility. By mitigating random noise while preserving essential edge details, the Gaussian filter ensures that the image retains its structural integrity, which is crucial for accurately detecting road cracks.</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mve7nunz03">
                <mml:mi>G</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mi>π</mml:mi>
                    <mml:msup>
                      <mml:mi>σ</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:msup>
                  <mml:mi>e</mml:mi>
                  <mml:mrow>
                    <mml:mo>−</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msup>
                          <mml:mi>x</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                        <mml:msup>
                          <mml:mi>y</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                        <mml:msup>
                          <mml:mi>σ</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:msup>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="m71aok0199">
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
  </mml:math>
</inline-formula> are the spatial coordinates, <inline-formula>
  <mml:math id="mfobes2o0p">
    <mml:mi>σ</mml:mi>
  </mml:math>
</inline-formula> controls the spread (standard deviation) of the Gaussian function.</p><p>By applying the Gaussian filter to the image, the resulting smoothed image makes crack patterns more noticeable, facilitating easier detection in later stages of the analysis. This approach ensures that the model can focus on the essential details, such as crack locations and shapes, while minimizing the influence of noise, which can lead to false detections. Convolve the Gaussian filter $G<inline-formula>
  <mml:math id="m4i2d6zjsq">
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>I<inline-formula>
  <mml:math id="momgjxsoog">
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>I_{\text {smosth}}$:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="m3h5rva644">
                <mml:msub>
                  <mml:mi>I</mml:mi>
                  <mml:mrow>
                    <mml:mtext>smooth </mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>⋅</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mi>x</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mi>I</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mi>v</mml:mi>
                <mml:mi>G</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>v</mml:mi>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>u</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                  <mml:mi>k</mml:mi>
                </mml:munderover>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>v</mml:mi>
                    <mml:mi>k</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                  <mml:mi>k</mml:mi>
                </mml:munderover>
              </mml:math>
            </disp-formula>
          
          <p>where, $k<inline-formula>
  <mml:math id="mmv9tf1ati">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>3 \sigma$.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Fuzzy logic model</title>
          
          <p>The fuzzy logic model in the proposed road crack detection framework introduces a flexible approach for handling the inherent uncertainty and imprecision in image data. Fuzzy logic allows the system to model the complexity of crack patterns, which often exhibit variations in size, shape, and intensity due to environmental factors and image quality. By incorporating fuzzy logic, the model can more accurately classify ambiguous or borderline pixels that traditional binary methods might misclassify. This results in a more robust detection process, particularly in cases of irregular crack patterns or low-contrast images. The fuzzy logic model enhances the overall precision and adaptability of the detection system, improving its performance across varied road conditions and crack geometries.</p>
          
            <sec>
              
                <title>2.2.1 Fuzzy contrast enhancement</title>
              
              <p>To improve the visibility of road cracks in an image, fuzzy contrast enhancement is applied using fuzzy histogram equalization. The idea is to modify the intensity levels of the image based on fuzzy membership functions, which can adjust the contrast more effectively than traditional methods, especially when dealing with varied lighting conditions or noisy images.</p><p>The fuzzy contrast enhancement procedure starts by defining the probability distribution of the intensity levels in the image. Let <inline-formula>
  <mml:math id="mvv4z9v3nj">
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> represent the probability of each intensity level $i<inline-formula>
  <mml:math id="mua8jy6lap">
    <mml:mo>.</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="m3coxn9tjl">
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mfrac>
      <mml:mrow>
        <mml:mi>f</mml:mi>
        <mml:mi>i</mml:mi>
        <mml:mo>(</mml:mo>
        <mml:mo>)</mml:mo>
      </mml:mrow>
      <mml:mi>N</mml:mi>
    </mml:mfrac>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mz0k5n1ugn">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>f(i)<inline-formula>
  <mml:math id="m86qg6sdag">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
  </mml:math>
</inline-formula>i<inline-formula>
  <mml:math id="m0ux2y5rir">
    <mml:mo>,</mml:mo>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>N<inline-formula>
  <mml:math id="mrjm22gp46">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>z</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>\mu_{\text {contrast }}<inline-formula>
  <mml:math id="m5bvxntu0h">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mo>.</mml:mo>
  </mml:math>
</inline-formula>P(i)$ with a value that determines how much enhancement should be applied to it. The function is designed as follows:</p>
              
                <disp-formula>
                  <label>(3)</label>
                  <mml:math id="mawzudxj8e">
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>contrast</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mi>P</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mrow>
                      <mml:mo>{</mml:mo>
                      <mml:mo fence="true"/>
                      <mml:mtable columnalign="left left" columnspacing="1em" rowspacing=".2em">
                        <mml:mtr>
                          <mml:mtd>
                            <mml:mn>1</mml:mn>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext>if </mml:mtext>
                            <mml:mtext>High Threshold</mml:mtext>
                            <mml:mi>P</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mo>(</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:mo>≥</mml:mo>
                            <mml:mo>,</mml:mo>
                          </mml:mtd>
                        </mml:mtr>
                        <mml:mtr>
                          <mml:mtd>
                            <mml:mfrac>
                              <mml:mrow>
                                <mml:mi>P</mml:mi>
                                <mml:mi>i</mml:mi>
                                <mml:mo>(</mml:mo>
                                <mml:mo>)</mml:mo>
                              </mml:mrow>
                              <mml:mtext>High Threshold</mml:mtext>
                            </mml:mfrac>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext>otherwise</mml:mtext>
                            <mml:mo>.</mml:mo>
                          </mml:mtd>
                        </mml:mtr>
                      </mml:mtable>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              <p> where, the fuzzy membership function <inline-formula>
  <mml:math id="m7z4zs5lpy">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>contrast</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
  </mml:math>
</inline-formula> is defined to modify intensity levels based on their probability <inline-formula>
  <mml:math id="meoi4r2el8">
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula>. The function operates in two parts:</p><p>•When the intensity probability <inline-formula>
  <mml:math id="mbw3frghfl">
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> is greater than or equal to the high threshold, the membership value is set to 1 , meaning the contrast enhancement effect is applied fully.</p><p>•For intensity probabilities lower than the threshold, the membership function is proportional to <inline-formula>
  <mml:math id="mrp1n7c4vj">
    <mml:mi>P</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula>, meaning the enhancement effect is scaled down. This allows for smoother transitions between regions of low and high contrast.</p><p>This approach contrasts with traditional contrast enhancement methods like histogram equalization, which might overly adjust intensity levels and introduce artifacts. By using fuzzy logic, the contrast enhancement process becomes adaptive and robust, especially in the presence of noise or varying illumination. The use of fuzzy contrast enhancement in crack detection allows for better visualization of cracks, which are often characterized by subtle intensity differences from their surroundings. This enhancement ensures that cracks, regardless of their size or orientation, are more easily detected, especially in low-contrast or noisy images. The gradual nature of the fuzzy adjustment also ensures that noise is not overly amplified, making the model more robust in real-world conditions.</p>
            </sec>
          
          
            <sec>
              
                <title>2.2.2 Fuzzy cumulative distribution function (cdf)</title>
              
              <p>In the proposed road crack detection model, the Fuzzy Cumulative Distribution Function (CDF) is applied to enhance contrast by adjusting pixel intensities based on their membership values. The cumulative distribution, <inline-formula>
  <mml:math id="m6ys43lslm">
    <mml:msub>
      <mml:mrow>
        <mml:mi data-mjx-auto-op="false">CDF</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>i</mml:mi>
  </mml:math>
</inline-formula>, is computed by summing the fuzzy membership values, <inline-formula>
  <mml:math id="m9n005pzvg">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>contrast</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula>, of pixel intensities up to a given level ig (Eq. (4)). This cumulative measure helps in amplifying the contrast selectively, enhancing the visibility of subtle crack patterns.</p><p>To update each pixel intensity <inline-formula>
  <mml:math id="mtf78sjht6">
    <mml:mi>I</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
  </mml:math>
</inline-formula> for improved clarity, the model employs the fuzzy CDF in Eq. (5). The enhanced intensity, <inline-formula>
  <mml:math id="m82mcxzmic">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mrow>
        <mml:mtext>enhanced</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
  </mml:math>
</inline-formula>, is adjusted by normalizing the fuzzy CDF , scaled by the maximum intensity $L<inline-formula>
  <mml:math id="mq1ugjfbmo">
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mn>255</mml:mn>
  </mml:math>
</inline-formula>M, N$. This results in a contrast-enhanced image where fine details of cracks are more pronounced, aiding in more accurate detection.</p>
              
                <disp-formula>
                  <label>(4)</label>
                  <mml:math id="mcxxu8zmq9">
                    <mml:msub>
                      <mml:mtext>CDF</mml:mtext>
                      <mml:mrow>
                        <mml:mtext>fuzzy</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>contrast</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>0</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:munderover>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(5)</label>
                  <mml:math id="mr0ta7utn7">
                    <mml:msub>
                      <mml:mi>I</mml:mi>
                      <mml:mrow>
                        <mml:mtext>enhanced</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>⋅</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mi>L</mml:mi>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mtext>CDF</mml:mtext>
                          <mml:mrow>
                            <mml:mtext>fuzzy</mml:mtext>
                          </mml:mrow>
                        </mml:msub>
                        <mml:msub>
                          <mml:mtext>CDF</mml:mtext>
                          <mml:mrow>
                            <mml:mtext>min</mml:mtext>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>(</mml:mo>
                        <mml:mo>(</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mo>)</mml:mo>
                        <mml:mo>−</mml:mo>
                        <mml:mi>I</mml:mi>
                        <mml:mi>x</mml:mi>
                        <mml:mi>y</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>M</mml:mi>
                        <mml:mi>N</mml:mi>
                        <mml:mo>⋅</mml:mo>
                        <mml:mo>−</mml:mo>
                        <mml:msub>
                          <mml:mtext>CDF</mml:mtext>
                          <mml:mrow>
                            <mml:mtext>min</mml:mtext>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mn>1</mml:mn>
                  </mml:math>
                </disp-formula>
              
            </sec>
          
          
            <sec>
              
                <title>2.2.3 Fuzzy wavelet transform for multi-scale feature extraction</title>
              
              <p>The wavelet transform allows for capturing details at different scales. Integrating fuzzy logic improves resilience against variations in crack characteristics. For each level $j$, calculate the fuzzy approximation and detail coefficients:</p>
              
                <disp-formula>
                  <label>(6)</label>
                  <mml:math id="mnkbs1jv09">
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>A</mml:mi>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>intensity </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>⋅</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>ϕ</mml:mi>
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>n</mml:mi>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>n</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mo>−</mml:mo>
                          <mml:msup>
                            <mml:mn>2</mml:mn>
                            <mml:mi>j</mml:mi>
                          </mml:msup>
                        </mml:mrow>
                        <mml:msup>
                          <mml:mn>2</mml:mn>
                          <mml:mi>j</mml:mi>
                        </mml:msup>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(7)</label>
                  <mml:math id="m51r6o2vzx">
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>H</mml:mi>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>intensity </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>ψ</mml:mi>
                      <mml:mi>H</mml:mi>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>⋅</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>n</mml:mi>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>n</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mo>−</mml:mo>
                          <mml:msup>
                            <mml:mn>2</mml:mn>
                            <mml:mi>j</mml:mi>
                          </mml:msup>
                        </mml:mrow>
                        <mml:msup>
                          <mml:mn>2</mml:mn>
                          <mml:mi>j</mml:mi>
                        </mml:msup>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(8)</label>
                  <mml:math id="mo50vbbtxv">
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>V</mml:mi>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>intensity </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>ψ</mml:mi>
                      <mml:mi>V</mml:mi>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>⋅</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>n</mml:mi>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>n</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mo>−</mml:mo>
                          <mml:msup>
                            <mml:mn>2</mml:mn>
                            <mml:mi>j</mml:mi>
                          </mml:msup>
                        </mml:mrow>
                        <mml:msup>
                          <mml:mn>2</mml:mn>
                          <mml:mi>j</mml:mi>
                        </mml:msup>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(9)</label>
                  <mml:math id="mx4ea8kp8t">
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>D</mml:mi>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>μ</mml:mi>
                      <mml:mrow>
                        <mml:mtext>intensity </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>ψ</mml:mi>
                      <mml:mi>D</mml:mi>
                    </mml:msub>
                    <mml:mo>(</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>⋅</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mi>y</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>n</mml:mi>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>n</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mo>−</mml:mo>
                          <mml:msup>
                            <mml:mn>2</mml:mn>
                            <mml:mi>j</mml:mi>
                          </mml:msup>
                        </mml:mrow>
                        <mml:msup>
                          <mml:mn>2</mml:mn>
                          <mml:mi>j</mml:mi>
                        </mml:msup>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              <p> where, <inline-formula>
  <mml:math id="m740r4ezde">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>intensity</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mo>(</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mi>I</mml:mi>
    <mml:mi>n</mml:mi>
  </mml:math>
</inline-formula> is the fuzzy membership function based on pixel intensity. <inline-formula>
  <mml:math id="meuden8aae">
    <mml:mi>ϕ</mml:mi>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mxk848mcqe">
    <mml:mi>ψ</mml:mi>
  </mml:math>
</inline-formula> represent the scaling and wavelet functions, respectively.</p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>2.3. Mathematical morphology for crack segmentation</title>
          
          <p>Morphological operations, such as erosion, dilation, opening, and closing, are used to emphasize and refine crack-like structures in road images by manipulating shapes and boundaries. These techniques enhance line structures, making cracks more visible while reducing noise and small objects. By adapting to various image conditions, they effectively highlight cracks, improving detection accuracy.</p><p>Top-Hat (enhances bright structures):</p>
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="mkmp1mwldm">
                <mml:mtext> Top-Hat </mml:mtext>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>∘</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mi>I</mml:mi>
                <mml:mi>I</mml:mi>
                <mml:mi>I</mml:mi>
                <mml:mi>B</mml:mi>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="my3s9llfz4">
    <mml:mo>∘</mml:mo>
  </mml:math>
</inline-formula> denotes morphological opening.</p><p>Bottom-Hat (enhances dark structures):</p>
          
            <disp-formula>
              <label>(11)</label>
              <mml:math id="m781eddb42">
                <mml:mtext> Bottom-Hat </mml:mtext>
                <mml:mo>(</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>⋅</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mi>I</mml:mi>
                <mml:mi>I</mml:mi>
                <mml:mi>B</mml:mi>
                <mml:mi>I</mml:mi>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="m7u067g6qo">
    <mml:mo>⋅</mml:mo>
  </mml:math>
</inline-formula> denotes morphological closing.</p>
        </sec>
      
      
        <sec>
          
            <title>2.4. Fuzzy graph-based model for crack structure representation</title>
          
          <p>The fuzzy graph-based model for crack structure representation is a technique used to model and analyze the connectivity and structure of road cracks in an image. In this approach, the pixels representing cracks are treated as nodes in a graph, with edges representing relationships between adjacent nodes. The fuzzy logic component is applied to capture the uncertainty in crack structures, such as varying pixel intensities and connectivity patterns. By using fuzzy relationships, the model accounts for variations in crack width, orientation, and continuity, allowing for more robust and flexible detection of crack patterns in complex road surfaces. The edges in the graph are weighted based on factors like intensity similarity and spatial proximity between nodes, enhancing the model's ability to detect fine, branching, or irregular crack patterns that are typically challenging for traditional methods.</p>
          
            <sec>
              
                <title>2.4.1 Fuzzy adjacency matrix $a_{fuzzy}$</title>
              
              <p>In the proposed road crack detection model, a Fuzzy Adjacency Matrix Afuzzy is constructed to represent the relationships between neighboring pixels or nodes, enhancing the model's ability to detect crack continuity. The entries of this matrix are "fuzzified" based on two criteria: the distance <inline-formula>
  <mml:math id="m91ddnpl4m">
    <mml:msub>
      <mml:mi>d</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> between nodes $i<inline-formula>
  <mml:math id="mv4wie0bip">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>j<inline-formula>
  <mml:math id="mso8qxd0jk">
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>I_i<inline-formula>
  <mml:math id="m62yob9odt">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>I_j<inline-formula>
  <mml:math id="mvt2osg3o0">
    <mml:mo>(</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mi>E</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mn>12</mml:mn>
  </mml:math>
</inline-formula>d_i<inline-formula>
  <mml:math id="m4qkuq07sf">
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>{ }_j<inline-formula>
  <mml:math id="mr76aoubcj">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>d<inline-formula>
  <mml:math id="mnw4rxr2sg">
    <mml:mo>,</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>A_{\text {fuzzy}, i, j}<inline-formula>
  <mml:math id="mcdpf50f5s">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>:</mml:mo>
  </mml:math>
</inline-formula>\mu_{\text {proximity }}\left(d_{i, j}\right)<inline-formula>
  <mml:math id="mi3q04nwfh">
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>\mu_{\text {intensity }}\left(I_i, I_j\right)$, which measures the similarity in intensity. Otherwise, the adjacency value is set to zero.</p><p>This fuzzy adjacency matrix helps the model emphasize connections between closely located and similar-intensity pixels, enhancing its ability to follow the path of cracks accurately.</p>
              
                <disp-formula>
                  <label>(12)</label>
                  <mml:math id="m69l9qrdx4">
                    <mml:msub>
                      <mml:mi>A</mml:mi>
                      <mml:mrow>
                        <mml:mtext>fuzzy</mml:mtext>
                        <mml:mo>,</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:mrow>
                      <mml:mo>{</mml:mo>
                      <mml:mo fence="true"/>
                      <mml:mtable columnalign="left left" columnspacing="1em" rowspacing=".2em">
                        <mml:mtr>
                          <mml:mtd>
                            <mml:msub>
                              <mml:mi>μ</mml:mi>
                              <mml:mrow>
                                <mml:mtext>proximity</mml:mtext>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>d</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                                <mml:mo>,</mml:mo>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>μ</mml:mi>
                              <mml:mrow>
                                <mml:mtext>intensity</mml:mtext>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>I</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>I</mml:mi>
                              <mml:mi>j</mml:mi>
                            </mml:msub>
                            <mml:mo>(</mml:mo>
                            <mml:mo>)</mml:mo>
                            <mml:mo>⋅</mml:mo>
                            <mml:mo>(</mml:mo>
                            <mml:mo>,</mml:mo>
                            <mml:mo>)</mml:mo>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext>if </mml:mtext>
                            <mml:msub>
                              <mml:mi>d</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                                <mml:mo>,</mml:mo>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>≤</mml:mo>
                            <mml:mo>,</mml:mo>
                            <mml:mi>d</mml:mi>
                          </mml:mtd>
                        </mml:mtr>
                        <mml:mtr>
                          <mml:mtd>
                            <mml:mn>0</mml:mn>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext>otherwise.</mml:mtext>
                          </mml:mtd>
                        </mml:mtr>
                      </mml:mtable>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
              <p>The matrix <inline-formula>
  <mml:math id="mo9fibhmh2">
    <mml:msub>
      <mml:mi>A</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is constructed using two primary factors: **distance** <inline-formula>
  <mml:math id="mnlzzhzp81">
    <mml:msub>
      <mml:mi>d</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> and ** intensity similarity** <inline-formula>
  <mml:math id="mguiauiw2k">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula>, <inline-formula>
  <mml:math id="moeetap5ww">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mi>j</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula>, which help establish the strength of connectivity between any two pixels (or nodes) in the image. The distance <inline-formula>
  <mml:math id="mwlzy459uv">
    <mml:msub>
      <mml:mi>d</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> measures how far apart two neighboring pixels are in the image. In a typical image, the spatial proximity of pixels is a natural indicator of their potential relationship in terms of belonging to the same object or structure, such as a road crack. In the fuzzy model, the proximity function <inline-formula>
  <mml:math id="m700av49dq">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>proximity</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msub>
        <mml:mi>d</mml:mi>
        <mml:mrow>
          <mml:mi>i</mml:mi>
          <mml:mi>j</mml:mi>
          <mml:mo>,</mml:mo>
        </mml:mrow>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula> is used to quantify the likelihood that two pixels are neighbors based on their distance.</p><p>The intensity similarity <inline-formula>
  <mml:math id="mjw8b07yol">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="mj7dq1vsmb">
    <mml:msub>
      <mml:mi>I</mml:mi>
      <mml:mi>j</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> between two pixels captures their brightness values (or any other feature of the image, such as texture). Since cracks are often distinguishable based on intensity differences from their surroundings, intensity similarity helps refine the adjacency matrix by ensuring that only pixels with similar intensities are connected. The fuzzy membership function <inline-formula>
  <mml:math id="mpvx2yl8c9">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>intensity</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msub>
        <mml:mi>I</mml:mi>
        <mml:mi>i</mml:mi>
      </mml:msub>
      <mml:msub>
        <mml:mi>I</mml:mi>
        <mml:mi>j</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula> is used to quantify this similarity.</p><p>The fuzzification process in the fuzzy adjacency matrix is governed by two main factors:</p><p>•If the distance between pixels <inline-formula>
  <mml:math id="m3d8817vm8">
    <mml:msub>
      <mml:mi>d</mml:mi>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
        <mml:mo>,</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is within a predefined threshold $d<inline-formula>
  <mml:math id="mrphpjndw2">
    <mml:mo>,</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>A_{\text {fuzzy}, i, j}<inline-formula>
  <mml:math id="mh5wny0drx">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mo>:</mml:mo>
  </mml:math>
</inline-formula>\mu_{\text {proximity}}\left(d_{i, j}\right)<inline-formula>
  <mml:math id="mnqomc1b3o">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>\mu_{\text {intensity}}\left(I_i, I_j\right)<inline-formula>
  <mml:math id="mvijhmpszx">
    <mml:mo>.</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>•</mml:mo>
    <mml:mi>T</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula>d_{i, j}<inline-formula>
  <mml:math id="mpwsfvg654">
    <mml:mi>e</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>d$, indicating that the two pixels are far apart, their adjacency value is set to zero. This reflects the fact that distant pixels are unlikely to belong to the same crack structure and thus should not be connected.</p>
            </sec>
          
          
            <sec>
              
                <title>2.4.2 Fuzzy degree matrix $d_{fuzzy}$</title>
              
              <p>The Fuzzy Degree Matrix <inline-formula>
  <mml:math id="m0ztgfijep">
    <mml:msub>
      <mml:mi>D</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is used to quantify the connectivity strength of each node (or pixel) within the network of detected crack patterns. Specifically, each diagonal entry <inline-formula>
  <mml:math id="m9e73jtjfy">
    <mml:msub>
      <mml:mi>D</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
        <mml:mo>,</mml:mo>
        <mml:mo>,</mml:mo>
        <mml:mi>i</mml:mi>
        <mml:mi>i</mml:mi>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> represents the total sum of fuzzy adjacency values, <inline-formula>
  <mml:math id="mgosr8tcaz">
    <mml:msub>
      <mml:mi>A</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
        <mml:mo>,</mml:mo>
        <mml:mo>,</mml:mo>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula>, for all neighboring nodes $j<inline-formula>
  <mml:math id="mmnqt43gkp">
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>i$ (Eq. (13)). This sum effectively captures the intensity of connections or “fuzzy edges” associated with each node, providing a measure of how strongly it is linked to its surrounding nodes.</p><p>By accumulating these connection values, the fuzzy degree matrix helps enhance the model's sensitivity to continuous crack paths, supporting more reliable detection of complex and branching cracks. This matrix plays a crucial role in the structural analysis of cracks by weighing nodes with higher connectivity, which are more likely part of the crack pattern.</p>
              
                <disp-formula>
                  <label>(13)</label>
                  <mml:math id="mmrb0p1agg">
                    <mml:msub>
                      <mml:mi>D</mml:mi>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mi data-mjx-auto-op="false">fuzzy</mml:mi>
                        </mml:mrow>
                        <mml:mo>,</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>A</mml:mi>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mi data-mjx-auto-op="false">fuzzy</mml:mi>
                        </mml:mrow>
                        <mml:mo>,</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:munderover>
                  </mml:math>
                </disp-formula>
              
            </sec>
          
          
            <sec>
              
                <title>2.4.3 Fuzzy graph laplacian $l_{fuzzy}$</title>
              
              <p>In our crack detection model, the Fuzzy Graph Laplacian Lfuzzy is introduced to capture the connectivity within the network of pixels and to analyze the structure of the cracks. The Laplacian matrix <inline-formula>
  <mml:math id="ma4l2s5dv8">
    <mml:msub>
      <mml:mi>L</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is computed as the difference between the fuzzy degree matrix <inline-formula>
  <mml:math id="mwljalo0gf">
    <mml:msub>
      <mml:mi>D</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> and the fuzzy adjacency matrix <inline-formula>
  <mml:math id="mywu70wrjd">
    <mml:msub>
      <mml:mi>A</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> (Eq. (14)). This matrix provides valuable insights into the spatial relationships between nodes, allowing the model to better distinguish crack patterns from the surrounding background.</p><p>Each element <inline-formula>
  <mml:math id="maeo6qh06r">
    <mml:msub>
      <mml:mi>L</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
        <mml:mo>,</mml:mo>
        <mml:mo>,</mml:mo>
        <mml:mi>i</mml:mi>
        <mml:mi>j</mml:mi>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> of the Laplacian matrix is defined as follows (Eq. (15)): if <inline-formula>
  <mml:math id="m0wjx4hvog">
    <mml:mi>i</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mo>=</mml:mo>
  </mml:math>
</inline-formula>, the entry is set to the diagonal value of the degree matrix <inline-formula>
  <mml:math id="mi7ga1x3ef">
    <mml:msub>
      <mml:mi>D</mml:mi>
      <mml:mrow>
        <mml:mtext>fuzzy</mml:mtext>
        <mml:mo>,</mml:mo>
        <mml:mo>,</mml:mo>
        <mml:mi>i</mml:mi>
        <mml:mi>i</mml:mi>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula>, representing the total connectivity strength of node $i<inline-formula>
  <mml:math id="me3vhcod0u">
    <mml:mo>.</mml:mo>
    <mml:mi>I</mml:mi>
    <mml:mi>f</mml:mi>
  </mml:math>
</inline-formula>i=j<inline-formula>
  <mml:math id="mpre1uuk0h">
    <mml:mo>,</mml:mo>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>j</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>e</mml:mi>
  </mml:math>
</inline-formula>A_{\text {fuzzy}, i, j}<inline-formula>
  <mml:math id="mzefqwvnp4">
    <mml:mo>,</mml:mo>
    <mml:mi>w</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>i<inline-formula>
  <mml:math id="mtxzqg94rb">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>j$. This structure allows the Laplacian matrix to highlight the edges and boundaries of the cracks, supporting more precise crack detection.</p>
              
                <disp-formula>
                  <label>(14)</label>
                  <mml:math id="m9ubsewecx">
                    <mml:msub>
                      <mml:mi>L</mml:mi>
                      <mml:mrow>
                        <mml:mtext>fuzzy </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>D</mml:mi>
                      <mml:mrow>
                        <mml:mtext>fuzzy</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>A</mml:mi>
                      <mml:mrow>
                        <mml:mtext>fuzzy</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:mo>−</mml:mo>
                  </mml:math>
                </disp-formula>
              
              
                <disp-formula>
                  <label>(15)</label>
                  <mml:math id="mtwhosizey">
                    <mml:msub>
                      <mml:mi>L</mml:mi>
                      <mml:mrow>
                        <mml:mtext>fuzzy</mml:mtext>
                        <mml:mo>,</mml:mo>
                        <mml:mo>,</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:mrow>
                      <mml:mo>{</mml:mo>
                      <mml:mo fence="true"/>
                      <mml:mtable columnalign="left left" columnspacing="1em" rowspacing=".2em">
                        <mml:mtr>
                          <mml:mtd>
                            <mml:msub>
                              <mml:mi>D</mml:mi>
                              <mml:mrow>
                                <mml:mrow>
                                  <mml:mi data-mjx-auto-op="false">fuzzy</mml:mi>
                                </mml:mrow>
                                <mml:mo>,</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mi>i</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext> if </mml:mtext>
                            <mml:mi>i</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mo>=</mml:mo>
                          </mml:mtd>
                        </mml:mtr>
                        <mml:mtr>
                          <mml:mtd>
                            <mml:mo>−</mml:mo>
                            <mml:msub>
                              <mml:mi>A</mml:mi>
                              <mml:mrow>
                                <mml:mrow>
                                  <mml:mi data-mjx-auto-op="false">fuzzy</mml:mi>
                                </mml:mrow>
                                <mml:mo>,</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mtd>
                          <mml:mtd>
                            <mml:mtext> if </mml:mtext>
                            <mml:mi>i</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mo>≠</mml:mo>
                          </mml:mtd>
                        </mml:mtr>
                      </mml:mtable>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
              
            </sec>
          
          
            <sec>
              
                <title>2.4.4 Path length analysis with fuzzy connectivity</title>
              
              <p>Using Dijkstra's algorithm adapted for fuzzy weights, we calculate the shortest paths between nodes, providing insights into crack continuity, see <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p>
              
                <disp-formula>
                  <label>(16)</label>
                  <mml:math id="m31rxke2gv">
                    <mml:msub>
                      <mml:mtext>Fuzzy Path Length</mml:mtext>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                        <mml:mo>,</mml:mo>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:mo>min</mml:mo>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>k</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:munderover>
                    <mml:mfrac>
                      <mml:mn>1</mml:mn>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>μ</mml:mi>
                          <mml:mrow>
                            <mml:mtext>connectivity</mml:mtext>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>,</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <mml:math id="mcsyw4r9by">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mrow>
        <mml:mtext>connectivity</mml:mtext>
      </mml:mrow>
    </mml:msub>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>,</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msub>
        <mml:mi>x</mml:mi>
        <mml:mi>k</mml:mi>
      </mml:msub>
      <mml:msub>
        <mml:mi>y</mml:mi>
        <mml:mi>k</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula> represents the fuzzy connectivity strength for crack segments.</p>
              
                <fig id="fig_2">
                  <label>Figure 2</label>
                  <caption>
                    <title>Using Dijkstra's algorithm adapted for fuzzy weights in MATLAB</title>
                  </caption>
                  <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_skGPGATHgw9ZxuWF.png"/>
                </fig>
              
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>2.5. Feature extraction and classification</title>
          
          <p>After the segmentation process, which isolates the crack regions from the background, geometric features such as crack length, width, area, and curvature are extracted. These features provide valuable information about the characteristics of the cracks, such as their severity, shape, and potential for growth.</p><p>The extracted features are then used for classification, where the crack patterns are categorized based on predefined criteria, often using machine learning or fuzzy logic models. Classification helps in determining whether a detected feature represents a significant structural issue or is a minor imperfection. By analyzing these geometric features, the model can prioritize cracks that are critical for road maintenance, aiding in the proactive management of road infrastructure.</p>
          
            <sec>
              
                <title>2.5.1 Crack length</title>
              
              <p>Crack Length refers to the total length of a detected crack in a road surface, and it plays a significant role in assessing the severity of the damage. It is calculated by measuring the continuous path of the crack pixels, typically using edge detection and pixel connectivity algorithms. The formula for crack length often involves summing the distances between adjacent crack points or pixels along the detected crack line.</p>
              
                <disp-formula>
                  <label>(17)</label>
                  <mml:math id="mjkn85jv8j">
                    <mml:msub>
                      <mml:mtext> Length </mml:mtext>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                        <mml:mo>,</mml:mo>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>=</mml:mo>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>k</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                        <mml:mo>−</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:munderover>
                    <mml:msqrt>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mrow>
                              <mml:mi>k</mml:mi>
                              <mml:mo>+</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mo>−</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mrow>
                              <mml:mi>k</mml:mi>
                              <mml:mo>+</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>y</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                      <mml:mo>+</mml:mo>
                    </mml:msqrt>
                  </mml:math>
                </disp-formula>
              
              <p>This feature provides an indication of the crack's extent along its path.</p>
            </sec>
          
          
            <sec>
              
                <title>2.5.2 Curvature</title>
              
              <p>It refers to the rate at which the direction of a crack changes along its length. It is computed by evaluating the angle between two consecutive tangent vectors at different points along the crack. The curvature formula is based on the cosine of the angle between these vectors, which indicates how sharply the crack bends.</p>
              
                <disp-formula>
                  <label>(18)</label>
                  <mml:math id="mgk15d6fym">
                    <mml:mi>cos</mml:mi>
                    <mml:mi>θ</mml:mi>
                    <mml:mo>⁡</mml:mo>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                          </mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>+</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>⋅</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mo>‖</mml:mo>
                          <mml:mo>‖</mml:mo>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mi>e</mml:mi>
                            </mml:mrow>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mo>‖</mml:mo>
                          <mml:mo>‖</mml:mo>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mi>e</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>+</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <mml:math id="mkl8e5zy44">
    <mml:msub>
      <mml:mrow>
        <mml:mi>e</mml:mi>
      </mml:mrow>
      <mml:mi>i</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="miolamg33m">
    <mml:msub>
      <mml:mrow>
        <mml:mi>e</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>,</mml:mo>
        <mml:mn>1</mml:mn>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> are the unit tangent vectors at points $i<inline-formula>
  <mml:math id="m5pxxvpr7h">
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>i+1$ along the crack path. This feature reflects the sharpness or smoothness of the crack's trajectory.</p><p>These extracted features are then used for classification, which aids in distinguishing cracks with varying shapes and sizes.</p>
            </sec>
          
        </sec>
      
      
        <sec>
          
            <title>2.6. Summary</title>
          
          <p>Existing road crack detection models often face limitations in handling complex road textures, variable lighting, and diverse crack structures, leading to inaccurate segmentation and increased false detections. They typically lack adaptability to multi-scale crack patterns and are sensitive to noise, making them less effective across varying conditions. To address these limitations, the proposed model integrates Gaussian filtering, fuzzy contrast enhancement, and multi-scale fuzzy wavelet transforms for enhanced crack visibility and detail capture across scales. Mathematical morphology is used to refine segmentation, while a fuzzy graph-based approach models pixel connectivity, enabling robust crack isolation. Dijkstra’s algorithm then analyzes crack continuity, and geometric feature extraction supports precise characterization. Together, these methods deliver a comprehensive, adaptive framework for accurate road crack detection, contributing to more reliable maintenance planning.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Experimental results</title>
      <p>The experimental results presented in this section evaluate the performance of the proposed road crack detection model. (a) The proposed model leverages advanced techniques such as feature extraction through crack length and curvature, combined with a robust fuzzy approach, to accurately detect and classify road cracks. (b) To benchmark the performance of the proposed model, we compare its results with those from competing models, including the approaches by Ahmadi et al. [<xref ref-type="bibr" rid="ref_9">9</xref>], Ashraf et al. [<xref ref-type="bibr" rid="ref_17">17</xref>], and Xu et al. [<xref ref-type="bibr" rid="ref_20">20</xref>], which have established effectiveness in crack detection. (c) All experiments were conducted using MATLAB R2019, with images of varying sizes (e.g., 256×256 pixels) processed on a high-performance computing system with 8 GB of RAM. The evaluation considers metrics such as accuracy, precision, and computational efficiency for a comprehensive comparison. The dataset used in this study consists of 300 images of road surfaces captured under various real-world conditions, enabling the evaluation of the model's generalization ability. These images were sourced from publicly available datasets.</p><p>The images cover diverse road types, including asphalt, concrete, and gravel, which exhibit different surface textures and crack characteristics. The dataset contains a variety of crack types, including but not limited to longitudinal, transverse, and alligator cracks. The cracks vary in size, orientation, and severity, providing a comprehensive representation of common crack patterns encountered in road infrastructure. The proposed road crack detection model effectively identifies and traces crack paths with high precision. The result in <xref ref-type="fig" rid="fig_3">Figure 3</xref> showcases the model's ability to accurately map initial crack contours and simulate intensity profiles, culminating in a refined output that distinctly highlights the crack's structure against the background. This approach enhances crack visibility and offers reliable results, demonstrating the model’s robustness and potential for practical applications in automated road maintenance systems. <xref ref-type="fig" rid="fig_4">Figure 4</xref> illustrates the superiority of the proposed crack detection model by highlighting its ability to accurately delineate crack boundaries and generate precise bounding boxes, in contrast to previous methods like Xu's model. The model's results reveal a clear and comprehensive mapping of complex crack networks, demonstrating enhanced detection performance and the potential for more reliable structural assessment in road maintenance. The Xu's model struggles to effectively detect cracks of varying sizes and scales. While it performs adequately on prominent cracks, its ability to capture fine or faint cracks is limited. This restricts its applicability in scenarios involving subtle or micro-cracks that are critical for early maintenance.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>
            <title>Input cracked image, initial contour, simulated crack intensity, and output of the proposed model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_g9uPjzaZ-h8CTaWV.png"/>
        </fig>
      
      
        <fig id="fig_4">
          <label>Figure 4</label>
          <caption>
            <title>Input cracked images, results of the Xu's model, bounding boxes of the proposed model, and final output of the proposed model</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_3hlg435ovV0q4dXx.png"/>
        </fig>
      
      <p>Additionally, the proposed model outperforms both competing models—Ashraf's model and Xu'smodel—in terms of visual clarity, as shown in <xref ref-type="fig" rid="fig_5">Figure 5</xref>. In this figure, Ashraf's model fails to accurately detect the road cracks, as it is primarily effective only for larger cracks. The Ashraf's model struggles with detecting fine or micro-cracks and performs poorly in handling intersecting or branching crack patterns. It is sensitive to lighting variations and uneven surfaces, leading to false negatives. Additionally, its bounding boxes are imprecise, reducing accuracy in delineating cracks. Similarly, the Xu's model struggles to detect fine road cracks due to its limitations in handling branching cracks and irregular patterns, resulting in incomplete crack mapping. The Xu's model fails to detect multi-scale cracks, particularly smaller ones, and fragments continuous cracks due to occlusions. It relies heavily on fixed thresholds, reducing adaptability to diverse datasets. Moreover, it struggles with complex branching patterns, resulting in incomplete crack mapping.</p>
      
        <fig id="fig_5">
          <label>Figure 5</label>
          <caption>
            <title>Input cracked images, results of Ashraf's model, Xu's model, and the proposed model in the second, third, and fourth columns, respectively</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_WUrF-a03ogjt1Pec.png"/>
        </fig>
      
      <p> <xref ref-type="table" rid="table_1">Table 1</xref> presents a comparison of the time (in seconds) taken for performance evaluation of the proposed road crack detection model and the models by Xu's model, Ashraf's model, and Alavi's model. The results are shown for four different images, labeled Image-1 through Image-4. As seen in the table, the proposed model consistently performs faster than the competing models across all images. For instance, in Image-1, the proposed model completes the task in 8.45 seconds, while Xu's model takes 81.25 seconds. This trend holds for the remaining images, indicating that the proposed model is more efficient in terms of processing time compared to the other models.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>Comparison of time (s) taken for performance evaluation</title>
          </caption>
          <table><tr><th >Image No.</th><th >Proposed Model </th><th >Xu's Model</th><th >Ashraf's Model</th><th >Alavi's Model</th></tr><tr><td >Image-1</td><td >8.45</td><td >81.25</td><td >57.71</td><td >64.11</td></tr><tr><td >Image-2</td><td >7.49</td><td >73.65</td><td >61.79</td><td >58.61</td></tr><tr><td >Image-3</td><td >5.52</td><td >68.15</td><td >63.01</td><td >69.56</td></tr><tr><td >Image-4</td><td >11.15</td><td >91.25</td><td >89.71</td><td >74.11</td></tr></table>
        </table-wrap>
      
      
        <sec>
          
            <title>3.1. Confusion matrix analysis</title>
          
          <p>The confusion matrix is a vital tool for evaluating the performance of our proposed model. It provides a summary of the model's prediction results by comparing the predictions with the ground truth data, offering a comprehensive insight into the model's effectiveness. For a binary classification problem, such as crack versus non-crack detection, the confusion matrix consists of four metrics:</p><p>True Positive (TP): The number of pixels correctly identified as crack.</p><p>True Negative (TN): The number of pixels correctly identified as non-crack.</p><p>False Positive (FP): The number of pixels incorrectly identified as crack when they are actually non-crack.</p><p>False Negative (FN): The number of pixels incorrectly identified as non-crack when they are actually crack.</p><p>These values can be arranged in a matrix form as follows:</p><p><inline-formula>
  <mml:math id="myag1ar31c">
    <mml:mtext> Confusion Matrix </mml:mtext>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>[</mml:mo>
      <mml:mo>]</mml:mo>
      <mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt">
        <mml:mtr>
          <mml:mtd>
            <mml:mrow>
              <mml:mi data-mjx-auto-op="false">TP</mml:mi>
            </mml:mrow>
          </mml:mtd>
          <mml:mtd>
            <mml:mi>a</mml:mi>
            <mml:mi>m</mml:mi>
            <mml:mi>p</mml:mi>
            <mml:mo>;</mml:mo>
            <mml:mrow>
              <mml:mi data-mjx-auto-op="false">FN</mml:mi>
            </mml:mrow>
          </mml:mtd>
        </mml:mtr>
        <mml:mtr>
          <mml:mtd>
            <mml:mrow>
              <mml:mi data-mjx-auto-op="false">FP</mml:mi>
            </mml:mrow>
          </mml:mtd>
          <mml:mtd>
            <mml:mi>a</mml:mi>
            <mml:mi>m</mml:mi>
            <mml:mi>p</mml:mi>
            <mml:mo>;</mml:mo>
            <mml:mrow>
              <mml:mi data-mjx-auto-op="false">TN</mml:mi>
            </mml:mrow>
          </mml:mtd>
        </mml:mtr>
      </mml:mtable>
    </mml:mrow>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mirmqv3dp5">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>:&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>−</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>w</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>A</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:msup>
      <mml:mi>l</mml:mi>
      <mml:mo>′</mml:mo>
    </mml:msup>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mribjirohq">
    <mml:mtext>Accuracy</mml:mtext>
    <mml:mo>=</mml:mo>
    <mml:mfrac>
      <mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TP</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TN</mml:mi>
        </mml:mrow>
        <mml:mo>+</mml:mo>
      </mml:mrow>
      <mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TP</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TN</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">FP</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">FN</mml:mi>
        </mml:mrow>
        <mml:mo>+</mml:mo>
        <mml:mo>+</mml:mo>
        <mml:mo>+</mml:mo>
      </mml:mrow>
    </mml:mfrac>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mq89qr9ckv">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>Q</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mrve38cc83">
    <mml:mtext>Precision</mml:mtext>
    <mml:mo>=</mml:mo>
    <mml:mfrac>
      <mml:mrow>
        <mml:mi data-mjx-auto-op="false">TP</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TP</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">FP</mml:mi>
        </mml:mrow>
        <mml:mo>+</mml:mo>
      </mml:mrow>
    </mml:mfrac>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="m9qjp8zs8q">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>M</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mef2niv7w9">
    <mml:mtext>Recall</mml:mtext>
    <mml:mo>=</mml:mo>
    <mml:mfrac>
      <mml:mrow>
        <mml:mi data-mjx-auto-op="false">TP</mml:mi>
      </mml:mrow>
      <mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">TP</mml:mi>
        </mml:mrow>
        <mml:mrow>
          <mml:mi data-mjx-auto-op="false">FN</mml:mi>
        </mml:mrow>
        <mml:mo>+</mml:mo>
      </mml:mrow>
    </mml:mfrac>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mcymcdekjo">
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mo>:</mml:mo>
    <mml:mo>.</mml:mo>
    <mml:mo>&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;&amp;lt;</mml:mo>
    <mml:mo>&amp;gt;</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>F</mml:mi>
    <mml:mi>S</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>P</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mn>1</mml:mn>
  </mml:math>
</inline-formula><inline-formula>
  <mml:math id="mmugvcfb31">
    <mml:mtext> F1 Score </mml:mtext>
    <mml:mo>=</mml:mo>
    <mml:mo>×</mml:mo>
    <mml:mn>2</mml:mn>
    <mml:mfrac>
      <mml:mrow>
        <mml:mtext> Precision </mml:mtext>
        <mml:mtext> Recall </mml:mtext>
        <mml:mo>×</mml:mo>
      </mml:mrow>
      <mml:mrow>
        <mml:mtext> Precision </mml:mtext>
        <mml:mtext> Recall </mml:mtext>
        <mml:mo>+</mml:mo>
      </mml:mrow>
    </mml:mfrac>
  </mml:math>
</inline-formula>$</p><p>These metrics help us assess the model’s effectiveness in detecting road cracks. A higher accuracy indicates a greater proportion of correctly classified pixels. Precision reflects the accuracy of crack pixel predictions, while recall demonstrates the model’s sensitivity to actual cracks. The F1 Score provides a balance between precision and recall, summarizing the model’s overall effectiveness.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Comparative analysis of performance metrics</title>
          
          <p>The <xref ref-type="fig" rid="fig_6">Figure 6</xref> illustrates a comparative analysis of four methods-Our, Xu, Ashraf, and Alavi-across four key performance metrics: Accuracy, Precision, Recall, and F-Measure. This analysis reveals that our method consistently outperforms the other methods in each metric, indicating its superior capability in classification tasks.</p><p>In terms of Accuracy, the Our method achieves a notably high score of 94.20%, suggesting a strong ability to correctly classify samples. The Xu method follows with an Accuracy of 88.60%, showing moderate performance, albeit lower than our method. Ashraf and Alavi, with scores of 85.30% and 79.50%, respectively, exhibit lower accuracies, suggesting a higher misclassification rate compared to the leading methods.</p>
          
            <fig id="fig_6">
              <label>Figure 6</label>
              <caption>
                <title>Comparative analysis of performance metrics across competing models and propose model</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_ntt1NsrTQwSziRrJ.png"/>
            </fig>
          
          <p>For Precision, which reflects the effectiveness in minimizing false positives, our method again leads with a score of 91.50%. This high precision implies that our method is particularly effective at correctly identifying positive cases. Xu and Ashraf reach Precision scores of 85.10% and 80.50%, respectively, indicating moderate effectiveness. Alavi, with the lowest Precision at 70.20%, appears to have a substantial rate of false positives, which could be problematic in applications where precision is crucial.</p><p>The Recall metric, representing sensitivity, further highlights the strengths of our method, which achieves a high Recall of 89.70%. This indicates a strong capability in capturing all relevant cases. Xu follows with a Recall of 82.30%, while Ashraf and Alavi score lower, at 75.80% and 65.40%, respectively. The lower Recall scores for Ashraf and Alavi suggest that these methods fail to capture a significant portion of relevant cases, potentially resulting in higher false negatives.</p><p>The F-Measure, which balances Precision and Recall, emphasizes the robustness of our method, achieving a score of 90.60%. This balance between Precision and Recall makes it an ideal choice for applications that require both accuracy and sensitivity. Xu, with an F-Measure of 83.50%, performs reasonably well, though not at the level of our method. Ashraf and Alavi score 78.10% and 67.70%, respectively, indicating that they struggle to achieve a balanced performance in these critical metrics.</p><p>In summary, our method consistently excels across all evaluation criteria, making it the most reliable and effective approach among the four methods, see <xref ref-type="table" rid="table_2">Table 2</xref>. In contrast, Xu serves as a competent but less effective alternative, while Ashraf and Alavi exhibit considerable limitations, particularly Alavi, which consistently scores the lowest across all metrics. This analysis underscores our method as highly suitable for applications demanding high classification accuracy, precision, and sensitivity.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Confusion matrix analysis for road crack detection models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>Accuracy</p></td><td colspan="1" rowspan="1"><p>Precision</p></td><td colspan="1" rowspan="1"><p>Recall</p></td><td colspan="1" rowspan="1"><p>F1 Score</p></td></tr><tr><td colspan="1" rowspan="1"><p>Alavi’s model</p></td><td colspan="1" rowspan="1"><p>78.5%</p></td><td colspan="1" rowspan="1"><p>70.2%</p></td><td colspan="1" rowspan="1"><p>65.4%</p></td><td colspan="1" rowspan="1"><p>67.7%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Ashraf’s model</p></td><td colspan="1" rowspan="1"><p>85.3%</p></td><td colspan="1" rowspan="1"><p>80.5%</p></td><td colspan="1" rowspan="1"><p>75.8%</p></td><td colspan="1" rowspan="1"><p>78.1%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Xu’s model</p></td><td colspan="1" rowspan="1"><p>88.6%</p></td><td colspan="1" rowspan="1"><p>85.1%</p></td><td colspan="1" rowspan="1"><p>82.3%</p></td><td colspan="1" rowspan="1"><p>83.6%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Proposed model</p></td><td colspan="1" rowspan="1"><p>94.2%</p></td><td colspan="1" rowspan="1"><p>91.5%</p></td><td colspan="1" rowspan="1"><p>89.7%</p></td><td colspan="1" rowspan="1"><p>90.6%</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Conclusion</title>
      <p>The proposed road crack detection model demonstrates significant advancements by integrating fuzzy logic and graph theory to address challenges such as fine crack detection, irregular geometries, and multi-scale feature analysis. This innovative approach outperforms existing models, which are limited in adapting to complex road conditions, as evidenced by the model's superior accuracy of 94.2%, high precision, and recall. These results, validated through detailed confusion matrix analysis, establish the model's reliability and robustness. Beyond detection accuracy, the proposed framework contributes to proactive and scalable infrastructure maintenance, offering practical relevance in enhancing roadway safety and management. By incorporating Dijkstra's algorithm within a fuzzy graph-based framework, the model effectively assesses crack continuity and severity, ensuring comprehensive crack analysis. This research not only provides a reliable solution for road maintenance but also lays the foundation for future advancements, such as real-time crack detection and adaptability to diverse environmental conditions.</p><p>However, the model does have limitations, including its sensitivity to image resolution and potential challenges in processing images with excessive noise. The proposed road crack detection model's performance is influenced by crack type (fine, branching, or interconnected), road surface material and texture, and environmental conditions like lighting, weather, and debris. Future work could explore optimizing the model for lower-resolution images, enhancing its robustness under noisy conditions, and integrating deep learning techniques to further improve its capabilities. The proposed model represents a significant advancement in automated road maintenance systems, improving road safety and reducing maintenance costs.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data supporting our research results are included within the article or supplementary material.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author declares no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="report">
          <article-title>Status of the Nation’s Highways, Bridges, and Transit: Conditions and Performance Report, 2015</article-title>
          <source>, undefined</source>
          <year>2019</year>
          <publisher-name>Federal Highway Administration</publisher-name>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>512</volume>
          <page-range>012045</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ng</surname>
              <given-names>C P</given-names>
            </name>
            <name>
              <surname>Law</surname>
              <given-names>T H</given-names>
            </name>
            <name>
              <surname>Jakarni</surname>
              <given-names>F M</given-names>
            </name>
            <name>
              <surname>Kulanthayan</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1757-899x/512/1/012045</pub-id>
          <article-title>Road infrastructure development and economic growth</article-title>
          <source>IOP Conference Series: Materials Science and Engineering</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>16</volume>
          <page-range>2910</page-range>
          <issue>16</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yuan</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs16162910</pub-id>
          <article-title>A review of computer vision-based crack detection methods in civil infrastructure: Progress and challenges</article-title>
          <source>Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>2008</volume>
          <page-range>861701</page-range>
          <year>2008</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ayenu-Prah</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Attoh-Okine</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2008/861701</pub-id>
          <article-title>Evaluating pavement cracks with bidimensional empirical mode decomposition</article-title>
          <source>EURASIP J. Adv. Signal Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>60</volume>
          <page-range>6080</page-range>
          <issue>21</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Su</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1364/ao.423406</pub-id>
          <article-title>Automatic crack segmentation using deep high-resolution representation learning</article-title>
          <source>Appl. Opt.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>651</page-range>
          <issue>2</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app14020651</pub-id>
          <article-title>DFP-Net: A crack segmentation method based on a feature pyramid network</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>247</volume>
          <page-range>123314</page-range>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ranyal</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Sadhu</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jain</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.eswa.2024.123314</pub-id>
          <article-title>Enhancing pavement health assessment: An attention-based approach for accurate crack detection, measurement, and mapping</article-title>
          <source>Expert Syst. Appl.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Cheng</surname>
              <given-names>H. D.</given-names>
            </name>
          </person-group>
          <source>Deep Learning for Crack-like Object Detection</source>
          <publisher-name>CRC Press</publisher-name>
          <year>2023</year>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>85–97</page-range>
          <issue>S</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ahmadi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>S. Khalesi</surname>
            </name>
            <name>
              <surname>Bagheri</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Automatic road crack detection and classification using image processing techniques, machine learning and integrated models in urban areas: A novel image binarization technique</article-title>
          <source>J. Ind. Syst. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>5749</page-range>
          <issue>13</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Xie</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/app14135749</pub-id>
          <article-title>A road crack detection method based on residual and attention mechanism</article-title>
          <source>Appl. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1591-1598</page-range>
          <issue>12</issue>
          <year>2003</year>
          <person-group person-group-type="author">
            <name>
              <surname>Naik</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Murthy</surname>
              <given-names>C.A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/tip.2003.819231</pub-id>
          <article-title>Hue-preserving color image enhancement without gamut problem</article-title>
          <source>IEEE Trans. Image Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>24</volume>
          <page-range>70-76</page-range>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Boubenna</surname>
              <given-names>Hadjer</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>Dohoon</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.bica.2018.04.008</pub-id>
          <article-title>Image-based emotion recognition using evolutionary algorithms</article-title>
          <source>Biologically Inspired Cognitive Architectures</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>627-634</page-range>
          <issue>6</issue>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhou</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1049/iet-ipr.2011.0534</pub-id>
          <article-title>Image zooming using directional cubic convolution interpolation</article-title>
          <source>IET Image Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>33</volume>
          <page-range>1090-1109</page-range>
          <issue>12</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Luo</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>X.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/mice.12412</pub-id>
          <article-title>Automatic pixel-level crack detection and measurement using fully convolutional network</article-title>
          <source>Comput. Aided Civ. Infrastruct. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>28</volume>
          <page-range>1498-1512</page-range>
          <issue>3</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zou</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Qi</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/tip.2018.2878966</pub-id>
          <article-title>Deepcrack: Learning hierarchical convolutional features for crack detection</article-title>
          <source>IEEE Trans. Image Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>29316-29331</page-range>
          <issue>11</issue>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Jo</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Ryu</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s151129316</pub-id>
          <article-title>Pothole detection system using a black-box camera</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>4</volume>
          <page-range>655-675</page-range>
          <issue>4</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ashraf</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Sophian</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bawono</surname>
              <given-names>A. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/constrmater4040036</pub-id>
          <article-title>Crack detection, classification, and segmentation on road pavement material using multi-scale feature aggregation and transformer-based attention mechanisms</article-title>
          <source>Constr. Mater.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="conf-paper">
          <volume>2016</volume>
          <page-range>3708-3712</page-range>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Daniel Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>Y. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/icip.2016.7533052</pub-id>
          <article-title>Road crack detection using deep convolutional neural network</article-title>
          <source>2016 IEEE International Conference on Image Processing (ICIP), Phoenix, AZ, USA</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Maeda</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Sekimoto</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Seto</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Kashiyama</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Omata</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48550/ARXIV.1801.09454</pub-id>
          <article-title>Road damage detection using deep neuralnetworks with images captured through a smartphone</article-title>
          <source>arXiv Prepr.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>2257</page-range>
          <issue>12</issue>
          <year>2024</year>
          <person-group person-group-type="author">
            <name>
              <surname>Xu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/electronics13122257</pub-id>
          <article-title>A road crack segmentation method based on transformer and multiscale feature fusion</article-title>
          <source>Electron.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>