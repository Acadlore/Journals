<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">JUDM</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Journal of Urban Development and Management</journal-title>
        <abbrev-journal-title abbrev-type="issn">J. Urban Dev. Manag.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">JUDM</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2957-9597</issn>
      <issn publication-format="print">2957-9589</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-DO9jaz5_FNTDaWYs1np_5AnDu5iCYOlD</article-id>
      <article-id pub-id-type="doi">10.56578/judm040303</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Enhancing Land Use Classification Accuracy Through High-Resolution GIS and Remote Sensing: A Case Study of Urban Sprawl in Baghdad</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-8735-7760</contrib-id>
          <name>
            <surname>Hasan</surname>
            <given-names>Rasha Flayyih</given-names>
          </name>
          <email>rasha.f.hasan@uotechnology.edu.iq</email>
        </contrib>
        <aff id="aff_1">Training and Workshop Center, University of Technology–Iraq, 10066 Baghdad, Iraq</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>10</day>
        <month>08</month>
        <year>2025</year>
      </pub-date>
      <volume>4</volume>
      <issue>3</issue>
      <fpage>204</fpage>
      <lpage>215</lpage>
      <page-range>204-215</page-range>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>06</month>
          <year>2025</year>
        </date>
        <date date-type="accepted">
          <day>04</day>
          <month>08</month>
          <year>2025</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2025 by the author(s)</copyright-statement>
        <copyright-year>2025</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The accuracy of land use classification is significantly enhanced by the integration of high-resolution Geographic Information System (GIS) data and remote sensing technologies. This study examines the urban sprawl in Baghdad, Iraq, a city undergoing rapid urbanization due to population growth and infrastructural development, resulting in extensive land use changes. High-resolution satellite imagery, including WorldView-2 (0.5 m), QuickBird (0.6 m), and Landsat 8 (30 m), is utilized to classify land into categories such as urban areas, agricultural land, water bodies, vegetation, and barren land. The application of machine learning algorithms, specifically Random Forest (RF) and Support Vector Machine (SVM), facilitates the achievement of higher classification accuracy. The integration of GIS with remote sensing data improves the precision of urban growth pattern analysis and mapping. Temporal and spatial integration proves essential in monitoring urban sprawl, offering valuable insights into how urban areas encroach upon agricultural land. The results indicate that high-resolution satellite imagery significantly enhances classification accuracy, particularly in identifying small-scale urban features, thus surpassing the performance of traditional satellite data. The study underscores the critical role of high-resolution remote sensing in urban planning and land use management, providing a robust framework to guide policymakers and urban planners in making informed decisions regarding resource allocation, infrastructure development, and sustainable urban growth. Future research directions suggest the potential application of AI-driven models for real-time detection and prediction of urban sprawl.</p></abstract>
      <kwd-group>
        <kwd>Urban sprawl</kwd>
        <kwd>Remote sensing</kwd>
        <kwd>GIS</kwd>
        <kwd>Machine learning</kwd>
        <kwd>Random Forest</kwd>
        <kwd>Support Vector Machine</kwd>
        <kwd>Satellite imagery</kwd>
        <kwd>Baghdad</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="1"/>
        <fig-count count="3"/>
        <table-count count="6"/>
        <ref-count count="17"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>The process of classifying land into functional uses that include residential, commercial, and agricultural use, which are fundamental in city planning and environmental management, has been termed “land use classification”. The current developments of space data analysis through Geographic Information System (GIS) and remote sensing have improved on the exactness and effectiveness of this categorizing [<xref ref-type="bibr" rid="ref_1">1</xref>]. The land use maps designed well would play a vital role in proper urban planning and sustainable development; they would facilitate the planners in formulating decisions relating to infrastructure, transport, management of resources, and zoning. Such maps are used during the control of land development and distribution of resources, assessment of environmental effects, promotion of the conservatory policies, and the preservation of the balance between the progressive world and the preservation of the environment in the fast-growing cities [<xref ref-type="bibr" rid="ref_2">2</xref>]. Remote sensing and GIS are the technologies that are necessary in the acquisition and processing of spatial and temporal data. GIS allows urban planners to measure, store, examine, and visualize geographical information, which helps in the analysis of land use patterns and comprehending the geographical features. On the other hand, remote sensing entails the acquisition of information using satellite and airborne sensors, applying aerial photographs and high-resolution satellite images to avail a current status of information regarding the change of land cover and land use [<xref ref-type="bibr" rid="ref_3">3</xref>].</p>
    </sec>
    <sec sec-type="">
      <title>2. Literature review</title>
      
        <sec>
          
            <title>2.1. Previous studies on land use classification using gis and remote sensing</title>
          
          <p>Verma et al. [<xref ref-type="bibr" rid="ref_3">3</xref>] explained how remote sensing and GIS can be used in the urban planning calculations in India and the reason why the high-quality satellite images will be a good concept in studying the land use and growth measurement of the city. They illustrate the fact that GIS can help organize spatial data, and this can be used by urban planners to take reasonable decisions with the dynamism of urbanization that is a challenge and an opportunity for sustainable progress. To expand on this point, Zhang et al. [<xref ref-type="bibr" rid="ref_1">1</xref>] presented the impact of deep learning methods, specifically convolutional neural networks (CNNs), in improving the quality of land feature classification to enable automated aspects that can enhance supervision of land use transformation in rapidly developing cities. In their study, Shi et al. [<xref ref-type="bibr" rid="ref_2">2</xref>] investigated the concept of merging remote sensing image data obtained with social media information to improve the accuracy of land classification in the urban environment. Their innovative nature seeks to depict the movements in urban scenes that would be missed by the conventional remote sensing through which the land use patterns can be enhanced. In the article, Zong et al. [<xref ref-type="bibr" rid="ref_4">4</xref>] introduced an efficient methodology of urban land use mapping by combining satellite, GIS, and ground data, identifying Lanzhou as the case study. Their laboratory effort reveals how they have placed more credible urban land cover classifications by taking their approach as multifaceted. Wiatkowska et al. [<xref ref-type="bibr" rid="ref_5">5</xref>] discussed remote sensing and GIS used as the techniques to study spatial-temporal dynamics of land use in Opole, Poland, which proves the usefulness of the specified tools in the context of the need to track urban development and provide reasonable planning of cities. Finally, the authors of the research by Song et al. [<xref ref-type="bibr" rid="ref_6">6</xref>] explored the application of high-resolution remote sensing images with the points of interest (POI) data sets to demarcate urban functional areas in Xiamen, China. Their study is successful in classifying urban spaces based on functional use, e.g., residential, commercial, and industrial, and giving important information regarding resource management and building up of infrastructures. A combination of these studies highlights the potential of a transformation by implementing the use of advanced technologies in the urban mapping and planning that will be especially relevant to the issues of urbanization that occur at a rapid pace.</p>
        </sec>
      
      
        <sec>
          
            <title>2.2. Challenges in classifying urban sprawl</title>
          
          <p>Treitz et al. [<xref ref-type="bibr" rid="ref_7">7</xref>] studied the difficulty of applying the satellite and GIS technologies in land-cover and land-use mapping and in rural-urban fringe regions where it is difficult to separate different types of land use. They reiterated the fact that high-resolution satellite imagery and GIS tools have to be used in enhancing the accuracy of classification in these complex areas. The article by Mohammady and Delavar [<xref ref-type="bibr" rid="ref_8">8</xref>] examined the dynamics of urban sprawl in terms of Landsat imagery and GIS and fitted well to understand the importance of remote sensing in efficient urban planning and human environmental management in high-speed areas. Singh et al. [<xref ref-type="bibr" rid="ref_9">9</xref>] also discussed the problems with spatial resolution and accuracy of urban land cover classification by combining the LiDAR and Landsat data to increase the classification results in multifaceted urban areas. Hu et al. [<xref ref-type="bibr" rid="ref_10">10</xref>] were preoccupied with extracting the urban boundaries and analyzing the urban sprawl in Wuhan, China, by using Landsat images, showing that the irregular character of urbanization creates issues when challenges with the analysis of urban areas are concerned. Fenta et al. [<xref ref-type="bibr" rid="ref_11">11</xref>] used a remote sensing map to examine the dynamics of land use and urban growth in Mekelle, Ethiopia, and avoided challenges in identifying land use change in speedily urbanizing regions. Their results emphasized the importance of state-of-the-art remote sensing technology in urban sprawl and the planning of sustainable urbanization.</p>
        </sec>
      
      
        <sec>
          
            <title>2.3. Key methodologies and approaches in optimizing land use accuracy</title>
          
          <p>Advanced machine learning combined with high-resolution remote sensing and GIS has been shown to improve urban land use classification accuracy. Tong et al. [<xref ref-type="bibr" rid="ref_12">12</xref>] established the effectiveness of the application of a genetic algorithm-evolved artificial neural network (GA-ANN) to surmount the urban sprawl classification of the Jiading and Putuo regions of Shanghai, improve classification accuracy, and support the urban planning process because it enhances the detection of land use and cover alterations. Luo et al. [<xref ref-type="bibr" rid="ref_13">13</xref>] added to this by using the high-resolution remotely sensed data and the OpenStreetMap (OSM) data, which resolved the issue of poor training data and provided a low-cost classification technique. Shao et al. [<xref ref-type="bibr" rid="ref_14">14</xref>] also complemented the analysis of urban sprawl by using the remote sensing data with the social media data and allowed analyzing the dynamics of urban development based on social-economic factors.</p><p>Recently, Georganos et al. [<xref ref-type="bibr" rid="ref_15">15</xref>] applied extreme gradient boosting (XGBoost) to the one-meter spatial resolution satellite data to classify land use and covers, which proved to be better than the conventional method because of its capabilities to work with big data sets and its feature selection capabilities. In similar research, Georganos et al. [<xref ref-type="bibr" rid="ref_16">16</xref>] have stressed the importance of feature selection in optimal classification outcomes of urban applications; they focus on the feature selection that optimizes the classification performance as well as on lessening the computation requirements without diminishing the performance, especially in high-resolution data. Kalogiannidis et al. [<xref ref-type="bibr" rid="ref_17">17</xref>] explored how remote sensing and GIS may be integrated to monitor urban sprawl in various urban centres in Europe. They provide a study of how spatial data and satellite imagery may be used with machine learning algorithms to trace the modification of land use over time. They maintain that such a method is critical towards the study of urban growth trends and making informed decisions about the planning of cities especially in urban areas with issues surrounding sustainable development and land use.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>3. Novelty and contributions of the present study</title>
      <p>This study has great contributions to urban land use classification in the post-conflict Baghdad using the high-resolution imagery and machine learning models. It creates the underlying typology of urban sprawl in the city and among the challenges, it points out challenges of informal settlements and growth of population. The paper combines statistics of GIS, remote sensing, and social media, which shows its possibilities in detecting urban sprawl. Based on the findings of the empirical analysis, urban growth was 35% between the year 2000 and 2025, through the evaluation of agriculture land loss with the help of spatial maps. It also compares the performance of Random Forest (RF) and Support Vector Machine (SVM) using the high resolution dataset to choose a better model in the Middle East environment. Lastly, the research can be applied to the city planning, uncontrolled development, and a proposal of a zoning system based on data.</p>
    </sec>
    <sec sec-type="">
      <title>4. Study area and data sources</title>
      
        <sec>
          
            <title>4.1. Description of the case study area</title>
          
          <p>The capital and the most populated city in Iraq, Baghdad has experienced a rapid urbanization over the past decades and especially after the war when individuals immigrate towards economic opportunities. Baghdad has more than 7 million residents and thus due to the development, arable land and resources have been overstretched resulting to land use planning and environmental sustainability issues. Its city environment characteristics are modern infrastructure and informal developments, which were characterized by drastic land use pattern, which included residential mobilization and connectivity construction, so Baghdad is an important location to research urban sprawl.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Overview of high-resolution gis and remote sensing data sources</title>
          
          <p>In order to examine the concept of urban sprawl within Baghdad, it will exploit high-resolution GIS and remote sensing data. The detailed spatial information can be found in these data sources, and thus an in-depth evaluation of the urban development and change of land use can be calculated. Principal sources of data used in the study are:</p><p>(1) Satellite Imagery:</p><p>WorldView-2 is a high-resolution satellite data, this provides a spatial resolution of 0.5 m, enabling maps of cities and infrastructure to be created in detail, building by building, road by road, and land cover type by land cover type. The high spatial resolution of WorldView-2 will be the most suitable image to detect small urban structures as well as land-use pattern changes in urban landscapes.</p><p>Landsat 8 provides multispectral imagery with a spatial resolution of 30 m. The images from Landsat are very important to trace the longer-term developments in urban areas, since they possess exceptionally large temporal depth and enable investigation of a few decades of land use change.</p><p>QuickBird is also another useful source of data that can be used in this study since a spatial coverage of 0.6 m is available. The plots that QuickBird provides are applicable in detecting the minor details pertaining to the urban characteristics and in determining the alterations to the land use in detail.</p><p>(2) GIS Data:</p><p>OSM is free of charge and is publicly edited, so data on road networks, building footprints, and other urban infrastructure is available as vector data provided by contributors. The information comes in handy when mapping and analyzing urban sprawls, planning infrastructure, and land use.</p><p>Topographic maps that can be obtained through government sources include such spatial layers as elevation information, administrative boundaries, or hydrological features and thus supplement remote sensing data.</p><p>(3) Light Detection and Ranging (LiDAR) data:</p><p>LiDAR contains a very specific piece of information–elevation data, which will be necessary to calculate the terrain shape of the city of Baghdad and determine the altered terrain due to the growth of the city. Data obtained through LiDAR can be utilized in extraction of building height, detection of the type of vegetation, and analysis of the impact of urban sprawl on the landscape. The spatial resolution of LiDAR falls between 1 m and 5 m.</p><p>(4) Crowdsourced Data and Social Media:</p><p>Human activities and migration patterns can be viewed through social media, including Twitter and Instagram, alongside crowdsourced data. The flow of individuals in the city can be captured by adding geographic location data to the posts that may be uploaded and using location-based services, which help to enhance knowledge of urban development.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Methodology</title>
      
        <sec>
          
            <title>5.1. Data preprocessing and preparation</title>
          
          <p>Data preprocessing is the first critical step to ensure the data is usable for classification tasks. The following steps are involved:</p><p>(1) Geometric correction: This process ensures that the satellite images align with the correct geographic coordinates. The geometric distortion caused by sensor parameters or atmospheric conditions is corrected using ground control points (GCPs).</p><p>(2) Radiometric correction: This step adjusts for radiometric errors in the image. The equation for radiometric correction is:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mgtioef3rd">
                <mml:msub>
                  <mml:mi>L</mml:mi>
                  <mml:mrow>
                    <mml:mtext>corrected </mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>L</mml:mi>
                      <mml:mrow>
                        <mml:mtext>raw </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>B</mml:mi>
                      <mml:mrow>
                        <mml:mtext>min </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>B</mml:mi>
                      <mml:mrow>
                        <mml:mtext>max </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>B</mml:mi>
                      <mml:mrow>
                        <mml:mtext>min </mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mshrbkxpl5">
    <mml:msub>
      <mml:mi>L</mml:mi>
      <mml:mrow>
        <mml:mtext>corrected</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is the corrected pixel value, <inline-formula>
  <mml:math id="mwevaptzd5">
    <mml:msub>
      <mml:mi>L</mml:mi>
      <mml:mrow>
        <mml:mtext>raw</mml:mtext>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> is the raw pixel value, and <inline-formula>
  <mml:math id="mwrf9r1c4h">
    <mml:msub>
      <mml:mi>B</mml:mi>
      <mml:mrow>
        <mml:mo>min</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> and <inline-formula>
  <mml:math id="m3szgngpw2">
    <mml:msub>
      <mml:mi>B</mml:mi>
      <mml:mrow>
        <mml:mo>max</mml:mo>
      </mml:mrow>
    </mml:msub>
  </mml:math>
</inline-formula> are the minimum and maximum radiometric values for each band.</p><p>(3) Cloud removal: Clouds are detected and removed using cloud identification algorithms, e.g., the Fmask (Function of mask) algorithm, to prevent the misclassification.</p><p>(4) Resampling: Dissimilar spatial resolutions can occur in various data sources. Globally, as an example, Landsat 8 has a resolution of 30 m compared to the WorldView-2, with a resolution of 0.5 m. To standardize, bilinear interpolation or nearest-neighbor resampling are employing resampling algorithms.</p>
        </sec>
      
      
        <sec>
          
            <title>5.2. Image classification techniques</title>
          
          <p>Classifying the images is achieved through supervised and unsupervised approaches:</p><p>(1) Supervised classification standard</p><p>The method usually used is Maximum Likelihood Classification (MLC). The maximum likelihood formula is:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="ma4ootgr9r">
                <mml:mi>P</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>∣</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:msub>
                    <mml:mi>C</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                  <mml:mi>X</mml:mi>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>∣</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>X</mml:mi>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mi>X</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mh47ck16rc">
    <mml:mi>P</mml:mi>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>∣</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:msub>
        <mml:mi>C</mml:mi>
        <mml:mi>k</mml:mi>
      </mml:msub>
      <mml:mi>X</mml:mi>
    </mml:mrow>
  </mml:math>
</inline-formula> is the posterior probability of class, <inline-formula>
  <mml:math id="mymah3exd3">
    <mml:msub>
      <mml:mi>C</mml:mi>
      <mml:mi>k</mml:mi>
    </mml:msub>
    <mml:mo>,</mml:mo>
    <mml:mi>P</mml:mi>
    <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mo>∣</mml:mo>
      <mml:mo>)</mml:mo>
      <mml:mi>X</mml:mi>
      <mml:msub>
        <mml:mi>C</mml:mi>
        <mml:mi>k</mml:mi>
      </mml:msub>
    </mml:mrow>
  </mml:math>
</inline-formula> is the likelihood of observing data $X<inline-formula>
  <mml:math id="mdvyil7u6m">
    <mml:mi>g</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>C_k<inline-formula>
  <mml:math id="mrevf09850">
    <mml:mo>,</mml:mo>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>P\left(C_k\right)<inline-formula>
  <mml:math id="m5vv1zrfpj">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
  </mml:math>
</inline-formula>C_k$.</p><p>SVM also performs classification: The algorithm aims to do is to identify a hyperplane, which will best distinguish between the various classes in the feature space. The SVM optimization problem is as follows:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="mir5hrxq8w">
                <mml:munder>
                  <mml:mo>min</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi>w</mml:mi>
                    </mml:mrow>
                    <mml:mo>,</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mi>b</mml:mi>
                    <mml:mi>ξ</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mn>2</mml:mn>
                </mml:mfrac>
                <mml:mo fence="false">‖</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:mi>w</mml:mi>
                </mml:mrow>
                <mml:msup>
                  <mml:mo fence="false">‖</mml:mo>
                  <mml:mn>2</mml:mn>
                </mml:msup>
                <mml:mi>C</mml:mi>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>n</mml:mi>
                </mml:munderover>
                <mml:msub>
                  <mml:mi>ξ</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mdjtk7zt4b">
    <mml:mrow>
      <mml:mi>w</mml:mi>
    </mml:mrow>
  </mml:math>
</inline-formula> is the weight vector, $b<inline-formula>
  <mml:math id="mnrsfe3b61">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>m</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>\xi_i<inline-formula>
  <mml:math id="mgfmgcaa8e">
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>k</mml:mi>
    <mml:mi>v</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>r</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>b</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mo>,</mml:mo>
  </mml:math>
</inline-formula>C$ is the penalty parameter.</p><p>(2) Unsupervised classification</p><p>K-means Clustering: K-means clustering splits the pixels into K groups depending on the similarity in the spectrum. The K-means update equation is:</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mlrnhjj5os">
                <mml:msub>
                  <mml:mi>μ</mml:mi>
                  <mml:mi>k</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>x</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:msub>
                    <mml:mi>N</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                </mml:mfrac>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>∈</mml:mo>
                    <mml:msub>
                      <mml:mi>C</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:munder>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mndu0dzplx">
    <mml:msub>
      <mml:mi>μ</mml:mi>
      <mml:mi>k</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is the centroid of cluster $k<inline-formula>
  <mml:math id="m0d6zxnxol">
    <mml:mo>,</mml:mo>
    <mml:mi>a</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula>C_k<inline-formula>
  <mml:math id="m275o8o4kg">
    <mml:mi>i</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>h</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>f</mml:mi>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>i</mml:mi>
    <mml:mi>g</mml:mi>
    <mml:mi>n</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>o</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>u</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>t</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>r</mml:mi>
  </mml:math>
</inline-formula>k$.</p>
        </sec>
      
      
        <sec>
          
            <title>5.3. Feature extraction and selection</title>
          
          <p>To enhance the performance of the classification, feature extraction and selection are done:</p><p>(1) Spectral indexes, which are used to discriminate between vegetation and non-vegetation lands, come into use Normalized Difference Vegetation Index (NDVI).</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="muaoh1qgqn">
                <mml:mi>N</mml:mi>
                <mml:mi>D</mml:mi>
                <mml:mi>V</mml:mi>
                <mml:mi>I</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>R</mml:mi>
                    <mml:mi>R</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>d</mml:mi>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                    <mml:mi>I</mml:mi>
                    <mml:mi>R</mml:mi>
                    <mml:mi>R</mml:mi>
                    <mml:mi>e</mml:mi>
                    <mml:mi>d</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mjvej6woht">
    <mml:mi>N</mml:mi>
    <mml:mi>I</mml:mi>
    <mml:mi>R</mml:mi>
  </mml:math>
</inline-formula> is the Near-Infrared band and <inline-formula>
  <mml:math id="m8ofhy6wyp">
    <mml:mi>R</mml:mi>
    <mml:mi>e</mml:mi>
    <mml:mi>d</mml:mi>
  </mml:math>
</inline-formula> is the red bands of the satellite image.</p><p>(2) Texture features are to be extracted using Gray-Level Co-occurrence Matrix (GLCM). It gives details about the spatial correlation of the pixels available in an image. The typical texture measures include Contrast, Correlation, Energy and Homogeneity.</p><p>(3) The shape extraction is done using Object-Based Image Analysis (OBIA). This can take the shape of compactness, elongation, and roundness, among others that are capable of separating features of urban objects (e.g., buildings) and natural features (e.g., vegetation).</p><p>(4) Feature selection</p><p>Principal Component Analysis (PCA) is used to reduce the data dimensionality. PCA projects the features into a projection of linearly independent variables known as principal components so that only highly important features are maintained.</p><p>Relevant or irrelevant and redundant features are eliminated through the Recursive Feature Elimination (RFE), introduced to enhance the correctness of classification and avoid overfitting.</p>
        </sec>
      
      
        <sec>
          
            <title>5.4. Machine learning models used</title>
          
          <p>In the study, the land use was classified and urban sprawls identified using different machine-learning models:</p><p>RF is an ensemble learning approach made up of decision trees. They train each tree with a random subset of the data, which forms the conclusion about the data classification taking place by the majority of the trees.</p><p>SVM is employed in determining the most suitable boundary amidst varieties of classes. It works well in multidimensional spaces, and this is the most employed classification system of remote sensing.</p><p>The K-Nearest Neighbors (KNN) algorithm offers an alternate simpler method in which pixels are determined to be of a certain class in the feature space by the majority of the neighboring classes.</p><p>Artificial Neural Networks (ANN) is applied to describe the complex relationships in the data, especially in areas where urban growth follows a nonlinear rather than a linear pattern.</p><p><xref ref-type="table" rid="table_1">Table 1</xref> compares different machine learning models used for land use classification, including RF, SVM, KNN, and ANN, by summarizing their core principles, strengths, weaknesses, and typical application scenarios. This comparison helps identify the most appropriate model according to data characteristics and classification objectives.</p>
          
            <table-wrap id="table_1">
              <label>Table 1</label>
              <caption>
                <title>Comparison of machine learning models for land use classification</title>
              </caption>
              <table><tr><td >Method</td><td >Description</td><td >Strengths</td><td >Weaknesses</td><td >Application</td></tr><tr><td >RF</td><td >Ensemble of decision trees that vote on classification outcomes.</td><td >Handles high-dimensional data well, robust against overfitting.</td><td >Computationally expensive for large datasets, slower with very high dimensional data.</td><td >Urban sprawl detection, land use mapping.</td></tr><tr><td >SVM</td><td >Classifies data by finding an optimal separating hyperplane between classes.</td><td >Works well in high-dimensional spaces, effective for classification of complex datasets.</td><td >Sensitive to the choice of kernel and regularization parameters.</td><td >Classifying heterogeneous urban environments.</td></tr><tr><td >KNN</td><td >Classifies data based on majority voting of nearby neighbors.</td><td >Simple and easy to implement, does not require model training.</td><td >Performance drops with large datasets, sensitive to noisy data.</td><td >Preliminary land use classification, clustering.</td></tr><tr><td >ANN</td><td >Mimics the human brain's network of neurons for pattern recognition.</td><td >Very flexible, can capture non-linear patterns, suitable for complex datasets.</td><td >Requires a lot of data for training, prone to overfitting with small datasets.</td><td >Non-linear urban growth, complex land-use change detection.</td></tr></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>5.5. Accuracy assessment techniques</title>
          
          <p>To evaluate the chart of classification, several methods were utilized:</p><p>(1) Confusion Matrix: This method contrasts the labeled output to the data with the ground truth, which enables one to know what sort of errors the model is likely to make.</p><p>(2) Kappa Coefficient (K): The level of Kappa measures the agreement between the classified map, and the ground truth map, but adjusted against chances. It is derived by the following formula:</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="mqzussto8g">
                <mml:mi>K</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>P</mml:mi>
                      <mml:mi>o</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>P</mml:mi>
                      <mml:mi>e</mml:mi>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>P</mml:mi>
                      <mml:mi>e</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>where, <inline-formula>
  <mml:math id="mk51x8p8rf">
    <mml:msub>
      <mml:mi>P</mml:mi>
      <mml:mi>o</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is the observed accuracy, and <inline-formula>
  <mml:math id="mzqpndw1ip">
    <mml:msub>
      <mml:mi>P</mml:mi>
      <mml:mi>e</mml:mi>
    </mml:msub>
  </mml:math>
</inline-formula> is the expected accuracy.</p><p>(3) Overall Accuracy: It is a ratio of the classified pixels that are correct to all pixels.</p><p>(4) Producer’s Accuracy: This indicates the extent to which each category was labeled and the accuracy of consumers tells of the likelihood that a pixel may be labeled to belong to a certain category.</p>
          <p><xref ref-type="table" rid="table_2">Table 2</xref> summarizes the broader categories of classification approaches and representative algorithms, highlighting the general characteristics of supervised and unsupervised methods and their suitability for urban land use mapping.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Overview of land use classification methodologies</title>
              </caption>
              <table><tr><td >Classification Technique</td><td >Description</td><td >Strengths</td><td >Weaknesses</td></tr><tr><td >Supervised classification</td><td >Requires labeled training data</td><td >High accuracy with labeled data</td><td >Depends on quality of training data</td></tr><tr><td >Unsupervised classification</td><td >Does not require labeled data</td><td >Useful for discovering new classes</td><td >May not work well for complex urban landscapes</td></tr><tr><td >RF</td><td >Ensemble of decision trees</td><td >Handles high-dimensional data well</td><td >Computationally expensive for large datasets</td></tr><tr><td >SVM</td><td >Finds optimal boundary between classes</td><td >Works well in high-dimensional spaces</td><td >Sensitive to the choice of kernel</td></tr><tr><td >KNN</td><td >Classifies based on neighbor pixels</td><td >Simple and easy to implement</td><td >Performance drops with large datasets</td></tr></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Results and discussion</title>
      
        <sec>
          
            <title>6.1. Land use classification performance using high-resolution data</title>
          
          <p>Land use classification was done using high-resolution data in Baghdad, including WorldView-2 (0.5 m spatial resolution), QuickBird (0.6 m), and Landsat 8 (30 m). Machine learning, RF, and SVM were used in the processing of the data to identify and categorize the various types of land use.</p><p><xref ref-type="fig" rid="fig_1">Figure 1</xref> shows the confusion matrix of the land use classification models. This is a graphical comparison of the observed and estimated land use (urban, agriculture, water, vegetation and barren land). It demonstrates the utility of the model in classifying the land types by comparing the labels that are calculated with the real label. The dots in the diagonal show the properly classified samples and the dots off diagonal are used to indicate misclassifications. Intensity of the color in the matrix represents accuracy of the predictions and a darker cell represents higher accuracy. This graph is essential in comprehending the performance of the model and in determining where they need to have an improvement.</p>
          
            <fig id="fig_1">
              <label>Figure 1</label>
              <caption>
                <title>Confusion matrix showing the accuracy of land use classification models</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2026/0/img_mPSBMPApaZ8JtmOJ.png"/>
            </fig>
          
          <p>The metrics include producer and consumer accuracy, and Kappa coefficient all of which are based on the confusion matrix, for each land use type in Baghdad are summarized in <xref ref-type="table" rid="table_3">Table 3</xref>. Urban areas achieved a producer’s accuracy of 92% and a consumer’s accuracy of 90%, with a Kappa coefficient of 0.88, indicating robust classification reliability. Water bodies exhibited the highest classification accuracy (K = 0.92), whereas agricultural land and barren land showed relatively lower producer’s accuracy values (85% and 87%, respectively). The results confirm that high-resolution imagery enables reliable discrimination of major land use types in the complex urban environment of Baghdad. This could be attributed to spectral confounding of dry croplands and desert fringes that are not inhabited by humans—which is a frequent problem in arid-zone urban research. The same classification ambiguities are observed in Tehran, where there is misclassification of land covers of the season and soil reflectance [<xref ref-type="bibr" rid="ref_14">14</xref>].</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Land use classification accuracy for land use types in Baghdad</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Land Use Type</p></td><td colspan="1" rowspan="1"><p>Description</p></td><td colspan="1" rowspan="1"><p>Producer’s Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Consumer’s Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Kappa Coefficient (K)</p></td></tr><tr><td colspan="1" rowspan="1"><p>Urban</p></td><td colspan="1" rowspan="1"><p>Residential affairs, trade-related, and industrial sites</p></td><td colspan="1" rowspan="1"><p>92</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>0.88</p></td></tr><tr><td colspan="1" rowspan="1"><p>Agriculture</p></td><td colspan="1" rowspan="1"><p>Cropland, pastures, and orchard</p></td><td colspan="1" rowspan="1"><p>85</p></td><td colspan="1" rowspan="1"><p>88</p></td><td colspan="1" rowspan="1"><p>0.83</p></td></tr><tr><td colspan="1" rowspan="1"><p>Water</p></td><td colspan="1" rowspan="1"><p>Rivers, lakes, and other water bodies</p></td><td colspan="1" rowspan="1"><p>95</p></td><td colspan="1" rowspan="1"><p>94</p></td><td colspan="1" rowspan="1"><p>0.92</p></td></tr><tr><td colspan="1" rowspan="1"><p>Vegetation</p></td><td colspan="1" rowspan="1"><p>Parks, grasslands, and forests</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>89</p></td><td colspan="1" rowspan="1"><p>0.87</p></td></tr><tr><td colspan="1" rowspan="1"><p>Barren land</p></td><td colspan="1" rowspan="1"><p>Lands that have no considerable vegetation or buildings</p></td><td colspan="1" rowspan="1"><p>87</p></td><td colspan="1" rowspan="1"><p>90</p></td><td colspan="1" rowspan="1"><p>0.85</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>6.2. Performance comparison of machine learning models</title>
          
          <p><xref ref-type="table" rid="table_4">Table 4</xref> reports classification accuracy derived from urban land use mapping using satellite imagery with varying spatial resolutions (WorldView-2, QuickBird, and Landsat 8) to evaluate the performance of four machine learning models (RF, SVM, KNN, and ANN). RF and SVM had similarly high values of classification accuracy, with overall accuracies of 89.6% (K = 0.88) and 88.9% (K = 0.87), respectively. These findings are quite comparable meaning that the two approaches are adequate in the classification of land use though there are slight variations in their performance. Whereas, KNN and ANN exhibited lower classification accuracy under the same conditions, suggesting reduced robustness when applied to heterogeneous urban environments [<xref ref-type="bibr" rid="ref_6">6</xref>].</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Comparison of machine learning models for land use classification</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Method</p></td><td colspan="1" rowspan="1"><p>Performance (Overall Accuracy) (%)</p></td><td colspan="1" rowspan="1"><p>Kappa Coefficient (K)</p></td></tr><tr><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>89.6</p></td><td colspan="1" rowspan="1"><p>0.88</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>88.9</p></td><td colspan="1" rowspan="1"><p>0.87</p></td></tr><tr><td colspan="1" rowspan="1"><p>KNN</p></td><td colspan="1" rowspan="1"><p>85.7</p></td><td colspan="1" rowspan="1"><p>0.80</p></td></tr><tr><td colspan="1" rowspan="1"><p>ANN</p></td><td colspan="1" rowspan="1"><p>86.9</p></td><td colspan="1" rowspan="1"><p>0.82</p></td></tr></tbody></table>
            </table-wrap>
          
          <p><xref ref-type="table" rid="table_5">Table 5</xref> compares model performance across different data sources and integration strategies. When single-source imagery is used, classification accuracy shows a clear dependence on spatial resolution, with WorldView-2 consistently outperforming QuickBird and Landsat 8 across all models. In contrast, classifications based on Landsat imagery yielded the lowest overall accuracy and Kappa values, reflecting the limitations of medium-resolution data in heterogeneous urban environments.</p>
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>Performance comparison of different data sources and models</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Data Source</p></td><td colspan="1" rowspan="1"><p>Model</p></td><td colspan="1" rowspan="1"><p>Overall Accuracy (%)</p></td><td colspan="1" rowspan="1"><p>Kappa Coefficient (K)</p></td></tr><tr><td colspan="1" rowspan="4"><p>WorldView-2</p></td><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>89.6</p></td><td colspan="1" rowspan="1"><p>0.88</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>88.2</p></td><td colspan="1" rowspan="1"><p>0.85</p></td></tr><tr><td colspan="1" rowspan="1"><p>KNN</p></td><td colspan="1" rowspan="1"><p>85.7</p></td><td colspan="1" rowspan="1"><p>0.80</p></td></tr><tr><td colspan="1" rowspan="1"><p>ANN</p></td><td colspan="1" rowspan="1"><p>86.9</p></td><td colspan="1" rowspan="1"><p>0.82</p></td></tr><tr><td colspan="1" rowspan="4"><p>QuickBird</p></td><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>88.2</p></td><td colspan="1" rowspan="1"><p>0.85</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>87.4</p></td><td colspan="1" rowspan="1"><p>0.83</p></td></tr><tr><td colspan="1" rowspan="1"><p>KNN</p></td><td colspan="1" rowspan="1"><p>84.3</p></td><td colspan="1" rowspan="1"><p>0.79</p></td></tr><tr><td colspan="1" rowspan="1"><p>ANN</p></td><td colspan="1" rowspan="1"><p>86.4</p></td><td colspan="1" rowspan="1"><p>0.81</p></td></tr><tr><td colspan="1" rowspan="4"><p>Landsat 8</p></td><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>82.4</p></td><td colspan="1" rowspan="1"><p>0.79</p></td></tr><tr><td colspan="1" rowspan="1"><p>SVM</p></td><td colspan="1" rowspan="1"><p>81.2</p></td><td colspan="1" rowspan="1"><p>0.76</p></td></tr><tr><td colspan="1" rowspan="1"><p>KNN</p></td><td colspan="1" rowspan="1"><p>78.5</p></td><td colspan="1" rowspan="1"><p>0.73</p></td></tr><tr><td colspan="1" rowspan="1"><p>ANN</p></td><td colspan="1" rowspan="1"><p>80.1</p></td><td colspan="1" rowspan="1"><p>0.75</p></td></tr><tr><td colspan="1" rowspan="1"><p>WorldView-2 + LiDAR + OSM</p></td><td colspan="1" rowspan="1"><p>RF</p></td><td colspan="1" rowspan="1"><p>92.3</p></td><td colspan="1" rowspan="1"><p>0.90</p></td></tr><tr><td colspan="1" rowspan="1"><p>All fused (incl. Social Media)</p></td><td colspan="1" rowspan="1"><p>ANN</p></td><td colspan="1" rowspan="1"><p>93.1</p></td><td colspan="1" rowspan="1"><p>0.91</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Across classifiers, RF and SVM exhibited relatively stable performance, whereas KNN produced consistently lower accuracy, indicating reduced robustness. ANN did not outperform RF or SVM under single-source conditions but showed substantial improvement when multi-source data were integrated.</p><p>The integration of complementary datasets resulted in a marked performance gain. The fusion of WorldView-2, LiDAR, and OSM data improved classification accuracy (92.3%, K = 0.90), while the fully integrated dataset achieved the best overall performance, with ANN reaching an accuracy of 93.1% (K = 0.91). These results indicate that multi-source data integration plays a more critical role in enhancing classification performance than algorithm selection alone.</p>
        </sec>
      
      
        <sec>
          
            <title>6.3. Temporal changes and spatial patterns in urban sprawl in baghdad (2000–2025)</title>
          
          <p>Urban development in Baghdad increased by approximately 35% over the study period (2000–2025), corresponding to an average annual growth rate of about 2%. This expansion was predominantly concentrated along the southern and western corridors of the city, closely associated with ongoing infrastructure development and the establishment of new residential areas. Importantly, the observed urban sprawl is characterized not only by its magnitude but also by its form. Urban growth in Baghdad has occurred largely through horizontal expansion into surrounding rural areas rather than through vertical densification within the existing urban core.</p><p>This pattern of horizontal growth reflects a combination of post-conflict urban migration, the proliferation of informal settlements, and limited enforcement of land use regulations. Similar urban sprawl dynamics have been reported in cities such as Cairo, Nairobi, and Karachi, where deficiencies in urban governance have contributed to informal land occupation and peripheral expansion. In this context, the spatial patterns identified in Baghdad suggest that existing urban planning responses have struggled to keep pace with the rapid transformation of land use, underscoring the need for more effective land governance frameworks.</p><p>Urban sprawl, commonly defined as the unplanned expansion of cities into surrounding rural landscapes, has had pronounced implications for land use and environmental conditions in Baghdad. Population growth has driven the conversion of agricultural land into built-up areas, resulting in a reduction of arable land at a time when food production capacity is under increasing pressure. Continuous infrastructure development has further accelerated this process through the expansion of residential, industrial, and commercial zones, as well as improvements in transportation networks that facilitate outward urban growth.</p><p>The expansion of urban areas has also been accompanied by broader environmental impacts, including landscape fragmentation, environmental degradation, loss of biodiversity, and disruptions to local hydrological processes. To quantify these changes, land use transitions for the years 2000, 2020, and 2025 were determined and analyzed using remote sensing data, including high-resolution satellite imagery. This temporal analysis provides an empirical basis for assessing the extent and characteristics of urban sprawl in Baghdad.</p><p>To spatially represent these land use patterns, <xref ref-type="fig" rid="fig_2">Figure 2</xref> presents the classified land use map of Baghdad for 2025 derived from WorldView-2 imagery. The map clearly delineates areas of recent urban expansion, particularly in the southern and western parts of the city, where urban footprints have progressively replaced agricultural land. This spatial representation supports the numerical results and highlights major growth trends driven by infrastructure development. When considered alongside transportation networks and terrain constraints, such spatial information can assist in identifying priority areas for urban management and land use regulation. <xref ref-type="fig" rid="fig_3">Figure 3</xref> illustrates the spatial distribution of land use in Baghdad in 2025, showing that urban areas are mainly concentrated along major transportation routes and the river corridor.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Temporal changes in land use in Baghdad (2000–2025)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2026/0/img_AV5fw8UFoKWMxdvf.png"/>
            </fig>
          
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Land use classification map of Baghdad (2025)</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2026/0/img_BvlXqgsdqN8hgbxd.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>6.4. Contribution of high-resolution data and multi-source data integration</title>
          
          <p>The use of high-resolution satellite imagery and multi-source data integration played a key role in improving the accuracy and robustness of urban land use classification in Baghdad. Compared with single-source datasets, the integrated approach resulted in higher overall accuracy and Kappa coefficients, as demonstrated by the results summarized in <xref ref-type="table" rid="table_4">Table 4</xref> and <xref ref-type="table" rid="table_5">Table 5</xref>. In particular, the urban classification accuracy achieved in this study exceeds or is comparable to those reported in previous studies that relied primarily on medium-resolution imagery.</p><p><xref ref-type="table" rid="table_6">Table 6</xref> presents a comparative overview of classification accuracy obtained in this study and in selected related works [<xref ref-type="bibr" rid="ref_9">9</xref>], [<xref ref-type="bibr" rid="ref_12">12</xref>]. The comparison demonstrates that the use of high-resolution WorldView-2 imagery in Baghdad resulted in a higher urban classification accuracy (92%) than studies based on Landsat 8 data in Charlotte, North Carolina (87%) [<xref ref-type="bibr" rid="ref_9">9</xref>] and Shanghai (80%) [<xref ref-type="bibr" rid="ref_12">12</xref>]. These findings underscore the added value of high-resolution data in capturing the complex spatial heterogeneity characteristic of dense urban environments.</p>
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Comparison with previous studies using traditional and high-resolution data</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Study</p></td><td colspan="1" rowspan="1"><p>Satellite Data Used</p></td><td colspan="1" rowspan="1"><p>Spatial Resolution</p></td><td colspan="1" rowspan="1"><p>Urban Classification Accuracy</p></td></tr><tr><td colspan="1" rowspan="1"><p>Baghdad, Iraq (Current study)</p></td><td colspan="1" rowspan="1"><p>WorldView-2 (High-Res.)</p></td><td colspan="1" rowspan="1"><p>0.5 m</p></td><td colspan="1" rowspan="1"><p>92%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Charlotte, North Carolina, USA [<xref ref-type="bibr" rid="ref_9">9</xref>]</p></td><td colspan="1" rowspan="1"><p>Landsat 8 (Traditional)</p></td><td colspan="1" rowspan="1"><p>1 m</p></td><td colspan="1" rowspan="1"><p>87%</p></td></tr><tr><td colspan="1" rowspan="1"><p>Shanghai, China [<xref ref-type="bibr" rid="ref_12">12</xref>]</p></td><td colspan="1" rowspan="1"><p>Landsat 8 (Traditional)</p></td><td colspan="1" rowspan="1"><p>30 m</p></td><td colspan="1" rowspan="1"><p>80%</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Beyond improvements in numerical accuracy, the integration of high-resolution and multi-source datasets significantly enhanced the detection of fine-scale spatial patterns of urban expansion. The improved delineation of urban boundaries and peri-urban zones enabled a clearer identification of horizontal growth trends and agricultural land conversion, particularly along the southern and western development corridors of Baghdad, as discussed in Section 6.3. Such spatial detail would be difficult to capture using medium-resolution data alone.</p><p>Thus, the results indicate that advances in urban land-use classification are driven not only by algorithm selection but, more importantly, by data resolution and data integration strategies. While machine learning models such as RF and SVM provided stable baseline performance, the incorporation of high-resolution satellite imagery and ancillary GIS data substantially improved the ability to characterize complex urban growth dynamics. These findings suggest that improvements in classification accuracy are closely linked to the spatial richness of input data rather than reliance on increasingly complex algorithms alone. This integrated approach therefore offers a more reliable and effective framework for long-term urban sprawl monitoring in rapidly expanding cities such as Baghdad, where fine spatial detail is essential for informed and sustainable urban planning.</p>
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>7. Implications, limitations, and uncertainties</title>
      
        <sec>
          
            <title>7.1. Issues related to data quality and resolution</title>
          
          <p>The input data (both noisy and incomplete) affects the accuracy of land use classification. Remote sensing is an important factor whereby low-resolution data may help to disperse the land usage type, whereas high-resolution data, although more specific, makes it more computationally demanding and over-fitting risky. It should further be noted that the classification is also affected by the temporal resolution because without seasonal change it is more difficult to identify any dynamics of the land use, including agriculture or urban development.</p>
        </sec>
      
      
        <sec>
          
            <title>7.2. The impact of urban variability on classification accuracy</title>
          
          <p>The use of residential, commercial, industrial and recreational areas will make urban classifications complex; it will be difficult to identify the urban areas and greenery, waterways, and buildings that are tall. The necessity of the up-to-date data and adaptable models can be observed, since the change in buildings and roads always occurs, influencing the quality of classifications and challenging algorithms to be delicate enough in identifying urban landscapes.</p>
        </sec>
      
      
        <sec>
          
            <title>7.3. Computational challenges and model limitations</title>
          
          <p>Some of the primary issues in the land use classification projects include high computation, complex modeling, imbalance of classes, problems in data fusion, and integrating data. Big geographic data is characterized by classification difficulties since high-resolution images and a variety of data sources require a great amount of calculation. Deep learning algorithms need an extensive amount of labeled training data and cannot work well without additional improvement. The imbalance of the classes can favor model forecasts of more commonly occurring land types, and ignore less common ones. Besides, the different formats, scales, and resolutions of data fusion may also create classification error, thus the necessity of better data preparation, model choice, mathematical procedures, and development of machine learning and remote sensing systems should improve the performance and accuracy of classification.</p>
        </sec>
      
      
        <sec>
          
            <title>7.4. Practical implications for urban planners and policymakers</title>
          
          <p>The land use classification maps will be crucial to the policymakers and planners in the city to determine land allocation and movement of urban centers. They assist in the recognition of areas that may be developed or conserved and the development of infrastructures, which enhance zoning and allocation of resources. Urban sprawl, agricultural land preservation, and sustainable urbanization are some of the objects of analysis of land use changes that help in their management. These maps also give infrastructure investments the priority, making sure that the resources are distributed well and that there is fair dispersion of services whether in urban or in rural areas.</p>
        </sec>
      
      
        <sec>
          
            <title>7.5. Using optimized land use maps for sustainable urban development</title>
          
          <p>Improved land use maps will be useful in the conservation of land, infrastructure planning, and resilience to climate change through the identification of essential green spaces and vulnerable locations. The resources are used to coordinate development and environmental conservation by the urban planners, which enhances biodiversity and well-being of people. The sustainable infrastructure through the mapping also helps in the prioritization of where resources should be distributed and location choice to minimize environmental interference. In addition to this, they help the creation of climate-resilient cities through highlighting areas prone to flooding and areas with high heat islands so that policies can be enacted to protect against floods and green roofing and cool the city.</p>
        </sec>
      
      
        <sec>
          
            <title>7.6. Future research directions for urban sprawl monitoring</title>
          
          <p>The future studies will be aimed at improving the land use classification resolution and accuracy by applying the highest-resolution remote sensing technologies: LiDAR, UAVs, and hyperspectral imaging. The associated technologies can enable one to identify slight deviations in land use in small areas in detail and measure urban sprawl in real time. The merge of machine learning and big data will help to track the trends and hence give early signals to the policymaker in control of the urban growth. In addition, dynamic land use change detector systems are under development and real-time monitoring to help urban planners to cope with the dynamism of urban growth. Simulations of urban sprawl will be used to integrate different data in order to predict the possible rise in case of application of different policies. Future research might determine the effects of urban sprawl on local ecosystems, biodiversity, and human health that will help planners to encourage sustainable urban development. Urban planning will continue its development based on the introduction of new technologies to contribute to the better life quality and growth management of the population.</p>
        </sec>
      
    </sec>
    <sec sec-type="conclusions">
      <title>8. Conclusions</title>
      
        <sec>
          
            <title>8.1. Summary of key findings</title>
          
          <p>This study demonstrates that high-resolution remote sensing data combined with GIS-based spatial information can significantly improve the accuracy and reliability of urban land use classification. The results confirm that land use classification is an effective tool for monitoring urban sprawl and distinguishing between urban and non-urban land uses in rapidly expanding cities. Machine learning algorithms such as RF and SVM achieved stable and consistent performance, enabling the detection of fine-scale land use changes and reducing classification uncertainty, particularly in heterogeneous urban environments.</p>
        </sec>
      
      
        <sec>
          
            <title>8.2. Contributions of the study to land use classification methodology</title>
          
          <p>The primary methodological contribution of this study lies in highlighting the importance of data resolution and multi-source integration in enhancing land use classification accuracy. By integrating high-resolution satellite imagery with GIS-based spatial information, the study demonstrates that classification performance can be substantially improved without relying solely on increasingly complex algorithms. The findings emphasize that spatial richness and contextual information play a decisive role in accurately characterizing land use patterns, especially in complex urban settings. This study provides an empirical reference for applying integrated, high-resolution datasets to urban land use classification, while also indicating that further comparative assessments of individual versus integrated data sources remain a valuable direction for future research.</p>
        </sec>
      
      
        <sec>
          
            <title>8.3. Final remarks on the role of high-resolution gis and remote sensing</title>
          
          <p>High-resolution GIS and remote sensing data offer critical advantages for accurate land use classification in urban areas, where subtle spatial differences between land use types can lead to significant classification uncertainty. The ability to capture fine spatial detail is essential for distinguishing between residential, commercial, and other urban land uses and for generating up-to-date land use maps that support sustainable urban planning. As remote sensing technologies continue to advance, including improvements in satellite, UAV, and data processing capabilities, the integration of high-resolution spatial data with machine learning approaches will further enhance the monitoring of urban growth dynamics. Such developments provide valuable opportunities for evidence-based urban planning and informed decision-making in rapidly urbanizing regions.</p>
        </sec>
      
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The author declares no conflicts of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>18</volume>
          <page-range>3717</page-range>
          <issue>11</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Ke</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s18113717</pub-id>
          <article-title>Urban land use and land cover classification using novel deep learning models based on high spatial resolution satellite imagery</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>2719</page-range>
          <issue>22</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shi</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Qi</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Niu</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs11222719</pub-id>
          <article-title>Urban land use and land cover classification using multisource remote sensing images and social media data</article-title>
          <source>Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="conf-paper">
          <year>2009</year>
          <person-group person-group-type="author">
            <name>
              <surname>Verma</surname>
              <given-names>R. K.</given-names>
            </name>
            <name>
              <surname>Kumari</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tiwary</surname>
              <given-names>R. K.</given-names>
            </name>
          </person-group>
          <article-title>Application of remote sensing and GIS technique for efficient urban planning in India</article-title>
          <source>Geomatrix Conference Proceedings</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>12</volume>
          <page-range>1987</page-range>
          <issue>12</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zong</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lian</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bie</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Xie</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs12121987</pub-id>
          <article-title>Detailed mapping of urban land use based on multi-source data: A case study of Lanzhou</article-title>
          <source>Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>312</page-range>
          <issue>8</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wiatkowska</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Słodczyk</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Stokowska</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/geosciences11080312</pub-id>
          <article-title>Spatial-temporal land use and land cover changes in urban areas using remote sensing images and GIS analysis: The case study of Opole, Poland</article-title>
          <source>Geosciences</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>1737</page-range>
          <issue>11</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Song</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Alexander Prishchepov</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs10111737</pub-id>
          <article-title>Mapping urban functional zones by integrating very high spatial resolution remote sensing imagery and points of interest: A case study of Xiamen, China</article-title>
          <source>Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="journal">
          <volume>58</volume>
          <page-range>439-448</page-range>
          <year>1992</year>
          <person-group person-group-type="author">
            <name>
              <surname>Treitz</surname>
              <given-names>P. M.</given-names>
            </name>
            <name>
              <surname>P. J. Howarth</surname>
            </name>
            <name>
              <surname>Gong</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Application of satellite and GIS technologies for land-cover and land-use mapping at the rural-urban fringe: A case study</article-title>
          <source>Photogramm. Eng. Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>155</page-range>
          <issue>3</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mohammady</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Delavar</surname>
              <given-names>M. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s40808-016-0209-4</pub-id>
          <article-title>Urban sprawl assessment and modeling using Landsat images and GIS</article-title>
          <source>Modeling Earth Systems and Environment</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>74</volume>
          <page-range>110-121</page-range>
          <year>2012</year>
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>K. K.</given-names>
            </name>
            <name>
              <surname>Vogler</surname>
              <given-names>J. B.</given-names>
            </name>
            <name>
              <surname>D. A. Shoemaker</surname>
            </name>
            <name>
              <surname>Meentemeyer</surname>
              <given-names>R. K.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2012.09.009</pub-id>
          <article-title>LiDAR-Landsat data fusion for large-area assessment of urban land cover: Balancing spatial resolution, data volume and mapping accuracy</article-title>
          <source>ISPRS Journal of Photogrammetry and Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <volume>47</volume>
          <page-range>183-195</page-range>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <surname>Hu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tong</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Frazier</surname>
              <given-names>A. E.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.habitatint.2015.01.017</pub-id>
          <article-title>Urban boundary extraction and sprawl analysis using Landsat images: A case study in Wuhan, China</article-title>
          <source>Habitat International</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>38</volume>
          <page-range>4107-4129</page-range>
          <issue>14</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Fenta</surname>
              <given-names>A. A.</given-names>
            </name>
            <name>
              <surname>Yasuda</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Haregeweyn</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Belay</surname>
              <given-names>A. S.</given-names>
            </name>
            <name>
              <surname>Hadush</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Gebremedhin</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Mekonnen</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/01431161.2017.1317936</pub-id>
          <article-title>The dynamics of urban expansion and land use/land cover changes using remote sensing and spatial metrics: The case of Mekelle City of northern Ethiopia</article-title>
          <source>International Journal of Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>31</volume>
          <page-range>1485-1504</page-range>
          <issue>6</issue>
          <year>2010</year>
          <person-group person-group-type="author">
            <name>
              <surname>Tong</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/01431160903475290</pub-id>
          <article-title>Detection of urban sprawl using a genetic algorithm-evolved artificial neural network classification in remote sensing: A case study in Jiading and Putuo districts of Shanghai, China</article-title>
          <source>International Journal of Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>88</page-range>
          <issue>1</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Luo</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Wan</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Hao</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>Q.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/rs11010088</pub-id>
          <article-title>Fusing high-spatial-resolution remotely sensed imagery and OpenStreetMap data for land cover classification over urban areas</article-title>
          <source>Remote Sensing</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>24</volume>
          <page-range>241-255</page-range>
          <issue>2</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Sumari</surname>
              <given-names>N. S.</given-names>
            </name>
            <name>
              <surname>Portnov</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ujoh</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Musakwa</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Mandela</surname>
              <given-names>P. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/10095020.2020.1787800</pub-id>
          <article-title>Urban sprawl and its impact on sustainable urban development: A combination of remote sensing and social media data</article-title>
          <source>Geo-spatial Information Science</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>607-611</page-range>
          <issue>4</issue>
          <year>2018</year>
          <person-group person-group-type="author">
            <name>
              <surname>Georganos</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Grippa</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Vanhuysse</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lennert</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Shimoni</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wolff</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/lgrs.2018.2803259</pub-id>
          <article-title>Very high resolution object-based land use–land cover urban classification using extreme gradient boosting</article-title>
          <source>IEEE Geoscience and Remote Sensing Letters</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>55</volume>
          <page-range>221-242</page-range>
          <issue>2</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Georganos</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Grippa</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Vanhuysse</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lennert</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Shimoni</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kalogirou</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Wolff</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/15481603.2017.1408892</pub-id>
          <article-title>Less is more: Optimizing classification performance through feature selection in a very-high-resolution remote sensing object-based urban application</article-title>
          <source>GISci. Remote Sens.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>16</volume>
          <page-range>75-90</page-range>
          <issue>2</issue>
          <year>2025</year>
          <person-group person-group-type="author">
            <name>
              <surname>Kalogiannidis</surname>
              <given-names>Stavros</given-names>
            </name>
            <name>
              <surname>Spinthiropoulos</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kalfas</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Chatzitheodoridis</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Tziampazi</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.48088/ejg.s.kal.16.2.075.090</pub-id>
          <article-title>Integration of remote aensing and GIS for urban sprawl monitoring in European cities</article-title>
          <source>Eur. J. Geogr.</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>