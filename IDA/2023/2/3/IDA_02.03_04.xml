<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">IDA</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Information Dynamics and Applications</journal-title>
        <abbrev-journal-title abbrev-type="issn">Inf. Dyn. Appl.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">IDA</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2958-1494</issn>
      <issn publication-format="print">2958-1486</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-nPHrtPcBUKBLYHTZaT9RkPQeGmES_jkX</article-id>
      <article-id pub-id-type="doi">10.56578/ida020304</article-id>
      <title-group>
        <article-title>MR Image Feature Analysis for Alzheimer’s Disease Detection Using Machine Learning Approaches</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Reza</surname>
            <given-names>D. S. A. Aashiqur</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1968-0419</contrib-id>
          <email>aashiq.reza007@gmail.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Afrin</surname>
            <given-names>Sadia</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0009-3429-3896</contrib-id>
          <email>sadia171261@gmail.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Ullah</surname>
            <given-names>Md. Ahsan</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-6472-3365</contrib-id>
          <email>ahsanullah5@yahoo.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Kha</surname>
            <given-names>Sourav Kumar</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0000-7514-2124</contrib-id>
          <email>souravkumarkhabd33@gmail.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Toma</surname>
            <given-names>Sadia Chowdhury</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0007-2095-1347</contrib-id>
          <email>sadia.toma356@gmail.com</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Roy</surname>
            <given-names>Raju</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0733-755X</contrib-id>
          <email>rajuroy@math.ku.ac.bd</email>
        </contrib>
        <contrib contrib-type="author">
          <xref ref-type="aff" rid="1">1</xref>
          <name>
            <surname>Ali</surname>
            <given-names>Lasker Ershad</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4987-9493</contrib-id>
          <email>ershad@math.ku.ac.bd</email>
        </contrib>
        <aff id="1">Mathematics Discipline, Khulna University, 9208 Khulna, Bangladesh</aff>
      </contrib-group>
      <year>2023</year>
      <volume>2</volume>
      <issue>3</issue>
      <fpage>143</fpage>
      <lpage>152</lpage>
      <page-range>143-152</page-range>
      <history>
        <date date-type="received">
          <month>06</month>
          <day>30</day>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <month>09</month>
          <day>04</day>
          <year>2023</year>
        </date>
        <date date-type="pub">
          <month>09</month>
          <day>26</day>
          <year>2023</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2023 by the authors</copyright-statement>
        <copyright-year>2023</copyright-year>
        <license>. Licensee Acadlore Publishing Services Limited, Hong Kong. This article can be downloaded for free, and reused and quoted with a citation of the original published version, under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 license</ext-link>.</license>
      </permissions>
      <abstract><p>Alzheimer’s disease (AD), a progressive neurological disorder, predominantly impacts cognitive functions, manifesting as memory loss and deteriorating thinking abilities. Recognized as the primary form of dementia, this affliction subtly commences within brain cells and gradually aggravates over time. In 2023, dementia's financial burden for elderly adults aged 65 and older was projected to reach \$345 billion, encompassing health care, long-term care, and hospice services. Alarmingly, Alzheimer's disease claims one in three seniors, outnumbering combined fatalities from breast and prostate cancer. Currently, the diagnostic landscape for Alzheimer's lacks definitive tests, and diagnoses based purely on biological definitions have been observed to possess low predictive accuracy. In the presented study, a diagnostic methodology has been proposed using machine learning models that harness image features derived from brain MRI scans. Specifically, nine salient image features, grounded in color, texture, shape, and orientation, were extracted for the study. Four classifiers — Naïve-Bayes, Logistic regression, XGBoost, and AdaBoost — were employed, as the challenge presented a binary classification scenario. A grid search parameter optimization technique was employed to fine-tune model configurations, ensuring optimal predictive outcomes. Conducted experiments utilizing the Kaggle dataset, and for each model, parameters were rigorously optimized. The XGBoost classifier demonstrated superior performance, achieving a test accuracy of 92%, while Naïve Bayes, Logistic Regression, and AdaBoost registered accuracies of 63%, 70%, and 72%, respectively. Relative to contemporary methods, the proposed diagnostic approach exhibits commendable accuracy in predicting AD. If AI-based predictive diagnostics for AD are realized using the strategies delineated in this study, significant benefits may be anticipated for healthcare practitioners.</p></abstract>
      <kwd-group>
        <kwd>Alzheimer's disease (AD)</kwd>
        <kwd>Machine learning</kwd>
        <kwd>Image classification</kwd>
        <kwd>Disease detection</kwd>
        <kwd>XGBoost</kwd>
        <kwd>MRI</kwd>
        <kwd>Feature extraction</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors">7</count>
        <fig-count>3</fig-count>
        <table-count>2</table-count>
        <ref-count>33</ref-count>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec disp-level="level1" sec-type="intro">
      <title>1. Introduction</title>
      <p>AD has been identified as a predominant aging-related illness. Increases in average life expectancy in recent years have amplified the economic and societal implications of AD [<xref ref-type="bibr" rid="ref_1">1</xref>]. As advancements in treatments for central nervous system (CNS) disorders emerge, the significance of aiding medical practitioners in establishing precise early diagnostic distinctions has been accentuated [<xref ref-type="bibr" rid="ref_1">1</xref>]. Over the next forty years, a tripling in AD prevalence is anticipated, escalating from 27 to 106 million. During this period, it is projected that 1 in 85 individuals worldwide will be afflicted by the disorder. Notably, even a minor one-year delay in the onset and progression of the disease could potentially reduce the number of cases by 9 million [<xref ref-type="bibr" rid="ref_2">2</xref>].</p>
      <p>AD has been noted as the leading cause of memory impairment in both senile and presenile individuals, with the severity of the condition amplifying as individuals age [<xref ref-type="bibr" rid="ref_3">3</xref>]. Neuroimaging investigations have become instrumental in the early diagnosis of AD, acquiring valuable data and insights from multiple sources, including structural MRI, functional MRI (fMRI), and blood perfusion information [<xref ref-type="bibr" rid="ref_4">4</xref>]. In 1980, clinical criteria for AD diagnosis were established using a binary evaluation methodology by the National Institute of Neurologic and Communicative Disorders and Stroke in conjunction with the AD and Related Disorders Association [<xref ref-type="bibr" rid="ref_5">5</xref>].</p>
      <p>MR brain imaging, in evaluating degeneration in grey and white matter tissues, has frequently been employed in AD diagnosis [<xref ref-type="bibr" rid="ref_6">6</xref>]. The preliminary diagnostic steps often involve differentiating between normal aging-related physical and cognitive changes and symptoms suggestive of Mild Cognitive Impairment. An in-depth review of the MRI, complemented by a clinical interview with the affected individual, can facilitate the confirmation of memory loss or AD diagnosis [<xref ref-type="bibr" rid="ref_7">7</xref>]. Contemporary research endeavors have focused on the development of deep learning-based diagnostics for AD, exploring MRIs using robust classification models [<xref ref-type="bibr" rid="ref_8">8</xref>]. Integration of state-of-the-art computational machine learning algorithms with advanced neuroimaging methodologies has enabled the identification of structural and molecular biomarkers associated with AD [<xref ref-type="bibr" rid="ref_9">9</xref>]. AD, characterized by a progressive loss of cognitive capabilities, currently lacks effective or curative treatments [<xref ref-type="bibr" rid="ref_10">10</xref>]. Given the escalating number of AD cases, early diagnosis has become paramount. One challenge in image signal processing is the vast number of features, which contributes to extended execution times. Thus, pivotal image features have been extracted, aiming to reduce this execution duration by limiting feature numbers.</p>
      <p>The study at hand seeks to detect AD through brain MRIs via machine learning methodologies. Its significance is rooted in its potential contribution to the early detection and diagnosis of AD, thereby paving the way for effective management, treatment planning, and preparatory care for patients and their families. Features like image intensity, texture, shape, eccentricity, orientation, entropy, coarseness, energy, homogeneity, dissimilarity, standard deviation, variance, and skewness of image intensities have been harnessed for the feature extraction phase. Utilizing these features, AD detection is pursued through machine learning models such as Naïve-Bayes, Logistic Regression, XGBoosting, and AdaBoosting. It is hoped that these findings might facilitate early AD diagnosis, potentially enhancing life expectancy for affected individuals.</p>
      <p>The subsequent section (section 2) encompasses an extended literature review. The materials and methodologies adopted in this investigation are detailed in section 3. The findings of this research are elucidated in section 4, culminating in a comprehensive conclusion in section 5.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>2. Related works</title>
      <p>The literature encompasses various approaches for the prediction and detection of AD, primarily bifurcating into deep learning and machine learning methodologies.</p>
      <p>In recent years, advancements have been observed in the deployment of convolutional neural networks (CNNs) for AD detection. An identification system for AD, encompassing both binary and multi-class tasks, was proposed by Maqsood et al. [<xref ref-type="bibr" rid="ref_11">11</xref>] in 2019, wherein a pre-trained CNN, augmented with transfer learning, was validated using data from brain MRI images. Parallel research by Tambe et al. [<xref ref-type="bibr" rid="ref_12">12</xref>] explored multiple deep-learning models, with the VGG19 model exhibiting an accuracy of 91.38%. Additionally, a machine learning methodology predicated on GoogleNet, VGG, and Alexnet was constructed by Muhammed Raees and Thomas [<xref ref-type="bibr" rid="ref_13">13</xref>]. Such patterns of utilizing CNN-based transfer learning for both binary and multiclass classifications of AD were also noticed in works by Ghaffari et al. [<xref ref-type="bibr" rid="ref_14">14</xref>], where ResNet101, Xception, and InceptionV3 were employed. Substantial performance metrics were reported by Mamun et al. [<xref ref-type="bibr" rid="ref_15">15</xref>], where CNN outperformed other models when applied to a dataset of 6219 MRI images for AD detection. Beyond MRI data, EEG recordings have also been harnessed. Ieracitano et al. [<xref ref-type="bibr" rid="ref_16">16</xref>] introduced a data-driven strategy, utilizing CNN to discern binary and multiclass images, achieving accuracies of 89.8% and 83.3% respectively. Complementing this, Liu et al. [<xref ref-type="bibr" rid="ref_17">17</xref>] leveraged a 3D ShuffleNet model based on ResNet and DenseNet within a CNN architecture. Song et al. [<xref ref-type="bibr" rid="ref_18">18</xref>] conducted an exhaustive analysis, and findings suggested RF, MLP, and CNN achieved accuracies of 90.2%, 89.6%, and 90.5%, respectively. It is worth noting that while these deep learning algorithms can process large and intricate datasets, occasionally outperforming traditional machine learning algorithms, there remains the possibility of overfitting.</p>
      <p>Conversely, traditional machine-learning approaches have been pursued extensively for AD prediction. For instance, Achilleos et al. [<xref ref-type="bibr" rid="ref_19">19</xref>] employed decision trees (DT) and random forests (RF) for the classification of normal control (NC) cases of AD. Kadhim et al. [<xref ref-type="bibr" rid="ref_20">20</xref>] conducted a comprehensive review, emphasizing the positive results achieved by algorithms such as SVM, U-Net Architecture 2.5D, and ResNet. Savaş [<xref ref-type="bibr" rid="ref_21">21</xref>] embarked on a journey to discern the early stages of AD, classifying them using brain MRIs. In a more recent study by Bigham et al. [<xref ref-type="bibr" rid="ref_22">22</xref>], an automated system was developed to classify AD patients, leveraging diffusion tensor imaging (DTI) and MATLAB for the analysis. Gupta et al. [<xref ref-type="bibr" rid="ref_23">23</xref>] focused on an ensemble of machine learning algorithms, integrating features from voxel-based morphometry (VBM), cortical and subcortical volumetric features, and hippocampal volumetric features. Decision trees, particularly pruned variants like J48, were applied by Battineni et al. [<xref ref-type="bibr" rid="ref_24">24</xref>] to prognosticate late-life AD. Baglat et al. [<xref ref-type="bibr" rid="ref_25">25</xref>] tested an assortment of machine learning methodologies on T1-weighted MRI data, with RF and AdaBoost classifiers yielding an accuracy of 86%. Tuan et al. [<xref ref-type="bibr" rid="ref_26">26</xref>] proposed a deep learning model tailored for 3D brain MR image segmentation.</p>
      <p>It is discernible from the literature that while deep learning models often proffer higher accuracy rates, they come with the trade-offs of increased computational complexity, interpretability challenges, and resource-intensive training processes. On the other hand, machine learning models, owing to their simplicity and well-defined mathematical underpinnings, often exhibit swifter training durations and reduced computational demands. Therefore, it becomes pivotal to balance these trade-offs based on the specific requirements and constraints of a study. The following section (Section 3: Materials and Methods) delves into the machine learning methodologies adopted in this research, elucidating ten feature extraction techniques complemented by four classification models.</p>
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>3. Methodology</title>
      <p>The objective of this study was to predict AD using four distinct machine learning classification models, drawing upon nine specific features extracted from brain MR images.</p>
      <p>Upon the careful acquisition of data, key image features were quantified. Intensity, shape, entropy, eccentricity, energy, coarseness, homogeneity, and dissimilarity were computed for both the training and testing sets. These computations were facilitated using formulas described in Section 3, executed within a Python environment supported by the OpenCV library. The criticality of feature selection in image classification became evident as intensity, representative of pixel brightness, and shape, delineating object structure, were assessed. Additionally, texture metrics such as entropy, which quantifies randomness, and dissimilarity, evaluating pixel value variations, were integrated. The amalgamation of these diverse features provided a comprehensive portrayal of visual attributes, enhancing the model's prowess in distinguishing and classifying image objects.</p>
      <p>Post feature extraction, the machine learning models were trained using the identified features. Parameter optimization was undertaken to ascertain optimal results. While model performance is often evaluated using accuracy, this metric may not suffice in scenarios with imbalanced class distributions or varying error costs. As such, sensitivity, specificity, and AUC values were also considered pivotal performance indicators in this analysis.</p>
      <p>The overarching process of the study is illustrated in <xref ref-type="fig" rid="fig_1">Figure 1</xref>: Systematic Flowchart of the Proposed Approach. Detailed discussions on feature extraction and classification strategies are presented in the ensuing sections.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>The systematic flowchart of the proposed approach</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/8/img_4AerpRcvCjz1aCrz.png"/>
        </fig>
      
      
        <sec disp-level="level2">
          
            <title>3.1. Image feature extraction</title>
          
          <p>Feature extraction is understood as the transformation of raw, unprocessed data into numerical attributes that can be processed, ensuring the retention of the original dataset's pertinent information. Image features, in this context, signify visual patterns or characteristics extractable from an image, presenting its content in a more concise and interpretable manner. These extracted features encapsulate pivotal information, from shapes and textures to edges and other visually relevant properties. Historically, attributes such as shape, texture, pixel intensity, homogeneity, and dissimilarity have been identified as the most pertinent features in an image. It has been observed that leveraging these specific image attributes results in enhanced performance. In this study, the features of pixel intensity, shape, entropy, orientation, eccentricity, energy, coarseness, homogeneity, and pixel dissimilarity were examined, as delineated in the following subsections.</p>
          
            <sec disp-level="level3">
              
                <title>3.1. 1 Pixel intensity</title>
              
              <p>Pixel intensity describes the level of brightness or darkness exhibited by image pixels. In digital imaging, a numerical value is attributed to each pixel, representing its intensity. Pixels with higher luminosity are associated with elevated intensity values, whereas their darker counterparts exhibit diminished values. This elemental property has been harnessed in diverse applications spanning edge detection, contrast augmentation, and image segmentation. Not just mean intensity, but also variance, standard deviation, and skewness of the intensity have been considered as features in this investigation. The average intensity of an image is computationally determined using the equation:</p>
              
                <disp-formula>
                  <label>(1)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mtext> Intensity </mtext>
                    <mo>=</mo>
                    <mo data-mjx-texclass="OP">∑</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mi>m</mi>
                    </mfrac>
                    <mi>I</mi>
                    <mi>x</mi>
                    <mi>y</mi>
                  </math>
                </disp-formula>
              
              <p>where, <italic>m</italic> represents the total number of pixels, and <italic>I</italic>(<italic>x, y</italic>) denotes the intensity at each specific image point.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 2 Shape features</title>
              
              <p>The concept of shape in imagery pertains to the spatial layout and geometric properties inherent to objects or regions encapsulated within. This encompasses the contour, boundary delineations, and the general structure of the visual content. Shape analysis, a method of extracting and chronicling geometric object properties, finds utility in various applications such as object recognition, character recognition, and medical image diagnostics. The geometric features of objects embedded in images are deciphered to gain invaluable insights, underscoring the significance of shape analysis in the broader realms of image processing and computer vision.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 3 Image entropy</title>
              
              <p>Entropy, in the image domain, delineates the unpredictability quotient inherent to an image. In the realm of image coding, entropy serves as a baseline, dictating the average coding length, quantified in bits per pixel, achievable by optimal coding techniques without information compromise. Its value oscillates not just with image focus levels but also entropy. The computation of pixel value entropy within a 2-dimensional expanse centered at coordinates (<italic>i, j</italic>) reveals the image's entropy. A multifaceted image, boasting a diverse range of pixel values, is indicated by a higher entropy number, whereas simplicity and uniformity are represented by a diminished entropy figure. The entropy of an image is mathematically defined by:</p>
              
                <disp-formula>
                  <label>(2)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>η</mi>
                    <mi>p</mi>
                    <mi>log</mi>
                    <mi>p</mi>
                    <mo>=</mo>
                    <mo data-mjx-texclass="OP">∑</mo>
                    <mo>∗</mo>
                    <mo data-mjx-texclass="NONE">⁡</mo>
                    <mo stretchy="false">(</mo>
                    <mo stretchy="false">)</mo>
                  </math>
                </disp-formula>
              
              <p>where, <italic>p</italic> denotes the normalized histogram counts corresponding to a specific grey level of a pixel.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 4 Patterns local orientations</title>
              
              <p>Orientation, a salient feature of edges and patterns exhibiting a marked direction, provides insights into intricate image facets. Local orientation, beyond merely deciphering the directionality of a pattern, is an indispensable component of motion analysis, involving the scrutiny of an image to deduce the orientation of an embedded object based on its angular disposition.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 5 Eccentricity of an image region</title>
              
              <p>Eccentricity, in the context of a connected graph, is defined as the shortest path length between one vertex and any other vertex. Within the realm of ellipses, the ratio of the length of the major axis to the distance between its foci determines the eccentricity, producing values ranging between 0 and 1, with degenerate cases at both extremities. Specifically, an ellipse possessing an eccentricity of 0 is identified as a perfect circle, while an eccentricity of 1 delineates a line segment. Eccentricity measures the discrepancy between the predicted central position of an object in the image and its actual location. It has been postulated that for precise measurements, potential eccentricities ought to be rectified. The intersection of a double-napped cone, related to a conic section, and a plane offers a method to ascertain eccentricity. In this study, the mean eccentricity of the image was derived as a feature by calculating the eccentricity of each region, utilizing the formula:</p>
              
                <disp-formula>
                  <label>(3)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>e</mi>
                    <mo>=</mo>
                    <mo>−</mo>
                    <mn>1</mn>
                    <mfrac>
                      <msup>
                        <mi>b</mi>
                        <mn>2</mn>
                      </msup>
                      <msup>
                        <mi>a</mi>
                        <mn>2</mn>
                      </msup>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p>where, <italic>a</italic> represents the length of the major axis and <italic>b </italic>symbolizes the minor axis length of the region.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 6 Energy features</title>
              
              <p>The term 'energy' in texture attributes encapsulates the collective magnitude or intensity of the pixel values within an image, signifying the image's intricacy spectrum. A subdued energy signifies an image leaning towards smoothness and reduced texture, while an elevated energy resonates with an image possessing richer details and textures. The energy of an image is mathematically deduced using:</p>
              
                <disp-formula>
                  <label>(4)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>E</mi>
                    <mi>p</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mo>=</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <msup>
                      <mo stretchy="false">)</mo>
                      <mn>2</mn>
                    </msup>
                  </math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>p</mi>
    <mi>i</mi>
    <mi>j</mi>
    <mo stretchy="false">(</mo>
    <mo>,</mo>
    <mo stretchy="false">)</mo>
  </math>
</inline-formula> denotes the (<italic>i, j</italic>)th element of the normalized Gray-Level Co-occurrence Matrix (GLCM).</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 7 Image coarseness features</title>
              
              <p>Image coarseness characterizes the magnitude or dimensionality of the predominant textures within an image, shedding light on the granularity or fidelity of texture patterns. Images leaning towards fineness possess diminutive, less conspicuous textures, in contrast to coarse images characterized by pronounced, substantial textures. The coarseness of an image is evaluated through:</p>
              
                <disp-formula>
                  <label>(5)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mtext> Coarseness </mtext>
                    <mo>=</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo>−</mo>
                    <mo stretchy="false">(</mo>
                    <mo>+</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <mo stretchy="false">|</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mi>Q</mi>
                    </mfrac>
                    <mfrac>
                      <mn>1</mn>
                      <mrow>
                        <mn>2</mn>
                        <mo stretchy="false">(</mo>
                        <mo>−</mo>
                        <mo stretchy="false">)</mo>
                        <mi>L</mi>
                        <mi>d</mi>
                      </mrow>
                    </mfrac>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>d</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>Q</mi>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>x</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <mi>L</mi>
                        <mi>d</mi>
                        <mo>−</mo>
                      </mrow>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>y</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>L</mi>
                    </munderover>
                    <mrow data-mjx-texclass="ORD">
                      <mo stretchy="false">|</mo>
                    </mrow>
                    <mi>I</mi>
                    <mi>x</mi>
                    <mi>y</mi>
                    <mi>I</mi>
                    <mi>x</mi>
                    <mi>d</mi>
                    <mi>y</mi>
                  </math>
                </disp-formula>
              
              <p>where, <italic>Q</italic> refers to the number of directional considerations, <italic>L </italic>represents the image size, and <italic>I</italic>(<italic>x, y</italic>) is the intensity at the specified pixel location.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 8 Pixels homogeneity</title>
              
              <p>Pixel homogeneity alludes to a measure denoting the uniformity or similarity among pixel values in an image. A criterion for its evaluation is how congruently pixel values align with the median value of their proximal neighborhood. Enhanced homogeneity implies that neighboring pixels possess analogous values, resulting in an image that appears more coherent. The homogeneity of an image is computed as:</p>
              
                <disp-formula>
                  <label>(6)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>H</mi>
                    <mi>p</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mo>=</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <mfrac>
                      <mn>1</mn>
                      <mrow>
                        <mn>1</mn>
                        <mo>+</mo>
                        <mo>−</mo>
                        <mo stretchy="false">|</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mo stretchy="false">|</mo>
                        </mrow>
                        <mi>i</mi>
                        <mi>j</mi>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.1. 9 Image pixels dissimilarity features</title>
              
              <p>Conversely, dissimilarity functions as a counterpoint to homogeneity, gauging the disparity or variation in pixel values within an image. It signals the presence of contrasting textures or patterns, emphasizing distinctions between adjacent pixels. A heightened dissimilarity is emblematic of an image teeming with variations. The dissimilarity metric is derived using:</p>
              
                <disp-formula>
                  <label>(7)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mtext> Diss </mtext>
                    <mo>=</mo>
                    <mo>−</mo>
                    <mo stretchy="false">(</mo>
                    <mo>,</mo>
                    <mo stretchy="false">)</mo>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <munderover>
                      <mo data-mjx-texclass="OP">∑</mo>
                      <mrow data-mjx-texclass="ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mi>N</mi>
                    </munderover>
                    <mrow data-mjx-texclass="ORD">
                      <mo stretchy="false">|</mo>
                    </mrow>
                    <mrow data-mjx-texclass="ORD">
                      <mo stretchy="false">|</mo>
                    </mrow>
                    <mi>i</mi>
                    <mi>j</mi>
                    <mi>p</mi>
                    <mi>i</mi>
                    <mi>j</mi>
                  </math>
                </disp-formula>
              
            </sec>
          
        </sec>
      
      
        <sec disp-level="level2">
          
            <title>3.2. Classification models</title>
          
          <p>Classification pertains to the task of predicting a class label for a given input data sample. In this study, four distinct classification models were utilized for the analysis of extracted features, aiming to predict AD. These models include logistic regression, naïve bayes, XGBoost, and AdaBoost.</p>
          
            <sec disp-level="level3">
              
                <title>3.2. 1 Logistic regression model</title>
              
              <p>Logistic regression, often employed in binary classification scenarios, is designed to predict the probability of an instance aligning with one of two categorical outcomes. The output is usually bound between two classes, such as true/false or yes/no. Using the logistic function, predicted values are constrained between 0 and 1. A decision boundary at 0.5 is typically established; values below this threshold are assigned to one class, while values above belong to the other. The logistic function is represented as:</p>
              
                <disp-formula>
                  <label>(8)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>P</mi>
                    <mi>I</mi>
                    <mo stretchy="false">(</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mfrac>
                      <mrow>
                        <mi>Exp</mi>
                        <mi>c</mi>
                        <mi>d</mi>
                        <mi>I</mi>
                        <mstyle scriptlevel="0">
                          <mspace width="0.167em"/>
                        </mstyle>
                        <mo stretchy="false">(</mo>
                        <mo>+</mo>
                        <mo stretchy="false">)</mo>
                      </mrow>
                      <mrow>
                        <mn>1</mn>
                        <mo>+</mo>
                        <mo stretchy="false">(</mo>
                        <mo>+</mo>
                        <mo stretchy="false">)</mo>
                        <mi>Exp</mi>
                        <mi>c</mi>
                        <mi>d</mi>
                        <mi>l</mi>
                        <mstyle scriptlevel="0">
                          <mspace width="0.167em"/>
                        </mstyle>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p>where, <italic>P</italic>(<italic>I</italic>) denotes the probability associated with the image pixels, while <italic>c</italic> and <italic>d</italic> represent model parameters.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.2. 2 Naïve bayes classifier</title>
              
              <p>The Naïve Bayes algorithm, despite its simplicity, is a robust mechanism for binary classification. Drawing from the Bayes theorem, it operates under the assumption of conditional independence of features, given the class label. Probabilities of an instance falling under each class are computed, with the class of highest probability chosen as the final prediction. It is particularly adept at handling text and categorical data. The Bayes theorem, in its most rudimentary form, is expressed as:</p>
              
                <disp-formula>
                  <label>(9)</label>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>P</mi>
                    <mi>A</mi>
                    <mi>B</mi>
                    <mo stretchy="false">(</mo>
                    <mo>∣</mo>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mfrac>
                      <mrow>
                        <mi>P</mi>
                        <mi>B</mi>
                        <mi>A</mi>
                        <mi>P</mi>
                        <mi>A</mi>
                        <mo stretchy="false">(</mo>
                        <mo>∣</mo>
                        <mo stretchy="false">)</mo>
                        <mo>∗</mo>
                        <mo stretchy="false">(</mo>
                        <mo stretchy="false">)</mo>
                      </mrow>
                      <mrow>
                        <mi>P</mi>
                        <mi>B</mi>
                        <mo stretchy="false">(</mo>
                        <mo stretchy="false">)</mo>
                      </mrow>
                    </mfrac>
                  </math>
                </disp-formula>
              
              <p>where, <inline-formula>
  <math xmlns="http://www.w3.org/1998/Math/MathML">
    <mi>P</mi>
    <mi>A</mi>
    <mi>B</mi>
    <mo stretchy="false">(</mo>
    <mo>∣</mo>
    <mo stretchy="false">)</mo>
  </math>
</inline-formula> is the posterior probability of interest, while <italic>P</italic>(<italic>A</italic>) denotes the prior probability or the marginal likelihood of occurrence.</p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.2. 3 Adaboost classifier</title>
              
              <p>AdaBoost, or Adaptive Boosting, emerges as a recognized ensemble learning strategy for classification tasks. By aggregating a multitude of weak learners, commonly decision trees, a robust classifier is constructed. Training instances are assigned weights, which are then adjusted based on the performance of preceding models. Emphasis is particularly laid on misclassified instances in subsequent iterations. The outputs from these weak learners are combined through weighted voting to deliver the final classification. </p>
            </sec>
          
          
            <sec disp-level="level3">
              
                <title>3.2. 4 Xgboost classifier</title>
              
              <p>XGBoost, an abbreviation for Extreme Gradient Boosting, is an advanced gradient boosting machine learning algorithm that has shown proficiency in various tasks such as classification, regression, and ranking. This technique integrates a series of weak learners, predominantly decision trees, to formulate a potent prediction model. The gradient descent optimization technique is employed by XGBoost to minimize the associated loss function. Regularization algorithms are incorporated to counteract overfitting, enabling the model to efficiently manage high-dimensional datasets. In this investigation, the decision to employ these specific classifiers was informed by their individual merits. XGBoost, with its optimized speed and accuracy, and AdaBoost, celebrated for boosting decision trees' performance on binary classifications, were deemed suitable. The logistic regression model, owing to its simplicity and effectiveness with linearly separable classes, and the memory-efficient Naïve Bayes Classifier were also integrated into this research framework.</p>
            </sec>
          
        </sec>
      
    </sec>
    <sec disp-level="level1" sec-type="">
      <title>4. Results and discussions</title>
      <p>The experimental setup, encompassing the detailed description of the database utilized and the results achieved using various statistical measures, is presented in this section. Brain MR image data, crucial for the detection of AD, were sourced from Kaggle [<xref ref-type="bibr" rid="ref_27">27</xref>]. Within the original dataset, four distinct classes were identified: Mild impairment, Moderate impairment, No impairment, and Very low impairment. For the purpose of this research, these classes were amalgamated into two broader categories: Impairment and Non-impairment. The dataset comprised 5121 training images and 1279 test images. Of the training set, 2561 images were categorized under impairment, and 2560 under non-impairment. Conversely, the test set included 639 impairment images and 640 non-impairment images.</p>
      <p>Each image was processed individually, and the features delineated in the methodology section were computed utilizing the Python programming language. Subsequent to this feature computation, two datasets, corresponding to the training and test sets, were established and archived in CSV format. Both datasets encompassed features elaborated upon in the image feature extraction section, coupled with a binary response variable: 0 indicating non-impairment and 1 indicating impairment.</p>
      <p>Following the application of the stacked ensemble technique, its efficacy was ascertained using a labeled training set. The ensuing performance was quantified via the generation of a confusion matrix, with overarching metrics of accuracy, sensitivity, and specificity being derived for the experiment. Accuracy, indicative of the proportion of correctly predicted values, was ascertained using the formula:</p>
      
        <disp-formula>
          <label>(10)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext> Accuracy </mtext>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>T</mi>
                <mi>P</mi>
                <mi>F</mi>
                <mi>P</mi>
                <mo>+</mo>
              </mrow>
              <mrow>
                <mi>T</mi>
                <mi>P</mi>
                <mi>F</mi>
                <mi>P</mi>
                <mi>T</mi>
                <mi>N</mi>
                <mi>F</mi>
                <mi>N</mi>
                <mo>+</mo>
                <mo>+</mo>
                <mo>+</mo>
              </mrow>
            </mfrac>
          </math>
        </disp-formula>
      
      <p>where, <italic>TP</italic> and <italic>TN</italic> represent the counts of true positives and true negatives, respectively. <italic>FP</italic> denotes false positives, while <italic>FN </italic>corresponds to false negatives. Sensitivity, which represents the proficiency of the model in correctly identifying positive cases, is calculated as:</p>
      
        <disp-formula>
          <label>(11)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext> Sensitivity </mtext>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>T</mi>
                <mi>P</mi>
              </mrow>
              <mrow>
                <mi>T</mi>
                <mi>P</mi>
                <mi>F</mi>
                <mi>N</mi>
                <mo>+</mo>
              </mrow>
            </mfrac>
          </math>
        </disp-formula>
      
      <p>Conversely, specificity, reflecting the model's capability in accurately identifying negative cases, is computed as:</p>
      
        <disp-formula>
          <label>(12)</label>
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
            <mtext> Specificity </mtext>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>T</mi>
                <mi>N</mi>
              </mrow>
              <mrow>
                <mi>T</mi>
                <mi>N</mi>
                <mi>F</mi>
                <mi>N</mi>
                <mo>+</mo>
              </mrow>
            </mfrac>
          </math>
        </disp-formula>
      
      <p>Another performance metric, the receiver operating characteristic curve (ROC), provides insights into the performance of binary classifiers by capturing the entire area under this two-dimensional curve. The area under the ROC curve (AUC) serves as an indicator of the likelihood that the model would rank a randomly selected positive instance higher than a randomly selected negative one.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>Parameter settings for the classifiers</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p style="text-align: center">Model</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Parameter Setup</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Range of Parameters</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">Naïve-Bayes</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Tuning not required</p></td><td colspan="1" rowspan="1"><p style="text-align: center">None</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">Logistic Regression</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Regularization strength = 10, Regularization = L2</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Regularization strength= 0.01, 0.1, 1, 10</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">XGBoosting</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Estimators = 100, Max depth = 5, Learning rate = 0.3</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Estimators=50, 100, 200. Max Depth=3, 5, 7. Learning rate=0.01, 0.03, 0.05, 0.1, 1 None</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">AdaBoosting</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Learning rate = 0.1, n_estimators = 100</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Learning rate=0.01, 0.1, 0.2 Estimator=50, 100, 200</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>In the context of AD detection, predictive models were constructed employing the Naïve-Bayes classifier, logistic regression, XGBoost, and AdaBoost. To optimize the model's performance, parameter tuning was undertaken. The grid search method, coupled with a 5-fold cross-validation technique, was deployed to discern the optimal parameter values. After extensive iterations with diverse parameter settings for each model, the configurations presented in <xref ref-type="table" rid="table_1">Table 1</xref> were identified as the most efficacious.</p><p>The optimal parameter setting was applied to the training data, resulting in the subsequent training of the model. The test data were then employed to calculate accuracy, among other statistical values. The predictive capability of the models, as well as their respective accuracies, were determined using measures derived from the confusion matrix, juxtaposed with prediction results. These findings are elucidated in <xref ref-type="table" rid="table_2">Table 2</xref>.</p>
      
        <table-wrap id="table_2">
          <label>Table 2</label>
          <caption>Performance of the classifiers</caption>
          <abstract/>
          <table><tbody><tr><td colspan="1" rowspan="1"><p style="text-align: center">Model</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Accuracy</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Sensitivity</p></td><td colspan="1" rowspan="1"><p style="text-align: center">Specificity</p></td><td colspan="1" rowspan="1"><p style="text-align: center">AUC</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">Naïve-Bayes</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.63</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.76</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.50</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.73</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">Logistic Regression</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.70</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.71</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.70</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.74</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">AdaBoost</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.72</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.64</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.80</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.78</p></td></tr><tr><td colspan="1" rowspan="1"><p style="text-align: center">XGBoost</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.92</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.90</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.94</p></td><td colspan="1" rowspan="1"><p style="text-align: center">0.98</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>As evidenced by <xref ref-type="table" rid="table_2">Table 2</xref>, accuracy rates observed for Naive Bayes, Logistic Regression, AdaBoost, and XGBoost were 63%, 70%, 92%, and 72%, respectively. Among the classifiers investigated in this study, XGBoost displayed superior overall accuracy. The results suggest that the XGBoost model offers enhanced performance in predicting AD relative to the other models under consideration. Moreover, in comparison to the other three classifiers, XGBoost also exhibited the highest sensitivity, specificity, and AUC scores, noted at 90%, 94%, and 98% respectively. ROC curves were delineated, and the AUC was calculated to provide a deeper understanding of the prediction model, as depicted in <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p>
      
        <fig id="fig_2">
          <label>Figure 2</label>
          <caption>ROC curve for different classifiers</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/8/img_YB-r5RVdCPPOxQSi.png"/>
        </fig>
      
      <p>From an analysis of <xref ref-type="fig" rid="fig_2">Figure 2</xref>, it can be discerned that the XGBoost model's ROC curve, represented by the green trajectory, is more fluent than those of the other three classifiers. The accompanying AUC values are annotated within the plot legend of <xref ref-type="fig" rid="fig_2">Figure 2</xref>. AUC values ranging between 0.7 and 0.8 are deemed commendable, those between 0.8 and 0.9 are considered exceptional, and values exceeding 0.9 are characterized as outstanding. An AUC of 0.5 typically implies a lack of distinction. Given that the XGBoost classifier yielded an AUC of 0.98, it can be inferred that the proposed approach delivers significant results. The relative effectiveness of the four classifiers, as indicated by accuracy, sensitivity, specificity, and AUC values, is further portrayed in <xref ref-type="fig" rid="fig_3">Figure 3</xref>. A perusal of <xref ref-type="fig" rid="fig_3">Figure 3</xref> reaffirms the superior performance of XGBoost across all metrics.</p>
      <p>The marked performance of XGBoost over its counterparts, namely Naive Bayes, Logistic Regression, and AdaBoost, can be attributed to its inherent ability to process complex non-linear relationships within data sets. By progressively constructing an ensemble of decision trees designed to rectify errors engendered by preceding models, XGBoost adeptly discerns intricate patterns. The regularization techniques employed by XGBoost, including depth limitations and minimal child weight, have been identified as instrumental in mitigating overfitting. Furthermore, its inherent support for handling missing data streamlines the preprocessing phase. The gradient boosting framework is noted to iteratively refine model weights, bolstering accuracy by focusing on challenging data instances. The flexibility endowed by XGBoost's hyperparameters renders it a formidable tool for achieving elevated predictive accuracy.</p>
      <p>A direct comparison between the results gleaned from the proposed XGBoost classification model and existing state-of-the-art techniques proves challenging due to the disparate nature of the databases. However, previous studies, such as those conducted by Mehmood et al. [<xref ref-type="bibr" rid="ref_28">28</xref>], Odusam et al. [<xref ref-type="bibr" rid="ref_29">29</xref>], Venugopalan et al. [<xref ref-type="bibr" rid="ref_30">30</xref>], Pradhan et al. [<xref ref-type="bibr" rid="ref_31">31</xref>], Razavi et al. [<xref ref-type="bibr" rid="ref_32">32</xref>], and Islam and Zhang [<xref ref-type="bibr" rid="ref_33">33</xref>], have reported accuracies of 98%, 99%, 89%, 88%, 94.5%, and 88%, respectively, using diverse datasets from the AD Neuroimaging Initiative (ADNI) database. Remarkably, the model proposed in this study achieved a 92% accuracy with XGBoost by leveraging pertinent image features from a Kaggle dataset. This performance stands as competitive, even when juxtaposed with preceding research endeavors.</p>
      
        <fig id="fig_3">
          <label>Figure 3</label>
          <caption>Performance of the classifiers</caption>
          <abstract/>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2023/8/img_LliZ0v2OQLiGfPf_.png"/>
        </fig>
      
    </sec>
    <sec disp-level="level1" sec-type="conclusions">
      <title>5. Conclusions</title>
      <p>The principal objective of this study was to classify individuals into either impairment or non-impairment groups based on brain MR images. To achieve this distinction, brain MR images were amassed, and machine learning methodologies were employed. The results and corresponding performance metrics ascertain that an accuracy of 92% can be attained utilizing the proposed approach, effectively classifying individuals into the aforementioned groups. Furthermore, it was observed that the discrepancy between sensitivity and specificity is minimal, signifying the model's adeptness at unbiased classification, rather than gravitating towards prevalent responses. The research established that the proposed XGBoost machine learning model holds the potential to execute classifications with a precision rivalling that of deep learning models. Machine learning models, being less intricate in structure and more straightforward in implementation than deep learning models, necessitate fewer resources and a reduced duration for training and testing. Consequently, the adaptation of machine learning models in industry practices might lead to substantial savings in terms of time, computational memory, and financial costs.</p>
      <p>However, as with most methodologies, avenues for refinement persist. Features employed in this study were chosen arbitrarily. A more judicious and methodical selection could potentially amplify the accuracy of the results. An impressive 92% accuracy in Alzheimer's disease prediction using XGBoost underscores its potential for future therapeutic implications. Such a precise model could serve as an invaluable clinical decision support tool, potentially aiding medical practitioners in the early identification and intervention of the disease. This model might facilitate personalized healthcare trajectories and risk-informed treatments by pinpointing those at elevated risk. The insights furnished by the model concerning predictive attributes could further enrich our understanding of Alzheimer's disease progression.</p>
      <p>Nonetheless, hurdles impede the seamless translation of this research into practice. Challenges including data quality, privacy concerns, clinical receptiveness, model validation, model interpretability, evolving disease patterns, regulatory nuances, and constrained resources have been identified. Overcoming these obstacles necessitates a holistic approach encompassing diverse data procurement, ethical data stewardship, collaborative clinician engagement, cross-population validation, innovative interpretation techniques, consistent model updates, regulatory adherence, and strategic resource allocation. Together, these steps can pave the way for the effective integration of predictive models into the Alzheimer's disease clinical landscape. It was also noted that no pre-processing techniques were applied to the acquired images. Incorporating pre-processing prior to feature extraction might bolster the model's predictive prowess.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      <p>The contributions of each author is listed in the following statement: “Conceptualization, D. S. A. Aashiqur Reza; methodology, D. S. A. Aashiqur Reza, Sadia Afrin, Md. Ahsan Ullah; software, D. S. A. Aashiqur Reza; validation, Lasker Ershad Ali, Raju Roy; formal analysis, D. S. A. Aashiqur Reza; investigation, Lasker Ershad Ali and Raju Roy; writing- original draft preparation, D. S. A. Aashiqur Reza, Sadia Afrin , Md. Ahsan Ullah ,Sadia Chowdhury Toma, Sourav Kumar Kha.; writing- review and editing, Lasker Ershad Ali and Raju Roy; visualization, D. S. A. Aashiqur Reza; Overall supervision: Prof. Dr. Lasker Ershad Ali.</p>
    </notes>
    <notes>
      <title>Funding</title>
      <p></p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      <p>Informed consent was obtained from all subjects involved in the study.</p>
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data of AD supporting our research results are deposited in Kaggle [<xref ref-type="bibr" rid="ref_27">27</xref>].</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>Springer Berlin Heidelberg, 2004, pp. 393–401.</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>Y.</given-names>
              <surname>Liu</surname>
            </name>
            <name>
              <given-names>L.</given-names>
              <surname>Teverovskiy</surname>
            </name>
            <name>
              <given-names>O.</given-names>
              <surname>Carmichael</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Kikinis</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Shenton</surname>
            </name>
            <name>
              <given-names>C. S.</given-names>
              <surname>Carter</surname>
            </name>
            <name>
              <given-names>V. A.</given-names>
              <surname>Stenger</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Davis</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Aizenstein</surname>
            </name>
            <name>
              <given-names>J. T.</given-names>
              <surname>Becker</surname>
            </name>
            <name>
              <given-names>O. L.</given-names>
              <surname>Lopez</surname>
            </name>
            <name>
              <given-names>C. C.</given-names>
              <surname>Meltzer</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1007/978-3-540-30135-6</pub-id>
          <article-title>Discriminative MR image feature analysis for automatic schizophrenia and AD classification</article-title>
          <source>, https://doi.org/10.1007/978-3-540-30135-6</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>3</volume>
          <page-range>186-191</page-range>
          <issue>3</issue>
          <year>2007</year>
          <person-group person-group-type="author">
            <name>
              <given-names>R.</given-names>
              <surname>Brookmeyer</surname>
            </name>
            <name>
              <given-names>E.</given-names>
              <surname>Johnson</surname>
            </name>
            <name>
              <given-names>K.</given-names>
              <surname>Ziegler‐Graham</surname>
            </name>
            <name>
              <given-names>H. M.</given-names>
              <surname>Arrighi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.jalz.2007.04.381</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Forecasting the global burden of AD</article-title>
          <source>Alzheimers Dement</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>32</volume>
          <page-range>17-21</page-range>
          <issue>1</issue>
          <year>2008</year>
          <person-group person-group-type="author">
            <name>
              <given-names>W.P.</given-names>
              <surname>Santos</surname>
            </name>
            <name>
              <given-names>R.E.</given-names>
              <surname>Souza</surname>
            </name>
            <name>
              <given-names>A.F.D.</given-names>
              <surname>Silva</surname>
            </name>
            <name>
              <given-names>P.B.</given-names>
              <surname>Santos Filho</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compmedimag.2007.08.004</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Evaluation of AD by analysis of MR images using multilayer perceptrons and committee machines</article-title>
          <source>Comput. Med. Imaging Graph.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>Florida, United States, 2013, pp. 192–199.</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Pulido</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Rueda</surname>
            </name>
            <name>
              <given-names>E.</given-names>
              <surname>Romero</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1117/12.2007092</pub-id>
          <article-title>Classification of AD using regional saliency maps from brain MR volumes</article-title>
          <source>, http://dx.doi.org/10.1117/12.2007092</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>307</page-range>
          <issue/>
          <year>2015</year>
          <person-group person-group-type="author">
            <name>
              <given-names>C.</given-names>
              <surname>Salvatore</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Cerasa</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Battista</surname>
            </name>
            <name>
              <given-names>M. C.</given-names>
              <surname>Gilardi</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Quattrone</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Castiglioni</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3389/fnins.2015.00307</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Magnetic resonance imaging biomarkers for the early diagnosis of Alzheimer’s disease: A machine learning approach</article-title>
          <source>Front. Neurosci.</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>13</volume>
          <page-range>575–588</page-range>
          <issue>5</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <given-names>F. J.</given-names>
              <surname>Martinez-Murcia</surname>
            </name>
            <name>
              <given-names>J. M.</given-names>
              <surname>Górriz</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Ramírez</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Ortiz</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.2174/156720</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>A spherical brain mapping of MR images for the detection of AD</article-title>
          <source>Curr. Alzheimer Res.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>Melbourne, VIC, Australia, 2018, pp. 406–422.</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>K. M.</given-names>
              <surname>Poloni</surname>
            </name>
            <name>
              <given-names>R. J.</given-names>
              <surname>Ferrari</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1007/978-3-319-95162-1</pub-id>
          <article-title>Detection and classification of hippocampal structural changes in MR images as a biomarker for AD</article-title>
          <source>, http://dx.doi.org/10.1007/978-3-319-95162-1</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>San Diego, CA, USA, 2019, pp. 2324–2330</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>Z.</given-names>
              <surname>Cui</surname>
            </name>
            <name>
              <given-names>Z.</given-names>
              <surname>Gao</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Leng</surname>
            </name>
            <name>
              <given-names>T.</given-names>
              <surname>Zhang</surname>
            </name>
            <name>
              <given-names>P.</given-names>
              <surname>Quan</surname>
            </name>
            <name>
              <given-names>W.</given-names>
              <surname>Zhao</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/BIBM47256.20</pub-id>
          <article-title>AD diagnosis using enhanced inception network based on brain Magnetic Resonance Image</article-title>
          <source>, https://doi.org/10.1109/BIBM47256.20</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>5616–5634</page-range>
          <issue>8</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Z. S.</given-names>
              <surname>Aaraji</surname>
            </name>
            <name>
              <given-names>H. H.</given-names>
              <surname>Abbas</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Asady</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher"/>
          <article-title>ADs detection by using MRI brain images: A survey</article-title>
          <source>J. Posit. Sch. Psychol.</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="book">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>2023, arXiv preprint arXiv:2304.13314</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>K.</given-names>
              <surname>Mahapatra</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi"/>
          <article-title>Detection of AD using MRI scans based on inertia tensor and machine learning</article-title>
          <source/>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>19</volume>
          <page-range>2645</page-range>
          <issue>11</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Maqsood</surname>
            </name>
            <name>
              <given-names>F.</given-names>
              <surname>Nazir</surname>
            </name>
            <name>
              <given-names>U.</given-names>
              <surname>Khan</surname>
            </name>
            <name>
              <given-names>F.</given-names>
              <surname>Aadil</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Jamal</surname>
            </name>
            <name>
              <given-names>I.</given-names>
              <surname>Mehmood</surname>
            </name>
            <name>
              <given-names>O.</given-names>
              <surname>Song</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/s19112645</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Transfer learning assisted classification and detection of AD stages using 3D MRI scans</article-title>
          <source>Sensors</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="conference-proceedings">
          <volume>40</volume>
          <page-range>03021</page-range>
          <issue/>
          <year>0</year>
          <publisher-name>EDP Sciences, 2021,</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>P.</given-names>
              <surname>Tambe</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Saigaonkar</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Devadiga</surname>
            </name>
            <name>
              <given-names>P. H.</given-names>
              <surname>Chitte</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1051/itmconf/20214003021</pub-id>
          <article-title>Deep learning techniques for effective diagnosis of Alzheimer’s disease using MRI images</article-title>
          <source>, https://doi.org/10.1051/itmconf/20214003021</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="journal">
          <volume>1921</volume>
          <page-range>012024</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>P. C.</given-names>
              <surname>Muhammed Raees</surname>
            </name>
            <name>
              <given-names>V.</given-names>
              <surname>Thomas</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1742-6596/1921/1/012024</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Automated detection of AD using deep learning in MRI</article-title>
          <source>J. Phys.: Conf. Ser.</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>95</volume>
          <page-range>20211253</page-range>
          <issue>1136</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>H.</given-names>
              <surname>Ghaffari</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Tavakoli</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Pirzad Jahromi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher"/>
          <article-title>Deep transfer learning–based fully automated detection and classification of AD on brain MRI</article-title>
          <source>Br. J. Radiol.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>New York, USA, 2022, pp. 0510–0516.</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>M. A. A.</given-names>
              <surname>Mamun</surname>
            </name>
            <name>
              <given-names>S. B.</given-names>
              <surname>Shawkat</surname>
            </name>
            <name>
              <given-names>M. S.</given-names>
              <surname>Ahammed</surname>
            </name>
            <name>
              <given-names>M. M.</given-names>
              <surname>Uddin</surname>
            </name>
            <name>
              <given-names>M. I.</given-names>
              <surname>Mahmud</surname>
            </name>
            <name>
              <given-names>A. K. M. M.</given-names>
              <surname>Islam</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/uemcon54665.2022.9965730</pub-id>
          <article-title>Deep learning based model for AD detection using brain MRI images</article-title>
          <source>, http://dx.doi.org/10.1109/uemcon54665.2022.9965730</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>323</volume>
          <page-range>96-107</page-range>
          <issue/>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>C.</given-names>
              <surname>Ieracitano</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Mammone</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Bramanti</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Hussain</surname>
            </name>
            <name>
              <given-names>F. C.</given-names>
              <surname>Morabito</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neucom.2018.09.071</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>A convolutional neural network approach for classification of dementia stages based on 2D-spectral representation of EEG recordings</article-title>
          <source>Neurocomputing</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>238</volume>
          <page-range>107942</page-range>
          <issue/>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Z.</given-names>
              <surname>Liu</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Lu</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Pan</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Xu</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Lan</surname>
            </name>
            <name>
              <given-names>X.</given-names>
              <surname>Luo</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.knos</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Diagnosis of AD via an attention-based multi-scale convolutional neural network</article-title>
          <source>Knowl.-Based Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>453</page-range>
          <issue>4</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Song</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Jung</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Lee</surname>
            </name>
            <name>
              <given-names>D.</given-names>
              <surname>Kim</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Ahn</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/brainsci11040453</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Diagnostic classification and biomarker identification of AD with random forest algorithm</article-title>
          <source>Brain Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>Cincinnati, OH, USA, 2020, pp. 1036–1041</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>K.G.</given-names>
              <surname>Achilleos</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Leandrou</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Prentzas</surname>
            </name>
            <name>
              <given-names>P.A.</given-names>
              <surname>Kyriacou</surname>
            </name>
            <name>
              <given-names>A.C.</given-names>
              <surname>Kakas</surname>
            </name>
            <name>
              <given-names>C.S.</given-names>
              <surname>Pattichis</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/bibe50027.2020.00175</pub-id>
          <article-title>Extracting explainable assessments of AD via machine learning on brain MRI imaging data</article-title>
          <source>, http://dx.doi.org/10.1109/bibe50027.2020.00175</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>1892</volume>
          <page-range>012009</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>K. A.</given-names>
              <surname>Kadhim</surname>
            </name>
            <name>
              <given-names>F.</given-names>
              <surname>Mohamed</surname>
            </name>
            <name>
              <given-names>Z. N.</given-names>
              <surname>Khudhair</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1088/1742-6596/1892/1/012009</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Deep learning: Classification and automated detection earlier of AD using brain MRI images</article-title>
          <source>J. Phys.: Conf. Ser.</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>47</volume>
          <page-range>2201-2218</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>S.</given-names>
              <surname>Savaş</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s13369-021-06131-3</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Detecting the stages of AD with pre-trained deep learning architectures</article-title>
          <source>Arab. J. Sci. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>e08725</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>B.</given-names>
              <surname>Bigham</surname>
            </name>
            <name>
              <given-names>S. A.</given-names>
              <surname>Zamanpour</surname>
            </name>
            <name>
              <given-names>H.</given-names>
              <surname>Zare</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.heliyon.2022.e08725</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Features of the superficial white matter as biomarkers for the detection of AD and mild cognitive impairment: A diffusion tensor imaging study</article-title>
          <source>Heliyon</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>14</volume>
          <page-range>e0222446</page-range>
          <issue>10</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>Y.</given-names>
              <surname>Gupta</surname>
            </name>
            <name>
              <given-names>K. H.</given-names>
              <surname>Lee</surname>
            </name>
            <name>
              <given-names>K. Y.</given-names>
              <surname>Choi</surname>
            </name>
            <name>
              <given-names>J. J.</given-names>
              <surname>Lee</surname>
            </name>
            <name>
              <given-names>B. C.</given-names>
              <surname>Kim</surname>
            </name>
            <name>
              <given-names>G. R.</given-names>
              <surname>Kwon</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0222446</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Early diagnosis of Alzheimer’s disease using combined features from voxel-based morphometry and cortical, subcortical, and hippocampus regions of MRI T1 brain images</article-title>
          <source>PLoS One</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>033</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <given-names>G.</given-names>
              <surname>Battineni</surname>
            </name>
            <name>
              <given-names>N.</given-names>
              <surname>Chintalapudi</surname>
            </name>
            <name>
              <given-names>F.</given-names>
              <surname>Amenta</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.23937/2469-5866/1410033</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Late-life AD detection using pruned decision trees</article-title>
          <source>Int. J. Brain Disord. Treat.</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="conference-proceedings">
          <volume/>
          <page-range/>
          <issue/>
          <year>0</year>
          <publisher-name>Tiruchirappalli, India, 2020, pp. 614–622.</publisher-name>
          <person-group person-group-type="author">
            <name>
              <given-names>P.</given-names>
              <surname>Baglat</surname>
            </name>
            <name>
              <given-names>A.W.</given-names>
              <surname>Salehi</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Gupta</surname>
            </name>
            <name>
              <given-names>G.</given-names>
              <surname>Gupta</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1007/978-3-030-64849-7</pub-id>
          <article-title>Multiple machine learning models for detection of AD using OASIS dataset</article-title>
          <source>, http://dx.doi.org/10.1007/978-3-030-64849-7</source>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>132</volume>
          <page-range>689-698</page-range>
          <issue>7</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <given-names>T. A.</given-names>
              <surname>Tuan</surname>
            </name>
            <name>
              <given-names>T. B.</given-names>
              <surname>Pham</surname>
            </name>
            <name>
              <given-names>J. Y.</given-names>
              <surname>Kim</surname>
            </name>
            <name>
              <given-names>J. M. R.</given-names>
              <surname>Tavares</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/00207454.2020.1835900</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Alzheimer’s diagnosis using deep learning in segmenting and classifying 3D brain MR images</article-title>
          <source>Int. J. Neurosci.</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="webpage">
          <article-title>Dataset Alzheimer</article-title>
          <source>, https://www.kaggle.com/datasets/yasserhessein/dataset-alzheimer/code?resource=down load, accessed: 2023-07-22.</source>
          <year/>
          <uri/>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <volume>460</volume>
          <page-range>43–52</page-range>
          <issue/>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Mehmood</surname>
            </name>
            <name>
              <given-names>S.</given-names>
              <surname>Yang</surname>
            </name>
            <name>
              <given-names>Z.</given-names>
              <surname>Feng</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Wang</surname>
            </name>
            <name>
              <given-names>A.</given-names>
              <surname>Ahmad</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Khan</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.neuroscience.2021.01.002</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Transfer learning approach for early diagnosis of Alzheimer’s disease on MRI images</article-title>
          <source>Neuroscience</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>1-16</page-range>
          <issue>6</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>M.</given-names>
              <surname>Odusami</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Maskeliūnas</surname>
            </name>
            <name>
              <given-names>R.</given-names>
              <surname>Damaševičius</surname>
            </name>
            <name>
              <given-names>T.</given-names>
              <surname>Krilavičius</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/diagnostics11061071</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Detection of early stage from functional brain changes in magnetic resonance images using a Finetuned ResNet18 network</article-title>
          <source>Diagnostics</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>3254</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Venugopalan</surname>
            </name>
            <name>
              <given-names>L.</given-names>
              <surname>Tong</surname>
            </name>
            <name>
              <given-names>H. R.</given-names>
              <surname>Hassanzadeh</surname>
            </name>
            <name>
              <given-names>M. D.</given-names>
              <surname>Wang</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1038/s41598-020-74399-w</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>Multimodal deep learning models for early detection of Alzheimer’s disease stage</article-title>
          <source>Sci. Rep.</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>580–585</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <given-names>A.</given-names>
              <surname>Pradhan</surname>
            </name>
            <name>
              <given-names>J.</given-names>
              <surname>Gige</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Eliazer</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi"/>
          <pub-id pub-id-type="publisher"/>
          <article-title>Detection of Alzheimer’s Disease (AD) in MRI images using deep learning</article-title>
          <source>Int. J. Eng. Res. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <volume>6</volume>
          <page-range>1–16</page-range>
          <issue>32</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <given-names>F.</given-names>
              <surname>Razavi</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Tarokh</surname>
            </name>
            <name>
              <given-names>M.</given-names>
              <surname>Alborzi</surname>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1186/s40537-019-0190-7</pub-id>
          <pub-id pub-id-type="publisher"/>
          <article-title>An intelligent Alzheimer’s disease diagnosis method using unsupervised feature learning</article-title>
          <source>J. Big Data</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="book">
          <volume/>
          <page-range>1881–1883</page-range>
          <issue/>
          <year>2018</year>
          <publisher-name/>
          <person-group person-group-type="author">
            <name>
              <given-names>J.</given-names>
              <surname>Islam</surname>
            </name>
            <name>
              <given-names>Y.</given-names>
              <surname>Zhang</surname>
            </name>
          </person-group>
          <person-group person-group-type="editor"/>
          <pub-id pub-id-type="doi">10.1109/cvprw.2018.00247</pub-id>
          <article-title>Early diagnosis of Alzheimer’s disease: A neuroimaging study with deep learning architectures</article-title>
          <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>