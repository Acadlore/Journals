<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xml:lang="en" dtd-version="1.3" article-type="research-article" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">ESM</journal-id>
      <journal-id journal-id-type="doi">10.56578</journal-id>
      <journal-title-group>
        <journal-title>Education Science and Management</journal-title>
        <abbrev-journal-title abbrev-type="issn">Educ. Sci. Manag.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="publisher">ESM</abbrev-journal-title>
      </journal-title-group>
      <issn publication-format="electronic">2959-6319</issn>
      <issn publication-format="print">2959-6300</issn>
      <publisher>
        <publisher-name>Acadlore</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">AR-aaDrqKgdpfFDm8I7AvZBv2OHUIWf-6k9</article-id>
      <article-id pub-id-type="doi">10.56578/esm020402</article-id>
      <article-categories>
        <subj-group>
          <subject>Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Strategic Analytics for Predicting Students’ Academic Performance Using Cluster Analysis and Bayesian Networks</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-1011-2014</contrib-id>
          <name>
            <surname>Saeedi</surname>
            <given-names>Shamila</given-names>
          </name>
          <email>Shamila.saeedii@yahoo.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_2">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9657-0889</contrib-id>
          <name>
            <surname>BožAnić</surname>
            <given-names>Darko</given-names>
          </name>
          <email>dbozanic@yahoo.com</email>
        </contrib>
        <contrib contrib-type="author" rid="aff_1">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1779-1019</contrib-id>
          <name>
            <surname>Safa</surname>
            <given-names>Ramin</given-names>
          </name>
          <email>safa@aihe.ac.ir</email>
        </contrib>
        <aff id="aff_1">Department of Computer Engineering, Ayandegan Institute of Higher Education, 4681853617 Tonekabon, Iran</aff>
        <aff id="aff_2">Military Academy, University of Defence in Belgrade, 11000 Belgrade, Serbia</aff>
      </contrib-group>
      <pub-date publication-format="electronic" date-type="pub">
        <day>22</day>
        <month>12</month>
        <year>2024</year>
      </pub-date>
      <volume>2</volume>
      <issue>4</issue>
      <fpage>197</fpage>
      <lpage>214</lpage>
      <page-range>197-214</page-range>
      <history>
        <date date-type="received">
          <day>13</day>
          <month>10</month>
          <year>2024</year>
        </date>
        <date date-type="accepted">
          <day>13</day>
          <month>12</month>
          <year>2024</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>©2024 by the author(s)</copyright-statement>
        <copyright-year>2024</copyright-year>
        <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
          <license-p> Published by Acadlore Publishing Services Limited, Hong Kong. This article is available for free download and can be reused and cited, provided that the original published version is credited, under the CC BY 4.0 license.</license-p>
        </license>
      </permissions>
      <abstract><p>The evolution of educational systems, marked by an increasing number of institutions, has prompted the integration of advanced data mining techniques to address the limitations of traditional pedagogical models. Predicting students’ academic performance, derived from large-scale educational data, has emerged as a critical application within educational data mining (EDM), a multidisciplinary field combining education and computational science. As educational institutions seek to enhance student outcomes and reduce the risk of failure, the ability to anticipate academic performance has gained considerable attention. A novel methodology, employing cluster analysis in combination with Bayesian networks, was introduced to predict student performance and classify academic quality. Students were first categorized into two distinct clusters, followed by the use of Bayesian networks to model and predict academic performance within each cluster. The proposed framework was evaluated against existing approaches using several standard performance metrics, demonstrating its superior accuracy and robustness. This method not only enhances predictive capabilities but also provides a valuable tool for early intervention in educational settings. The results underscore the potential of integrating machine learning techniques with educational data to foster more effective and personalized learning environments.</p></abstract>
      <kwd-group>
        <kwd>Academic performance prediction</kwd>
        <kwd>Cluster analysis</kwd>
        <kwd>Bayesian networks</kwd>
        <kwd>Educational data mining</kwd>
        <kwd>Machine learning in education</kwd>
      </kwd-group>
      <counts>
        <count count-type="contributors" count="3"/>
        <fig-count count="10"/>
        <table-count count="13"/>
        <ref-count count="41"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro">
      <title>1. Introduction</title>
      <p>The maturity of humans depends on their proper education, and education is a tool to use to reach the highest point of human nobility (<xref ref-type="bibr" rid="ref_14">Gul &amp;amp; Yucesan, 2022</xref>). Looking at the Ministry of Education as the official institution for education for social, political, and cultural development and thinking deeply about it necessitate focusing on the quality of educational services and using state-of-the-art equipment introduced for educational systems (<xref ref-type="bibr" rid="ref_19">Mahboob et al., 2023</xref>). Education quality improvement depends on improving employment status, education, social status, and up-to-date equipment, and tutors need to gain enough knowledge to use these e-learning systems (<xref ref-type="bibr" rid="ref_32">Shukla et al., 2021</xref>). Information and communication technology (ICT) development has created new patterns in education and learning, especially the internet (<xref ref-type="bibr" rid="ref_24">Rathour et al., 2022</xref>). E-learning is a modern educational system in which ICT is utilized for education and learning (<xref ref-type="bibr" rid="ref_26">Romero &amp;amp; Ventura, 2020</xref>). As the main features, e-learning is highly flexible, student-centered, and does not depend on time and location constraints (<xref ref-type="bibr" rid="ref_12">Gardas &amp;amp; Navimipour, 2022</xref>). Providing and establishing human, technological, administrative, social, cultural, managerial, and economic infrastructures are obvious actions to take to start e-learning courses successfully and, ultimately, realize the virtual university concept (<xref ref-type="bibr" rid="ref_13">Gonçalves et al., 2023</xref>). The main challenges and obstacles e-learning faces include cultural, economic, legal, educational, strategic, and technical obstacles, untrue beliefs, content, non-allocation of sufficient budget, lack of internet access for most people, and non-tendency to acquire information and electronic literacy skills (<xref ref-type="bibr" rid="ref_29">Salloum et al., 2020</xref>).</p><p>Families, especially those with few kids, are mainly concerned about their academic status and future. One of the biggest problems of the Ministry of Education and some families is students’ failure in education (<xref ref-type="bibr" rid="ref_36">Wanke et al., 2022</xref>). Hence, the Ministry of Education and families should look for a solution to predict students’ academic performance (<xref ref-type="bibr" rid="ref_38">Yağcı, 2022</xref>). Records of students exist in schools, including personal information of students and their families, personal features, course feedback, and a sample of exam papers. Students’ report cards in the records of schools under study are collected after the exams once the students finish elementary school, getting ready to register for the next educational stage (<xref ref-type="bibr" rid="ref_3">Amjad et al., 2022</xref>). Among these students, those with better academic status qualify for gifted schools. However, a number of students are neither qualified nor have the resources to register in their respective schools despite having excellent report cards.</p><p>Failure in education can cause moral disorders in students, making them lose self-esteem and feel stress, and the feeling of stress causes the students to become aggressive or introverted (<xref ref-type="bibr" rid="ref_1">Adhikari et al., 2022</xref>). Schools hold records of each student, which contain information including personal features, course feedback, and a sample of exam papers. This study uses data mining and cluster analysis to predict students’ academic performance, and tries to predict the problems a student can face in a course and the possibility of failure in education in the future if he/she keeps studying in the same manner using the information on his/her records (<xref ref-type="bibr" rid="ref_19">Mahboob et al., 2023</xref>; <xref ref-type="bibr" rid="ref_38">Yağcı, 2022</xref>).</p><p>Failure in education is one of the primary problems that some families and kids face, given that it gives rise to moral disorders in students (<xref ref-type="bibr" rid="ref_5">Bago, 2022</xref>). For example, students lose self-esteem and feel stressed, which can cause aggressive or introverted behaviors. This study aims to predict students’ academic performance using data mining and records specific to each student, expecting to predict their failure in education before it happens and to keep families posed to prevent it.</p><p>This study is organized as follows: In section 2, leading papers on fields related to the subject of this research were reviewed. Section 3 gives an overview of initial research theories, concepts, and other necessary items to get better acquainted. In section 4, the presented method was explained in detail, along with a completely clarified flowchart, and the recommended algorithm was explained. In section 5, the introduced model was compared in various dimensions to existing methods using various metrics. Ultimately, the final section concludes this study with a conclusion and discussion.</p>
    </sec>
    <sec sec-type="">
      <title>2. Research background</title>
      <p>The learner model is defined as a representation of beliefs of a computer system about the learner; hence, it is an abstract representation of the learner (<xref ref-type="bibr" rid="ref_27">Rostaminezhad et al., 2013</xref>). Learner modeling consists of a set of views and attitudes that a learner can possess. However, in practice, the learner and user models should be discriminated, which is a more comprehensive model. It is obvious that learners (students) are essential components of a smart educational system.</p><p>The user model has a more general form than the learner model, and conducted research can focus on more general behaviors that do not address a specific aspect of learner behaviors. Hence, the user model consists of aspects not limited to teaching (education). Investigating the learner model through an educational plan and learning theory is better. Three main theories of learning include behaviorism, cognitive constructivism, and constructivism. The oldest theory of learning is behaviorism which looks at the learner as a black box. The instructor of behaviorism is like a machine that responds in the face of stimuli. Learning occurs when learners are provoked to respond to a specific stimulus. Hence, learning happens when a learner faces those stimuli repeatedly; his/her correct responses are boosted through rewards, and wrong responses are rejected through punishments.</p><p>Based on behaviorism, cognitive constructivism theory assumes that learning consists of acquiring cognitive structures through saving information and processing them (<xref ref-type="bibr" rid="ref_20">Mosharraf et al., 2017</xref>). In other words, learning is defined as reshaping and recorrecting mental representations of intended aspects. Therefore, in cognitive constructivism, an individual member of the learners’ group is not defined as a black box; rather, his/her mental representations are defined through cognitive models.</p><p>The third theory is constructivism. Whereas the previous two theories are concrete theories of learning in which pre-determined behaviors possessing cognitive structures are transferred to the learner, the third theory is a speculative theory in which learners reconstruct the truth based on acquired experiences. Instead of being transferred, new knowledge is shaped according to previous experiences. Existing mental structures, as well as the learner’s beliefs, are employed to interpret events and objects. Each learner is, therefore, expected to construct his/her own reality. But where do traditional Intelligent Tutoring Systems (ITSs) containing a learner model fit into this psychological framework, and how do they relate to one another? A theory in which a test is used to assess a learner’s skill level belongs to the theory of behaviorism and the behaviorist viewpoint. Likewise, ITSs that attempt to model a learner’s internal state are, in fact, cognitive constructivist. Constructivist theories, however, are not compatible with traditional ITSs. Suppose each learner constructs a reality based on his/her own specific prior experiences and knowledge. Assuming that a pre-determined model can reasonably define such a learner is meaningless. Therefore, this study represents a proposed learner model, which utilizes Bayesian networks in the form of behaviorist and cognitive constructivist theories, given that current ITSs support these two.</p><p><xref ref-type="bibr" rid="ref_37">White &amp;amp; King (2020)</xref> proposed a model for identifying key factors in academic guidance of students using decision tree and neural network algorithms in data mining, and used the model to help facilitate the students’ academic guidance and advancements and increase their chances for success. <xref ref-type="bibr" rid="ref_39">Zaki et al. (2020)</xref> investigated the possibilities for education quality improvement in e-learning systems using EDM. Their research mainly aims to utilize data mining to obtain experiences that go beyond those of experts and to use these experiences for academic guidance in e-learning systems. The research also deals with hidden patterns in students’ course unit selection and prediction of their grades. In addition, it investigates the effects of activeness, the circumstances and time of entrance, season, etc., in an e-learning management system. <xref ref-type="bibr" rid="ref_41">Zhang et al. (2019)</xref> identified the key factors behind academic slumps using association rules and cluster analysis. The research attempts to implement predictive data mining models to predict students’ academic performance based on their personal and academic information. The statistical results in this research, produced from the implementation of models for predicting student status, can be used to discover the most effective factors that cause academic slumps and to help prevent them, as well as to improve the quality of communication between administrators/parents and students, and to improve the quality of education overall. <xref ref-type="bibr" rid="ref_4">Asif et al. (2017)</xref> proposed a method for student academic guidance based on mixed-technique data mining, and used student academic history in guidance school and first-year high school to point them toward appropriate academic majors. Various techniques were used to construct the intended models, such as improved decision trees and nearest-neighbor algorithms. A genetic algorithm was also used to process information gathered from 969 students besides the crisp methodology in MATLAB and clementine.</p><p>Several studies have examined and categorized the most important and beloved data mining techniques for improving education and creating personalized education based on data from traditional and distance education systems in recent years, including web-based courses, educational material management systems, and web-based intelligent/adaptive education systems.</p><p><xref ref-type="bibr" rid="ref_9">Dutt et al. (2017)</xref> presented a decision support system based on a multilayered perceptron neural network to help facilitate selecting an appropriate guidance strategy. In the next stage, an evolutionary algorithm was used to validate the knowledge produced by the neural network and evaluate the effectiveness of the specified guidance strategy. The neural network must be built using the fewest layers to prevent system decision-making mistakes (<xref ref-type="bibr" rid="ref_34">Sorourkhah et al., 2019</xref>). The proposed method mitigates many problems and complexities with neural networks by constructing trees out of the information and data. <xref ref-type="bibr" rid="ref_33">Slater et al. (2017)</xref> combined multiple classification algorithms to categorize students and predict their grades based on features extracted from their status. A genetic algorithm was utilized to weigh data features. And as the results point out, the rates for classification and predicting the students’ status have improved in this article. <xref ref-type="bibr" rid="ref_8">Devasia et al. (2016)</xref> used data mining techniques like association rule mining and inter-session and intra-session frequent pattern mining to extract useful patterns for instructors, administrators, as well as web managers who evaluate the students’ online course activity. A computer-based method was proposed for handling problems in student learning regarding courses in the sciences and for providing students with counseling.</p>
    </sec>
    <sec sec-type="">
      <title>3. Theoretical foundations and literature review</title>
      <p>Effective and efficient living in the 21<sup>st</sup> century requires recognizing the characteristics of this century (<xref ref-type="bibr" rid="ref_23">Qiu et al., 2023</xref>). The main characteristics of this era are the Information Age and the information-oriented community (<xref ref-type="bibr" rid="ref_15">Guzzo et al., 2023</xref>). In this community, information and its management and transformation to base knowledge constitute the foundation of the communities’ economy (<xref ref-type="bibr" rid="ref_22">Muniz, 2022</xref>). Such characteristics significantly impact social and economic institutions, based on which social institutions are forced to be reconstructed (<xref ref-type="bibr" rid="ref_28">Saberhoseini et al., 2022</xref>). Institutions for education and learning in general and at higher levels are one of the social institutions that will go through significant changes (<xref ref-type="bibr" rid="ref_16">Heilporn et al., 2022</xref>). Currently, the industry-oriented community is the institution’s foundation for education and learning. Graduates of traditional educational systems cannot possess the needed proficiency in an information-oriented community. In the past, people have been educated commensurate with the agricultural and industrial ages. However, such a procedure is not acceptable today. Today, information technology allows people to educate commensurate with needs, considering that it eliminates past constraints, provides us with authority, and allows students to realize their academic needs for learning in a proper time (<xref ref-type="bibr" rid="ref_40">Zhang et al., 2020</xref>). A new approach is needed for education and learning so that students can possess the necessary proficiency in an information-oriented community. Information technology and available tools are needed to implement the new approach (<xref ref-type="bibr" rid="ref_6">Chansamut, 2021</xref>). Such opportunity has been provided given the development of the information network, such as the internet. Using these opportunities quickly and in time can help people progress and develop. E-learning is one of these opportunities. Education planning should be done to help use this opportunity in the best way possible.</p>
      
        <sec>
          
            <title>3.1. Data mining</title>
          
          <p>In the last two decades, humans have become more capable of producing and quickly collecting data (<xref ref-type="bibr" rid="ref_17">Imani et al., 2022</xref>). The following factors have a significant role in these changes: using barcodes for business productions, using computers in business, science, and public services, and developing data collection instruments such as image and text scanners and remote sensing satellites (<xref ref-type="bibr" rid="ref_25">Roiger, 2017</xref>). Data mining can be considered a natural evolutionary process of information technology resulting from an evolutionary process in the dataset industry (<xref ref-type="bibr" rid="ref_21">Moterased et al., 2021</xref>). Data mining uses several scientific fields simultaneously, just like data collection, data management, and data analysis (<xref ref-type="bibr" rid="ref_18">Leskovec et al., 2020</xref>), including dataset technology, artificial intelligence (AI), machine learning, neural networks, statistics, pattern recognition, knowledge-based systems, acquisition of knowledge, information retrieval (IR), high-speed calculations, and data visualization.</p><p>Algorithm architectures define the instructions clearly to express the functions. In simple terms, an algorithm is a step-by-step calculation method and machine learning algorithms are used for various types of predication. They are categorized as supervised, unsupervised, semi-supervised, and reinforcement learning includes Artificial Neural Networks (ANNs), decision trees, Bayesian networks, k-nearest neighbors (KNN), and Support Vector Machines (SVMs) (<xref ref-type="bibr" rid="ref_2">Alsariera et al., 2022</xref>; <xref ref-type="bibr" rid="ref_30">Sharifi et al., 2022</xref>).</p><p>Bayes algorithm is based on Bayes’ theorem and is utilized for making real-time predictions and ensuring that the task is done risk-free (<xref ref-type="bibr" rid="ref_35">Wang et al., 2021</xref>). For example, each school intends to introduce several teams to the Paya Scientific League so that students can participate in the scientific league competition. In this study, students with the potential to attain acceptable scores and ranks were requested to participate in the competition, seeking to save time and increase efficiency. Individuals who are not eager to participate in the competition or are weak were exempted. Students’ information was stored in the system, including their grades, the financial status of their families, and their guarantee of presence at the completion. Using this algorithm, students can be informed and invited only to participate in this competition.</p>
        </sec>
      
      
        <sec>
          
            <title>3.2. Cluster analysis</title>
          
          <p>Clustering is the same task as daily categorization people do daily. For example, people place items in the same group due to their similarity and in another group due to their difference. In addition, the same items can belong to various groups based on their model, size, or use (<xref ref-type="bibr" rid="ref_10">Ebeling et al., 2019</xref>). This algorithm can place one item in two or more groups, given the similarities and differences. There is an essential difference between chain clustering and cluster analysis. In cluster analysis, the clusters are formed based on similarity. However, in chain clustering, clusters are formed based on the model. In chain clustering, each step is connected to the next one, just like a chain, meaning that the next step starts upon passing the first step. For example, in the case of Instagram, people should first register on Instagram and enter their personal information. Then after becoming an Instagram user to visit pages, Instagram shows pages they are interested in. As a result, friends with the same conditions can be shown (<xref ref-type="bibr" rid="ref_31">Shen et al., 2016</xref>).</p>
        </sec>
      
      
        <sec>
          
            <title>3.3. Evaluation metrics</title>
          
          <p>There are various evaluation metrics to measure and evaluate classification systems. These metrics include classification accuracy, recall, precision, and error rate. Before introducing these metrics, it is better to get familiarized with concepts, including True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN), which are utilized in the metrics.</p><p>TP is a percentage of the number of members in class <italic>X</italic> that the classification system correctly classifies as members of class <italic>X</italic>. TN is a percentage of the number of members in other classes classified correctly as not belonging to class <italic>X</italic>. FP is a percentage of the number of members in other classes classified incorrectly as members of class <italic>X</italic>. FN is a percentage of the number of members in class <italic>X</italic> classified incorrectly as members of other classes. Positive (P) is the total number of class members classified correctly. Negative (N) is the total number of class members classified incorrectly.</p><p>The evaluation metric recall is the accuracy of a classification system in correctly classifying members of class <italic>X</italic>, which are correctly classified as a member of class <italic>X</italic>, and is calculated as follows:</p>
          
            <disp-formula>
              <label>(1)</label>
              <mml:math id="mdpsoxwh04">
                <mml:mtext>Recall</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">FN</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>The evaluation metric precision is the percentage of members classified as class <italic>X</italic> members that truly belong to class <italic>X</italic> and is calculated as follows:</p>
          
            <disp-formula>
              <label>(2)</label>
              <mml:math id="m8a1pb53g3">
                <mml:mtext>Precision</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>Additionally, classification accuracy is another metric to evaluate the classification systems’ performance, owning an expansive and comprehensive view and domain of the performance of classification systems. It includes all the members who are classified correctly. Classification accuracy is calculated using the following equation:</p>
          
            <disp-formula>
              <label>(3)</label>
              <mml:math id="m6scn23z91">
                <mml:mtext>Accuracy</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">FN</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>In addition to those said above, F-score is another metric that is the weighted mean between accuracy and recall metrics. It is used to determine the efficiency of classification systems. It is calculated as follows:</p>
          
            <disp-formula>
              <label>(4)</label>
              <mml:math id="mfp7euu6kb">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mi data-mjx-auto-op="false">score</mml:mi>
                  <mml:mo>−</mml:mo>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mo>∗</mml:mo>
                <mml:mn>2</mml:mn>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mtext> Precision </mml:mtext>
                    <mml:mtext> Recall </mml:mtext>
                    <mml:mo>∗</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext> Precision </mml:mtext>
                    <mml:mtext> Recall </mml:mtext>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>Ultimately, the error rate of the suggested composition is calculated using the following formula:</p>
          
            <disp-formula>
              <label>(5)</label>
              <mml:math id="mihlmhzpw3">
                <mml:mtext>Error  rate</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mn>100</mml:mn>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                      </mml:mrow>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">FP</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi data-mjx-auto-op="false">FN</mml:mi>
                      </mml:mrow>
                      <mml:mo>+</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>+</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>4. Methodology</title>
      <p>There has been a limited number of studies until today focusing on predicting students’ academic performance using their records and report cards in school. Considering the potential of data mining methods in predicting future values, this study tries to use these technologies and cluster analysis to predict students’ failure in education and determine effective features. Ultimately, useful recommendations can be provided to parents through data analysis.</p><p>The suggested method in this research consists of the following parts to predict students’ academic performance:</p><p>• Clustering students</p><p>• Predicting students’ academic performance using a new algorithm</p><p>The main goal of the suggested method is first to find similar users using cluster analysis and determine the academic status of students given the users’ academic status in the same cluster.</p>
      
        <fig id="fig_1">
          <label>Figure 1</label>
          <caption>
            <title>Proposed diagram</title>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_0J7o6SODr-XOWmj5.png"/>
        </fig>
      
      <p>The suggested flowchart can be observed in the following <xref ref-type="fig" rid="fig_1">Figure 1</xref>. <xref ref-type="table" rid="table_1">Table 1</xref> illustrates students’ general features and information. This form is available for all elementary school students under investigation and in the records. Additionally, each <italic>F</italic>1, <italic>F</italic>2, <italic>F</italic>3, <italic>F</italic>4, and <italic>F</italic>5 is a student’s feature.</p>
      
        <table-wrap id="table_1">
          <label>Table 1</label>
          <caption>
            <title>Students’ general features and information</title>
          </caption>
          <table><tbody><tr><td colspan="1" rowspan="1"><p>No.</p></td><td colspan="3" rowspan="1"><p>F1</p></td><td colspan="2" rowspan="1"><p>F2</p></td><td colspan="7" rowspan="1" colwidth="0,,,,,,54"><p>F3</p></td><td colspan="4" rowspan="1" colwidth="0,59,60"><p>F4</p></td><td colspan="4" rowspan="1"><p>F5</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="3" rowspan="1"><p>Students being interested in a course</p></td><td colspan="2" rowspan="1"><p>Families checking on how their kids are educated</p></td><td colspan="4" rowspan="1"><p>Family Status</p></td><td colspan="2" rowspan="1"><p>Absence</p></td><td colspan="1" rowspan="2" colwidth="54"><p>Students without any absence</p></td><td colspan="2" rowspan="1" colwidth="0,59"><p>Financial Status</p></td><td colspan="2" rowspan="1" colwidth="60"><p>Student's IQ</p></td><td colspan="4" rowspan="1"><p>Parents' Education Stage</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Very Good</p></td><td colspan="1" rowspan="1"><p>Good</p></td><td colspan="1" rowspan="1"><p>Average</p></td><td colspan="1" rowspan="1"><p>Average</p></td><td colspan="1" rowspan="1"><p>Good</p></td><td colspan="1" rowspan="1"><p>Divorced Parents</p></td><td colspan="1" rowspan="1"><p>Conflicted Family</p></td><td colspan="1" rowspan="1"><p>Good</p></td><td colspan="1" rowspan="1"><p>Dead Parents</p></td><td colspan="1" rowspan="1"><p>Excused</p></td><td colspan="1" rowspan="1"><p>Unexcused</p></td><td colspan="1" rowspan="1"><p>Good</p></td><td colspan="1" rowspan="1" colwidth="59"><p>Average</p></td><td colspan="1" rowspan="1" colwidth="60"><p>Good</p></td><td colspan="1" rowspan="1"><p>Average</p></td><td colspan="1" rowspan="1"><p>Bachelor's degree and lower (Father)</p></td><td colspan="1" rowspan="1"><p>Master's</p><p>degree and higher (father)</p></td><td colspan="1" rowspan="1"><p>Bachelor's degree and lower (mother)</p></td><td colspan="1" rowspan="1"><p>Master's degree and higher (mother)</p></td></tr><tr><td colspan="1" rowspan="1"><p>Student 1</p></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="54"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1" colwidth="59"></td><td colspan="1" rowspan="1" colwidth="60"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Student 2</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1" colwidth="54"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="59"><p>*</p></td><td colspan="1" rowspan="1" colwidth="60"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Student 3</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="54"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="59"><p>*</p></td><td colspan="1" rowspan="1" colwidth="60"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>…</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="54"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="59"></td><td colspan="1" rowspan="1" colwidth="60"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Student n</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="54"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1" colwidth="59"></td><td colspan="1" rowspan="1" colwidth="60"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>*</p></td></tr></tbody></table>
        </table-wrap>
      
      <p>It can be noted that the school under investigation is a public school; therefore, parents either have a high income or average income, and low-income families do not exist. An intelligence quotient (IQ) test was conducted to register students in said school. It was found that students are either highly intelligent or have average intelligence, and students with low IQs do not exist. Students living with conflicted families have parents who disagree with each other, or the kids are only enrolled in public school because their parents do not bear the responsibility for their kids’ education. The result of academic status can be categorized as follows: a) Students with very good academic status enroll in a gifted school. b) Students with very good report cards but lower academic status than the first group enroll in a middle-range school for their next grade. c) Students with much lower academic status than other said groups enroll in a low-range school for their next grade.</p>
      
        <sec>
          
            <title>4.1. Clustering similar students</title>
          
          <p>Cluster analysis was used in this study so that data can benefit from a better structure and coherence. This method was also used to predict students’ academic performance with high accuracy, given that the dataset consists of students and there are similarities between students. Usually, similar students have the same academic performance. The first purpose of this study is to cluster the students and make predictions based on students of the same cluster, benefiting from a high accuracy. Other algorithms, such as machine learning and association rule learning, can also be beneficial in this context. However, cluster analysis helps the data set to have better similarities for intended students.</p><p>The k-means clustering algorithm has a complexity of <italic>O </italic>(<italic>I</italic>×<italic>K</italic>×<italic>n</italic>), where <italic>I</italic> is the number of iterations, <italic>K</italic> is the number of clusters, and <italic>n</italic> is the number of samples. K-means clustering is a non-hierarchical, flat, and algorithmic method that starts its search in a local environment, dividing data into each <italic>K</italic> cluster with a specific feature. This way, data in each cluster can be similar to each other to a feasible extent, and the difference between data of different clusters can have the highest value.</p><p>Each cluster has a centroid consisting of data, and all data are placed at the least distance from the cluster centroid. K-means clustering is an iterative clustering algorithm that minimizes the total distance between objects inside the cluster and the centroid. Next, the objects are placed in various clusters until the distance between objects does not change. The result of this clustering algorithm is completely separated clusters that do not resemble each other under no circumstances. For example, it’s assumed that students with the features mentioned in <xref ref-type="table" rid="table_2">Table 2</xref> exist for academic status. This is a hypothetical table, aiming to elaborate on the suggested method step-by-step using an example.</p>
          
            <table-wrap id="table_2">
              <label>Table 2</label>
              <caption>
                <title>Data of several students with similar features</title>
              </caption>
              <table><tbody><tr><td><p>Student Code</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td><td></td></tr><tr><td><p>Student 1</p></td><td><p>20</p></td><td><p>20</p></td><td><p>12</p></td><td><p>20</p></td><td><p>12</p></td><td></td></tr><tr><td><p>Student 2</p></td><td><p>17</p></td><td><p>18</p></td><td><p>4</p></td><td><p>15</p></td><td><p>12</p></td><td></td></tr><tr><td><p>Student 3</p></td><td><p>16</p></td><td><p>19</p></td><td><p>8</p></td><td><p>20</p></td><td><p>12</p></td><td></td></tr><tr><td><p>Student 4</p></td><td><p>19</p></td><td><p>17</p></td><td><p>9</p></td><td><p>16</p></td><td><p>20</p></td><td></td></tr><tr><td><p>Student 5</p></td><td><p>15</p></td><td><p>20</p></td><td><p>8</p></td><td><p>20</p></td><td><p>20</p></td><td></td></tr><tr><td><p>Student 6</p></td><td><p>18</p></td><td><p>18</p></td><td><p>2</p></td><td><p>17</p></td><td><p>10</p></td><td></td></tr><tr><td><p>Student 7</p></td><td><p>19</p></td><td><p>16</p></td><td><p>20</p></td><td><p>17</p></td><td><p>12</p></td><td></td></tr><tr><td><p>Student 8</p></td><td><p>14</p></td><td><p>20</p></td><td><p>9</p></td><td><p>20</p></td><td><p>12</p></td><td></td></tr><tr><td><p>Student 9</p></td><td><p>17</p></td><td><p>19</p></td><td><p>1</p></td><td><p>15</p></td><td><p>14</p></td><td></td></tr><tr><td><p>Student 10</p></td><td><p>19</p></td><td><p>17</p></td><td><p>8</p></td><td><p>16</p></td><td><p>14</p></td><td></td></tr></tbody></table>
            </table-wrap>
          
          <p>The following figures are given for each said feature: <italic>F</italic>1 (students being interested in a course): 18 to 20 is considered for the “very good” section, 15 to 17 for the “good” section, and 12 to 14 for the “average” section. <italic>F</italic>2 (families checking on how their kids are educated): 15 to 17 is considered for the “average” section, and 18 to 20 for the “good” section. <italic>F</italic>3: Regarding family status, 2 is considered for “divorced families,” 3 for “conflicted families,” 10 for “good families,” and 4 for “dead parents.” Regarding students’ absence, 10 is considered for “students without absence,” -1 for “excused absences,” and -2 for “unexcused absences.” <italic>F</italic>4: Regarding financial status, 3 is considered for the “average” section, 6 for the “good” section, 6 to 10 for students with “good IQ”; and 3 to 5 for students with “average IQ.” <italic>F</italic>5: According to the laws of the Ministry of Education, each educational stage has 2 points. In other words, a diploma has 2 points, an associate degree 4 points, a bachelor’s degree 6 points, a master’s degree 8 points, and a Ph.D. 10 points. Academic degrees of parents, bachelor’s degree and lower, are placed in one section in <xref ref-type="table" rid="table_1">Table 1</xref>.</p><p>Next, student clustering was conducted below. First, a mean vector was constructed based on input data. The mean value of each feature was calculated by dividing the total values of each feature by the number of features. For example, the mean value of <italic>F</italic>5 in <xref ref-type="table" rid="table_2">Table 2</xref> is calculated as follows:</p><p style="text-align: center"><inline-formula>
  <mml:math id="m7ywf4x5cm">
    <mml:mi>F</mml:mi>
    <mml:mn>5</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>20</mml:mn>
    <mml:mn>20</mml:mn>
    <mml:mn>10</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>14</mml:mn>
    <mml:mn>14</mml:mn>
    <mml:mn>10</mml:mn>
    <mml:mn>17.4</mml:mn>
    <mml:mo>=</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula></p><p>Three cluster heads were selected based on this vector, including a vector with the greatest positive distance from the mean vector, the least distance from the mean vector, and the greatest negative distance from the mean vector. The distance of all vectors from the mean vector was calculated using the following formula:</p>
          
            <disp-formula>
              <label>(6)</label>
              <mml:math id="mksv62ii4l">
                <mml:mtext>d(x, y)</mml:mtext>
                <mml:mo>=</mml:mo>
                <mml:msqrt>
                  <mml:munderover>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mi>n</mml:mi>
                  </mml:munderover>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>−</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>y</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                </mml:msqrt>
              </mml:math>
            </disp-formula>
          
          <p style="text-align: center"><inline-formula>
  <mml:math id="mu56gqh9rf">
    <mml:mi>d</mml:mi>
    <mml:mi>x</mml:mi>
    <mml:mi>y</mml:mi>
    <mml:mo>(</mml:mo>
    <mml:mo>,</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:msqrt>
      <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mo>(</mml:mo>
        <mml:mo>−</mml:mo>
        <mml:mo>+</mml:mo>
        <mml:mo>(</mml:mo>
        <mml:mo>−</mml:mo>
        <mml:mo>+</mml:mo>
        <mml:mo>(</mml:mo>
        <mml:mo>−</mml:mo>
        <mml:mo>+</mml:mo>
        <mml:mo>(</mml:mo>
        <mml:mo>−</mml:mo>
        <mml:mo>+</mml:mo>
        <mml:mo>(</mml:mo>
        <mml:mo>−</mml:mo>
        <mml:mo>)</mml:mo>
        <mml:mn>17.4</mml:mn>
        <mml:mn>20</mml:mn>
        <mml:mn>18.9</mml:mn>
        <mml:mn>20</mml:mn>
        <mml:mn>7.9</mml:mn>
        <mml:mn>12</mml:mn>
        <mml:mn>17.6</mml:mn>
        <mml:mn>20</mml:mn>
        <mml:mn>14.8</mml:mn>
        <mml:mn>12</mml:mn>
        <mml:msup>
          <mml:mo>)</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:msup>
        <mml:msup>
          <mml:mo>)</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:msup>
        <mml:msup>
          <mml:mo>)</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:msup>
        <mml:msup>
          <mml:mo>)</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:msup>
        <mml:msup>
          <mml:mo>)</mml:mo>
          <mml:mn>2</mml:mn>
        </mml:msup>
      </mml:mrow>
      <mml:mo>=</mml:mo>
      <mml:mn>6.19758</mml:mn>
    </mml:msqrt>
  </mml:math>
</inline-formula></p><p>The similarity between vectors increased as the distance decreased. For example, the distance of student 1 from the mean vector was calculated as follows based on <xref ref-type="table" rid="table_2">Table 2</xref>.</p><p>The distances of all data in <xref ref-type="table" rid="table_2">Table 2</xref> from the mean vector were calculated and are illustrated in <xref ref-type="table" rid="table_3">Table 3</xref>.</p>
          
            <table-wrap id="table_3">
              <label>Table 3</label>
              <caption>
                <title>Distance from the mean value</title>
              </caption>
              <table><tbody><tr><td><p>Student Code</p></td><td><p>Distance</p></td></tr><tr><td><p>Student 1</p></td><td><p>6.19758</p></td></tr><tr><td><p>Student 2</p></td><td><p>5.547972</p></td></tr><tr><td><p>Student 3</p></td><td><p>3.94715</p></td></tr><tr><td><p>Student 4</p></td><td><p>6.1229011</p></td></tr><tr><td><p>Student 5</p></td><td><p>6.57114</p></td></tr><tr><td><p>Student 6</p></td><td><p>10.73175</p></td></tr><tr><td><p>Student 7</p></td><td><p>12.569</p></td></tr><tr><td><p>Student 8</p></td><td><p>5.98163</p></td></tr><tr><td><p>Student 9</p></td><td><p>7.360706</p></td></tr><tr><td><p>Student 10</p></td><td><p>3.062678</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The average distance is 5.889. Hence, vector data of students 7, 8, and 10 were selected as cluster heads considering: a) Student 7 has the greatest positive distance compared to the mean value of 5.889 (the greatest figure among figures larger than 5.889). b) Student 10 has the greatest negative distance compared to the mean value of 5.889 (the smallest figure among figures smaller than 5.889). c) Student 8 has the least distance from the mean vector.</p>
          
            <table-wrap id="table_4">
              <label>Table 4</label>
              <caption>
                <title>Results of clustering data from Table 2</title>
              </caption>
              <table><tbody><tr><td><p>Members</p></td><td><p>Cluster Heads</p></td></tr><tr><td><p>Student 6</p></td><td><p>Student 7</p></td></tr><tr><td><p>Students 1, 2, 4, 5, and 9</p></td><td><p>Student 8</p></td></tr><tr><td><p>Student 3</p></td><td><p>Student 10</p></td></tr><tr><td><p>Student 10</p></td><td><p>3.062678</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>The distance of each data point from selected cluster heads was calculated using the said formula to select members of each cluster. Clusters absorbed vectors with the least distance, and the results are elaborated in <xref ref-type="table" rid="table_4">Table 4</xref>.</p><p>The distance between each vector was calculated from cluster heads for the next input data. For a lower distance between the vector and average distances, the vector was absorbed by one of the cluster heads; otherwise, it was selected as one of the new cluster heads.</p>
        </sec>
      
      
        <sec>
          
            <title>4.2. Prediction using new algorithms</title>
          
          <p>In the previous sections, students were clustered, given their features. This section aims to predict students’ academic performance using the Bayesian networks.</p><p>Bayesian network is a learning process based on statistical learning theory, which is one of the best machine learning approaches in data mining. This method has been successful in various tasks, such as data classification, pattern recognition, content classification, face recognition on images, recognition of figures written by hand, and bioinformatics. In fact, the Bayesian network is a binary classifier that separates two classes using a linear boundary. This method uses all bands and an optimization algorithm to obtain samples that form the boundary of classes. These samples are called support vectors. A number of learning points with the least distance from the decision boundary can be considered a subset to define decision boundaries and as a support vector. Assume that two data classes have a total of <italic>x<sub>i</sub></italic>=<italic>i</italic>, <italic>i</italic>=1, ..., <italic>L</italic> learning points (<italic>x<sub>i</sub></italic> is a vector). These two classes are tagged with <italic>y</italic>=±1. The optimal margin classifier calculates the decision boundary of two completely separated classes. In this method, the linear boundary between two classes is calculated so that all samples of the +1 class are on one side of the boundary, and samples of the -1 class are on the other side of the boundary. The decision boundary should be selected so that the distance of the nearest educational samples from each other in each class, orthogonal to the decision boundary, is maximized to a feasible extent. A linear decision boundary can be defined as follows in general: <italic>w. x</italic> +<italic>b</italic> =0. <italic>x</italic> is a point on the decision boundary, and <italic>w</italic> is an <italic>n</italic>-dimensional vector orthogonal to the decision boundary. <italic>b</italic>/|<italic>w</italic>| is the distance between the origin and decision boundary, and <italic>w. x</italic> represents the inner product of two vectors of <italic>w</italic> and <italic>x</italic>.</p>
          <p>The equality is still established by multiplying both sides of the equation by a constant. Finding the nearest educational samples of two classes is the first step to calculating optimal decision boundaries. Next, the distance between these points, orthogonal to the boundaries that separate two classes completely, is calculated. The optimal decision boundary has the maximum margin. The optimal decision boundary is calculated by solving the following optimization problem.</p>
          
            <disp-formula>
              <label>(7)</label>
              <mml:math id="mhjoosq521">
                <mml:mfrac>
                  <mml:mo>min</mml:mo>
                  <mml:mrow>
                    <mml:mi>w</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mfrac>
                  <mml:mo>min</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>…</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mrow>
                  <mml:mo>[</mml:mo>
                  <mml:mo>]</mml:mo>
                  <mml:msub>
                    <mml:mi>y</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>⋅</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:mi>w</mml:mi>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mi>b</mml:mi>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:mi>w</mml:mi>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:math>
            </disp-formula>
          
          <p>The above-written equation can be written as follows using a set of mathematical operations:</p>
          
            <disp-formula>
              <label>(8)</label>
              <mml:math id="m9orhzfqlx">
                <mml:mfrac>
                  <mml:mo>min</mml:mo>
                  <mml:mrow>
                    <mml:mi>w</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mn>2</mml:mn>
                </mml:mfrac>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                </mml:mrow>
                <mml:mi>w</mml:mi>
                <mml:mi>w</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:mi>b</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>L</mml:mi>
                <mml:msup>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                  <mml:mn>2</mml:mn>
                </mml:msup>
                <mml:mo>,</mml:mo>
                <mml:mo>(</mml:mo>
                <mml:mo>.</mml:mo>
                <mml:mo>+</mml:mo>
                <mml:mo>)</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mo>≥</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:mo>…</mml:mo>
                <mml:mo>,</mml:mo>
                <mml:msub>
                  <mml:mi>y</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mn>1</mml:mn>
                <mml:mn>0</mml:mn>
                <mml:mn>1</mml:mn>
              </mml:math>
            </disp-formula>
          
          <p>It is difficult to reach a solution to the above-written optimization problem. A Lagrange multiplier was utilized to write this optimization problem in the form of the following equation aiming at simplifying it. <italic>λ<sub>i</sub></italic> are the coefficients of the Lagrange multiplier.</p>
          
            <disp-formula>
              <label>(9)</label>
              <mml:math id="m8fgks2lj6">
                <mml:mover>
                  <mml:munder>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>λ</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>λ</mml:mi>
                        <mml:mi>L</mml:mi>
                      </mml:msub>
                      <mml:mo>…</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>λ</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mo>≥</mml:mo>
                      <mml:mn>0</mml:mn>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mo>max</mml:mo>
                </mml:mover>
                <mml:munder>
                  <mml:mrow>
                    <mml:mo>⌈</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>⌉</mml:mo>
                    <mml:mfrac>
                      <mml:mn>1</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:mfrac>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>L</mml:mi>
                    </mml:munderover>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>L</mml:mi>
                    </mml:munderover>
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mi>L</mml:mi>
                    </mml:munderover>
                    <mml:msub>
                      <mml:mi>λ</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>y</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>y</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>λ</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mi>λ</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mo>.</mml:mo>
                      <mml:mo>)</mml:mo>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:msub>
                        <mml:mi>x</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mi>L</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:mo>…</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:munder>
              </mml:math>
            </disp-formula>
          
          
            <disp-formula>
              <label>(10)</label>
              <mml:math id="mmr7lu6mq3">
                <mml:mi>w</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>L</mml:mi>
                </mml:munderover>
                <mml:msub>
                  <mml:mi>λ</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>y</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mn>0</mml:mn>
              </mml:math>
            </disp-formula>
          
          <p><italic>w</italic> can be calculated using the following equation after solving the above-written problem and finding the coefficients of the Lagrange multiplier.</p>
          
            <disp-formula>
              <label>(11)</label>
              <mml:math id="m0it5m4yra">
                <mml:mi>w</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>L</mml:mi>
                </mml:munderover>
                <mml:msub>
                  <mml:mi>λ</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>y</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:msub>
                  <mml:mi>x</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
              </mml:math>
            </disp-formula>
          
          <p><italic>λ<sub>i</sub></italic> is larger than zero for support vectors and equal to zero for other points. Therefore, considering the above equation and <italic>λ<sub>i</sub></italic> being zero for <italic>x<sub>i</sub></italic> other than support vectors, a limited number of educational points, which are the same as support vectors, are needed to obtain the decision boundary. Not all the points are needed.</p><p>In such circumstances, the following operations were conducted:</p><p>a) A cluster for the new student was specified.</p><p>b) Students in a cluster were separated as normal and non-normal. Students who did not fail in education were considered normal; otherwise, non-normal. Next, data obtained in this section was considered a training set.</p><p>c) New students and students in the same cluster were evaluated using the suggested algorithm to make predictions as follows:</p><p>• Firstly, training data were specified.</p><p>• Training data were separated as normal and not-normal.</p><p>• Two classifiers were utilized to determine the academic status of each student.</p><p>The first classifier specifies whether the new student fails in education. The output of this classifier is either one or zero. In other words, the output “1” means that failure in education occurs, and the output “0” means undetermined. In this classifier, data from students who fail in education were used in training data.</p><p>• The second classifier specifies whether the new student has a good academic status. The output of this classifier is either one or zero. In other words, the output “1” means that failure in education does not occur, and the output “0” means undetermined. This classifier uses data from students with good academic status in the training set.</p><p>• After finding the output of each classifier, the final results were studied as follows:</p><p>If the first classifier gains output “1” and the second classifier gains output “0,” the student definitely fails in education.</p><p>If the first classifier gains output “0” and the second classifier gains output “1,” the student does not definitely fail in education.</p><p>If both classifiers gain either output “1” or “0,” an indefinite circumstance occurs. To eliminate such circumstances, the vector distance of the student from the average vector of normal and non-normal data was calculated. If any of them have a lesser value, the student is placed in that class. Next, the suggested algorithm was explained using an example.</p><p>The suggested algorithm uses the training data set to execute this task. Several students were in this data set, and whether they fail in education was determined. Students with better academic status have class “1,” and those with inferior academic status have class “0”, which are depicted in the following table.</p><p><xref ref-type="table" rid="table_5">Table 5</xref> illustrates 15 education vectors as an example. In this table, each row represents a student with <italic>F</italic>1, <italic>F</italic>2, <italic>F</italic>3, …, features.</p><p><xref ref-type="table" rid="table_6">Table 6</xref> illustrates test data, showing the students’ current status. However, their normal or non-normal status is not specified.</p>
          
            <table-wrap id="table_5">
              <label>Table 5</label>
              <caption>
                <title>Train set sample (Users in the same cluster)</title>
              </caption>
              <table><tbody><tr><td><p>Class</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>0</p></td><td><p>18</p></td><td><p>16</p></td><td><p>14</p></td><td><p>15</p></td><td><p>8</p></td></tr><tr><td><p>1</p></td><td><p>18</p></td><td><p>18</p></td><td><p>17</p></td><td><p>13</p></td><td><p>8</p></td></tr><tr><td><p>0</p></td><td><p>16</p></td><td><p>16</p></td><td><p>13</p></td><td><p>14</p></td><td><p>20</p></td></tr><tr><td><p>1</p></td><td><p>19</p></td><td><p>19</p></td><td><p>19</p></td><td><p>18</p></td><td><p>16</p></td></tr><tr><td><p>1</p></td><td><p>20</p></td><td><p>18</p></td><td><p>17</p></td><td><p>15</p></td><td><p>12</p></td></tr><tr><td><p>1</p></td><td><p>19</p></td><td><p>19</p></td><td><p>20</p></td><td><p>13</p></td><td><p>12</p></td></tr><tr><td><p>0</p></td><td><p>13</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>10</p></td></tr><tr><td><p>1</p></td><td><p>20</p></td><td><p>18</p></td><td><p>20</p></td><td><p>15</p></td><td><p>4</p></td></tr><tr><td><p>0</p></td><td><p>13</p></td><td><p>15</p></td><td><p>0</p></td><td><p>12</p></td><td><p>2</p></td></tr><tr><td><p>1</p></td><td><p>15</p></td><td><p>16</p></td><td><p>1</p></td><td><p>10</p></td><td><p>12</p></td></tr><tr><td><p>1</p></td><td><p>13</p></td><td><p>15</p></td><td><p>2</p></td><td><p>10</p></td><td><p>20</p></td></tr><tr><td><p>1</p></td><td><p>18</p></td><td><p>20</p></td><td><p>20</p></td><td><p>11</p></td><td><p>14</p></td></tr><tr><td><p>0</p></td><td><p>12</p></td><td><p>15</p></td><td><p>14</p></td><td><p>11</p></td><td><p>6</p></td></tr><tr><td><p>1</p></td><td><p>18</p></td><td><p>17</p></td><td><p>20</p></td><td><p>15</p></td><td><p>4</p></td></tr><tr><td><p>0</p></td><td><p>17</p></td><td><p>17</p></td><td><p>20</p></td><td><p>20</p></td><td><p>6</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_6">
              <label>Table 6</label>
              <caption>
                <title>Test data sample</title>
              </caption>
              <table><tbody><tr><td colspan="1" rowspan="1"><p>Class</p></td><td colspan="1" rowspan="1"><p><italic>F</italic>1</p></td><td colspan="1" rowspan="1"><p><italic>F</italic>2</p></td><td colspan="1" rowspan="1"><p><italic>F</italic>3</p></td><td colspan="1" rowspan="1"><p><italic>F</italic>4</p></td><td colspan="1" rowspan="1"><p><italic>F</italic>5</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>2</p></td><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>2</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>12</p></td><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>0</p></td><td colspan="1" rowspan="1"><p>10</p></td><td colspan="1" rowspan="1"><p>20</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>17</p></td><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>12</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>18</p></td><td colspan="1" rowspan="1"><p>14</p></td><td colspan="1" rowspan="1"><p>18</p></td><td colspan="1" rowspan="1"><p>8</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>18</p></td><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>13</p></td><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>4</p></td></tr><tr><td colspan="1" rowspan="1"><p>---</p></td><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>19</p></td><td colspan="1" rowspan="1"><p>20</p></td><td colspan="1" rowspan="1"><p>15</p></td><td colspan="1" rowspan="1"><p>4</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>This study aims to specify new students’ academic status using the suggested algorithm. Two columns were added to <xref ref-type="table" rid="table_5">Table 5</xref> as the output of classifier No. 1 and classifier No. 2 to determine the current vectors’ status. Using the output of each classifier, outputs of the current vector status were determined. In the naive Bayes classifier, all shared features were first summed and then divided by the number of features. Then, the data test was compared. <xref ref-type="table" rid="table_7">Table 7</xref> shows the average features of students in each class.</p><p style="text-align: center"><inline-formula>
  <mml:math id="m52i69zo6d">
    <mml:mi>F</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mn>1</mml:mn>
    <mml:mn>1</mml:mn>
    <mml:mn>18</mml:mn>
    <mml:mn>19</mml:mn>
    <mml:mn>20</mml:mn>
    <mml:mn>19</mml:mn>
    <mml:mn>20</mml:mn>
    <mml:mn>13</mml:mn>
    <mml:mn>18</mml:mn>
    <mml:mn>17</mml:mn>
    <mml:mn>8</mml:mn>
    <mml:mn>18</mml:mn>
    <mml:mn>6</mml:mn>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula></p><p style="text-align: center"><inline-formula>
  <mml:math id="m01bxz7dq8">
    <mml:mi>F</mml:mi>
    <mml:mi>c</mml:mi>
    <mml:mi>l</mml:mi>
    <mml:mi>a</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mi>s</mml:mi>
    <mml:mn>1</mml:mn>
    <mml:mn>0</mml:mn>
    <mml:mn>18</mml:mn>
    <mml:mn>16</mml:mn>
    <mml:mn>13</mml:mn>
    <mml:mn>13</mml:mn>
    <mml:mn>15</mml:mn>
    <mml:mn>13</mml:mn>
    <mml:mn>12</mml:mn>
    <mml:mn>7</mml:mn>
    <mml:mn>14</mml:mn>
    <mml:mn>2</mml:mn>
    <mml:mo>(</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
  </mml:math>
</inline-formula></p>
          
            <table-wrap id="table_7">
              <label>Table 7</label>
              <caption>
                <title>The average features of students in each class</title>
              </caption>
              <table><tbody><tr><td><p>Class</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>1</p></td><td><p>18.6</p></td><td><p>18.2</p></td><td><p>19.1</p></td><td><p>14.8</p></td><td><p>8.7</p></td></tr><tr><td><p>0</p></td><td><p>14.2</p></td><td><p>15.4</p></td><td><p>6.5</p></td><td><p>12.1</p></td><td><p>11.14</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>4.3. Classifier no. 1</title>
          
          <p>The negative selection classification algorithm (NSCA) with a variable length and real values and detection systems with a variable radius were used to design classifier No. 1. The radius of self-samples (RS) is the main parameter that significantly affects classification efficiency, and it is a crucial element in learning capability (classifier generalization). It also plays a significant role in both the NSCA and the positive selection classification algorithm (PSCA) with real values. If this classifier generates a positive output, it most likely shows the high quality of educational services, and a suitable warning should be issued. RS was calculated below for all test data. The similarity ratio of each test data to data from the education section was calculated in non-normal circumstances.</p><p>The similarity ratio is the number of shared features of both the vector and training data vectors. It is illustrated in percentage at the end, and the highest value is considered the similarity ratio. RS of a vector is the average similarity ratio of all vectors. This classifier generates an output equal to 1 when the similarity ratio of a vector exceeds RS.</p><p><xref ref-type="table" rid="table_8">Table 8</xref> shows the similarity ratio for test data to non-normal training data. It can be noted that the evaluation of each data feature was tested using <xref ref-type="table" rid="table_5">Table 5</xref> to achieve the ratio of RS similarity to normal and non-normal data. This way, the similarity ratio to normal and non-normal data was obtained. Additionally, each of these features was considered as 20%.</p>
          
            <table-wrap id="table_8">
              <label>Table 8</label>
              <caption>
                <title>The ratio of test data similarity to non-normal data</title>
              </caption>
              <table><tbody><tr><td><p>Ratio of Similarity to Non-Normal Data</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>60%</p></td><td><p>17</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td></tr><tr><td><p>80%</p></td><td><p>12</p></td><td><p>17</p></td><td><p>0</p></td><td><p>10</p></td><td><p>20</p></td></tr><tr><td><p>20%</p></td><td><p>16</p></td><td><p>19</p></td><td><p>17</p></td><td><p>14</p></td><td><p>12</p></td></tr><tr><td><p>0%</p></td><td><p>19</p></td><td><p>18</p></td><td><p>14</p></td><td><p>18</p></td><td><p>8</p></td></tr><tr><td><p>20%</p></td><td><p>18</p></td><td><p>20</p></td><td><p>13</p></td><td><p>20</p></td><td><p>4</p></td></tr><tr><td><p>0%</p></td><td><p>20</p></td><td><p>19</p></td><td><p>20</p></td><td><p>15</p></td><td><p>4</p></td></tr></tbody></table>
            </table-wrap>
          
          <p style="text-align: justify">Given the similarity ratio of test data in <xref ref-type="table" rid="table_7">Table 7</xref>, obtained based on non-normal data from training data, RS is as follows:</p><p style="text-align: center"><inline-formula>
  <mml:math id="m0mbs27m5m">
    <mml:mrow>
      <mml:mi data-mjx-auto-op="false">RS</mml:mi>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mi data-mjx-auto-op="false">RS</mml:mi>
    </mml:mrow>
    <mml:mo>=</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mn>0.6</mml:mn>
    <mml:mn>0.8</mml:mn>
    <mml:mn>0.2</mml:mn>
    <mml:mn>0</mml:mn>
    <mml:mn>0.2</mml:mn>
    <mml:mn>0</mml:mn>
    <mml:mn>6</mml:mn>
    <mml:mn>30</mml:mn>
    <mml:mi>%</mml:mi>
  </mml:math>
</inline-formula></p><p>Based on what was said previously, classifier No. 1 generated output “1” for vectors with a ratio of similarity larger than RS, as illustrated in <xref ref-type="table" rid="table_8">Table 8</xref>.</p>
        </sec>
      
      
        <sec>
          
            <title>4.4. Classifier no. 2</title>
          
          <p>The second classifier examines whether the current vectors of the students are in a normal state or not. This classifier operates based on the normal training data. If the vector is normal, it outputs one; otherwise, it outputs zero. <xref ref-type="table" rid="table_9">Table 9</xref> shows the percentage of similarity between the test data and the normal training data.</p>
          
            <table-wrap id="table_9">
              <label>Table 9</label>
              <caption>
                <title>The ratio of test data similarity to normal data</title>
              </caption>
              <table><tbody><tr><td><p>Ratio of Similarity to Normal Data</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>60%</p></td><td><p>17</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td></tr><tr><td><p>20%</p></td><td><p>12</p></td><td><p>17</p></td><td><p>0</p></td><td><p>10</p></td><td><p>20</p></td></tr><tr><td><p>80%</p></td><td><p>16</p></td><td><p>19</p></td><td><p>17</p></td><td><p>14</p></td><td><p>12</p></td></tr><tr><td><p>100%</p></td><td><p>19</p></td><td><p>18</p></td><td><p>14</p></td><td><p>18</p></td><td><p>8</p></td></tr><tr><td><p>40%</p></td><td><p>18</p></td><td><p>20</p></td><td><p>13</p></td><td><p>20</p></td><td><p>4</p></td></tr><tr><td><p>100%</p></td><td><p>20</p></td><td><p>19</p></td><td><p>20</p></td><td><p>15</p></td><td><p>4</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Based on the percentage of similarity in the table for the test data, obtained based on the normal training data, the value of RS is equal to:</p><p style="text-align: center"><inline-formula>
  <mml:math id="mlxzroaoiy">
    <mml:mrow>
      <mml:mi data-mjx-auto-op="false">RS</mml:mi>
    </mml:mrow>
    <mml:mrow>
      <mml:mo>/</mml:mo>
    </mml:mrow>
    <mml:mrow>
      <mml:mi data-mjx-auto-op="false">RS</mml:mi>
    </mml:mrow>
    <mml:mo>=</mml:mo>
    <mml:mo>(</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>+</mml:mo>
    <mml:mo>)</mml:mo>
    <mml:mo>=</mml:mo>
    <mml:mn>0.6</mml:mn>
    <mml:mn>0.2</mml:mn>
    <mml:mn>0.8</mml:mn>
    <mml:mn>1</mml:mn>
    <mml:mn>0.4</mml:mn>
    <mml:mn>1</mml:mn>
    <mml:mn>6</mml:mn>
    <mml:mn>66</mml:mn>
    <mml:mi>%</mml:mi>
  </mml:math>
</inline-formula></p>
          <p>Therefore, vectors that have a similarity value greater than RS received one output from the second classifier. <xref ref-type="table" rid="table_10">Table 10</xref> shows the outputs generated by classifiers.</p>
          
            <table-wrap id="table_10">
              <label>Table 10</label>
              <caption>
                <title>Outputs generated by classifiers</title>
              </caption>
              <table><tbody><tr><td><p>Classifier #1</p></td><td><p>Classifier #2</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>1</p></td><td><p>1</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td><td><p>15</p></td><td><p>17</p></td></tr><tr><td><p>1</p></td><td><p>0</p></td><td><p>20</p></td><td><p>10</p></td><td><p>0</p></td><td><p>17</p></td><td><p>12</p></td></tr><tr><td><p>0</p></td><td><p>1</p></td><td><p>12</p></td><td><p>14</p></td><td><p>17</p></td><td><p>19</p></td><td><p>16</p></td></tr><tr><td><p>0</p></td><td><p>1</p></td><td><p>8</p></td><td><p>18</p></td><td><p>14</p></td><td><p>18</p></td><td><p>19</p></td></tr><tr><td><p>0</p></td><td><p>0</p></td><td><p>4</p></td><td><p>20</p></td><td><p>13</p></td><td><p>20</p></td><td><p>18</p></td></tr><tr><td><p>0</p></td><td><p>1</p></td><td><p>4</p></td><td><p>15</p></td><td><p>20</p></td><td><p>19</p></td><td><p>20</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
      
        <sec>
          
            <title>4.5. Mechanism to select the best classifier</title>
          
          <p>During the test phase, four modes occurred for a new input sample: Classifier No. 1, which covers a non-self area, generated the output “1,” and classifier No. 2, which covers the self area, generated the output “0.” In this case, it can be 100% said that the new sample belongs to class 2, is a malformed sample, and generates a warning system.</p><p>Classifier No. 1 generates the output “0,” and classifier No. 2 generates the output “1”. In this case, it can be 100% said that the new sample belongs to class 1 and is a normal sample. Both classifiers generate either output “0” or “1”; such circumstances are called indefinite. A method was used for selecting one of the classifiers explained below. <xref ref-type="table" rid="table_11">Table 11</xref> shows the result of the initial evaluation of classifiers.</p>
          
            <table-wrap id="table_11">
              <label>Table 11</label>
              <caption>
                <title>Result of the initial evaluation</title>
              </caption>
              <table><tbody><tr><td><p>Class</p></td><td><p>Classifier #1</p></td><td><p>Classifier #2</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>Indefinite</p></td><td><p>1</p></td><td><p>1</p></td><td><p>17</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td></tr><tr><td><p>Non-normal</p></td><td><p>1</p></td><td><p>0</p></td><td><p>12</p></td><td><p>17</p></td><td><p>0</p></td><td><p>10</p></td><td><p>20</p></td></tr><tr><td><p>Normal</p></td><td><p>0</p></td><td><p>1</p></td><td><p>16</p></td><td><p>19</p></td><td><p>17</p></td><td><p>14</p></td><td><p>12</p></td></tr><tr><td><p>Normal</p></td><td><p>0</p></td><td><p>1</p></td><td><p>19</p></td><td><p>18</p></td><td><p>14</p></td><td><p>18</p></td><td><p>8</p></td></tr><tr><td><p>Indefinite</p></td><td><p>0</p></td><td><p>0</p></td><td><p>18</p></td><td><p>20</p></td><td><p>13</p></td><td><p>20</p></td><td><p>4</p></td></tr><tr><td><p>Normal</p></td><td><p>0</p></td><td><p>1</p></td><td><p>20</p></td><td><p>19</p></td><td><p>20</p></td><td><p>15</p></td><td><p>4</p></td></tr></tbody></table>
            </table-wrap>
          
          <p>Vectors with normal or non-normal classes have a definite status. However, the methods said were used below for indefinite circumstances.</p>
        </sec>
      
      
        <sec>
          
            <title>4.6. Indefinite circumstances</title>
          
          <p>This occurs when both classifiers generate either output “1” or “0.” A survey was used in such circumstances. If a group has the highest number of mature data resembling test data, its tag was selected for test data. However, suppose the similarity ratio was the same for both normal and non-normal groups. In that case, if the vector has only one feature different from the education section vector, it can be called similar. </p><p>As seen in <xref ref-type="table" rid="table_11">Table 11</xref>, some vectors are overlapped. The said method needs to be used to specify whether they are normal or non-normal; this matter was explained vector by vector below. In <xref ref-type="table" rid="table_12">Table 12</xref>, vectors in overlapping mode are depicted along with the similarity ratio.</p><p>Based on <xref ref-type="table" rid="table_13">Table 13</xref>, the status of one vector was specified. However, one vector still remained indefinite. The said method was used to calculate the new similarity ratio in such a case. In this method, if the vector has only one feature different from the education section vector, it can be called similar.</p>
          
            <table-wrap id="table_12">
              <label>Table 12</label>
              <caption>
                <title>Vector status in overlapping mode</title>
              </caption>
              <table><tbody><tr><td><p>Ratio of Similarity to Normal Data</p></td><td><p>Ratio of Similarity to Non-Normal Data</p></td><td><p>Class</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>60%</p></td><td><p>60%</p></td><td><p>Indefinite</p></td><td><p>17</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td></tr><tr><td><p>40%</p></td><td><p>20%</p></td><td><p>Normal</p></td><td><p>18</p></td><td><p>20</p></td><td><p>13</p></td><td><p>20</p></td><td><p>4</p></td></tr></tbody></table>
            </table-wrap>
          
          
            <table-wrap id="table_13">
              <label>Table 13</label>
              <caption>
                <title>Similarity ratio</title>
              </caption>
              <table><tbody><tr><td><p>Class</p></td><td><p>Output of Classifier No. 1</p></td><td><p>Output of Classifier No. 2</p></td><td><p><italic>F</italic>1</p></td><td><p><italic>F</italic>2</p></td><td><p><italic>F</italic>3</p></td><td><p><italic>F</italic>4</p></td><td><p><italic>F</italic>5</p></td></tr><tr><td><p>Normal</p></td><td><p>20%</p></td><td><p>40%</p></td><td><p>17</p></td><td><p>15</p></td><td><p>2</p></td><td><p>13</p></td><td><p>2</p></td></tr></tbody></table>
            </table-wrap>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>5. Results and comparison with available methods</title>
      <p>This section evaluates results acquired in the simulation using several metrics. MATLAB was used for simulation tasks, and several phases were considered for each evaluation metric. The results were implemented for various data and compared with available methods. It is worth noting that the data evaluated in each phase is larger than the dataset. Simulation was used several times to obtain results in each phase, and the average-acquired results were considered the output result.</p><p><xref ref-type="bibr" rid="ref_7">Chuan et al. (2017)</xref> used decision trees and neural networks to introduce a model for identifying factors affecting students’ performance by studying their records and consulting them. A model was suggested with the aid of decision tree algorithms and neural networks in data mining that helps students’ performance and increases their success. In the study by <xref ref-type="bibr" rid="ref_11">Francis &amp;amp; Babu (2019)</xref>, data mining techniques, such as association rule mining, intersession, and intra-session frequent pattern mining, were utilized to extract useful patterns for tutors, heads of education, and web managers who evaluate students’ online activities. A computer-based method was suggested to eliminate students’ learning problems in scientific courses and consult them.</p>
      
        <sec>
          
            <title>5.1. Recall</title>
          
          <p>Recall is one of the important metrics to evaluate extracted rules. To calculate this metric, the output of average values is depicted for each phase in <xref ref-type="fig" rid="fig_2">Figure 2</xref>.</p>
          
            <fig id="fig_2">
              <label>Figure 2</label>
              <caption>
                <title>Comparison of recall metrics</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_cEtGmiMgjY_PYR3L.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>5.2. Precision</title>
          
          <p><xref ref-type="fig" rid="fig_3">Figure 3</xref> depicts the comparison result of the above-said metric. In each phase, the average of the above-said metric values was calculated. The extracted rule benefits from a higher assurance as the value increases.</p><p>The result shows that the suggested method for the above-said metric performs better than the previous methods.</p>
          
            <fig id="fig_3">
              <label>Figure 3</label>
              <caption>
                <title>Comparison of precision metrics</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_4s-gRquneW8THy_I.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>5.3. F-measure</title>
          
          <p>This metric was calculated using the following equation given two metrics of recall and precision:</p>
          
            <disp-formula>
              <label>(12)</label>
              <mml:math id="mk4ulr2ui6">
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                </mml:mrow>
                <mml:mo>−</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mtext>Measure</mml:mtext>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mo>∗</mml:mo>
                    <mml:mo>∗</mml:mo>
                    <mml:mtext> Reacall </mml:mtext>
                    <mml:mtext> Presicion </mml:mtext>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext> Reacall </mml:mtext>
                    <mml:mtext> Presicion </mml:mtext>
                    <mml:mo>∗</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p><xref ref-type="fig" rid="fig_4">Figure 4</xref> depicts the metric results for simulation and comparison.</p>
          
            <fig id="fig_4">
              <label>Figure 4</label>
              <caption>
                <title>Comparison of the F1-measure metric</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_0ILP3UVQ0sBoN1mf.png"/>
            </fig>
          
          <p>The results of the simulation, shown in the figure, mean that the suggested method is improved by 12%.</p>
        </sec>
      
      
        <sec>
          
            <title>5.4. Fpr</title>
          
          <p>FPR is one of the significantly important evaluation metrics, and it shows the error rate of the intended method in determining non-correct modes. In other words, this metric shows the error rate for modes that are supposed to be determined as wrong, but the method could not recognize that. The lesser the metric, the better the result. This metric is calculated as follows: <italic>FPR</italic>=<italic>FP</italic>/<italic>N</italic>, where <italic>N</italic> is the total number of non-normal vectors, and <italic>FP</italic> is the number of data recognized wrongly as positive. The simulation was conducted in four phases to evaluate this metric, and the number of data investigated in each phase increased. <xref ref-type="fig" rid="fig_5">Figure 5</xref> depicts the results.</p><p>The simulation result shows that the suggested method performed better, and <xref ref-type="fig" rid="fig_6">Figure 6</xref> depicts the resulting average for all simulation modes.</p>
          
            <fig id="fig_5">
              <label>Figure 5</label>
              <caption>
                <title>FPR metric</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_C6nNRftUMTwmQtK-.png"/>
            </fig>
          
          
            <fig id="fig_6">
              <label>Figure 6</label>
              <caption>
                <title>The mean of FPR</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_zPAEukeJ2LoAwn2c.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>5.5. Frr</title>
          
          <p>This metric is utilized to investigate how wrong the suggested method is in determining normal circumstances, incorrectly reporting non-risky modes as unsafe. This metric shows what percentage of correct modes are incorrectly recognized as incorrect by the recognition system, issuing a wrong warning. This metric is calculated using the following equation: <italic>FRR</italic>=<italic>FN</italic>/<italic>P</italic>, where <italic>P</italic> is the total number of positive data, and <italic>FN</italic> is the number of data to be recognized as negative incorrectly. The lesser the metric, the better the result.</p>
          
            <fig id="fig_7">
              <label>Figure 7</label>
              <caption>
                <title>Comparison result of the FRR metric</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_FBxaIM7uGJ5e2bii.png"/>
            </fig>
          
          <p>Like the previous metric, the simulation was conducted in four phases, and <xref ref-type="fig" rid="fig_7">Figure 7</xref> depicts the results.</p><p>Simulation shows that the suggested method in this metric improved less compared to the two previous methods. <xref ref-type="fig" rid="fig_8">Figure 8</xref> depicts the average of the metric.</p>
          
            <fig id="fig_8">
              <label>Figure 8</label>
              <caption>
                <title>The mean of FRR</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_X-MFBFm1qv67X8je.png"/>
            </fig>
          
        </sec>
      
      
        <sec>
          
            <title>5.6. Accuracy</title>
          
          <p>Classification accuracy is another metric to evaluate classification systems’ performance, providing a more extensive and comprehensive view of their performance. It is defined as the number of correct classifications. Classification accuracy is calculated using the following equation:</p>
          
            <disp-formula>
              <label>(13)</label>
              <mml:math id="mkl4o8c03a">
                <mml:mrow>
                  <mml:mi data-mjx-auto-op="false">Accuracy</mml:mi>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">TN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi data-mjx-auto-op="false">FN</mml:mi>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>+</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
              </mml:math>
            </disp-formula>
          
          <p>The simulation result in the metric shows that the suggested method performed better compared to the previous two methods, and <xref ref-type="fig" rid="fig_9">Figure 9</xref> depicts the mean accuracy of each method.</p>
          
            <fig id="fig_9">
              <label>Figure 9</label>
              <caption>
                <title>Comparison result of the accuracy metric</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_9T6GO8BXHj3rArD9.png"/>
            </fig>
          
          <p>Simulation is one of the crucial parts of scientific research and can be used to prove the performance of the suggested methods. In this section, the method suggested in Section 4 was simulated using MATLAB, analyzed, and compared with the other two available methods based on several important metrics. Simulation results using 10-fold cross-validation and the comparison show that the proposed method performed better in analyzing and predicting behavior and can be used in related settings. <xref ref-type="fig" rid="fig_10">Figure 10</xref> shows the mean accuracy.</p>
          
            <fig id="fig_10">
              <label>Figure 10</label>
              <caption>
                <title>The mean accuracy</title>
              </caption>
              <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://media.acadlore.com/assets/media/2024/11/img_10Pv7DnBYh7Mtw6R.png"/>
            </fig>
          
        </sec>
      
    </sec>
    <sec sec-type="">
      <title>6. Conclusion</title>
      <p>In this study, a new way was proposed to suggest educational services, consisting of users’ feature selection, clustering, and classification. In the first part, fruitful data were utilized for feature selection that possessed value in most records. The presented method was used to investigate which feature is found more frequently statistically to place the final choice. Feature selection helps the suggested algorithm work with valid input data, increasing output accuracy, which is one reason the suggested method is improved during simulations. The clustering technique places identical users in a group to get the aid of similarity to make predictions and increase output accuracy. The main algorithm was based on Bayesian networks, in which a new view of the operation of Bayesian networks was formed.</p><p>In other words, the user can receive the rules by entering the value of the intended parameters at the least time possible. The results show that the proposed model can be used as a service-suggesting system in the educational domain and also has benefits in terms of accuracy and speed compared to other methods. </p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      
    </ack>
    <app-group>
      <app>
        <title>Appendix</title>
        
      </app>
    </app-group>
    <notes>
      <title>Author Contributions</title>
      
    </notes>
    <notes>
      <title>Funding</title>
      
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data used to support the research findings are available from the corresponding author upon request.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="ref_1">
        <label>1.</label>
        <element-citation publication-type="journal">
          <volume>71</volume>
          <page-range>2630-2658</page-range>
          <issue>7</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Adhikari</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bhattacharyya</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Basu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bhattacharya</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1108/ijppm-07-2020-0374</pub-id>
          <article-title>Evaluating the performance of primary schools in India: Evidence from West Bengal</article-title>
          <source>Int. J. Productivity Perform. Manage.</source>
        </element-citation>
      </ref>
      <ref id="ref_2">
        <label>2.</label>
        <element-citation publication-type="journal">
          <volume>2022</volume>
          <page-range>4151487</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Alsariera</surname>
              <given-names>Y. A.</given-names>
            </name>
            <name>
              <surname>Baashar</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Alkawsi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Mustafa</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Alkahtani</surname>
              <given-names>A. A.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>N. A</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2022/4151487</pub-id>
          <article-title>Assessment and evaluation of different machine learning algorithms for predicting student performance</article-title>
          <source>Comput. Intell. Neurosci.</source>
        </element-citation>
      </ref>
      <ref id="ref_3">
        <label>3.</label>
        <element-citation publication-type="journal">
          <volume>2022</volume>
          <page-range>9299115</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Amjad</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Younas</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Anwar</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Shaheen</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Shiraz</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gani</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1155/2022/9299115</pub-id>
          <article-title>Data mining techniques to analyze the impact of social media on academic performance of high school students</article-title>
          <source>Wirel. Commun. Mob. Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_4">
        <label>4.</label>
        <element-citation publication-type="journal">
          <volume>113</volume>
          <page-range>177-194</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Asif</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Merceron</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>S. A.</given-names>
            </name>
            <name>
              <surname>Haider</surname>
              <given-names>N. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.compedu.2017.05.007</pub-id>
          <article-title>Analyzing undergraduate students’ performance using educational data mining</article-title>
          <source>Comput. Educ.</source>
        </element-citation>
      </ref>
      <ref id="ref_5">
        <label>5.</label>
        <element-citation publication-type="journal">
          <volume>8</volume>
          <page-range>216-226</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Bago</surname>
              <given-names>B. A.</given-names>
            </name>
          </person-group>
          <article-title>Effect of single parenthood in students’ academic performance; A case of selected secondary schools in Bitereko Sub County Mitooma District</article-title>
          <source>IAA J. Social Sci. (IAA-JSS)</source>
        </element-citation>
      </ref>
      <ref id="ref_6">
        <label>6.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>87-94</page-range>
          <issue>2</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Chansamut</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/riej.2021.285518.1225</pub-id>
          <article-title>Information system model for educational management in supply chain for Thai higher education institutions</article-title>
          <source>Int. J Res. Ind. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_7">
        <label>7.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>142-152</page-range>
          <year>2017</year>
          <publisher-name>Lausanne: Springer International Publishing</publisher-name>
          <person-group person-group-type="author">
            <name>
              <surname>Chuan</surname>
              <given-names>Y. Y.</given-names>
            </name>
            <name>
              <surname>Husain</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Shahiri</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>An exploratory study on students’ performance classification using hybrid of decision tree and naïve Bayes approaches</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_8">
        <label>8.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>91-95</page-range>
          <year>2016</year>
          <publisher-name>Ernakulam, India</publisher-name>
          <person-group person-group-type="author">
            <name>
              <surname>Devasia</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Vinushree</surname>
              <given-names>T. P.</given-names>
            </name>
            <name>
              <surname>Hegde</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Prediction of students performance using educational data mining</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_9">
        <label>9.</label>
        <element-citation publication-type="journal">
          <volume>5</volume>
          <page-range>15991-16005</page-range>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Dutt</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ismail</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Herawan</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/access.2017.2654247</pub-id>
          <article-title>A systematic review on educational data mining</article-title>
          <source>IEEE Access</source>
        </element-citation>
      </ref>
      <ref id="ref_10">
        <label>10.</label>
        <element-citation publication-type="journal">
          <page-range>15843</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Ebeling</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Atek</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Edge</surname>
              <given-names>A. C.</given-names>
            </name>
            <name>
              <surname>Kaiser</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kneib</surname>
              <given-names>J. P. R.</given-names>
            </name>
            <name>
              <surname>Limousin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>McPartland</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Repp</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Richard</surname>
              <given-names>J. P.</given-names>
            </name>
            <name>
              <surname>Toft</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Beyond MACS: A snapshot survey of the most massive clusters of galaxies at z= 0.5-1</article-title>
          <source>HST Proposal</source>
        </element-citation>
      </ref>
      <ref id="ref_11">
        <label>11.</label>
        <element-citation publication-type="journal">
          <volume>43</volume>
          <page-range>162</page-range>
          <issue>6</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Francis</surname>
              <given-names>B. K.</given-names>
            </name>
            <name>
              <surname>Babu</surname>
              <given-names>S. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s10916-019-1295-4</pub-id>
          <article-title>Predicting academic performance of students using a hybrid data mining approach</article-title>
          <source>J. Med. Syst.</source>
        </element-citation>
      </ref>
      <ref id="ref_12">
        <label>12.</label>
        <element-citation publication-type="journal">
          <volume>51</volume>
          <page-range>2508-2528</page-range>
          <issue>8</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gardas</surname>
              <given-names>B. B.</given-names>
            </name>
            <name>
              <surname>Navimipour</surname>
              <given-names>N. J.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1108/k-10-2020-0713</pub-id>
          <article-title>Performance evaluation of higher education system amid COVID-19: A threat or an opportunity?</article-title>
          <source>Kybernetes</source>
        </element-citation>
      </ref>
      <ref id="ref_13">
        <label>13.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>399-413</page-range>
          <year>2023</year>
          <publisher-name>Singapore: Springer Nature Singapore</publisher-name>
          <person-group person-group-type="author">
            <name>
              <surname>Gonçalves</surname>
              <given-names>M. J. A.</given-names>
            </name>
            <name>
              <surname>Tavares</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Terra</surname>
              <given-names>A. L.</given-names>
            </name>
            <name>
              <surname>Moreira da Silva</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bernardes</surname>
              <given-names>Ó.</given-names>
            </name>
            <name>
              <surname>Valente</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Lopes</surname>
              <given-names>I. C.</given-names>
            </name>
          </person-group>
          <article-title>Digital tools and methods to enhance learning: The digitools project</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_14">
        <label>14.</label>
        <element-citation publication-type="journal">
          <volume>80</volume>
          <page-range>101173</page-range>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Gul</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Yucesan</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.seps.2021.101173</pub-id>
          <article-title>Performance evaluation of Turkish Universities by an integrated Bayesian BWM-TOPSIS model</article-title>
          <source>Socio-Econ. Plann. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_15">
        <label>15.</label>
        <element-citation publication-type="journal">
          <volume>15</volume>
          <page-range>1426</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Guzzo</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Caschera</surname>
              <given-names>M. C.</given-names>
            </name>
            <name>
              <surname>Ferri</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Grifoni</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/su15021426</pub-id>
          <article-title>Analysis of the digital educational scenario in Italian high schools during the pandemic: Challenges and emerging tools</article-title>
          <source>Sustainability</source>
        </element-citation>
      </ref>
      <ref id="ref_16">
        <label>16.</label>
        <element-citation publication-type="journal">
          <volume>38</volume>
          <page-range>1657-1673</page-range>
          <issue>6</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Heilporn</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Lakhal</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bélisle</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1111/jcal.12701</pub-id>
          <article-title>Examining effects of instructional strategies on student engagement in blended online courses</article-title>
          <source>J. Comput. Assisted Learn.</source>
        </element-citation>
      </ref>
      <ref id="ref_17">
        <label>17.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>62-76</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Imani</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Abbasi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ahang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Ghaffari</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Mehdi</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/riej.2021.291738.1229</pub-id>
          <article-title>Customer segmentation to identify key customers based on RFM model by using data mining techniques</article-title>
          <source>Int. J. Res. Ind. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_18">
        <label>18.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Leskovec</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rajaraman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ullman</surname>
              <given-names>J. D.</given-names>
            </name>
          </person-group>
          <source>Mining of Massive Data Sets</source>
          <publisher-name>Cambridge, UK, Cambridge University Press</publisher-name>
          <year>2020</year>
        </element-citation>
      </ref>
      <ref id="ref_19">
        <label>19.</label>
        <element-citation publication-type="journal">
          <volume>42</volume>
          <page-range>120-136</page-range>
          <issue>1</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mahboob</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Asif</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Haider</surname>
              <given-names>N. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22581/muet1982.2301.12</pub-id>
          <article-title>Quality enhancement at higher education institutions by early identifying students at risk using data mining</article-title>
          <source>Mehran Univ. Res. J. Eng. Technol.</source>
        </element-citation>
      </ref>
      <ref id="ref_20">
        <label>20.</label>
        <element-citation publication-type="journal">
          <volume>20</volume>
          <page-range>91-109</page-range>
          <issue>2</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Mosharraf</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Taghiyareh</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Alaee</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/1097198x.2017.1321355</pub-id>
          <article-title>Investigating elearning research trends in Iran via automatic semantic network generation</article-title>
          <source>J. Global Inf. Technol. Manage.</source>
        </element-citation>
      </ref>
      <ref id="ref_21">
        <label>21.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>111-127</page-range>
          <issue>3</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Moterased</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sajadi</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Davari</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Zali</surname>
              <given-names>M. R.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/bdcv.2021.142089</pub-id>
          <article-title>Toward prediction of entrepreneurial exit in Iran; A study based on GEM 2008-2019 data and approach of machine learning algorithms</article-title>
          <source>Big Data Comput. Visions</source>
        </element-citation>
      </ref>
      <ref id="ref_22">
        <label>22.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>122-125</page-range>
          <issue>3</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Muniz</surname>
              <given-names>S. M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/cand.2022.161803</pub-id>
          <article-title>Deployment of agriculture 4.0 with the integration of IoT</article-title>
          <source>Comput. Algorithms Numer. Dimensions</source>
        </element-citation>
      </ref>
      <ref id="ref_23">
        <label>23.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>80</page-range>
          <issue>2</issue>
          <year>2023</year>
          <person-group person-group-type="author">
            <name>
              <surname>Qiu</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Sorourkhah</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kausar</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Cagin</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Edalatpanah</surname>
              <given-names>S. A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3390/systems11020080</pub-id>
          <article-title>Simplifying the complexity in the problem of choosing the best private-sector partner</article-title>
          <source>Systems</source>
        </element-citation>
      </ref>
      <ref id="ref_24">
        <label>24.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>141-146</page-range>
          <issue>4</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rathour</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Obradovic</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Tiwari</surname>
              <given-names>S. K.</given-names>
            </name>
            <name>
              <surname>Mishra</surname>
              <given-names>L. N.</given-names>
            </name>
            <name>
              <surname>Mishra</surname>
              <given-names>V. N.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/cand.2022.159701</pub-id>
          <article-title>Visualization method in mathematics classes</article-title>
          <source>Comput. Algorithms Numer. Dimensions</source>
        </element-citation>
      </ref>
      <ref id="ref_25">
        <label>25.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Roiger</surname>
              <given-names>R. J.</given-names>
            </name>
          </person-group>
          <source>Data Mining: A Tutorial-Based Primer</source>
          <publisher-name>Boca Raton, US, Chapman and Hall/CRC</publisher-name>
          <year>2017</year>
        </element-citation>
      </ref>
      <ref id="ref_26">
        <label>26.</label>
        <element-citation publication-type="journal">
          <volume>10</volume>
          <page-range>e1355</page-range>
          <issue>3</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Romero</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Ventura</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1002/widm.1355</pub-id>
          <article-title>Educational data mining and learning analytics: An updated survey</article-title>
          <source>Wiley Interdisciplin. Rev. Data Min. Knowl. Discovery</source>
        </element-citation>
      </ref>
      <ref id="ref_27">
        <label>27.</label>
        <element-citation publication-type="journal">
          <volume>83</volume>
          <page-range>522-527</page-range>
          <year>2013</year>
          <person-group person-group-type="author">
            <name>
              <surname>Rostaminezhad</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Mozayani</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Norozi</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Iziy</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.sbspro.2013.06.100</pub-id>
          <article-title>Factors related to e-learner dropout: Case study of IUST elearning center</article-title>
          <source>Procedia-Social Behav. Sci.</source>
        </element-citation>
      </ref>
      <ref id="ref_28">
        <label>28.</label>
        <element-citation publication-type="journal">
          <volume>2</volume>
          <page-range>61-68</page-range>
          <issue>2</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Saberhoseini</surname>
              <given-names>S. F.</given-names>
            </name>
            <name>
              <surname>Edalatpanah</surname>
              <given-names>S. A.</given-names>
            </name>
            <name>
              <surname>Sorourkhah</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/bdcv.2022.334005.1075</pub-id>
          <article-title>Choosing the best private-sector partner according to the risk factors in neutrosophic environment</article-title>
          <source>Big Data Comput. Visions</source>
        </element-citation>
      </ref>
      <ref id="ref_29">
        <label>29.</label>
        <element-citation publication-type="conference-proceedings">
          <page-range>92-102</page-range>
          <year>2020</year>
          <publisher-name>Switzerland: Springer International Publishing</publisher-name>
          <person-group person-group-type="author">
            <name>
              <surname>Salloum</surname>
              <given-names>S. A.</given-names>
            </name>
            <name>
              <surname>Alshurideh</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Elnagar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shaalan</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Mining in educational data: Review and future directions</article-title>
          <source>, undefined</source>
        </element-citation>
      </ref>
      <ref id="ref_30">
        <label>30.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>134-150</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sharifi</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Khalili Damghani</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Abdi</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Sardar</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/jarie.2021.291175.1343</pub-id>
          <article-title>A hybrid model for predicting bitcoin price using machine learning and metaheuristic algorithms</article-title>
          <source>J. Appl. Res. Ind. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_31">
        <label>31.</label>
        <element-citation publication-type="journal">
          <volume>25</volume>
          <page-range>5933-5942</page-range>
          <issue>12</issue>
          <year>2016</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hao</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Shao</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1109/tip.2016.2616302</pub-id>
          <article-title>Real-time superpixel segmentation by DBSCAN clustering algorithm</article-title>
          <source>IEEE Trans. Image Process.</source>
        </element-citation>
      </ref>
      <ref id="ref_32">
        <label>32.</label>
        <element-citation publication-type="journal">
          <volume>1</volume>
          <page-range>1-6</page-range>
          <issue>1</issue>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Shukla</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Khalilian</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Partouvi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.22105/bdcv.2021.142228</pub-id>
          <article-title>Academic progress monitoring through neural network</article-title>
          <source>Big Data Comput. Visions</source>
        </element-citation>
      </ref>
      <ref id="ref_33">
        <label>33.</label>
        <element-citation publication-type="journal">
          <volume>42</volume>
          <page-range>85-106</page-range>
          <issue>1</issue>
          <year>2017</year>
          <person-group person-group-type="author">
            <name>
              <surname>Slater</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Joksimović</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kovanovic</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Baker</surname>
              <given-names>R. S.</given-names>
            </name>
            <name>
              <surname>Gasevic</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.3102/1076998616666808</pub-id>
          <article-title>Tools for educational data mining: A review</article-title>
          <source>J. Educational Behav. Stat.</source>
        </element-citation>
      </ref>
      <ref id="ref_34">
        <label>34.</label>
        <element-citation publication-type="journal">
          <volume>11</volume>
          <page-range>39-53</page-range>
          <issue>1</issue>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Sorourkhah</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Babaie-Kafaki</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Azar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nikabadi</surname>
              <given-names>M. S.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1080/16168658.2021.1886811</pub-id>
          <article-title>A fuzzy-weighted approach to the problem of selecting the right strategy using the robustness analysis (Case study: Iran automotive industry)</article-title>
          <source>Fuzzy Inf. Eng.</source>
        </element-citation>
      </ref>
      <ref id="ref_35">
        <label>35.</label>
        <element-citation publication-type="journal">
          <volume>103</volume>
          <page-range>107176</page-range>
          <year>2021</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xiao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Tiong</surname>
              <given-names>R. L.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.asoc.2021.107176</pub-id>
          <article-title>Data-driven quantification of public–private partnership experience levels under uncertainty with Bayesian hierarchical model</article-title>
          <source>Appl. Soft Comput.</source>
        </element-citation>
      </ref>
      <ref id="ref_36">
        <label>36.</label>
        <element-citation publication-type="journal">
          <volume>71</volume>
          <page-range>2479-2495</page-range>
          <issue>6</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Wanke</surname>
              <given-names>P. F.</given-names>
            </name>
            <name>
              <surname>Antunes</surname>
              <given-names>J. J.</given-names>
            </name>
            <name>
              <surname>Miano</surname>
              <given-names>V. Y.</given-names>
            </name>
            <name>
              <surname>Couto</surname>
              <given-names>C. L. D.</given-names>
            </name>
            <name>
              <surname>Mixon</surname>
              <given-names>F. G.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1108/ijppm-11-2020-0602</pub-id>
          <article-title>Measuring higher education performance in Brazil: Government indicators of performance vs ideal solution efficiency measures</article-title>
          <source>Int. J. Productivity Perform. Manage.</source>
        </element-citation>
      </ref>
      <ref id="ref_37">
        <label>37.</label>
        <element-citation publication-type="journal">
          <volume>46</volume>
          <page-range>102081</page-range>
          <issue>1</issue>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>White</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>King</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.acalib.2019.102081</pub-id>
          <article-title>Shaping scholarly communication guidance channels to meet the research needs and skills of doctoral students at Kwame Nkrumah University of Science and Technology</article-title>
          <source>J. Academic Librarianship</source>
        </element-citation>
      </ref>
      <ref id="ref_38">
        <label>38.</label>
        <element-citation publication-type="journal">
          <volume>9</volume>
          <page-range>11</page-range>
          <issue>1</issue>
          <year>2022</year>
          <person-group person-group-type="author">
            <name>
              <surname>Yağcı</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1186/s40561-022-00192-z</pub-id>
          <article-title>Educational data mining: Prediction of students’ academic performance using machine learning algorithms</article-title>
          <source>Smart Learn. Env.</source>
        </element-citation>
      </ref>
      <ref id="ref_39">
        <label>39.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Zaki</surname>
              <given-names>M. J.</given-names>
            </name>
            <name>
              <surname>Meira Jr</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Meira</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <source>Data Mining and Machine Learning: Fundamental Concepts and Algorithms</source>
          <publisher-name>Cambridge, UK, Cambridge University Press</publisher-name>
          <year>2020</year>
        </element-citation>
      </ref>
      <ref id="ref_40">
        <label>40.</label>
        <element-citation publication-type="journal">
          <volume>81</volume>
          <page-range>101821</page-range>
          <year>2020</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>Q.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1016/j.evalprogplan.2020.101821</pub-id>
          <article-title>Performance evaluation and enrollment quota allocation for higher education institutions in China</article-title>
          <source>Eval. Program Plann.</source>
        </element-citation>
      </ref>
      <ref id="ref_41">
        <label>41.</label>
        <element-citation publication-type="journal">
          <volume>22</volume>
          <page-range>1189-1219</page-range>
          <year>2019</year>
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <pub-id pub-id-type="doi">10.1007/s11280-018-0559-0</pub-id>
          <article-title>Providing personalized learning guidance in MOOCs by multi-source data analysis</article-title>
          <source>World Wide Web</source>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>